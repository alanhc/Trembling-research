{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "announced-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils.data import *\n",
    "from utils.lstm_rnn import *\n",
    "import os\n",
    "import pandas as pd\n",
    "if not os.path.isdir(\"save\"):\n",
    "    os.mkdir(\"save\")\n",
    "##### config #####\n",
    "save_dataset = False # 儲存dataset，true: 生成dataset、false: 使用save/ 儲存的\n",
    "##### config #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spiritual-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "for i in range(len(physical_devices)):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[i], enable=True)\n",
    "\n",
    "repeat = 100\n",
    "if save_dataset:\n",
    "    X_raw, y = generate_dataset(repeat=repeat)\n",
    "    X = tf.reshape(X_raw, [y.shape[0],3,60])\n",
    "    np.save(\"save/X_raw.npy\", X_raw.numpy())\n",
    "    np.save(\"save/y.npy\", y)\n",
    "else:\n",
    "    X_raw = np.load(\"save/X_raw.npy\")\n",
    "    y = np.load(\"save/y.npy\")\n",
    "\n",
    "X_raw = tf.convert_to_tensor(X_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "general-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 100), (No 64400       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 100)       64400       input_8[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 317,880\n",
      "Trainable params: 317,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3559 - out_1_loss: 3.6809 - out_2_loss: 3.6749 - out_1_acc: 0.0405 - out_2_acc: 0.0570WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117877). Check your callbacks.\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 6.5611 - out_1_loss: 3.4190 - out_2_loss: 3.1421 - out_1_acc: 0.4602 - out_2_acc: 0.4383 - val_loss: 4.8146 - val_out_1_loss: 2.8036 - val_out_2_loss: 2.0110 - val_out_1_acc: 0.4803 - val_out_2_acc: 0.5362\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.8030 - out_1_loss: 1.8121 - out_2_loss: 0.9909 - out_1_acc: 0.6271 - out_2_acc: 0.7960 - val_loss: 1.2871 - val_out_1_loss: 0.9231 - val_out_2_loss: 0.3640 - val_out_1_acc: 0.8148 - val_out_2_acc: 0.9342\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9019 - out_1_loss: 0.6427 - out_2_loss: 0.2593 - out_1_acc: 0.8795 - out_2_acc: 0.9493 - val_loss: 0.6466 - val_out_1_loss: 0.4479 - val_out_2_loss: 0.1987 - val_out_1_acc: 0.9166 - val_out_2_acc: 0.9496\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5387 - out_1_loss: 0.3759 - out_2_loss: 0.1627 - out_1_acc: 0.9230 - out_2_acc: 0.9522 - val_loss: 0.4564 - val_out_1_loss: 0.3065 - val_out_2_loss: 0.1499 - val_out_1_acc: 0.9331 - val_out_2_acc: 0.9506\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3972 - out_1_loss: 0.2673 - out_2_loss: 0.1299 - out_1_acc: 0.9363 - out_2_acc: 0.9521 - val_loss: 0.3564 - val_out_1_loss: 0.2304 - val_out_2_loss: 0.1260 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9508\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3155 - out_1_loss: 0.2032 - out_2_loss: 0.1123 - out_1_acc: 0.9391 - out_2_acc: 0.9523 - val_loss: 0.2967 - val_out_1_loss: 0.1834 - val_out_2_loss: 0.1133 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9502\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2658 - out_1_loss: 0.1634 - out_2_loss: 0.1024 - out_1_acc: 0.9396 - out_2_acc: 0.9527 - val_loss: 0.2622 - val_out_1_loss: 0.1565 - val_out_2_loss: 0.1057 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9502\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2379 - out_1_loss: 0.1415 - out_2_loss: 0.0963 - out_1_acc: 0.9403 - out_2_acc: 0.9530 - val_loss: 0.2426 - val_out_1_loss: 0.1420 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9512\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2226 - out_1_loss: 0.1303 - out_2_loss: 0.0923 - out_1_acc: 0.9403 - out_2_acc: 0.9532 - val_loss: 0.2309 - val_out_1_loss: 0.1338 - val_out_2_loss: 0.0970 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2132 - out_1_loss: 0.1237 - out_2_loss: 0.0895 - out_1_acc: 0.9406 - out_2_acc: 0.9534 - val_loss: 0.2235 - val_out_1_loss: 0.1287 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9521\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2068 - out_1_loss: 0.1193 - out_2_loss: 0.0876 - out_1_acc: 0.9413 - out_2_acc: 0.9538 - val_loss: 0.2183 - val_out_1_loss: 0.1250 - val_out_2_loss: 0.0933 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9525\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2021 - out_1_loss: 0.1159 - out_2_loss: 0.0862 - out_1_acc: 0.9417 - out_2_acc: 0.9542 - val_loss: 0.2144 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9528\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1983 - out_1_loss: 0.1133 - out_2_loss: 0.0851 - out_1_acc: 0.9419 - out_2_acc: 0.9546 - val_loss: 0.2113 - val_out_1_loss: 0.1199 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9531\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1953 - out_1_loss: 0.1111 - out_2_loss: 0.0842 - out_1_acc: 0.9421 - out_2_acc: 0.9546 - val_loss: 0.2089 - val_out_1_loss: 0.1180 - val_out_2_loss: 0.0909 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9527\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1929 - out_1_loss: 0.1094 - out_2_loss: 0.0835 - out_1_acc: 0.9420 - out_2_acc: 0.9544 - val_loss: 0.2069 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.0905 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9527\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1909 - out_1_loss: 0.1080 - out_2_loss: 0.0829 - out_1_acc: 0.9422 - out_2_acc: 0.9545 - val_loss: 0.2052 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9524\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1893 - out_1_loss: 0.1068 - out_2_loss: 0.0825 - out_1_acc: 0.9421 - out_2_acc: 0.9547 - val_loss: 0.2036 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.0901 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9520\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1878 - out_1_loss: 0.1057 - out_2_loss: 0.0820 - out_1_acc: 0.9422 - out_2_acc: 0.9548 - val_loss: 0.2022 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9517\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1864 - out_1_loss: 0.1047 - out_2_loss: 0.0817 - out_1_acc: 0.9422 - out_2_acc: 0.9549 - val_loss: 0.2012 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9514\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1850 - out_1_loss: 0.1037 - out_2_loss: 0.0813 - out_1_acc: 0.9424 - out_2_acc: 0.9551 - val_loss: 0.2003 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9517\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1838 - out_1_loss: 0.1028 - out_2_loss: 0.0809 - out_1_acc: 0.9426 - out_2_acc: 0.9549 - val_loss: 0.1997 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9516\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1826 - out_1_loss: 0.1021 - out_2_loss: 0.0806 - out_1_acc: 0.9428 - out_2_acc: 0.9553 - val_loss: 0.1992 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9520\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1816 - out_1_loss: 0.1013 - out_2_loss: 0.0802 - out_1_acc: 0.9431 - out_2_acc: 0.9555 - val_loss: 0.1989 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9518\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1806 - out_1_loss: 0.1007 - out_2_loss: 0.0799 - out_1_acc: 0.9434 - out_2_acc: 0.9558 - val_loss: 0.1985 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9518\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1796 - out_1_loss: 0.1001 - out_2_loss: 0.0795 - out_1_acc: 0.9435 - out_2_acc: 0.9563 - val_loss: 0.1984 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9516\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1788 - out_1_loss: 0.0996 - out_2_loss: 0.0791 - out_1_acc: 0.9437 - out_2_acc: 0.9562 - val_loss: 0.1982 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9521\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1779 - out_1_loss: 0.0991 - out_2_loss: 0.0788 - out_1_acc: 0.9439 - out_2_acc: 0.9566 - val_loss: 0.1982 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0901 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1771 - out_1_loss: 0.0987 - out_2_loss: 0.0784 - out_1_acc: 0.9439 - out_2_acc: 0.9567 - val_loss: 0.1980 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0902 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1762 - out_1_loss: 0.0982 - out_2_loss: 0.0780 - out_1_acc: 0.9440 - out_2_acc: 0.9571 - val_loss: 0.1980 - val_out_1_loss: 0.1077 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1754 - out_1_loss: 0.0978 - out_2_loss: 0.0776 - out_1_acc: 0.9443 - out_2_acc: 0.9572 - val_loss: 0.1981 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.0905 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1745 - out_1_loss: 0.0974 - out_2_loss: 0.0771 - out_1_acc: 0.9445 - out_2_acc: 0.9577 - val_loss: 0.1981 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1737 - out_1_loss: 0.0970 - out_2_loss: 0.0767 - out_1_acc: 0.9446 - out_2_acc: 0.9577 - val_loss: 0.1984 - val_out_1_loss: 0.1075 - val_out_2_loss: 0.0909 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9522\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1729 - out_1_loss: 0.0966 - out_2_loss: 0.0762 - out_1_acc: 0.9448 - out_2_acc: 0.9581 - val_loss: 0.1986 - val_out_1_loss: 0.1074 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1720 - out_1_loss: 0.0963 - out_2_loss: 0.0757 - out_1_acc: 0.9452 - out_2_acc: 0.9585 - val_loss: 0.1988 - val_out_1_loss: 0.1075 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1711 - out_1_loss: 0.0959 - out_2_loss: 0.0752 - out_1_acc: 0.9454 - out_2_acc: 0.9586 - val_loss: 0.1991 - val_out_1_loss: 0.1075 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9522\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1702 - out_1_loss: 0.0955 - out_2_loss: 0.0747 - out_1_acc: 0.9456 - out_2_acc: 0.9591 - val_loss: 0.1995 - val_out_1_loss: 0.1075 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1692 - out_1_loss: 0.0952 - out_2_loss: 0.0741 - out_1_acc: 0.9458 - out_2_acc: 0.9594 - val_loss: 0.2001 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.0925 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1684 - out_1_loss: 0.0948 - out_2_loss: 0.0736 - out_1_acc: 0.9459 - out_2_acc: 0.9595 - val_loss: 0.2004 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9527\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1672 - out_1_loss: 0.0944 - out_2_loss: 0.0728 - out_1_acc: 0.9463 - out_2_acc: 0.9601 - val_loss: 0.2009 - val_out_1_loss: 0.1077 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1663 - out_1_loss: 0.0941 - out_2_loss: 0.0722 - out_1_acc: 0.9464 - out_2_acc: 0.9603 - val_loss: 0.2013 - val_out_1_loss: 0.1077 - val_out_2_loss: 0.0935 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9524\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1652 - out_1_loss: 0.0937 - out_2_loss: 0.0715 - out_1_acc: 0.9467 - out_2_acc: 0.9608 - val_loss: 0.2018 - val_out_1_loss: 0.1078 - val_out_2_loss: 0.0939 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9525\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1641 - out_1_loss: 0.0933 - out_2_loss: 0.0708 - out_1_acc: 0.9470 - out_2_acc: 0.9610 - val_loss: 0.2024 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0944 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9521\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1630 - out_1_loss: 0.0930 - out_2_loss: 0.0700 - out_1_acc: 0.9470 - out_2_acc: 0.9616 - val_loss: 0.2030 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1620 - out_1_loss: 0.0926 - out_2_loss: 0.0694 - out_1_acc: 0.9474 - out_2_acc: 0.9618 - val_loss: 0.2036 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1608 - out_1_loss: 0.0922 - out_2_loss: 0.0686 - out_1_acc: 0.9476 - out_2_acc: 0.9620 - val_loss: 0.2041 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9519\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1597 - out_1_loss: 0.0918 - out_2_loss: 0.0679 - out_1_acc: 0.9479 - out_2_acc: 0.9626 - val_loss: 0.2049 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9520\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1584 - out_1_loss: 0.0914 - out_2_loss: 0.0671 - out_1_acc: 0.9482 - out_2_acc: 0.9631 - val_loss: 0.2059 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9528\n",
      "Epoch 48/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1573 - out_1_loss: 0.0909 - out_2_loss: 0.0663 - out_1_acc: 0.9484 - out_2_acc: 0.9633 - val_loss: 0.2061 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9526\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1560 - out_1_loss: 0.0906 - out_2_loss: 0.0655 - out_1_acc: 0.9487 - out_2_acc: 0.9638 - val_loss: 0.2071 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1549 - out_1_loss: 0.0902 - out_2_loss: 0.0647 - out_1_acc: 0.9489 - out_2_acc: 0.9646 - val_loss: 0.2079 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9514\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1536 - out_1_loss: 0.0898 - out_2_loss: 0.0638 - out_1_acc: 0.9492 - out_2_acc: 0.9647 - val_loss: 0.2089 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9520\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1523 - out_1_loss: 0.0894 - out_2_loss: 0.0630 - out_1_acc: 0.9494 - out_2_acc: 0.9656 - val_loss: 0.2091 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9523\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1509 - out_1_loss: 0.0889 - out_2_loss: 0.0619 - out_1_acc: 0.9498 - out_2_acc: 0.9662 - val_loss: 0.2103 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.1005 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9515\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1497 - out_1_loss: 0.0885 - out_2_loss: 0.0612 - out_1_acc: 0.9500 - out_2_acc: 0.9665 - val_loss: 0.2114 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1014 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9518\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1483 - out_1_loss: 0.0880 - out_2_loss: 0.0602 - out_1_acc: 0.9506 - out_2_acc: 0.9669 - val_loss: 0.2127 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9525\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1469 - out_1_loss: 0.0876 - out_2_loss: 0.0594 - out_1_acc: 0.9508 - out_2_acc: 0.9673 - val_loss: 0.2141 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1457 - out_1_loss: 0.0871 - out_2_loss: 0.0585 - out_1_acc: 0.9510 - out_2_acc: 0.9678 - val_loss: 0.2157 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1047 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1446 - out_1_loss: 0.0867 - out_2_loss: 0.0580 - out_1_acc: 0.9514 - out_2_acc: 0.9682 - val_loss: 0.2169 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.1058 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9517\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1433 - out_1_loss: 0.0862 - out_2_loss: 0.0572 - out_1_acc: 0.9516 - out_2_acc: 0.9685 - val_loss: 0.2187 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9525\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1422 - out_1_loss: 0.0857 - out_2_loss: 0.0565 - out_1_acc: 0.9519 - out_2_acc: 0.9685 - val_loss: 0.2205 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.1086 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9530\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1409 - out_1_loss: 0.0852 - out_2_loss: 0.0557 - out_1_acc: 0.9523 - out_2_acc: 0.9693 - val_loss: 0.2234 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1112 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1398 - out_1_loss: 0.0847 - out_2_loss: 0.0551 - out_1_acc: 0.9525 - out_2_acc: 0.9693 - val_loss: 0.2268 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.1141 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9528\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1391 - out_1_loss: 0.0842 - out_2_loss: 0.0548 - out_1_acc: 0.9527 - out_2_acc: 0.9696 - val_loss: 0.2290 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1157 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9528\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1387 - out_1_loss: 0.0838 - out_2_loss: 0.0548 - out_1_acc: 0.9531 - out_2_acc: 0.9695 - val_loss: 0.2279 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.1144 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9520\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1378 - out_1_loss: 0.0834 - out_2_loss: 0.0544 - out_1_acc: 0.9536 - out_2_acc: 0.9700 - val_loss: 0.2297 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.1156 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1359 - out_1_loss: 0.0829 - out_2_loss: 0.0531 - out_1_acc: 0.9541 - out_2_acc: 0.9706 - val_loss: 0.2299 - val_out_1_loss: 0.1143 - val_out_2_loss: 0.1156 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1342 - out_1_loss: 0.0823 - out_2_loss: 0.0519 - out_1_acc: 0.9544 - out_2_acc: 0.9712 - val_loss: 0.2324 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1179 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9526\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1331 - out_1_loss: 0.0818 - out_2_loss: 0.0514 - out_1_acc: 0.9545 - out_2_acc: 0.9713 - val_loss: 0.2351 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1200 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1322 - out_1_loss: 0.0813 - out_2_loss: 0.0510 - out_1_acc: 0.9549 - out_2_acc: 0.9714 - val_loss: 0.2378 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1223 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1313 - out_1_loss: 0.0808 - out_2_loss: 0.0504 - out_1_acc: 0.9554 - out_2_acc: 0.9714 - val_loss: 0.2396 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.1238 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1298 - out_1_loss: 0.0802 - out_2_loss: 0.0496 - out_1_acc: 0.9558 - out_2_acc: 0.9723 - val_loss: 0.2397 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1237 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1287 - out_1_loss: 0.0797 - out_2_loss: 0.0491 - out_1_acc: 0.9562 - out_2_acc: 0.9723 - val_loss: 0.2413 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1244 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1277 - out_1_loss: 0.0792 - out_2_loss: 0.0485 - out_1_acc: 0.9563 - out_2_acc: 0.9726 - val_loss: 0.2444 - val_out_1_loss: 0.1173 - val_out_2_loss: 0.1271 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1268 - out_1_loss: 0.0787 - out_2_loss: 0.0482 - out_1_acc: 0.9567 - out_2_acc: 0.9729 - val_loss: 0.2471 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1261 - out_1_loss: 0.0783 - out_2_loss: 0.0478 - out_1_acc: 0.9569 - out_2_acc: 0.9732 - val_loss: 0.2482 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9525\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1251 - out_1_loss: 0.0777 - out_2_loss: 0.0474 - out_1_acc: 0.9573 - out_2_acc: 0.9736 - val_loss: 0.2508 - val_out_1_loss: 0.1190 - val_out_2_loss: 0.1318 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1246 - out_1_loss: 0.0773 - out_2_loss: 0.0474 - out_1_acc: 0.9577 - out_2_acc: 0.9734 - val_loss: 0.2522 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1327 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1234 - out_1_loss: 0.0768 - out_2_loss: 0.0466 - out_1_acc: 0.9581 - out_2_acc: 0.9740 - val_loss: 0.2537 - val_out_1_loss: 0.1200 - val_out_2_loss: 0.1337 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9527\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1230 - out_1_loss: 0.0762 - out_2_loss: 0.0467 - out_1_acc: 0.9583 - out_2_acc: 0.9738 - val_loss: 0.2559 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1352 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1221 - out_1_loss: 0.0758 - out_2_loss: 0.0463 - out_1_acc: 0.9588 - out_2_acc: 0.9738 - val_loss: 0.2578 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1365 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9519\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1214 - out_1_loss: 0.0753 - out_2_loss: 0.0460 - out_1_acc: 0.9588 - out_2_acc: 0.9740 - val_loss: 0.2590 - val_out_1_loss: 0.1219 - val_out_2_loss: 0.1370 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1204 - out_1_loss: 0.0749 - out_2_loss: 0.0456 - out_1_acc: 0.9596 - out_2_acc: 0.9748 - val_loss: 0.2615 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.1389 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1197 - out_1_loss: 0.0744 - out_2_loss: 0.0453 - out_1_acc: 0.9599 - out_2_acc: 0.9747 - val_loss: 0.2631 - val_out_1_loss: 0.1234 - val_out_2_loss: 0.1397 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9526\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1190 - out_1_loss: 0.0738 - out_2_loss: 0.0452 - out_1_acc: 0.9601 - out_2_acc: 0.9749 - val_loss: 0.2658 - val_out_1_loss: 0.1243 - val_out_2_loss: 0.1416 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1189 - out_1_loss: 0.0735 - out_2_loss: 0.0453 - out_1_acc: 0.9602 - out_2_acc: 0.9747 - val_loss: 0.2661 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.1415 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1174 - out_1_loss: 0.0729 - out_2_loss: 0.0445 - out_1_acc: 0.9606 - out_2_acc: 0.9754 - val_loss: 0.2695 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1172 - out_1_loss: 0.0726 - out_2_loss: 0.0445 - out_1_acc: 0.9609 - out_2_acc: 0.9756 - val_loss: 0.2707 - val_out_1_loss: 0.1265 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9521\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1163 - out_1_loss: 0.0722 - out_2_loss: 0.0441 - out_1_acc: 0.9611 - out_2_acc: 0.9759 - val_loss: 0.2740 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1468 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1154 - out_1_loss: 0.0717 - out_2_loss: 0.0437 - out_1_acc: 0.9614 - out_2_acc: 0.9762 - val_loss: 0.2760 - val_out_1_loss: 0.1281 - val_out_2_loss: 0.1479 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1144 - out_1_loss: 0.0712 - out_2_loss: 0.0432 - out_1_acc: 0.9615 - out_2_acc: 0.9765 - val_loss: 0.2787 - val_out_1_loss: 0.1287 - val_out_2_loss: 0.1500 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1138 - out_1_loss: 0.0707 - out_2_loss: 0.0430 - out_1_acc: 0.9622 - out_2_acc: 0.9766 - val_loss: 0.2810 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1517 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1128 - out_1_loss: 0.0703 - out_2_loss: 0.0426 - out_1_acc: 0.9624 - out_2_acc: 0.9769 - val_loss: 0.2847 - val_out_1_loss: 0.1301 - val_out_2_loss: 0.1546 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1121 - out_1_loss: 0.0697 - out_2_loss: 0.0423 - out_1_acc: 0.9627 - out_2_acc: 0.9777 - val_loss: 0.2868 - val_out_1_loss: 0.1306 - val_out_2_loss: 0.1562 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1117 - out_1_loss: 0.0694 - out_2_loss: 0.0423 - out_1_acc: 0.9629 - out_2_acc: 0.9775 - val_loss: 0.2897 - val_out_1_loss: 0.1320 - val_out_2_loss: 0.1578 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1115 - out_1_loss: 0.0691 - out_2_loss: 0.0424 - out_1_acc: 0.9628 - out_2_acc: 0.9772 - val_loss: 0.2897 - val_out_1_loss: 0.1325 - val_out_2_loss: 0.1573 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1103 - out_1_loss: 0.0685 - out_2_loss: 0.0418 - out_1_acc: 0.9631 - out_2_acc: 0.9776 - val_loss: 0.2929 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1599 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1090 - out_1_loss: 0.0680 - out_2_loss: 0.0410 - out_1_acc: 0.9640 - out_2_acc: 0.9787 - val_loss: 0.2917 - val_out_1_loss: 0.1336 - val_out_2_loss: 0.1581 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1084 - out_1_loss: 0.0676 - out_2_loss: 0.0408 - out_1_acc: 0.9640 - out_2_acc: 0.9787 - val_loss: 0.2952 - val_out_1_loss: 0.1343 - val_out_2_loss: 0.1609 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9514\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1076 - out_1_loss: 0.0671 - out_2_loss: 0.0404 - out_1_acc: 0.9645 - out_2_acc: 0.9786 - val_loss: 0.2957 - val_out_1_loss: 0.1349 - val_out_2_loss: 0.1609 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1071 - out_1_loss: 0.0666 - out_2_loss: 0.0404 - out_1_acc: 0.9649 - out_2_acc: 0.9785 - val_loss: 0.2984 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1629 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1066 - out_1_loss: 0.0663 - out_2_loss: 0.0404 - out_1_acc: 0.9653 - out_2_acc: 0.9784 - val_loss: 0.3000 - val_out_1_loss: 0.1361 - val_out_2_loss: 0.1639 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9522\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1062 - out_1_loss: 0.0660 - out_2_loss: 0.0402 - out_1_acc: 0.9653 - out_2_acc: 0.9787 - val_loss: 0.3001 - val_out_1_loss: 0.1369 - val_out_2_loss: 0.1631 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1059 - out_1_loss: 0.0656 - out_2_loss: 0.0404 - out_1_acc: 0.9656 - out_2_acc: 0.9783 - val_loss: 0.3012 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1640 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1044 - out_1_loss: 0.0650 - out_2_loss: 0.0395 - out_1_acc: 0.9659 - out_2_acc: 0.9791 - val_loss: 0.3028 - val_out_1_loss: 0.1379 - val_out_2_loss: 0.1650 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1033 - out_1_loss: 0.0645 - out_2_loss: 0.0388 - out_1_acc: 0.9663 - out_2_acc: 0.9799 - val_loss: 0.3044 - val_out_1_loss: 0.1384 - val_out_2_loss: 0.1661 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9527\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1028 - out_1_loss: 0.0643 - out_2_loss: 0.0385 - out_1_acc: 0.9663 - out_2_acc: 0.9799 - val_loss: 0.3080 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1687 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9524\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1019 - out_1_loss: 0.0639 - out_2_loss: 0.0380 - out_1_acc: 0.9667 - out_2_acc: 0.9803 - val_loss: 0.3094 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1690 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9527\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1007 - out_1_loss: 0.0633 - out_2_loss: 0.0374 - out_1_acc: 0.9670 - out_2_acc: 0.9808 - val_loss: 0.3114 - val_out_1_loss: 0.1410 - val_out_2_loss: 0.1704 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1011 - out_1_loss: 0.0629 - out_2_loss: 0.0382 - out_1_acc: 0.9674 - out_2_acc: 0.9802 - val_loss: 0.3110 - val_out_1_loss: 0.1420 - val_out_2_loss: 0.1690 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9517\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1007 - out_1_loss: 0.0626 - out_2_loss: 0.0380 - out_1_acc: 0.9672 - out_2_acc: 0.9804 - val_loss: 0.3145 - val_out_1_loss: 0.1425 - val_out_2_loss: 0.1719 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1018 - out_1_loss: 0.0627 - out_2_loss: 0.0391 - out_1_acc: 0.9673 - out_2_acc: 0.9798 - val_loss: 0.3127 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1693 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9515\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1001 - out_1_loss: 0.0622 - out_2_loss: 0.0379 - out_1_acc: 0.9676 - out_2_acc: 0.9804 - val_loss: 0.3175 - val_out_1_loss: 0.1434 - val_out_2_loss: 0.1741 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9522\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1003 - out_1_loss: 0.0620 - out_2_loss: 0.0383 - out_1_acc: 0.9679 - out_2_acc: 0.9800 - val_loss: 0.3162 - val_out_1_loss: 0.1440 - val_out_2_loss: 0.1722 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9519\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0996 - out_1_loss: 0.0617 - out_2_loss: 0.0378 - out_1_acc: 0.9680 - out_2_acc: 0.9805 - val_loss: 0.3189 - val_out_1_loss: 0.1450 - val_out_2_loss: 0.1738 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0992 - out_1_loss: 0.0613 - out_2_loss: 0.0379 - out_1_acc: 0.9683 - out_2_acc: 0.9804 - val_loss: 0.3172 - val_out_1_loss: 0.1450 - val_out_2_loss: 0.1722 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0977 - out_1_loss: 0.0608 - out_2_loss: 0.0370 - out_1_acc: 0.9688 - out_2_acc: 0.9809 - val_loss: 0.3248 - val_out_1_loss: 0.1461 - val_out_2_loss: 0.1786 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0982 - out_1_loss: 0.0604 - out_2_loss: 0.0377 - out_1_acc: 0.9688 - out_2_acc: 0.9803 - val_loss: 0.3248 - val_out_1_loss: 0.1469 - val_out_2_loss: 0.1779 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9529\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0970 - out_1_loss: 0.0602 - out_2_loss: 0.0367 - out_1_acc: 0.9685 - out_2_acc: 0.9813 - val_loss: 0.3240 - val_out_1_loss: 0.1475 - val_out_2_loss: 0.1765 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9534\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0963 - out_1_loss: 0.0595 - out_2_loss: 0.0368 - out_1_acc: 0.9689 - out_2_acc: 0.9810 - val_loss: 0.3282 - val_out_1_loss: 0.1488 - val_out_2_loss: 0.1794 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0951 - out_1_loss: 0.0591 - out_2_loss: 0.0360 - out_1_acc: 0.9694 - out_2_acc: 0.9818 - val_loss: 0.3289 - val_out_1_loss: 0.1504 - val_out_2_loss: 0.1786 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9520\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0961 - out_1_loss: 0.0593 - out_2_loss: 0.0368 - out_1_acc: 0.9691 - out_2_acc: 0.9812 - val_loss: 0.3332 - val_out_1_loss: 0.1517 - val_out_2_loss: 0.1815 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9523\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0948 - out_1_loss: 0.0591 - out_2_loss: 0.0357 - out_1_acc: 0.9692 - out_2_acc: 0.9819 - val_loss: 0.3351 - val_out_1_loss: 0.1527 - val_out_2_loss: 0.1825 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9526\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0948 - out_1_loss: 0.0589 - out_2_loss: 0.0359 - out_1_acc: 0.9691 - out_2_acc: 0.9820 - val_loss: 0.3320 - val_out_1_loss: 0.1537 - val_out_2_loss: 0.1784 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0952 - out_1_loss: 0.0589 - out_2_loss: 0.0363 - out_1_acc: 0.9693 - out_2_acc: 0.9816 - val_loss: 0.3351 - val_out_1_loss: 0.1552 - val_out_2_loss: 0.1798 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9525\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0939 - out_1_loss: 0.0585 - out_2_loss: 0.0355 - out_1_acc: 0.9694 - out_2_acc: 0.9819 - val_loss: 0.3338 - val_out_1_loss: 0.1549 - val_out_2_loss: 0.1789 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9526\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0946 - out_1_loss: 0.0583 - out_2_loss: 0.0363 - out_1_acc: 0.9700 - out_2_acc: 0.9818 - val_loss: 0.3376 - val_out_1_loss: 0.1571 - val_out_2_loss: 0.1805 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0946 - out_1_loss: 0.0586 - out_2_loss: 0.0360 - out_1_acc: 0.9696 - out_2_acc: 0.9820 - val_loss: 0.3362 - val_out_1_loss: 0.1572 - val_out_2_loss: 0.1790 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9537\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0962 - out_1_loss: 0.0589 - out_2_loss: 0.0373 - out_1_acc: 0.9692 - out_2_acc: 0.9811 - val_loss: 0.3388 - val_out_1_loss: 0.1574 - val_out_2_loss: 0.1813 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0967 - out_1_loss: 0.0587 - out_2_loss: 0.0380 - out_1_acc: 0.9694 - out_2_acc: 0.9810 - val_loss: 0.3372 - val_out_1_loss: 0.1559 - val_out_2_loss: 0.1813 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9531\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0951 - out_1_loss: 0.0583 - out_2_loss: 0.0367 - out_1_acc: 0.9694 - out_2_acc: 0.9812 - val_loss: 0.3359 - val_out_1_loss: 0.1561 - val_out_2_loss: 0.1798 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0927 - out_1_loss: 0.0572 - out_2_loss: 0.0355 - out_1_acc: 0.9700 - out_2_acc: 0.9822 - val_loss: 0.3395 - val_out_1_loss: 0.1566 - val_out_2_loss: 0.1829 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0921 - out_1_loss: 0.0567 - out_2_loss: 0.0354 - out_1_acc: 0.9708 - out_2_acc: 0.9822 - val_loss: 0.3396 - val_out_1_loss: 0.1571 - val_out_2_loss: 0.1825 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0905 - out_1_loss: 0.0561 - out_2_loss: 0.0343 - out_1_acc: 0.9711 - out_2_acc: 0.9829 - val_loss: 0.3427 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1845 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0900 - out_1_loss: 0.0561 - out_2_loss: 0.0339 - out_1_acc: 0.9711 - out_2_acc: 0.9834 - val_loss: 0.3460 - val_out_1_loss: 0.1592 - val_out_2_loss: 0.1867 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 135/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0895 - out_1_loss: 0.0556 - out_2_loss: 0.0339 - out_1_acc: 0.9713 - out_2_acc: 0.9833 - val_loss: 0.3437 - val_out_1_loss: 0.1592 - val_out_2_loss: 0.1845 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0878 - out_1_loss: 0.0549 - out_2_loss: 0.0329 - out_1_acc: 0.9718 - out_2_acc: 0.9837 - val_loss: 0.3503 - val_out_1_loss: 0.1613 - val_out_2_loss: 0.1891 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9518\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0882 - out_1_loss: 0.0550 - out_2_loss: 0.0331 - out_1_acc: 0.9717 - out_2_acc: 0.9835 - val_loss: 0.3510 - val_out_1_loss: 0.1611 - val_out_2_loss: 0.1898 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0860 - out_1_loss: 0.0544 - out_2_loss: 0.0317 - out_1_acc: 0.9720 - out_2_acc: 0.9848 - val_loss: 0.3526 - val_out_1_loss: 0.1622 - val_out_2_loss: 0.1904 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9519\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0868 - out_1_loss: 0.0544 - out_2_loss: 0.0324 - out_1_acc: 0.9718 - out_2_acc: 0.9845 - val_loss: 0.3536 - val_out_1_loss: 0.1631 - val_out_2_loss: 0.1904 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0864 - out_1_loss: 0.0541 - out_2_loss: 0.0324 - out_1_acc: 0.9720 - out_2_acc: 0.9841 - val_loss: 0.3543 - val_out_1_loss: 0.1643 - val_out_2_loss: 0.1900 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0851 - out_1_loss: 0.0537 - out_2_loss: 0.0315 - out_1_acc: 0.9727 - out_2_acc: 0.9845 - val_loss: 0.3584 - val_out_1_loss: 0.1652 - val_out_2_loss: 0.1932 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9534\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0840 - out_1_loss: 0.0533 - out_2_loss: 0.0307 - out_1_acc: 0.9728 - out_2_acc: 0.9851 - val_loss: 0.3617 - val_out_1_loss: 0.1663 - val_out_2_loss: 0.1954 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0840 - out_1_loss: 0.0533 - out_2_loss: 0.0307 - out_1_acc: 0.9726 - out_2_acc: 0.9851 - val_loss: 0.3627 - val_out_1_loss: 0.1665 - val_out_2_loss: 0.1963 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9529\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0836 - out_1_loss: 0.0530 - out_2_loss: 0.0305 - out_1_acc: 0.9731 - out_2_acc: 0.9852 - val_loss: 0.3668 - val_out_1_loss: 0.1674 - val_out_2_loss: 0.1995 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0828 - out_1_loss: 0.0527 - out_2_loss: 0.0301 - out_1_acc: 0.9731 - out_2_acc: 0.9854 - val_loss: 0.3687 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1999 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0825 - out_1_loss: 0.0526 - out_2_loss: 0.0299 - out_1_acc: 0.9731 - out_2_acc: 0.9856 - val_loss: 0.3692 - val_out_1_loss: 0.1698 - val_out_2_loss: 0.1994 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0809 - out_1_loss: 0.0519 - out_2_loss: 0.0290 - out_1_acc: 0.9738 - out_2_acc: 0.9866 - val_loss: 0.3704 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.2013 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0798 - out_1_loss: 0.0514 - out_2_loss: 0.0284 - out_1_acc: 0.9740 - out_2_acc: 0.9866 - val_loss: 0.3747 - val_out_1_loss: 0.1715 - val_out_2_loss: 0.2031 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0789 - out_1_loss: 0.0515 - out_2_loss: 0.0274 - out_1_acc: 0.9742 - out_2_acc: 0.9872 - val_loss: 0.3770 - val_out_1_loss: 0.1717 - val_out_2_loss: 0.2053 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9532\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0784 - out_1_loss: 0.0510 - out_2_loss: 0.0273 - out_1_acc: 0.9740 - out_2_acc: 0.9871 - val_loss: 0.3765 - val_out_1_loss: 0.1722 - val_out_2_loss: 0.2043 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9538\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(3)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3619 - out_1_loss: 0.1597 - out_2_loss: 0.2022 - out_1_acc: 0.9432 - out_2_acc: 0.9524\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 100), (No 52400       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 100)       52400       input_9[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 293,880\n",
      "Trainable params: 293,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3561 - out_1_loss: 3.6802 - out_2_loss: 3.6759 - out_1_acc: 0.0361 - out_2_acc: 0.0659WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.115555). Check your callbacks.\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 6.5267 - out_1_loss: 3.3217 - out_2_loss: 3.2050 - out_1_acc: 0.3307 - out_2_acc: 0.3223 - val_loss: 5.1323 - val_out_1_loss: 2.6163 - val_out_2_loss: 2.5160 - val_out_1_acc: 0.3830 - val_out_2_acc: 0.3902\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.2419 - out_1_loss: 2.2268 - out_2_loss: 2.0151 - out_1_acc: 0.4636 - out_2_acc: 0.5241 - val_loss: 3.3248 - val_out_1_loss: 1.8953 - val_out_2_loss: 1.4295 - val_out_1_acc: 0.5219 - val_out_2_acc: 0.6467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.5041 - out_1_loss: 1.5140 - out_2_loss: 0.9901 - out_1_acc: 0.6250 - out_2_acc: 0.7722 - val_loss: 1.6812 - val_out_1_loss: 1.0411 - val_out_2_loss: 0.6401 - val_out_1_acc: 0.7547 - val_out_2_acc: 0.8620\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.2178 - out_1_loss: 0.7447 - out_2_loss: 0.4731 - out_1_acc: 0.8313 - out_2_acc: 0.8990 - val_loss: 0.8750 - val_out_1_loss: 0.5271 - val_out_2_loss: 0.3479 - val_out_1_acc: 0.8884 - val_out_2_acc: 0.9210\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.7066 - out_1_loss: 0.4358 - out_2_loss: 0.2708 - out_1_acc: 0.9048 - out_2_acc: 0.9373 - val_loss: 0.5824 - val_out_1_loss: 0.3593 - val_out_2_loss: 0.2231 - val_out_1_acc: 0.9219 - val_out_2_acc: 0.9450\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.4959 - out_1_loss: 0.3096 - out_2_loss: 0.1863 - out_1_acc: 0.9263 - out_2_acc: 0.9490 - val_loss: 0.4382 - val_out_1_loss: 0.2680 - val_out_2_loss: 0.1703 - val_out_1_acc: 0.9355 - val_out_2_acc: 0.9490\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3751 - out_1_loss: 0.2300 - out_2_loss: 0.1451 - out_1_acc: 0.9353 - out_2_acc: 0.9511 - val_loss: 0.3478 - val_out_1_loss: 0.2079 - val_out_2_loss: 0.1398 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9487\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.3025 - out_1_loss: 0.1808 - out_2_loss: 0.1216 - out_1_acc: 0.9386 - out_2_acc: 0.9527 - val_loss: 0.2959 - val_out_1_loss: 0.1738 - val_out_2_loss: 0.1221 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9508\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2613 - out_1_loss: 0.1532 - out_2_loss: 0.1081 - out_1_acc: 0.9402 - out_2_acc: 0.9532 - val_loss: 0.2648 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1108 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9509\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2370 - out_1_loss: 0.1372 - out_2_loss: 0.0998 - out_1_acc: 0.9406 - out_2_acc: 0.9536 - val_loss: 0.2448 - val_out_1_loss: 0.1404 - val_out_2_loss: 0.1044 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9519\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2213 - out_1_loss: 0.1268 - out_2_loss: 0.0945 - out_1_acc: 0.9410 - out_2_acc: 0.9539 - val_loss: 0.2322 - val_out_1_loss: 0.1320 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9529\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2109 - out_1_loss: 0.1199 - out_2_loss: 0.0909 - out_1_acc: 0.9419 - out_2_acc: 0.9543 - val_loss: 0.2227 - val_out_1_loss: 0.1255 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9527\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2035 - out_1_loss: 0.1151 - out_2_loss: 0.0884 - out_1_acc: 0.9422 - out_2_acc: 0.9547 - val_loss: 0.2164 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9530\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1983 - out_1_loss: 0.1118 - out_2_loss: 0.0865 - out_1_acc: 0.9424 - out_2_acc: 0.9550 - val_loss: 0.2117 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9529\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1944 - out_1_loss: 0.1094 - out_2_loss: 0.0851 - out_1_acc: 0.9427 - out_2_acc: 0.9549 - val_loss: 0.2082 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.0930 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9526\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1913 - out_1_loss: 0.1073 - out_2_loss: 0.0839 - out_1_acc: 0.9430 - out_2_acc: 0.9554 - val_loss: 0.2056 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9526\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1886 - out_1_loss: 0.1057 - out_2_loss: 0.0829 - out_1_acc: 0.9432 - out_2_acc: 0.9554 - val_loss: 0.2042 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.0917 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9528\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1865 - out_1_loss: 0.1043 - out_2_loss: 0.0822 - out_1_acc: 0.9428 - out_2_acc: 0.9553 - val_loss: 0.2028 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1845 - out_1_loss: 0.1030 - out_2_loss: 0.0814 - out_1_acc: 0.9431 - out_2_acc: 0.9556 - val_loss: 0.2018 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.0910 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9529\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1829 - out_1_loss: 0.1021 - out_2_loss: 0.0808 - out_1_acc: 0.9433 - out_2_acc: 0.9558 - val_loss: 0.2011 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0908 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9525\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1814 - out_1_loss: 0.1013 - out_2_loss: 0.0800 - out_1_acc: 0.9434 - out_2_acc: 0.9562 - val_loss: 0.2006 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0908 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1800 - out_1_loss: 0.1006 - out_2_loss: 0.0793 - out_1_acc: 0.9437 - out_2_acc: 0.9566 - val_loss: 0.2003 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0910 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1788 - out_1_loss: 0.1000 - out_2_loss: 0.0788 - out_1_acc: 0.9440 - out_2_acc: 0.9566 - val_loss: 0.2001 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9529\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1776 - out_1_loss: 0.0995 - out_2_loss: 0.0781 - out_1_acc: 0.9440 - out_2_acc: 0.9570 - val_loss: 0.2000 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9524\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1765 - out_1_loss: 0.0990 - out_2_loss: 0.0775 - out_1_acc: 0.9442 - out_2_acc: 0.9573 - val_loss: 0.1997 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9530\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1755 - out_1_loss: 0.0985 - out_2_loss: 0.0770 - out_1_acc: 0.9447 - out_2_acc: 0.9576 - val_loss: 0.1997 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9529\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1745 - out_1_loss: 0.0981 - out_2_loss: 0.0764 - out_1_acc: 0.9446 - out_2_acc: 0.9582 - val_loss: 0.1996 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9538\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1735 - out_1_loss: 0.0976 - out_2_loss: 0.0759 - out_1_acc: 0.9449 - out_2_acc: 0.9586 - val_loss: 0.1996 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9535\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1726 - out_1_loss: 0.0971 - out_2_loss: 0.0755 - out_1_acc: 0.9452 - out_2_acc: 0.9586 - val_loss: 0.1995 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9530\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1718 - out_1_loss: 0.0967 - out_2_loss: 0.0751 - out_1_acc: 0.9454 - out_2_acc: 0.9591 - val_loss: 0.1996 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9528\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1710 - out_1_loss: 0.0964 - out_2_loss: 0.0747 - out_1_acc: 0.9454 - out_2_acc: 0.9593 - val_loss: 0.1985 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1704 - out_1_loss: 0.0961 - out_2_loss: 0.0743 - out_1_acc: 0.9456 - out_2_acc: 0.9592 - val_loss: 0.1980 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0901 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9527\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1698 - out_1_loss: 0.0958 - out_2_loss: 0.0740 - out_1_acc: 0.9459 - out_2_acc: 0.9596 - val_loss: 0.1983 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9530\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1692 - out_1_loss: 0.0956 - out_2_loss: 0.0736 - out_1_acc: 0.9458 - out_2_acc: 0.9600 - val_loss: 0.1992 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1686 - out_1_loss: 0.0953 - out_2_loss: 0.0733 - out_1_acc: 0.9457 - out_2_acc: 0.9602 - val_loss: 0.2006 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9532\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1680 - out_1_loss: 0.0950 - out_2_loss: 0.0730 - out_1_acc: 0.9459 - out_2_acc: 0.9604 - val_loss: 0.2008 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0924 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9536\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1681 - out_1_loss: 0.0948 - out_2_loss: 0.0732 - out_1_acc: 0.9459 - out_2_acc: 0.9595 - val_loss: 0.2008 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9529\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1678 - out_1_loss: 0.0946 - out_2_loss: 0.0732 - out_1_acc: 0.9459 - out_2_acc: 0.9599 - val_loss: 0.2017 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0931 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1673 - out_1_loss: 0.0943 - out_2_loss: 0.0730 - out_1_acc: 0.9464 - out_2_acc: 0.9598 - val_loss: 0.2018 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0937 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1667 - out_1_loss: 0.0941 - out_2_loss: 0.0725 - out_1_acc: 0.9461 - out_2_acc: 0.9602 - val_loss: 0.2018 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0935 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1657 - out_1_loss: 0.0942 - out_2_loss: 0.0716 - out_1_acc: 0.9459 - out_2_acc: 0.9600 - val_loss: 0.2017 - val_out_1_loss: 0.1078 - val_out_2_loss: 0.0939 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9532\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1648 - out_1_loss: 0.0936 - out_2_loss: 0.0712 - out_1_acc: 0.9465 - out_2_acc: 0.9603 - val_loss: 0.2033 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9518\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1639 - out_1_loss: 0.0934 - out_2_loss: 0.0705 - out_1_acc: 0.9474 - out_2_acc: 0.9608 - val_loss: 0.2051 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9525\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.1631 - out_1_loss: 0.0931 - out_2_loss: 0.0700 - out_1_acc: 0.9472 - out_2_acc: 0.9610 - val_loss: 0.2057 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1628 - out_1_loss: 0.0929 - out_2_loss: 0.0699 - out_1_acc: 0.9472 - out_2_acc: 0.9616 - val_loss: 0.2048 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9528\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1625 - out_1_loss: 0.0927 - out_2_loss: 0.0699 - out_1_acc: 0.9475 - out_2_acc: 0.9615 - val_loss: 0.2045 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9534\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1619 - out_1_loss: 0.0924 - out_2_loss: 0.0695 - out_1_acc: 0.9478 - out_2_acc: 0.9614 - val_loss: 0.2068 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9530\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1616 - out_1_loss: 0.0923 - out_2_loss: 0.0693 - out_1_acc: 0.9481 - out_2_acc: 0.9620 - val_loss: 0.2075 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9531\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1607 - out_1_loss: 0.0920 - out_2_loss: 0.0687 - out_1_acc: 0.9481 - out_2_acc: 0.9618 - val_loss: 0.2080 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0981 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9533\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1607 - out_1_loss: 0.0918 - out_2_loss: 0.0690 - out_1_acc: 0.9480 - out_2_acc: 0.9610 - val_loss: 0.2076 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1608 - out_1_loss: 0.0917 - out_2_loss: 0.0691 - out_1_acc: 0.9477 - out_2_acc: 0.9615 - val_loss: 0.2086 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0996 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1605 - out_1_loss: 0.0915 - out_2_loss: 0.0690 - out_1_acc: 0.9480 - out_2_acc: 0.9608 - val_loss: 0.2091 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.1004 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9517\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1596 - out_1_loss: 0.0912 - out_2_loss: 0.0684 - out_1_acc: 0.9482 - out_2_acc: 0.9615 - val_loss: 0.2090 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.1008 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9513\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1580 - out_1_loss: 0.0907 - out_2_loss: 0.0673 - out_1_acc: 0.9488 - out_2_acc: 0.9622 - val_loss: 0.2082 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0998 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9532\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1566 - out_1_loss: 0.0904 - out_2_loss: 0.0662 - out_1_acc: 0.9489 - out_2_acc: 0.9627 - val_loss: 0.2088 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0998 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9517\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1563 - out_1_loss: 0.0902 - out_2_loss: 0.0661 - out_1_acc: 0.9489 - out_2_acc: 0.9630 - val_loss: 0.2122 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.1028 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9530\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1556 - out_1_loss: 0.0900 - out_2_loss: 0.0656 - out_1_acc: 0.9489 - out_2_acc: 0.9633 - val_loss: 0.2130 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1030 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9528\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1550 - out_1_loss: 0.0896 - out_2_loss: 0.0655 - out_1_acc: 0.9494 - out_2_acc: 0.9637 - val_loss: 0.2140 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1031 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9527\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1544 - out_1_loss: 0.0895 - out_2_loss: 0.0649 - out_1_acc: 0.9494 - out_2_acc: 0.9635 - val_loss: 0.2145 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9525\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1532 - out_1_loss: 0.0892 - out_2_loss: 0.0641 - out_1_acc: 0.9498 - out_2_acc: 0.9644 - val_loss: 0.2141 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1035 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9533\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1520 - out_1_loss: 0.0888 - out_2_loss: 0.0632 - out_1_acc: 0.9498 - out_2_acc: 0.9650 - val_loss: 0.2158 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.1054 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9533\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1513 - out_1_loss: 0.0885 - out_2_loss: 0.0628 - out_1_acc: 0.9505 - out_2_acc: 0.9650 - val_loss: 0.2153 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9527\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1504 - out_1_loss: 0.0882 - out_2_loss: 0.0621 - out_1_acc: 0.9509 - out_2_acc: 0.9655 - val_loss: 0.2137 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.1038 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9521\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1498 - out_1_loss: 0.0880 - out_2_loss: 0.0618 - out_1_acc: 0.9508 - out_2_acc: 0.9656 - val_loss: 0.2156 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9531\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1490 - out_1_loss: 0.0877 - out_2_loss: 0.0613 - out_1_acc: 0.9507 - out_2_acc: 0.9656 - val_loss: 0.2142 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1037 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1486 - out_1_loss: 0.0876 - out_2_loss: 0.0610 - out_1_acc: 0.9512 - out_2_acc: 0.9660 - val_loss: 0.2157 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9522\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1482 - out_1_loss: 0.0871 - out_2_loss: 0.0611 - out_1_acc: 0.9514 - out_2_acc: 0.9653 - val_loss: 0.2160 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1052 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9533\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1476 - out_1_loss: 0.0869 - out_2_loss: 0.0608 - out_1_acc: 0.9510 - out_2_acc: 0.9657 - val_loss: 0.2215 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.1096 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1475 - out_1_loss: 0.0870 - out_2_loss: 0.0605 - out_1_acc: 0.9512 - out_2_acc: 0.9658 - val_loss: 0.2222 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.1099 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1468 - out_1_loss: 0.0868 - out_2_loss: 0.0600 - out_1_acc: 0.9510 - out_2_acc: 0.9659 - val_loss: 0.2208 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1087 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.1456 - out_1_loss: 0.0863 - out_2_loss: 0.0594 - out_1_acc: 0.9516 - out_2_acc: 0.9666 - val_loss: 0.2225 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1089 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1459 - out_1_loss: 0.0863 - out_2_loss: 0.0596 - out_1_acc: 0.9515 - out_2_acc: 0.9662 - val_loss: 0.2210 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1076 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1444 - out_1_loss: 0.0861 - out_2_loss: 0.0583 - out_1_acc: 0.9522 - out_2_acc: 0.9670 - val_loss: 0.2209 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1081 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9514\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1439 - out_1_loss: 0.0855 - out_2_loss: 0.0584 - out_1_acc: 0.9521 - out_2_acc: 0.9670 - val_loss: 0.2248 - val_out_1_loss: 0.1154 - val_out_2_loss: 0.1094 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1426 - out_1_loss: 0.0851 - out_2_loss: 0.0575 - out_1_acc: 0.9523 - out_2_acc: 0.9677 - val_loss: 0.2269 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1119 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9521\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1420 - out_1_loss: 0.0848 - out_2_loss: 0.0572 - out_1_acc: 0.9526 - out_2_acc: 0.9677 - val_loss: 0.2276 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1131 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9518\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1408 - out_1_loss: 0.0844 - out_2_loss: 0.0565 - out_1_acc: 0.9528 - out_2_acc: 0.9678 - val_loss: 0.2278 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1129 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1399 - out_1_loss: 0.0839 - out_2_loss: 0.0560 - out_1_acc: 0.9533 - out_2_acc: 0.9682 - val_loss: 0.2307 - val_out_1_loss: 0.1156 - val_out_2_loss: 0.1151 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9530\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1394 - out_1_loss: 0.0834 - out_2_loss: 0.0559 - out_1_acc: 0.9530 - out_2_acc: 0.9683 - val_loss: 0.2348 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1189 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9524\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 0.1390 - out_1_loss: 0.0832 - out_2_loss: 0.0559 - out_1_acc: 0.9538 - out_2_acc: 0.9686 - val_loss: 0.2366 - val_out_1_loss: 0.1167 - val_out_2_loss: 0.1199 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9528\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1381 - out_1_loss: 0.0826 - out_2_loss: 0.0554 - out_1_acc: 0.9537 - out_2_acc: 0.9684 - val_loss: 0.2334 - val_out_1_loss: 0.1161 - val_out_2_loss: 0.1173 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1366 - out_1_loss: 0.0819 - out_2_loss: 0.0547 - out_1_acc: 0.9541 - out_2_acc: 0.9689 - val_loss: 0.2311 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1153 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9521\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1354 - out_1_loss: 0.0817 - out_2_loss: 0.0537 - out_1_acc: 0.9545 - out_2_acc: 0.9691 - val_loss: 0.2324 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1164 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1335 - out_1_loss: 0.0809 - out_2_loss: 0.0526 - out_1_acc: 0.9553 - out_2_acc: 0.9705 - val_loss: 0.2374 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1208 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1334 - out_1_loss: 0.0805 - out_2_loss: 0.0529 - out_1_acc: 0.9552 - out_2_acc: 0.9700 - val_loss: 0.2377 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.1209 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9531\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1322 - out_1_loss: 0.0802 - out_2_loss: 0.0520 - out_1_acc: 0.9555 - out_2_acc: 0.9704 - val_loss: 0.2383 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1213 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1316 - out_1_loss: 0.0797 - out_2_loss: 0.0519 - out_1_acc: 0.9556 - out_2_acc: 0.9702 - val_loss: 0.2371 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1199 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9528\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1303 - out_1_loss: 0.0790 - out_2_loss: 0.0513 - out_1_acc: 0.9564 - out_2_acc: 0.9709 - val_loss: 0.2429 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1254 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1304 - out_1_loss: 0.0790 - out_2_loss: 0.0514 - out_1_acc: 0.9562 - out_2_acc: 0.9708 - val_loss: 0.2424 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1239 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1291 - out_1_loss: 0.0787 - out_2_loss: 0.0504 - out_1_acc: 0.9564 - out_2_acc: 0.9714 - val_loss: 0.2448 - val_out_1_loss: 0.1191 - val_out_2_loss: 0.1257 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9522\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1292 - out_1_loss: 0.0785 - out_2_loss: 0.0507 - out_1_acc: 0.9565 - out_2_acc: 0.9713 - val_loss: 0.2463 - val_out_1_loss: 0.1203 - val_out_2_loss: 0.1260 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9521\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1282 - out_1_loss: 0.0782 - out_2_loss: 0.0500 - out_1_acc: 0.9567 - out_2_acc: 0.9716 - val_loss: 0.2473 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.1274 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1274 - out_1_loss: 0.0777 - out_2_loss: 0.0497 - out_1_acc: 0.9572 - out_2_acc: 0.9721 - val_loss: 0.2505 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1289 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1269 - out_1_loss: 0.0776 - out_2_loss: 0.0493 - out_1_acc: 0.9576 - out_2_acc: 0.9725 - val_loss: 0.2515 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.1298 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1263 - out_1_loss: 0.0770 - out_2_loss: 0.0493 - out_1_acc: 0.9576 - out_2_acc: 0.9718 - val_loss: 0.2507 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9526\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1254 - out_1_loss: 0.0766 - out_2_loss: 0.0488 - out_1_acc: 0.9580 - out_2_acc: 0.9723 - val_loss: 0.2497 - val_out_1_loss: 0.1206 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1245 - out_1_loss: 0.0760 - out_2_loss: 0.0485 - out_1_acc: 0.9582 - out_2_acc: 0.9726 - val_loss: 0.2542 - val_out_1_loss: 0.1225 - val_out_2_loss: 0.1317 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1245 - out_1_loss: 0.0762 - out_2_loss: 0.0483 - out_1_acc: 0.9580 - out_2_acc: 0.9727 - val_loss: 0.2542 - val_out_1_loss: 0.1224 - val_out_2_loss: 0.1318 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1243 - out_1_loss: 0.0758 - out_2_loss: 0.0485 - out_1_acc: 0.9581 - out_2_acc: 0.9728 - val_loss: 0.2520 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1242 - out_1_loss: 0.0756 - out_2_loss: 0.0486 - out_1_acc: 0.9588 - out_2_acc: 0.9728 - val_loss: 0.2502 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9530\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1229 - out_1_loss: 0.0750 - out_2_loss: 0.0479 - out_1_acc: 0.9586 - out_2_acc: 0.9735 - val_loss: 0.2532 - val_out_1_loss: 0.1230 - val_out_2_loss: 0.1301 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1220 - out_1_loss: 0.0747 - out_2_loss: 0.0473 - out_1_acc: 0.9590 - out_2_acc: 0.9738 - val_loss: 0.2544 - val_out_1_loss: 0.1227 - val_out_2_loss: 0.1317 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1217 - out_1_loss: 0.0745 - out_2_loss: 0.0472 - out_1_acc: 0.9596 - out_2_acc: 0.9740 - val_loss: 0.2580 - val_out_1_loss: 0.1235 - val_out_2_loss: 0.1345 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1220 - out_1_loss: 0.0744 - out_2_loss: 0.0477 - out_1_acc: 0.9594 - out_2_acc: 0.9733 - val_loss: 0.2575 - val_out_1_loss: 0.1243 - val_out_2_loss: 0.1332 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9521\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1221 - out_1_loss: 0.0745 - out_2_loss: 0.0476 - out_1_acc: 0.9592 - out_2_acc: 0.9734 - val_loss: 0.2598 - val_out_1_loss: 0.1242 - val_out_2_loss: 0.1356 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9519\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1218 - out_1_loss: 0.0744 - out_2_loss: 0.0475 - out_1_acc: 0.9590 - out_2_acc: 0.9735 - val_loss: 0.2592 - val_out_1_loss: 0.1244 - val_out_2_loss: 0.1349 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9518\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1213 - out_1_loss: 0.0736 - out_2_loss: 0.0477 - out_1_acc: 0.9599 - out_2_acc: 0.9736 - val_loss: 0.2599 - val_out_1_loss: 0.1244 - val_out_2_loss: 0.1355 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9527\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1210 - out_1_loss: 0.0736 - out_2_loss: 0.0474 - out_1_acc: 0.9595 - out_2_acc: 0.9737 - val_loss: 0.2632 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1376 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9513\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1194 - out_1_loss: 0.0729 - out_2_loss: 0.0466 - out_1_acc: 0.9601 - out_2_acc: 0.9743 - val_loss: 0.2652 - val_out_1_loss: 0.1264 - val_out_2_loss: 0.1388 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9522\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1199 - out_1_loss: 0.0727 - out_2_loss: 0.0472 - out_1_acc: 0.9604 - out_2_acc: 0.9735 - val_loss: 0.2667 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.1400 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1185 - out_1_loss: 0.0723 - out_2_loss: 0.0462 - out_1_acc: 0.9606 - out_2_acc: 0.9743 - val_loss: 0.2682 - val_out_1_loss: 0.1262 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9519\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1184 - out_1_loss: 0.0721 - out_2_loss: 0.0463 - out_1_acc: 0.9609 - out_2_acc: 0.9745 - val_loss: 0.2696 - val_out_1_loss: 0.1277 - val_out_2_loss: 0.1418 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9522\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1191 - out_1_loss: 0.0719 - out_2_loss: 0.0472 - out_1_acc: 0.9602 - out_2_acc: 0.9740 - val_loss: 0.2693 - val_out_1_loss: 0.1281 - val_out_2_loss: 0.1412 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1184 - out_1_loss: 0.0718 - out_2_loss: 0.0466 - out_1_acc: 0.9608 - out_2_acc: 0.9742 - val_loss: 0.2728 - val_out_1_loss: 0.1285 - val_out_2_loss: 0.1443 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9524\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1174 - out_1_loss: 0.0714 - out_2_loss: 0.0461 - out_1_acc: 0.9612 - out_2_acc: 0.9748 - val_loss: 0.2721 - val_out_1_loss: 0.1288 - val_out_2_loss: 0.1434 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9523\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1173 - out_1_loss: 0.0715 - out_2_loss: 0.0458 - out_1_acc: 0.9610 - out_2_acc: 0.9745 - val_loss: 0.2747 - val_out_1_loss: 0.1299 - val_out_2_loss: 0.1448 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1162 - out_1_loss: 0.0710 - out_2_loss: 0.0452 - out_1_acc: 0.9613 - out_2_acc: 0.9750 - val_loss: 0.2768 - val_out_1_loss: 0.1305 - val_out_2_loss: 0.1463 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1147 - out_1_loss: 0.0701 - out_2_loss: 0.0446 - out_1_acc: 0.9615 - out_2_acc: 0.9755 - val_loss: 0.2802 - val_out_1_loss: 0.1323 - val_out_2_loss: 0.1479 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1143 - out_1_loss: 0.0696 - out_2_loss: 0.0447 - out_1_acc: 0.9620 - out_2_acc: 0.9753 - val_loss: 0.2851 - val_out_1_loss: 0.1318 - val_out_2_loss: 0.1533 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9514\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1144 - out_1_loss: 0.0695 - out_2_loss: 0.0449 - out_1_acc: 0.9619 - out_2_acc: 0.9751 - val_loss: 0.2867 - val_out_1_loss: 0.1328 - val_out_2_loss: 0.1539 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1144 - out_1_loss: 0.0695 - out_2_loss: 0.0449 - out_1_acc: 0.9624 - out_2_acc: 0.9753 - val_loss: 0.2874 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1522 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1130 - out_1_loss: 0.0691 - out_2_loss: 0.0439 - out_1_acc: 0.9630 - out_2_acc: 0.9758 - val_loss: 0.2936 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1564 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1126 - out_1_loss: 0.0689 - out_2_loss: 0.0437 - out_1_acc: 0.9628 - out_2_acc: 0.9764 - val_loss: 0.2887 - val_out_1_loss: 0.1367 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1114 - out_1_loss: 0.0682 - out_2_loss: 0.0432 - out_1_acc: 0.9629 - out_2_acc: 0.9764 - val_loss: 0.2907 - val_out_1_loss: 0.1380 - val_out_2_loss: 0.1527 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9509\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1107 - out_1_loss: 0.0681 - out_2_loss: 0.0426 - out_1_acc: 0.9634 - out_2_acc: 0.9766 - val_loss: 0.2884 - val_out_1_loss: 0.1384 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.1103 - out_1_loss: 0.0678 - out_2_loss: 0.0425 - out_1_acc: 0.9638 - out_2_acc: 0.9766 - val_loss: 0.2936 - val_out_1_loss: 0.1406 - val_out_2_loss: 0.1529 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9529\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1109 - out_1_loss: 0.0679 - out_2_loss: 0.0431 - out_1_acc: 0.9639 - out_2_acc: 0.9764 - val_loss: 0.2915 - val_out_1_loss: 0.1406 - val_out_2_loss: 0.1509 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9515\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1107 - out_1_loss: 0.0678 - out_2_loss: 0.0429 - out_1_acc: 0.9634 - out_2_acc: 0.9763 - val_loss: 0.2921 - val_out_1_loss: 0.1418 - val_out_2_loss: 0.1502 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1104 - out_1_loss: 0.0681 - out_2_loss: 0.0423 - out_1_acc: 0.9633 - out_2_acc: 0.9774 - val_loss: 0.2914 - val_out_1_loss: 0.1422 - val_out_2_loss: 0.1492 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1095 - out_1_loss: 0.0677 - out_2_loss: 0.0417 - out_1_acc: 0.9638 - out_2_acc: 0.9774 - val_loss: 0.2977 - val_out_1_loss: 0.1439 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1105 - out_1_loss: 0.0680 - out_2_loss: 0.0425 - out_1_acc: 0.9634 - out_2_acc: 0.9771 - val_loss: 0.2933 - val_out_1_loss: 0.1433 - val_out_2_loss: 0.1500 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1092 - out_1_loss: 0.0677 - out_2_loss: 0.0415 - out_1_acc: 0.9637 - out_2_acc: 0.9774 - val_loss: 0.2950 - val_out_1_loss: 0.1427 - val_out_2_loss: 0.1523 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1084 - out_1_loss: 0.0673 - out_2_loss: 0.0411 - out_1_acc: 0.9640 - out_2_acc: 0.9782 - val_loss: 0.2938 - val_out_1_loss: 0.1431 - val_out_2_loss: 0.1508 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1084 - out_1_loss: 0.0671 - out_2_loss: 0.0413 - out_1_acc: 0.9636 - out_2_acc: 0.9776 - val_loss: 0.2963 - val_out_1_loss: 0.1428 - val_out_2_loss: 0.1535 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9526\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.1087 - out_1_loss: 0.0674 - out_2_loss: 0.0412 - out_1_acc: 0.9640 - out_2_acc: 0.9783 - val_loss: 0.2972 - val_out_1_loss: 0.1439 - val_out_2_loss: 0.1533 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1080 - out_1_loss: 0.0667 - out_2_loss: 0.0413 - out_1_acc: 0.9641 - out_2_acc: 0.9777 - val_loss: 0.2946 - val_out_1_loss: 0.1429 - val_out_2_loss: 0.1517 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9512\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1058 - out_1_loss: 0.0658 - out_2_loss: 0.0401 - out_1_acc: 0.9650 - out_2_acc: 0.9789 - val_loss: 0.2995 - val_out_1_loss: 0.1438 - val_out_2_loss: 0.1557 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9511\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1053 - out_1_loss: 0.0654 - out_2_loss: 0.0399 - out_1_acc: 0.9650 - out_2_acc: 0.9787 - val_loss: 0.3043 - val_out_1_loss: 0.1453 - val_out_2_loss: 0.1590 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1050 - out_1_loss: 0.0650 - out_2_loss: 0.0400 - out_1_acc: 0.9652 - out_2_acc: 0.9784 - val_loss: 0.3028 - val_out_1_loss: 0.1433 - val_out_2_loss: 0.1594 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1039 - out_1_loss: 0.0645 - out_2_loss: 0.0395 - out_1_acc: 0.9658 - out_2_acc: 0.9797 - val_loss: 0.3044 - val_out_1_loss: 0.1439 - val_out_2_loss: 0.1605 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1037 - out_1_loss: 0.0641 - out_2_loss: 0.0396 - out_1_acc: 0.9661 - out_2_acc: 0.9791 - val_loss: 0.3026 - val_out_1_loss: 0.1437 - val_out_2_loss: 0.1589 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9524\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1013 - out_1_loss: 0.0628 - out_2_loss: 0.0385 - out_1_acc: 0.9665 - out_2_acc: 0.9803 - val_loss: 0.3102 - val_out_1_loss: 0.1474 - val_out_2_loss: 0.1629 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1002 - out_1_loss: 0.0624 - out_2_loss: 0.0378 - out_1_acc: 0.9672 - out_2_acc: 0.9802 - val_loss: 0.3087 - val_out_1_loss: 0.1462 - val_out_2_loss: 0.1625 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1008 - out_1_loss: 0.0626 - out_2_loss: 0.0382 - out_1_acc: 0.9671 - out_2_acc: 0.9800 - val_loss: 0.3142 - val_out_1_loss: 0.1482 - val_out_2_loss: 0.1660 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1000 - out_1_loss: 0.0626 - out_2_loss: 0.0374 - out_1_acc: 0.9673 - out_2_acc: 0.9812 - val_loss: 0.3098 - val_out_1_loss: 0.1470 - val_out_2_loss: 0.1627 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0992 - out_1_loss: 0.0621 - out_2_loss: 0.0370 - out_1_acc: 0.9673 - out_2_acc: 0.9811 - val_loss: 0.3137 - val_out_1_loss: 0.1481 - val_out_2_loss: 0.1655 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9528\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0984 - out_1_loss: 0.0617 - out_2_loss: 0.0367 - out_1_acc: 0.9679 - out_2_acc: 0.9814 - val_loss: 0.3182 - val_out_1_loss: 0.1509 - val_out_2_loss: 0.1674 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0982 - out_1_loss: 0.0621 - out_2_loss: 0.0361 - out_1_acc: 0.9677 - out_2_acc: 0.9816 - val_loss: 0.3206 - val_out_1_loss: 0.1508 - val_out_2_loss: 0.1698 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9517\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0982 - out_1_loss: 0.0616 - out_2_loss: 0.0366 - out_1_acc: 0.9681 - out_2_acc: 0.9814 - val_loss: 0.3224 - val_out_1_loss: 0.1522 - val_out_2_loss: 0.1702 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9524\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0987 - out_1_loss: 0.0617 - out_2_loss: 0.0370 - out_1_acc: 0.9677 - out_2_acc: 0.9812 - val_loss: 0.3221 - val_out_1_loss: 0.1525 - val_out_2_loss: 0.1695 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9507\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(6)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3047 - out_1_loss: 0.1440 - out_2_loss: 0.1607 - out_1_acc: 0.9412 - out_2_acc: 0.9521\n"
     ]
    }
   ],
   "source": [
    "try_timesteps=[3,6]#list(range(3,18,3))\n",
    "try_units=[100]#[50,100,200,300,180]#list(range(10,200,20))\n",
    "try_epochs=[150]\n",
    "\n",
    "\"\"\"\n",
    "try_timesteps=[3]\n",
    "try_units=[180]#list(range(10,200,20))\n",
    "try_epochs=[150]\n",
    "\"\"\"\n",
    "df_all = pd.DataFrame([], columns=[[\"loss\", \"out_1_loss\", \"out_2_loss\", \"out_1_acc\", \"out_2_acc\", \"timesteps\", \"units\", \"epoch\"]])\n",
    "for timesteps in try_timesteps:\n",
    "    for units in try_units:\n",
    "        for epoch in try_epochs:\n",
    "            X = tf.reshape(X_raw, [y.shape[0],timesteps,180//timesteps])\n",
    "            train_dataset, val_dataset, test_dataset = split_dataset(X, y)\n",
    "            \n",
    "            model = construct_model(timesteps=timesteps, data_dim = 180//timesteps, units=units)\n",
    "            model, history = compile_fit_model(model,epochs=epoch,train_dataset=train_dataset,val_dataset=val_dataset)\n",
    "            model.save(\"saved_model/lstm-rnn-unit(\"+str(units)+\")-timesteps(\"+str(timesteps)+\")-epoch(\"+str(epoch)+\")\")\n",
    "            results = model.evaluate(test_dataset)\n",
    "            results.extend([timesteps, units, epoch])\n",
    "            df = pd.DataFrame([results], columns=[[\"loss\", \"out_1_loss\", \"out_2_loss\", \"out_1_acc\", \"out_2_acc\", \"timesteps\", \"units\", \"epoch\"]])\n",
    "            df_all = df_all.append(df)\n",
    "df_all.to_csv(\"save/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863bdbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>out_1_loss</th>\n",
       "      <th>out_2_loss</th>\n",
       "      <th>out_1_acc</th>\n",
       "      <th>out_2_acc</th>\n",
       "      <th>timesteps</th>\n",
       "      <th>units</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361949</td>\n",
       "      <td>0.159725</td>\n",
       "      <td>0.202224</td>\n",
       "      <td>0.943208</td>\n",
       "      <td>0.952417</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304710</td>\n",
       "      <td>0.144047</td>\n",
       "      <td>0.160663</td>\n",
       "      <td>0.941167</td>\n",
       "      <td>0.952083</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss out_1_loss out_2_loss out_1_acc out_2_acc timesteps units epoch\n",
       "0  0.361949   0.159725   0.202224  0.943208  0.952417         3   100   150\n",
       "0  0.304710   0.144047   0.160663  0.941167  0.952083         6   100   150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa253a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e8265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f7f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c026239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opened-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss out_1_loss out_2_loss out_1_acc out_2_acc timesteps units epoch\n",
      "0  0.361949   0.159725   0.202224  0.943208  0.952417         3   100   150\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3, 60) for input Tensor(\"input_8_1:0\", shape=(None, 3, 60), dtype=float32), but it was called on an input with incompatible shape (None, 6, 30).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py:654 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer vfc_1_1: expected shape=(None, None, 60), found shape=[None, 6, 30]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33bca3aee106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_model/lstm-rnn-unit(\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbest_unit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\")-timesteps(\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbest_timesteps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\")-epoch(\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py:654 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:227 assert_input_compatibility\n        ', found shape=' + str(shape))\n\n    ValueError: Input 0 is incompatible with layer vfc_1_1: expected shape=(None, None, 60), found shape=[None, 6, 30]\n"
     ]
    }
   ],
   "source": [
    "d = df_all.copy().reset_index(drop=True)\n",
    "_max =  d[[\"out_1_acc\",\"out_2_acc\"]].sum(axis=1).max()\n",
    "best_result = d[ d[[\"out_1_acc\",\"out_2_acc\"]].sum(axis=1)==_max]\n",
    "print(best_result)\n",
    "best_unit = str(best_result.iloc[0]['units'][0])\n",
    "best_timesteps = str(best_result.iloc[0]['timesteps'][0])\n",
    "best_epoch = str(best_result.iloc[0]['epoch'][0])\n",
    "\n",
    "best_model = tf.keras.models.load_model(\"saved_model/lstm-rnn-unit(\"+best_unit+\")-timesteps(\"+best_timesteps+\")-epoch(\"+best_epoch+\")\")\n",
    "y_pred = best_model.predict(test_dataset)\n",
    "best_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-charge",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
