{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "announced-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils.data import *\n",
    "from utils.lstm_rnn import *\n",
    "import os\n",
    "import pandas as pd\n",
    "if not os.path.isdir(\"save\"):\n",
    "    os.mkdir(\"save\")\n",
    "##### config #####\n",
    "save_dataset = False # 儲存dataset，true: 生成dataset、false: 使用save/ 儲存的\n",
    "##### config #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "for i in range(len(physical_devices)):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[i], enable=True)\n",
    "\n",
    "repeat = 100\n",
    "if save_dataset:\n",
    "    X_raw, y = generate_dataset(repeat=repeat)\n",
    "    X = tf.reshape(X_raw, [y.shape[0],3,60])\n",
    "    np.save(\"save/X_raw.npy\", X_raw.numpy())\n",
    "    np.save(\"save/y.npy\", y)\n",
    "else:\n",
    "    X_raw = np.load(\"save/X_raw.npy\")\n",
    "    y = np.load(\"save/y.npy\")\n",
    "\n",
    "X_raw = tf.convert_to_tensor(X_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9eaa1321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28800000])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "general-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 100), (No 64400       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 100)       64400       input_1[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 317,880\n",
      "Trainable params: 317,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 6.5697 - out_1_loss: 3.3966 - out_2_loss: 3.1731 - out_1_acc: 0.3825 - out_2_acc: 0.5579 - val_loss: 4.7822 - val_out_1_loss: 2.7341 - val_out_2_loss: 2.0481 - val_out_1_acc: 0.4110 - val_out_2_acc: 0.6390\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 2.7499 - out_1_loss: 1.7854 - out_2_loss: 0.9645 - out_1_acc: 0.6166 - out_2_acc: 0.8213 - val_loss: 1.3123 - val_out_1_loss: 0.9396 - val_out_2_loss: 0.3728 - val_out_1_acc: 0.8077 - val_out_2_acc: 0.9368\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.9384 - out_1_loss: 0.6697 - out_2_loss: 0.2687 - out_1_acc: 0.8730 - out_2_acc: 0.9490 - val_loss: 0.6723 - val_out_1_loss: 0.4624 - val_out_2_loss: 0.2099 - val_out_1_acc: 0.9073 - val_out_2_acc: 0.9499\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.5562 - out_1_loss: 0.3833 - out_2_loss: 0.1729 - out_1_acc: 0.9220 - out_2_acc: 0.9520 - val_loss: 0.4668 - val_out_1_loss: 0.3099 - val_out_2_loss: 0.1569 - val_out_1_acc: 0.9333 - val_out_2_acc: 0.9504\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.4060 - out_1_loss: 0.2707 - out_2_loss: 0.1353 - out_1_acc: 0.9353 - out_2_acc: 0.9524 - val_loss: 0.3593 - val_out_1_loss: 0.2309 - val_out_2_loss: 0.1284 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3202 - out_1_loss: 0.2052 - out_2_loss: 0.1150 - out_1_acc: 0.9393 - out_2_acc: 0.9523 - val_loss: 0.2961 - val_out_1_loss: 0.1827 - val_out_2_loss: 0.1134 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2675 - out_1_loss: 0.1639 - out_2_loss: 0.1036 - out_1_acc: 0.9398 - out_2_acc: 0.9526 - val_loss: 0.2597 - val_out_1_loss: 0.1547 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2373 - out_1_loss: 0.1406 - out_2_loss: 0.0967 - out_1_acc: 0.9401 - out_2_acc: 0.9525 - val_loss: 0.2392 - val_out_1_loss: 0.1395 - val_out_2_loss: 0.0997 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9527\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.2206 - out_1_loss: 0.1284 - out_2_loss: 0.0922 - out_1_acc: 0.9412 - out_2_acc: 0.9531 - val_loss: 0.2276 - val_out_1_loss: 0.1313 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9523\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2108 - out_1_loss: 0.1215 - out_2_loss: 0.0893 - out_1_acc: 0.9416 - out_2_acc: 0.9534 - val_loss: 0.2202 - val_out_1_loss: 0.1263 - val_out_2_loss: 0.0939 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9525\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2044 - out_1_loss: 0.1171 - out_2_loss: 0.0873 - out_1_acc: 0.9420 - out_2_acc: 0.9535 - val_loss: 0.2151 - val_out_1_loss: 0.1228 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9531\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1998 - out_1_loss: 0.1139 - out_2_loss: 0.0859 - out_1_acc: 0.9422 - out_2_acc: 0.9537 - val_loss: 0.2113 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9534\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1963 - out_1_loss: 0.1114 - out_2_loss: 0.0849 - out_1_acc: 0.9425 - out_2_acc: 0.9537 - val_loss: 0.2085 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9535\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1934 - out_1_loss: 0.1093 - out_2_loss: 0.0841 - out_1_acc: 0.9425 - out_2_acc: 0.9540 - val_loss: 0.2063 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9536\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1911 - out_1_loss: 0.1077 - out_2_loss: 0.0834 - out_1_acc: 0.9426 - out_2_acc: 0.9542 - val_loss: 0.2045 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.0894 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9535\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1892 - out_1_loss: 0.1062 - out_2_loss: 0.0829 - out_1_acc: 0.9428 - out_2_acc: 0.9544 - val_loss: 0.2030 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9531\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1875 - out_1_loss: 0.1050 - out_2_loss: 0.0825 - out_1_acc: 0.9430 - out_2_acc: 0.9547 - val_loss: 0.2018 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1860 - out_1_loss: 0.1040 - out_2_loss: 0.0820 - out_1_acc: 0.9433 - out_2_acc: 0.9549 - val_loss: 0.2008 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9529\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1847 - out_1_loss: 0.1030 - out_2_loss: 0.0817 - out_1_acc: 0.9436 - out_2_acc: 0.9551 - val_loss: 0.2000 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0885 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1835 - out_1_loss: 0.1022 - out_2_loss: 0.0813 - out_1_acc: 0.9439 - out_2_acc: 0.9553 - val_loss: 0.1993 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0884 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9531\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1824 - out_1_loss: 0.1014 - out_2_loss: 0.0810 - out_1_acc: 0.9440 - out_2_acc: 0.9556 - val_loss: 0.1989 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0884 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9534\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1814 - out_1_loss: 0.1007 - out_2_loss: 0.0806 - out_1_acc: 0.9444 - out_2_acc: 0.9557 - val_loss: 0.1986 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0885 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9531\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1805 - out_1_loss: 0.1001 - out_2_loss: 0.0804 - out_1_acc: 0.9447 - out_2_acc: 0.9558 - val_loss: 0.1983 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9529\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1795 - out_1_loss: 0.0995 - out_2_loss: 0.0800 - out_1_acc: 0.9450 - out_2_acc: 0.9562 - val_loss: 0.1981 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9530\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1786 - out_1_loss: 0.0990 - out_2_loss: 0.0796 - out_1_acc: 0.9453 - out_2_acc: 0.9563 - val_loss: 0.1979 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9530\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1778 - out_1_loss: 0.0985 - out_2_loss: 0.0793 - out_1_acc: 0.9453 - out_2_acc: 0.9567 - val_loss: 0.1977 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1770 - out_1_loss: 0.0980 - out_2_loss: 0.0790 - out_1_acc: 0.9457 - out_2_acc: 0.9568 - val_loss: 0.1977 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9530\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1762 - out_1_loss: 0.0975 - out_2_loss: 0.0787 - out_1_acc: 0.9459 - out_2_acc: 0.9572 - val_loss: 0.1978 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9531\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1754 - out_1_loss: 0.0971 - out_2_loss: 0.0783 - out_1_acc: 0.9462 - out_2_acc: 0.9573 - val_loss: 0.1978 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9535\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1746 - out_1_loss: 0.0966 - out_2_loss: 0.0780 - out_1_acc: 0.9464 - out_2_acc: 0.9578 - val_loss: 0.1979 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0893 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9534\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1738 - out_1_loss: 0.0962 - out_2_loss: 0.0776 - out_1_acc: 0.9466 - out_2_acc: 0.9580 - val_loss: 0.1980 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9532\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1730 - out_1_loss: 0.0958 - out_2_loss: 0.0772 - out_1_acc: 0.9469 - out_2_acc: 0.9582 - val_loss: 0.1982 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9529\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1722 - out_1_loss: 0.0954 - out_2_loss: 0.0768 - out_1_acc: 0.9471 - out_2_acc: 0.9582 - val_loss: 0.1985 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9535\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1714 - out_1_loss: 0.0950 - out_2_loss: 0.0764 - out_1_acc: 0.9475 - out_2_acc: 0.9586 - val_loss: 0.1985 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9533\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1706 - out_1_loss: 0.0946 - out_2_loss: 0.0760 - out_1_acc: 0.9476 - out_2_acc: 0.9589 - val_loss: 0.1990 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9534\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1697 - out_1_loss: 0.0942 - out_2_loss: 0.0755 - out_1_acc: 0.9481 - out_2_acc: 0.9592 - val_loss: 0.1991 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9536\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1688 - out_1_loss: 0.0938 - out_2_loss: 0.0750 - out_1_acc: 0.9481 - out_2_acc: 0.9595 - val_loss: 0.1996 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0908 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9536\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1680 - out_1_loss: 0.0935 - out_2_loss: 0.0745 - out_1_acc: 0.9485 - out_2_acc: 0.9595 - val_loss: 0.2000 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9532\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1670 - out_1_loss: 0.0930 - out_2_loss: 0.0739 - out_1_acc: 0.9486 - out_2_acc: 0.9604 - val_loss: 0.2003 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9539\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1660 - out_1_loss: 0.0926 - out_2_loss: 0.0734 - out_1_acc: 0.9490 - out_2_acc: 0.9605 - val_loss: 0.2010 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0917 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9535\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1649 - out_1_loss: 0.0922 - out_2_loss: 0.0727 - out_1_acc: 0.9492 - out_2_acc: 0.9611 - val_loss: 0.2015 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9540\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1639 - out_1_loss: 0.0919 - out_2_loss: 0.0721 - out_1_acc: 0.9493 - out_2_acc: 0.9615 - val_loss: 0.2019 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9535\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1630 - out_1_loss: 0.0914 - out_2_loss: 0.0715 - out_1_acc: 0.9496 - out_2_acc: 0.9616 - val_loss: 0.2025 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0927 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9537\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1620 - out_1_loss: 0.0910 - out_2_loss: 0.0710 - out_1_acc: 0.9497 - out_2_acc: 0.9618 - val_loss: 0.2030 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0930 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9537\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1608 - out_1_loss: 0.0906 - out_2_loss: 0.0702 - out_1_acc: 0.9498 - out_2_acc: 0.9624 - val_loss: 0.2040 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9535\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1599 - out_1_loss: 0.0902 - out_2_loss: 0.0696 - out_1_acc: 0.9502 - out_2_acc: 0.9623 - val_loss: 0.2042 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9534\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1585 - out_1_loss: 0.0898 - out_2_loss: 0.0687 - out_1_acc: 0.9503 - out_2_acc: 0.9630 - val_loss: 0.2052 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0944 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9536\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1573 - out_1_loss: 0.0894 - out_2_loss: 0.0679 - out_1_acc: 0.9506 - out_2_acc: 0.9633 - val_loss: 0.2059 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9534\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1563 - out_1_loss: 0.0889 - out_2_loss: 0.0673 - out_1_acc: 0.9509 - out_2_acc: 0.9638 - val_loss: 0.2070 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9534\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1550 - out_1_loss: 0.0885 - out_2_loss: 0.0665 - out_1_acc: 0.9515 - out_2_acc: 0.9644 - val_loss: 0.2073 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9540\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1539 - out_1_loss: 0.0881 - out_2_loss: 0.0658 - out_1_acc: 0.9516 - out_2_acc: 0.9649 - val_loss: 0.2084 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0968 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9530\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1522 - out_1_loss: 0.0876 - out_2_loss: 0.0646 - out_1_acc: 0.9521 - out_2_acc: 0.9657 - val_loss: 0.2092 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1511 - out_1_loss: 0.0871 - out_2_loss: 0.0639 - out_1_acc: 0.9523 - out_2_acc: 0.9658 - val_loss: 0.2105 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0984 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1499 - out_1_loss: 0.0867 - out_2_loss: 0.0632 - out_1_acc: 0.9525 - out_2_acc: 0.9662 - val_loss: 0.2114 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.0989 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9533\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1487 - out_1_loss: 0.0863 - out_2_loss: 0.0624 - out_1_acc: 0.9529 - out_2_acc: 0.9666 - val_loss: 0.2128 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9526\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1470 - out_1_loss: 0.0858 - out_2_loss: 0.0612 - out_1_acc: 0.9532 - out_2_acc: 0.9673 - val_loss: 0.2138 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1007 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9536\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1462 - out_1_loss: 0.0854 - out_2_loss: 0.0608 - out_1_acc: 0.9534 - out_2_acc: 0.9673 - val_loss: 0.2156 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1022 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1445 - out_1_loss: 0.0848 - out_2_loss: 0.0597 - out_1_acc: 0.9540 - out_2_acc: 0.9681 - val_loss: 0.2168 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1030 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9531\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1434 - out_1_loss: 0.0844 - out_2_loss: 0.0590 - out_1_acc: 0.9541 - out_2_acc: 0.9681 - val_loss: 0.2182 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.1040 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9529\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1419 - out_1_loss: 0.0839 - out_2_loss: 0.0580 - out_1_acc: 0.9547 - out_2_acc: 0.9691 - val_loss: 0.2196 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9533\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1408 - out_1_loss: 0.0834 - out_2_loss: 0.0574 - out_1_acc: 0.9549 - out_2_acc: 0.9690 - val_loss: 0.2218 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1068 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9533\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1393 - out_1_loss: 0.0830 - out_2_loss: 0.0563 - out_1_acc: 0.9551 - out_2_acc: 0.9698 - val_loss: 0.2234 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1079 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9532\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1382 - out_1_loss: 0.0825 - out_2_loss: 0.0557 - out_1_acc: 0.9555 - out_2_acc: 0.9700 - val_loss: 0.2252 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1093 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9535\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1375 - out_1_loss: 0.0821 - out_2_loss: 0.0555 - out_1_acc: 0.9558 - out_2_acc: 0.9702 - val_loss: 0.2270 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.1106 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9535\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1360 - out_1_loss: 0.0816 - out_2_loss: 0.0544 - out_1_acc: 0.9561 - out_2_acc: 0.9711 - val_loss: 0.2295 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.1127 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9541\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1346 - out_1_loss: 0.0811 - out_2_loss: 0.0536 - out_1_acc: 0.9564 - out_2_acc: 0.9714 - val_loss: 0.2323 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1149 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9538\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1335 - out_1_loss: 0.0806 - out_2_loss: 0.0529 - out_1_acc: 0.9569 - out_2_acc: 0.9716 - val_loss: 0.2343 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1163 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9541\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1322 - out_1_loss: 0.0801 - out_2_loss: 0.0521 - out_1_acc: 0.9571 - out_2_acc: 0.9722 - val_loss: 0.2369 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1184 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9532\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1309 - out_1_loss: 0.0796 - out_2_loss: 0.0513 - out_1_acc: 0.9573 - out_2_acc: 0.9724 - val_loss: 0.2390 - val_out_1_loss: 0.1187 - val_out_2_loss: 0.1203 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9534\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1298 - out_1_loss: 0.0791 - out_2_loss: 0.0507 - out_1_acc: 0.9579 - out_2_acc: 0.9730 - val_loss: 0.2414 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1220 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9535\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1287 - out_1_loss: 0.0787 - out_2_loss: 0.0500 - out_1_acc: 0.9577 - out_2_acc: 0.9733 - val_loss: 0.2441 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.1240 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9537\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1279 - out_1_loss: 0.0783 - out_2_loss: 0.0496 - out_1_acc: 0.9583 - out_2_acc: 0.9735 - val_loss: 0.2463 - val_out_1_loss: 0.1211 - val_out_2_loss: 0.1252 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9539\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1269 - out_1_loss: 0.0778 - out_2_loss: 0.0491 - out_1_acc: 0.9586 - out_2_acc: 0.9737 - val_loss: 0.2495 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1279 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9536\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1256 - out_1_loss: 0.0772 - out_2_loss: 0.0484 - out_1_acc: 0.9589 - out_2_acc: 0.9738 - val_loss: 0.2518 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1301 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9534\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1249 - out_1_loss: 0.0767 - out_2_loss: 0.0482 - out_1_acc: 0.9590 - out_2_acc: 0.9739 - val_loss: 0.2548 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.1322 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9534\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1244 - out_1_loss: 0.0762 - out_2_loss: 0.0482 - out_1_acc: 0.9592 - out_2_acc: 0.9741 - val_loss: 0.2545 - val_out_1_loss: 0.1230 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9524\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1239 - out_1_loss: 0.0760 - out_2_loss: 0.0479 - out_1_acc: 0.9596 - out_2_acc: 0.9740 - val_loss: 0.2542 - val_out_1_loss: 0.1232 - val_out_2_loss: 0.1310 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1227 - out_1_loss: 0.0752 - out_2_loss: 0.0476 - out_1_acc: 0.9603 - out_2_acc: 0.9742 - val_loss: 0.2547 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1314 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9528\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1215 - out_1_loss: 0.0747 - out_2_loss: 0.0467 - out_1_acc: 0.9606 - out_2_acc: 0.9745 - val_loss: 0.2573 - val_out_1_loss: 0.1240 - val_out_2_loss: 0.1333 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1205 - out_1_loss: 0.0741 - out_2_loss: 0.0464 - out_1_acc: 0.9609 - out_2_acc: 0.9748 - val_loss: 0.2579 - val_out_1_loss: 0.1241 - val_out_2_loss: 0.1338 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9531\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1196 - out_1_loss: 0.0738 - out_2_loss: 0.0459 - out_1_acc: 0.9611 - out_2_acc: 0.9752 - val_loss: 0.2602 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.1356 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9529\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1184 - out_1_loss: 0.0731 - out_2_loss: 0.0453 - out_1_acc: 0.9612 - out_2_acc: 0.9755 - val_loss: 0.2626 - val_out_1_loss: 0.1255 - val_out_2_loss: 0.1371 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1170 - out_1_loss: 0.0727 - out_2_loss: 0.0442 - out_1_acc: 0.9617 - out_2_acc: 0.9765 - val_loss: 0.2641 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1385 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9530\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1165 - out_1_loss: 0.0723 - out_2_loss: 0.0442 - out_1_acc: 0.9619 - out_2_acc: 0.9762 - val_loss: 0.2674 - val_out_1_loss: 0.1265 - val_out_2_loss: 0.1409 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1153 - out_1_loss: 0.0719 - out_2_loss: 0.0434 - out_1_acc: 0.9624 - out_2_acc: 0.9772 - val_loss: 0.2689 - val_out_1_loss: 0.1270 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9529\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1145 - out_1_loss: 0.0715 - out_2_loss: 0.0430 - out_1_acc: 0.9627 - out_2_acc: 0.9771 - val_loss: 0.2710 - val_out_1_loss: 0.1280 - val_out_2_loss: 0.1431 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9530\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1138 - out_1_loss: 0.0711 - out_2_loss: 0.0426 - out_1_acc: 0.9628 - out_2_acc: 0.9773 - val_loss: 0.2726 - val_out_1_loss: 0.1288 - val_out_2_loss: 0.1438 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9533\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1132 - out_1_loss: 0.0707 - out_2_loss: 0.0425 - out_1_acc: 0.9631 - out_2_acc: 0.9777 - val_loss: 0.2758 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1466 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9535\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1126 - out_1_loss: 0.0702 - out_2_loss: 0.0424 - out_1_acc: 0.9635 - out_2_acc: 0.9777 - val_loss: 0.2786 - val_out_1_loss: 0.1302 - val_out_2_loss: 0.1484 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1117 - out_1_loss: 0.0698 - out_2_loss: 0.0420 - out_1_acc: 0.9638 - out_2_acc: 0.9777 - val_loss: 0.2799 - val_out_1_loss: 0.1311 - val_out_2_loss: 0.1488 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9533\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1113 - out_1_loss: 0.0695 - out_2_loss: 0.0418 - out_1_acc: 0.9639 - out_2_acc: 0.9781 - val_loss: 0.2829 - val_out_1_loss: 0.1314 - val_out_2_loss: 0.1515 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9529\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1109 - out_1_loss: 0.0690 - out_2_loss: 0.0419 - out_1_acc: 0.9642 - out_2_acc: 0.9780 - val_loss: 0.2833 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1512 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9522\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1107 - out_1_loss: 0.0689 - out_2_loss: 0.0418 - out_1_acc: 0.9642 - out_2_acc: 0.9777 - val_loss: 0.2860 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1530 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1102 - out_1_loss: 0.0684 - out_2_loss: 0.0418 - out_1_acc: 0.9645 - out_2_acc: 0.9780 - val_loss: 0.2876 - val_out_1_loss: 0.1332 - val_out_2_loss: 0.1544 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1091 - out_1_loss: 0.0678 - out_2_loss: 0.0413 - out_1_acc: 0.9651 - out_2_acc: 0.9784 - val_loss: 0.2880 - val_out_1_loss: 0.1339 - val_out_2_loss: 0.1541 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1088 - out_1_loss: 0.0674 - out_2_loss: 0.0414 - out_1_acc: 0.9651 - out_2_acc: 0.9787 - val_loss: 0.2885 - val_out_1_loss: 0.1343 - val_out_2_loss: 0.1542 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1080 - out_1_loss: 0.0672 - out_2_loss: 0.0408 - out_1_acc: 0.9650 - out_2_acc: 0.9790 - val_loss: 0.2908 - val_out_1_loss: 0.1356 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1077 - out_1_loss: 0.0667 - out_2_loss: 0.0410 - out_1_acc: 0.9653 - out_2_acc: 0.9785 - val_loss: 0.2917 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1562 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1065 - out_1_loss: 0.0661 - out_2_loss: 0.0404 - out_1_acc: 0.9655 - out_2_acc: 0.9791 - val_loss: 0.2915 - val_out_1_loss: 0.1365 - val_out_2_loss: 0.1551 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1059 - out_1_loss: 0.0659 - out_2_loss: 0.0400 - out_1_acc: 0.9657 - out_2_acc: 0.9793 - val_loss: 0.2945 - val_out_1_loss: 0.1377 - val_out_2_loss: 0.1568 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1050 - out_1_loss: 0.0656 - out_2_loss: 0.0394 - out_1_acc: 0.9660 - out_2_acc: 0.9795 - val_loss: 0.2946 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1574 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1035 - out_1_loss: 0.0650 - out_2_loss: 0.0385 - out_1_acc: 0.9663 - out_2_acc: 0.9803 - val_loss: 0.2989 - val_out_1_loss: 0.1383 - val_out_2_loss: 0.1606 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1025 - out_1_loss: 0.0645 - out_2_loss: 0.0379 - out_1_acc: 0.9668 - out_2_acc: 0.9805 - val_loss: 0.3001 - val_out_1_loss: 0.1386 - val_out_2_loss: 0.1615 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1019 - out_1_loss: 0.0642 - out_2_loss: 0.0378 - out_1_acc: 0.9670 - out_2_acc: 0.9804 - val_loss: 0.3010 - val_out_1_loss: 0.1392 - val_out_2_loss: 0.1618 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1011 - out_1_loss: 0.0639 - out_2_loss: 0.0372 - out_1_acc: 0.9669 - out_2_acc: 0.9805 - val_loss: 0.3035 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1638 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.1007 - out_1_loss: 0.0635 - out_2_loss: 0.0372 - out_1_acc: 0.9670 - out_2_acc: 0.9807 - val_loss: 0.3047 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1649 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0996 - out_1_loss: 0.0629 - out_2_loss: 0.0367 - out_1_acc: 0.9673 - out_2_acc: 0.9810 - val_loss: 0.3058 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1653 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0991 - out_1_loss: 0.0626 - out_2_loss: 0.0365 - out_1_acc: 0.9676 - out_2_acc: 0.9816 - val_loss: 0.3058 - val_out_1_loss: 0.1403 - val_out_2_loss: 0.1655 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0981 - out_1_loss: 0.0621 - out_2_loss: 0.0360 - out_1_acc: 0.9677 - out_2_acc: 0.9818 - val_loss: 0.3078 - val_out_1_loss: 0.1409 - val_out_2_loss: 0.1669 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9514\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0978 - out_1_loss: 0.0615 - out_2_loss: 0.0364 - out_1_acc: 0.9682 - out_2_acc: 0.9818 - val_loss: 0.3108 - val_out_1_loss: 0.1417 - val_out_2_loss: 0.1691 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9518\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0985 - out_1_loss: 0.0612 - out_2_loss: 0.0373 - out_1_acc: 0.9685 - out_2_acc: 0.9812 - val_loss: 0.3145 - val_out_1_loss: 0.1436 - val_out_2_loss: 0.1709 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9511\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0974 - out_1_loss: 0.0611 - out_2_loss: 0.0363 - out_1_acc: 0.9686 - out_2_acc: 0.9818 - val_loss: 0.3144 - val_out_1_loss: 0.1447 - val_out_2_loss: 0.1697 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0968 - out_1_loss: 0.0610 - out_2_loss: 0.0358 - out_1_acc: 0.9683 - out_2_acc: 0.9820 - val_loss: 0.3197 - val_out_1_loss: 0.1474 - val_out_2_loss: 0.1723 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9511\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0973 - out_1_loss: 0.0613 - out_2_loss: 0.0360 - out_1_acc: 0.9683 - out_2_acc: 0.9819 - val_loss: 0.3240 - val_out_1_loss: 0.1489 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0966 - out_1_loss: 0.0609 - out_2_loss: 0.0356 - out_1_acc: 0.9685 - out_2_acc: 0.9821 - val_loss: 0.3268 - val_out_1_loss: 0.1493 - val_out_2_loss: 0.1775 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9519\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0972 - out_1_loss: 0.0609 - out_2_loss: 0.0363 - out_1_acc: 0.9683 - out_2_acc: 0.9816 - val_loss: 0.3236 - val_out_1_loss: 0.1484 - val_out_2_loss: 0.1753 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0956 - out_1_loss: 0.0600 - out_2_loss: 0.0356 - out_1_acc: 0.9690 - out_2_acc: 0.9822 - val_loss: 0.3246 - val_out_1_loss: 0.1492 - val_out_2_loss: 0.1754 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0951 - out_1_loss: 0.0596 - out_2_loss: 0.0355 - out_1_acc: 0.9692 - out_2_acc: 0.9822 - val_loss: 0.3252 - val_out_1_loss: 0.1503 - val_out_2_loss: 0.1749 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0945 - out_1_loss: 0.0590 - out_2_loss: 0.0355 - out_1_acc: 0.9698 - out_2_acc: 0.9821 - val_loss: 0.3294 - val_out_1_loss: 0.1519 - val_out_2_loss: 0.1775 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9519\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0940 - out_1_loss: 0.0589 - out_2_loss: 0.0352 - out_1_acc: 0.9701 - out_2_acc: 0.9822 - val_loss: 0.3296 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1767 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9523\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0938 - out_1_loss: 0.0582 - out_2_loss: 0.0356 - out_1_acc: 0.9703 - out_2_acc: 0.9824 - val_loss: 0.3329 - val_out_1_loss: 0.1544 - val_out_2_loss: 0.1786 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0923 - out_1_loss: 0.0582 - out_2_loss: 0.0341 - out_1_acc: 0.9702 - out_2_acc: 0.9829 - val_loss: 0.3332 - val_out_1_loss: 0.1549 - val_out_2_loss: 0.1783 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9521\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0923 - out_1_loss: 0.0581 - out_2_loss: 0.0342 - out_1_acc: 0.9703 - out_2_acc: 0.9834 - val_loss: 0.3366 - val_out_1_loss: 0.1561 - val_out_2_loss: 0.1805 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9509\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0917 - out_1_loss: 0.0578 - out_2_loss: 0.0339 - out_1_acc: 0.9703 - out_2_acc: 0.9832 - val_loss: 0.3402 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1820 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0927 - out_1_loss: 0.0581 - out_2_loss: 0.0346 - out_1_acc: 0.9700 - out_2_acc: 0.9830 - val_loss: 0.3379 - val_out_1_loss: 0.1578 - val_out_2_loss: 0.1801 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9521\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0909 - out_1_loss: 0.0575 - out_2_loss: 0.0335 - out_1_acc: 0.9707 - out_2_acc: 0.9836 - val_loss: 0.3451 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1845 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0908 - out_1_loss: 0.0575 - out_2_loss: 0.0333 - out_1_acc: 0.9706 - out_2_acc: 0.9840 - val_loss: 0.3461 - val_out_1_loss: 0.1604 - val_out_2_loss: 0.1857 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9518\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0921 - out_1_loss: 0.0578 - out_2_loss: 0.0342 - out_1_acc: 0.9701 - out_2_acc: 0.9835 - val_loss: 0.3421 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1815 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9517\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0910 - out_1_loss: 0.0576 - out_2_loss: 0.0335 - out_1_acc: 0.9706 - out_2_acc: 0.9834 - val_loss: 0.3439 - val_out_1_loss: 0.1589 - val_out_2_loss: 0.1850 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0895 - out_1_loss: 0.0565 - out_2_loss: 0.0331 - out_1_acc: 0.9711 - out_2_acc: 0.9842 - val_loss: 0.3454 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1848 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0884 - out_1_loss: 0.0560 - out_2_loss: 0.0324 - out_1_acc: 0.9717 - out_2_acc: 0.9843 - val_loss: 0.3485 - val_out_1_loss: 0.1614 - val_out_2_loss: 0.1872 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9521\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0885 - out_1_loss: 0.0562 - out_2_loss: 0.0323 - out_1_acc: 0.9715 - out_2_acc: 0.9839 - val_loss: 0.3514 - val_out_1_loss: 0.1634 - val_out_2_loss: 0.1879 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9527\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0882 - out_1_loss: 0.0561 - out_2_loss: 0.0321 - out_1_acc: 0.9718 - out_2_acc: 0.9844 - val_loss: 0.3528 - val_out_1_loss: 0.1626 - val_out_2_loss: 0.1902 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0886 - out_1_loss: 0.0561 - out_2_loss: 0.0325 - out_1_acc: 0.9716 - out_2_acc: 0.9840 - val_loss: 0.3525 - val_out_1_loss: 0.1631 - val_out_2_loss: 0.1893 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9526\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0869 - out_1_loss: 0.0556 - out_2_loss: 0.0313 - out_1_acc: 0.9719 - out_2_acc: 0.9848 - val_loss: 0.3523 - val_out_1_loss: 0.1635 - val_out_2_loss: 0.1887 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9523\n",
      "Epoch 136/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0858 - out_1_loss: 0.0554 - out_2_loss: 0.0303 - out_1_acc: 0.9723 - out_2_acc: 0.9854 - val_loss: 0.3578 - val_out_1_loss: 0.1643 - val_out_2_loss: 0.1936 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0851 - out_1_loss: 0.0547 - out_2_loss: 0.0304 - out_1_acc: 0.9725 - out_2_acc: 0.9852 - val_loss: 0.3559 - val_out_1_loss: 0.1648 - val_out_2_loss: 0.1911 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0841 - out_1_loss: 0.0543 - out_2_loss: 0.0298 - out_1_acc: 0.9729 - out_2_acc: 0.9857 - val_loss: 0.3564 - val_out_1_loss: 0.1642 - val_out_2_loss: 0.1922 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0849 - out_1_loss: 0.0545 - out_2_loss: 0.0304 - out_1_acc: 0.9728 - out_2_acc: 0.9856 - val_loss: 0.3582 - val_out_1_loss: 0.1648 - val_out_2_loss: 0.1934 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0845 - out_1_loss: 0.0547 - out_2_loss: 0.0298 - out_1_acc: 0.9723 - out_2_acc: 0.9856 - val_loss: 0.3563 - val_out_1_loss: 0.1647 - val_out_2_loss: 0.1916 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0833 - out_1_loss: 0.0543 - out_2_loss: 0.0290 - out_1_acc: 0.9729 - out_2_acc: 0.9861 - val_loss: 0.3591 - val_out_1_loss: 0.1647 - val_out_2_loss: 0.1944 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0826 - out_1_loss: 0.0542 - out_2_loss: 0.0284 - out_1_acc: 0.9730 - out_2_acc: 0.9865 - val_loss: 0.3580 - val_out_1_loss: 0.1638 - val_out_2_loss: 0.1942 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0822 - out_1_loss: 0.0537 - out_2_loss: 0.0285 - out_1_acc: 0.9736 - out_2_acc: 0.9866 - val_loss: 0.3616 - val_out_1_loss: 0.1655 - val_out_2_loss: 0.1962 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9525\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0821 - out_1_loss: 0.0537 - out_2_loss: 0.0284 - out_1_acc: 0.9732 - out_2_acc: 0.9868 - val_loss: 0.3606 - val_out_1_loss: 0.1652 - val_out_2_loss: 0.1954 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0811 - out_1_loss: 0.0528 - out_2_loss: 0.0283 - out_1_acc: 0.9738 - out_2_acc: 0.9865 - val_loss: 0.3653 - val_out_1_loss: 0.1661 - val_out_2_loss: 0.1993 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0807 - out_1_loss: 0.0529 - out_2_loss: 0.0278 - out_1_acc: 0.9739 - out_2_acc: 0.9870 - val_loss: 0.3683 - val_out_1_loss: 0.1669 - val_out_2_loss: 0.2014 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9521\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0794 - out_1_loss: 0.0519 - out_2_loss: 0.0276 - out_1_acc: 0.9745 - out_2_acc: 0.9872 - val_loss: 0.3692 - val_out_1_loss: 0.1677 - val_out_2_loss: 0.2015 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0784 - out_1_loss: 0.0513 - out_2_loss: 0.0272 - out_1_acc: 0.9746 - out_2_acc: 0.9876 - val_loss: 0.3700 - val_out_1_loss: 0.1682 - val_out_2_loss: 0.2017 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9534\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0795 - out_1_loss: 0.0512 - out_2_loss: 0.0282 - out_1_acc: 0.9748 - out_2_acc: 0.9866 - val_loss: 0.3743 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.2051 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 0.0785 - out_1_loss: 0.0512 - out_2_loss: 0.0273 - out_1_acc: 0.9748 - out_2_acc: 0.9874 - val_loss: 0.3791 - val_out_1_loss: 0.1700 - val_out_2_loss: 0.2091 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "WARNING:tensorflow:From /home/alanhc-school/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(3)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3551 - out_1_loss: 0.1580 - out_2_loss: 0.1972 - out_1_acc: 0.9437 - out_2_acc: 0.9533\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 100), (No 64400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 100)       64400       input_2[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 317,880\n",
      "Trainable params: 317,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3750 - out_1_loss: 3.6841 - out_2_loss: 3.6909 - out_1_acc: 0.0270 - out_2_acc: 0.0078WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109631). Check your callbacks.\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 6.6382 - out_1_loss: 3.4354 - out_2_loss: 3.2028 - out_1_acc: 0.4540 - out_2_acc: 0.5661 - val_loss: 4.9044 - val_out_1_loss: 2.8524 - val_out_2_loss: 2.0520 - val_out_1_acc: 0.4825 - val_out_2_acc: 0.6515\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 2.8541 - out_1_loss: 1.8742 - out_2_loss: 0.9800 - out_1_acc: 0.6183 - out_2_acc: 0.8207 - val_loss: 1.3382 - val_out_1_loss: 0.9533 - val_out_2_loss: 0.3848 - val_out_1_acc: 0.8097 - val_out_2_acc: 0.9323\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9294 - out_1_loss: 0.6568 - out_2_loss: 0.2726 - out_1_acc: 0.8846 - out_2_acc: 0.9484 - val_loss: 0.6748 - val_out_1_loss: 0.4622 - val_out_2_loss: 0.2126 - val_out_1_acc: 0.9168 - val_out_2_acc: 0.9491\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5614 - out_1_loss: 0.3898 - out_2_loss: 0.1716 - out_1_acc: 0.9242 - out_2_acc: 0.9517 - val_loss: 0.4832 - val_out_1_loss: 0.3236 - val_out_2_loss: 0.1595 - val_out_1_acc: 0.9306 - val_out_2_acc: 0.9494\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4159 - out_1_loss: 0.2790 - out_2_loss: 0.1369 - out_1_acc: 0.9342 - out_2_acc: 0.9518 - val_loss: 0.3761 - val_out_1_loss: 0.2409 - val_out_2_loss: 0.1352 - val_out_1_acc: 0.9375 - val_out_2_acc: 0.9498\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3276 - out_1_loss: 0.2089 - out_2_loss: 0.1186 - out_1_acc: 0.9386 - out_2_acc: 0.9521 - val_loss: 0.3082 - val_out_1_loss: 0.1889 - val_out_2_loss: 0.1194 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9503\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2726 - out_1_loss: 0.1658 - out_2_loss: 0.1068 - out_1_acc: 0.9403 - out_2_acc: 0.9521 - val_loss: 0.2693 - val_out_1_loss: 0.1597 - val_out_2_loss: 0.1096 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9511\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2413 - out_1_loss: 0.1423 - out_2_loss: 0.0990 - out_1_acc: 0.9408 - out_2_acc: 0.9528 - val_loss: 0.2468 - val_out_1_loss: 0.1439 - val_out_2_loss: 0.1029 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9505\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2235 - out_1_loss: 0.1296 - out_2_loss: 0.0939 - out_1_acc: 0.9413 - out_2_acc: 0.9532 - val_loss: 0.2330 - val_out_1_loss: 0.1347 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9505\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2126 - out_1_loss: 0.1222 - out_2_loss: 0.0904 - out_1_acc: 0.9417 - out_2_acc: 0.9531 - val_loss: 0.2242 - val_out_1_loss: 0.1289 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9502\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2056 - out_1_loss: 0.1174 - out_2_loss: 0.0882 - out_1_acc: 0.9420 - out_2_acc: 0.9532 - val_loss: 0.2180 - val_out_1_loss: 0.1248 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9503\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2007 - out_1_loss: 0.1141 - out_2_loss: 0.0866 - out_1_acc: 0.9423 - out_2_acc: 0.9535 - val_loss: 0.2134 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.0918 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9506\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1969 - out_1_loss: 0.1116 - out_2_loss: 0.0854 - out_1_acc: 0.9426 - out_2_acc: 0.9537 - val_loss: 0.2099 - val_out_1_loss: 0.1191 - val_out_2_loss: 0.0908 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9508\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1940 - out_1_loss: 0.1095 - out_2_loss: 0.0845 - out_1_acc: 0.9427 - out_2_acc: 0.9542 - val_loss: 0.2071 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.0901 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9505\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1916 - out_1_loss: 0.1078 - out_2_loss: 0.0838 - out_1_acc: 0.9430 - out_2_acc: 0.9543 - val_loss: 0.2049 - val_out_1_loss: 0.1154 - val_out_2_loss: 0.0896 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9504\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1896 - out_1_loss: 0.1063 - out_2_loss: 0.0832 - out_1_acc: 0.9433 - out_2_acc: 0.9546 - val_loss: 0.2033 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9509\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1878 - out_1_loss: 0.1051 - out_2_loss: 0.0828 - out_1_acc: 0.9434 - out_2_acc: 0.9549 - val_loss: 0.2020 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9510\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1863 - out_1_loss: 0.1040 - out_2_loss: 0.0823 - out_1_acc: 0.9436 - out_2_acc: 0.9551 - val_loss: 0.2010 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9514\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1850 - out_1_loss: 0.1030 - out_2_loss: 0.0820 - out_1_acc: 0.9437 - out_2_acc: 0.9553 - val_loss: 0.2001 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9515\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1838 - out_1_loss: 0.1022 - out_2_loss: 0.0816 - out_1_acc: 0.9440 - out_2_acc: 0.9554 - val_loss: 0.1995 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1827 - out_1_loss: 0.1014 - out_2_loss: 0.0813 - out_1_acc: 0.9440 - out_2_acc: 0.9556 - val_loss: 0.1989 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1817 - out_1_loss: 0.1008 - out_2_loss: 0.0810 - out_1_acc: 0.9443 - out_2_acc: 0.9556 - val_loss: 0.1985 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1809 - out_1_loss: 0.1002 - out_2_loss: 0.0807 - out_1_acc: 0.9446 - out_2_acc: 0.9558 - val_loss: 0.1982 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1800 - out_1_loss: 0.0996 - out_2_loss: 0.0803 - out_1_acc: 0.9448 - out_2_acc: 0.9561 - val_loss: 0.1980 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9521\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1791 - out_1_loss: 0.0991 - out_2_loss: 0.0800 - out_1_acc: 0.9450 - out_2_acc: 0.9563 - val_loss: 0.1978 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1784 - out_1_loss: 0.0986 - out_2_loss: 0.0797 - out_1_acc: 0.9454 - out_2_acc: 0.9566 - val_loss: 0.1979 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1776 - out_1_loss: 0.0982 - out_2_loss: 0.0794 - out_1_acc: 0.9456 - out_2_acc: 0.9566 - val_loss: 0.1978 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0893 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1768 - out_1_loss: 0.0977 - out_2_loss: 0.0790 - out_1_acc: 0.9459 - out_2_acc: 0.9568 - val_loss: 0.1977 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0893 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1760 - out_1_loss: 0.0973 - out_2_loss: 0.0787 - out_1_acc: 0.9459 - out_2_acc: 0.9570 - val_loss: 0.1976 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0894 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1753 - out_1_loss: 0.0970 - out_2_loss: 0.0784 - out_1_acc: 0.9461 - out_2_acc: 0.9572 - val_loss: 0.1978 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1745 - out_1_loss: 0.0966 - out_2_loss: 0.0779 - out_1_acc: 0.9463 - out_2_acc: 0.9574 - val_loss: 0.1980 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1737 - out_1_loss: 0.0962 - out_2_loss: 0.0775 - out_1_acc: 0.9466 - out_2_acc: 0.9577 - val_loss: 0.1983 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0902 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9519\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1729 - out_1_loss: 0.0958 - out_2_loss: 0.0771 - out_1_acc: 0.9465 - out_2_acc: 0.9579 - val_loss: 0.1984 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1720 - out_1_loss: 0.0955 - out_2_loss: 0.0766 - out_1_acc: 0.9469 - out_2_acc: 0.9587 - val_loss: 0.1984 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1712 - out_1_loss: 0.0951 - out_2_loss: 0.0761 - out_1_acc: 0.9470 - out_2_acc: 0.9589 - val_loss: 0.1989 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0909 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1703 - out_1_loss: 0.0948 - out_2_loss: 0.0755 - out_1_acc: 0.9471 - out_2_acc: 0.9593 - val_loss: 0.1993 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1695 - out_1_loss: 0.0944 - out_2_loss: 0.0750 - out_1_acc: 0.9474 - out_2_acc: 0.9596 - val_loss: 0.1995 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1686 - out_1_loss: 0.0941 - out_2_loss: 0.0745 - out_1_acc: 0.9475 - out_2_acc: 0.9595 - val_loss: 0.1999 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0918 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9519\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1676 - out_1_loss: 0.0937 - out_2_loss: 0.0739 - out_1_acc: 0.9477 - out_2_acc: 0.9603 - val_loss: 0.2003 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1666 - out_1_loss: 0.0934 - out_2_loss: 0.0732 - out_1_acc: 0.9478 - out_2_acc: 0.9604 - val_loss: 0.2010 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0926 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1657 - out_1_loss: 0.0930 - out_2_loss: 0.0727 - out_1_acc: 0.9482 - out_2_acc: 0.9610 - val_loss: 0.2014 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0930 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1646 - out_1_loss: 0.0926 - out_2_loss: 0.0719 - out_1_acc: 0.9485 - out_2_acc: 0.9612 - val_loss: 0.2017 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0933 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1636 - out_1_loss: 0.0923 - out_2_loss: 0.0713 - out_1_acc: 0.9486 - out_2_acc: 0.9619 - val_loss: 0.2026 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1625 - out_1_loss: 0.0919 - out_2_loss: 0.0706 - out_1_acc: 0.9489 - out_2_acc: 0.9622 - val_loss: 0.2031 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0944 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1613 - out_1_loss: 0.0915 - out_2_loss: 0.0698 - out_1_acc: 0.9490 - out_2_acc: 0.9628 - val_loss: 0.2037 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0948 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1601 - out_1_loss: 0.0911 - out_2_loss: 0.0690 - out_1_acc: 0.9493 - out_2_acc: 0.9628 - val_loss: 0.2044 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9527\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1591 - out_1_loss: 0.0907 - out_2_loss: 0.0683 - out_1_acc: 0.9495 - out_2_acc: 0.9632 - val_loss: 0.2056 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1578 - out_1_loss: 0.0903 - out_2_loss: 0.0676 - out_1_acc: 0.9498 - out_2_acc: 0.9638 - val_loss: 0.2065 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0971 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1565 - out_1_loss: 0.0899 - out_2_loss: 0.0666 - out_1_acc: 0.9501 - out_2_acc: 0.9641 - val_loss: 0.2072 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9525\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1553 - out_1_loss: 0.0895 - out_2_loss: 0.0659 - out_1_acc: 0.9502 - out_2_acc: 0.9647 - val_loss: 0.2080 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9531\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1541 - out_1_loss: 0.0891 - out_2_loss: 0.0651 - out_1_acc: 0.9507 - out_2_acc: 0.9649 - val_loss: 0.2093 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9524\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1530 - out_1_loss: 0.0886 - out_2_loss: 0.0643 - out_1_acc: 0.9508 - out_2_acc: 0.9648 - val_loss: 0.2103 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9530\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1517 - out_1_loss: 0.0882 - out_2_loss: 0.0635 - out_1_acc: 0.9513 - out_2_acc: 0.9651 - val_loss: 0.2113 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9514\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1506 - out_1_loss: 0.0877 - out_2_loss: 0.0629 - out_1_acc: 0.9515 - out_2_acc: 0.9658 - val_loss: 0.2125 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1020 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9521\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1491 - out_1_loss: 0.0874 - out_2_loss: 0.0618 - out_1_acc: 0.9520 - out_2_acc: 0.9666 - val_loss: 0.2134 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.1026 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9517\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1476 - out_1_loss: 0.0869 - out_2_loss: 0.0607 - out_1_acc: 0.9521 - out_2_acc: 0.9671 - val_loss: 0.2152 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9522\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1463 - out_1_loss: 0.0864 - out_2_loss: 0.0599 - out_1_acc: 0.9525 - out_2_acc: 0.9676 - val_loss: 0.2168 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.1053 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9521\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1451 - out_1_loss: 0.0860 - out_2_loss: 0.0592 - out_1_acc: 0.9531 - out_2_acc: 0.9681 - val_loss: 0.2182 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1065 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9522\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1438 - out_1_loss: 0.0855 - out_2_loss: 0.0583 - out_1_acc: 0.9531 - out_2_acc: 0.9687 - val_loss: 0.2190 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9424 - val_out_2_acc: 0.9510\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1425 - out_1_loss: 0.0850 - out_2_loss: 0.0575 - out_1_acc: 0.9536 - out_2_acc: 0.9688 - val_loss: 0.2211 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.1087 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9509\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1413 - out_1_loss: 0.0845 - out_2_loss: 0.0568 - out_1_acc: 0.9540 - out_2_acc: 0.9693 - val_loss: 0.2226 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1099 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9520\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1402 - out_1_loss: 0.0841 - out_2_loss: 0.0561 - out_1_acc: 0.9543 - out_2_acc: 0.9697 - val_loss: 0.2246 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1115 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9516\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1390 - out_1_loss: 0.0836 - out_2_loss: 0.0554 - out_1_acc: 0.9548 - out_2_acc: 0.9697 - val_loss: 0.2258 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.1125 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9512\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1377 - out_1_loss: 0.0831 - out_2_loss: 0.0547 - out_1_acc: 0.9550 - out_2_acc: 0.9701 - val_loss: 0.2279 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1142 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1366 - out_1_loss: 0.0826 - out_2_loss: 0.0540 - out_1_acc: 0.9552 - out_2_acc: 0.9710 - val_loss: 0.2287 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1147 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9516\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1356 - out_1_loss: 0.0821 - out_2_loss: 0.0536 - out_1_acc: 0.9555 - out_2_acc: 0.9710 - val_loss: 0.2307 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.1164 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9523\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1343 - out_1_loss: 0.0815 - out_2_loss: 0.0527 - out_1_acc: 0.9562 - out_2_acc: 0.9714 - val_loss: 0.2332 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.1185 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9522\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1334 - out_1_loss: 0.0810 - out_2_loss: 0.0524 - out_1_acc: 0.9562 - out_2_acc: 0.9716 - val_loss: 0.2349 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.1197 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9524\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1322 - out_1_loss: 0.0805 - out_2_loss: 0.0517 - out_1_acc: 0.9568 - out_2_acc: 0.9719 - val_loss: 0.2371 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1212 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1306 - out_1_loss: 0.0800 - out_2_loss: 0.0506 - out_1_acc: 0.9571 - out_2_acc: 0.9726 - val_loss: 0.2415 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.1251 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9514\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1296 - out_1_loss: 0.0796 - out_2_loss: 0.0500 - out_1_acc: 0.9574 - out_2_acc: 0.9727 - val_loss: 0.2428 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.1260 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9513\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1282 - out_1_loss: 0.0790 - out_2_loss: 0.0492 - out_1_acc: 0.9578 - out_2_acc: 0.9729 - val_loss: 0.2445 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1270 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9516\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1272 - out_1_loss: 0.0784 - out_2_loss: 0.0488 - out_1_acc: 0.9581 - out_2_acc: 0.9734 - val_loss: 0.2459 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.1277 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9527\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1265 - out_1_loss: 0.0779 - out_2_loss: 0.0486 - out_1_acc: 0.9588 - out_2_acc: 0.9734 - val_loss: 0.2467 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1284 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9523\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1256 - out_1_loss: 0.0774 - out_2_loss: 0.0482 - out_1_acc: 0.9589 - out_2_acc: 0.9738 - val_loss: 0.2481 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9517\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1239 - out_1_loss: 0.0768 - out_2_loss: 0.0471 - out_1_acc: 0.9595 - out_2_acc: 0.9742 - val_loss: 0.2506 - val_out_1_loss: 0.1193 - val_out_2_loss: 0.1313 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9514\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1226 - out_1_loss: 0.0763 - out_2_loss: 0.0463 - out_1_acc: 0.9596 - out_2_acc: 0.9747 - val_loss: 0.2537 - val_out_1_loss: 0.1199 - val_out_2_loss: 0.1337 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9523\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1220 - out_1_loss: 0.0758 - out_2_loss: 0.0461 - out_1_acc: 0.9598 - out_2_acc: 0.9745 - val_loss: 0.2562 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1355 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9522\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1209 - out_1_loss: 0.0753 - out_2_loss: 0.0457 - out_1_acc: 0.9604 - out_2_acc: 0.9750 - val_loss: 0.2575 - val_out_1_loss: 0.1211 - val_out_2_loss: 0.1365 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9519\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1203 - out_1_loss: 0.0748 - out_2_loss: 0.0455 - out_1_acc: 0.9605 - out_2_acc: 0.9749 - val_loss: 0.2610 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.1394 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9520\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1192 - out_1_loss: 0.0741 - out_2_loss: 0.0451 - out_1_acc: 0.9609 - out_2_acc: 0.9754 - val_loss: 0.2629 - val_out_1_loss: 0.1225 - val_out_2_loss: 0.1404 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9520\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1184 - out_1_loss: 0.0736 - out_2_loss: 0.0448 - out_1_acc: 0.9613 - out_2_acc: 0.9757 - val_loss: 0.2665 - val_out_1_loss: 0.1232 - val_out_2_loss: 0.1433 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9515\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1178 - out_1_loss: 0.0732 - out_2_loss: 0.0446 - out_1_acc: 0.9613 - out_2_acc: 0.9759 - val_loss: 0.2680 - val_out_1_loss: 0.1237 - val_out_2_loss: 0.1443 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9520\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1167 - out_1_loss: 0.0726 - out_2_loss: 0.0440 - out_1_acc: 0.9621 - out_2_acc: 0.9762 - val_loss: 0.2689 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9523\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1154 - out_1_loss: 0.0721 - out_2_loss: 0.0433 - out_1_acc: 0.9622 - out_2_acc: 0.9767 - val_loss: 0.2704 - val_out_1_loss: 0.1249 - val_out_2_loss: 0.1455 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9512\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1147 - out_1_loss: 0.0716 - out_2_loss: 0.0431 - out_1_acc: 0.9625 - out_2_acc: 0.9767 - val_loss: 0.2732 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1475 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9525\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1139 - out_1_loss: 0.0710 - out_2_loss: 0.0429 - out_1_acc: 0.9629 - out_2_acc: 0.9772 - val_loss: 0.2749 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.1483 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9523\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1134 - out_1_loss: 0.0706 - out_2_loss: 0.0427 - out_1_acc: 0.9632 - out_2_acc: 0.9770 - val_loss: 0.2757 - val_out_1_loss: 0.1275 - val_out_2_loss: 0.1482 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9519\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1131 - out_1_loss: 0.0704 - out_2_loss: 0.0426 - out_1_acc: 0.9632 - out_2_acc: 0.9771 - val_loss: 0.2752 - val_out_1_loss: 0.1283 - val_out_2_loss: 0.1469 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9522\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1121 - out_1_loss: 0.0698 - out_2_loss: 0.0423 - out_1_acc: 0.9633 - out_2_acc: 0.9773 - val_loss: 0.2766 - val_out_1_loss: 0.1286 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1113 - out_1_loss: 0.0693 - out_2_loss: 0.0421 - out_1_acc: 0.9640 - out_2_acc: 0.9772 - val_loss: 0.2830 - val_out_1_loss: 0.1300 - val_out_2_loss: 0.1530 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9521\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1108 - out_1_loss: 0.0691 - out_2_loss: 0.0417 - out_1_acc: 0.9638 - out_2_acc: 0.9777 - val_loss: 0.2841 - val_out_1_loss: 0.1302 - val_out_2_loss: 0.1539 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9516\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1103 - out_1_loss: 0.0685 - out_2_loss: 0.0418 - out_1_acc: 0.9640 - out_2_acc: 0.9773 - val_loss: 0.2822 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1515 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9527\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1088 - out_1_loss: 0.0681 - out_2_loss: 0.0407 - out_1_acc: 0.9645 - out_2_acc: 0.9783 - val_loss: 0.2842 - val_out_1_loss: 0.1310 - val_out_2_loss: 0.1531 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1083 - out_1_loss: 0.0674 - out_2_loss: 0.0409 - out_1_acc: 0.9650 - out_2_acc: 0.9782 - val_loss: 0.2885 - val_out_1_loss: 0.1324 - val_out_2_loss: 0.1561 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9518\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1072 - out_1_loss: 0.0667 - out_2_loss: 0.0404 - out_1_acc: 0.9656 - out_2_acc: 0.9785 - val_loss: 0.2883 - val_out_1_loss: 0.1331 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9527\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1063 - out_1_loss: 0.0663 - out_2_loss: 0.0400 - out_1_acc: 0.9660 - out_2_acc: 0.9785 - val_loss: 0.2900 - val_out_1_loss: 0.1337 - val_out_2_loss: 0.1564 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1054 - out_1_loss: 0.0659 - out_2_loss: 0.0395 - out_1_acc: 0.9660 - out_2_acc: 0.9792 - val_loss: 0.2933 - val_out_1_loss: 0.1346 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1045 - out_1_loss: 0.0653 - out_2_loss: 0.0392 - out_1_acc: 0.9663 - out_2_acc: 0.9792 - val_loss: 0.2939 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9523\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1033 - out_1_loss: 0.0649 - out_2_loss: 0.0384 - out_1_acc: 0.9663 - out_2_acc: 0.9798 - val_loss: 0.2997 - val_out_1_loss: 0.1365 - val_out_2_loss: 0.1632 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9521\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1026 - out_1_loss: 0.0644 - out_2_loss: 0.0383 - out_1_acc: 0.9666 - out_2_acc: 0.9800 - val_loss: 0.2999 - val_out_1_loss: 0.1375 - val_out_2_loss: 0.1624 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9516\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1018 - out_1_loss: 0.0639 - out_2_loss: 0.0379 - out_1_acc: 0.9669 - out_2_acc: 0.9799 - val_loss: 0.3025 - val_out_1_loss: 0.1380 - val_out_2_loss: 0.1645 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9516\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1012 - out_1_loss: 0.0634 - out_2_loss: 0.0378 - out_1_acc: 0.9673 - out_2_acc: 0.9804 - val_loss: 0.3025 - val_out_1_loss: 0.1390 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1006 - out_1_loss: 0.0632 - out_2_loss: 0.0374 - out_1_acc: 0.9673 - out_2_acc: 0.9807 - val_loss: 0.3032 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1000 - out_1_loss: 0.0627 - out_2_loss: 0.0372 - out_1_acc: 0.9674 - out_2_acc: 0.9809 - val_loss: 0.3077 - val_out_1_loss: 0.1406 - val_out_2_loss: 0.1671 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9510\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0994 - out_1_loss: 0.0624 - out_2_loss: 0.0370 - out_1_acc: 0.9677 - out_2_acc: 0.9808 - val_loss: 0.3086 - val_out_1_loss: 0.1426 - val_out_2_loss: 0.1660 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9524\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0989 - out_1_loss: 0.0625 - out_2_loss: 0.0364 - out_1_acc: 0.9674 - out_2_acc: 0.9817 - val_loss: 0.3092 - val_out_1_loss: 0.1426 - val_out_2_loss: 0.1667 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9526\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0980 - out_1_loss: 0.0618 - out_2_loss: 0.0362 - out_1_acc: 0.9679 - out_2_acc: 0.9817 - val_loss: 0.3120 - val_out_1_loss: 0.1434 - val_out_2_loss: 0.1686 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9525\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0977 - out_1_loss: 0.0616 - out_2_loss: 0.0360 - out_1_acc: 0.9681 - out_2_acc: 0.9819 - val_loss: 0.3133 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1698 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9524\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0974 - out_1_loss: 0.0613 - out_2_loss: 0.0361 - out_1_acc: 0.9680 - out_2_acc: 0.9815 - val_loss: 0.3122 - val_out_1_loss: 0.1444 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9528\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0960 - out_1_loss: 0.0607 - out_2_loss: 0.0352 - out_1_acc: 0.9687 - out_2_acc: 0.9822 - val_loss: 0.3149 - val_out_1_loss: 0.1447 - val_out_2_loss: 0.1702 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9525\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0956 - out_1_loss: 0.0604 - out_2_loss: 0.0352 - out_1_acc: 0.9687 - out_2_acc: 0.9825 - val_loss: 0.3171 - val_out_1_loss: 0.1462 - val_out_2_loss: 0.1709 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9522\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0960 - out_1_loss: 0.0604 - out_2_loss: 0.0356 - out_1_acc: 0.9692 - out_2_acc: 0.9820 - val_loss: 0.3199 - val_out_1_loss: 0.1482 - val_out_2_loss: 0.1717 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9528\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0957 - out_1_loss: 0.0600 - out_2_loss: 0.0357 - out_1_acc: 0.9690 - out_2_acc: 0.9820 - val_loss: 0.3221 - val_out_1_loss: 0.1496 - val_out_2_loss: 0.1725 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9524\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0948 - out_1_loss: 0.0600 - out_2_loss: 0.0348 - out_1_acc: 0.9692 - out_2_acc: 0.9828 - val_loss: 0.3254 - val_out_1_loss: 0.1501 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9518\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0933 - out_1_loss: 0.0596 - out_2_loss: 0.0337 - out_1_acc: 0.9694 - out_2_acc: 0.9833 - val_loss: 0.3279 - val_out_1_loss: 0.1506 - val_out_2_loss: 0.1774 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9532\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0923 - out_1_loss: 0.0590 - out_2_loss: 0.0333 - out_1_acc: 0.9700 - out_2_acc: 0.9836 - val_loss: 0.3320 - val_out_1_loss: 0.1522 - val_out_2_loss: 0.1798 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9524\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0916 - out_1_loss: 0.0587 - out_2_loss: 0.0329 - out_1_acc: 0.9699 - out_2_acc: 0.9836 - val_loss: 0.3320 - val_out_1_loss: 0.1527 - val_out_2_loss: 0.1793 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9535\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0906 - out_1_loss: 0.0584 - out_2_loss: 0.0322 - out_1_acc: 0.9699 - out_2_acc: 0.9840 - val_loss: 0.3335 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1806 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0898 - out_1_loss: 0.0580 - out_2_loss: 0.0318 - out_1_acc: 0.9701 - out_2_acc: 0.9846 - val_loss: 0.3344 - val_out_1_loss: 0.1537 - val_out_2_loss: 0.1806 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9526\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0897 - out_1_loss: 0.0576 - out_2_loss: 0.0321 - out_1_acc: 0.9705 - out_2_acc: 0.9841 - val_loss: 0.3373 - val_out_1_loss: 0.1548 - val_out_2_loss: 0.1825 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0893 - out_1_loss: 0.0571 - out_2_loss: 0.0322 - out_1_acc: 0.9711 - out_2_acc: 0.9846 - val_loss: 0.3407 - val_out_1_loss: 0.1555 - val_out_2_loss: 0.1852 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0888 - out_1_loss: 0.0566 - out_2_loss: 0.0322 - out_1_acc: 0.9715 - out_2_acc: 0.9847 - val_loss: 0.3438 - val_out_1_loss: 0.1567 - val_out_2_loss: 0.1871 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0894 - out_1_loss: 0.0569 - out_2_loss: 0.0325 - out_1_acc: 0.9711 - out_2_acc: 0.9840 - val_loss: 0.3512 - val_out_1_loss: 0.1596 - val_out_2_loss: 0.1916 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0906 - out_1_loss: 0.0573 - out_2_loss: 0.0333 - out_1_acc: 0.9709 - out_2_acc: 0.9834 - val_loss: 0.3482 - val_out_1_loss: 0.1616 - val_out_2_loss: 0.1865 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0903 - out_1_loss: 0.0574 - out_2_loss: 0.0329 - out_1_acc: 0.9706 - out_2_acc: 0.9838 - val_loss: 0.3527 - val_out_1_loss: 0.1613 - val_out_2_loss: 0.1914 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0894 - out_1_loss: 0.0566 - out_2_loss: 0.0328 - out_1_acc: 0.9711 - out_2_acc: 0.9840 - val_loss: 0.3504 - val_out_1_loss: 0.1610 - val_out_2_loss: 0.1894 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0893 - out_1_loss: 0.0563 - out_2_loss: 0.0331 - out_1_acc: 0.9713 - out_2_acc: 0.9835 - val_loss: 0.3565 - val_out_1_loss: 0.1642 - val_out_2_loss: 0.1923 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0892 - out_1_loss: 0.0562 - out_2_loss: 0.0330 - out_1_acc: 0.9713 - out_2_acc: 0.9836 - val_loss: 0.3572 - val_out_1_loss: 0.1646 - val_out_2_loss: 0.1927 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9518\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0887 - out_1_loss: 0.0559 - out_2_loss: 0.0327 - out_1_acc: 0.9713 - out_2_acc: 0.9837 - val_loss: 0.3559 - val_out_1_loss: 0.1646 - val_out_2_loss: 0.1913 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0882 - out_1_loss: 0.0559 - out_2_loss: 0.0323 - out_1_acc: 0.9713 - out_2_acc: 0.9842 - val_loss: 0.3590 - val_out_1_loss: 0.1653 - val_out_2_loss: 0.1937 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9513\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0876 - out_1_loss: 0.0553 - out_2_loss: 0.0322 - out_1_acc: 0.9720 - out_2_acc: 0.9845 - val_loss: 0.3624 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1953 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9517\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0871 - out_1_loss: 0.0549 - out_2_loss: 0.0322 - out_1_acc: 0.9718 - out_2_acc: 0.9844 - val_loss: 0.3682 - val_out_1_loss: 0.1682 - val_out_2_loss: 0.2000 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9521\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0894 - out_1_loss: 0.0557 - out_2_loss: 0.0337 - out_1_acc: 0.9716 - out_2_acc: 0.9833 - val_loss: 0.3639 - val_out_1_loss: 0.1694 - val_out_2_loss: 0.1944 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9520\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0899 - out_1_loss: 0.0561 - out_2_loss: 0.0338 - out_1_acc: 0.9712 - out_2_acc: 0.9837 - val_loss: 0.3682 - val_out_1_loss: 0.1714 - val_out_2_loss: 0.1968 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0911 - out_1_loss: 0.0562 - out_2_loss: 0.0349 - out_1_acc: 0.9711 - out_2_acc: 0.9829 - val_loss: 0.3655 - val_out_1_loss: 0.1701 - val_out_2_loss: 0.1953 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9529\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0900 - out_1_loss: 0.0555 - out_2_loss: 0.0345 - out_1_acc: 0.9718 - out_2_acc: 0.9829 - val_loss: 0.3634 - val_out_1_loss: 0.1712 - val_out_2_loss: 0.1923 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0891 - out_1_loss: 0.0550 - out_2_loss: 0.0340 - out_1_acc: 0.9722 - out_2_acc: 0.9832 - val_loss: 0.3608 - val_out_1_loss: 0.1710 - val_out_2_loss: 0.1898 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9519\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0870 - out_1_loss: 0.0544 - out_2_loss: 0.0326 - out_1_acc: 0.9729 - out_2_acc: 0.9843 - val_loss: 0.3620 - val_out_1_loss: 0.1711 - val_out_2_loss: 0.1909 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0847 - out_1_loss: 0.0536 - out_2_loss: 0.0312 - out_1_acc: 0.9732 - out_2_acc: 0.9851 - val_loss: 0.3636 - val_out_1_loss: 0.1700 - val_out_2_loss: 0.1936 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0830 - out_1_loss: 0.0530 - out_2_loss: 0.0300 - out_1_acc: 0.9735 - out_2_acc: 0.9856 - val_loss: 0.3666 - val_out_1_loss: 0.1709 - val_out_2_loss: 0.1957 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9529\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0817 - out_1_loss: 0.0525 - out_2_loss: 0.0292 - out_1_acc: 0.9742 - out_2_acc: 0.9860 - val_loss: 0.3680 - val_out_1_loss: 0.1716 - val_out_2_loss: 0.1964 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9522\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0808 - out_1_loss: 0.0521 - out_2_loss: 0.0287 - out_1_acc: 0.9743 - out_2_acc: 0.9862 - val_loss: 0.3688 - val_out_1_loss: 0.1725 - val_out_2_loss: 0.1962 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0804 - out_1_loss: 0.0520 - out_2_loss: 0.0284 - out_1_acc: 0.9743 - out_2_acc: 0.9866 - val_loss: 0.3752 - val_out_1_loss: 0.1741 - val_out_2_loss: 0.2012 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9533\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0804 - out_1_loss: 0.0519 - out_2_loss: 0.0285 - out_1_acc: 0.9739 - out_2_acc: 0.9867 - val_loss: 0.3730 - val_out_1_loss: 0.1738 - val_out_2_loss: 0.1993 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9526\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0791 - out_1_loss: 0.0511 - out_2_loss: 0.0279 - out_1_acc: 0.9749 - out_2_acc: 0.9869 - val_loss: 0.3777 - val_out_1_loss: 0.1755 - val_out_2_loss: 0.2022 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9520\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0786 - out_1_loss: 0.0505 - out_2_loss: 0.0281 - out_1_acc: 0.9753 - out_2_acc: 0.9868 - val_loss: 0.3856 - val_out_1_loss: 0.1766 - val_out_2_loss: 0.2090 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9517\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0780 - out_1_loss: 0.0498 - out_2_loss: 0.0281 - out_1_acc: 0.9755 - out_2_acc: 0.9871 - val_loss: 0.3820 - val_out_1_loss: 0.1768 - val_out_2_loss: 0.2051 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0768 - out_1_loss: 0.0498 - out_2_loss: 0.0270 - out_1_acc: 0.9753 - out_2_acc: 0.9877 - val_loss: 0.3846 - val_out_1_loss: 0.1787 - val_out_2_loss: 0.2060 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9519\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0757 - out_1_loss: 0.0498 - out_2_loss: 0.0259 - out_1_acc: 0.9755 - out_2_acc: 0.9882 - val_loss: 0.3900 - val_out_1_loss: 0.1797 - val_out_2_loss: 0.2103 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0752 - out_1_loss: 0.0493 - out_2_loss: 0.0259 - out_1_acc: 0.9762 - out_2_acc: 0.9882 - val_loss: 0.3920 - val_out_1_loss: 0.1810 - val_out_2_loss: 0.2110 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0737 - out_1_loss: 0.0488 - out_2_loss: 0.0249 - out_1_acc: 0.9763 - out_2_acc: 0.9887 - val_loss: 0.3932 - val_out_1_loss: 0.1813 - val_out_2_loss: 0.2118 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0733 - out_1_loss: 0.0485 - out_2_loss: 0.0249 - out_1_acc: 0.9763 - out_2_acc: 0.9887 - val_loss: 0.3977 - val_out_1_loss: 0.1832 - val_out_2_loss: 0.2144 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0731 - out_1_loss: 0.0483 - out_2_loss: 0.0248 - out_1_acc: 0.9766 - out_2_acc: 0.9891 - val_loss: 0.3986 - val_out_1_loss: 0.1843 - val_out_2_loss: 0.2142 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0737 - out_1_loss: 0.0491 - out_2_loss: 0.0246 - out_1_acc: 0.9757 - out_2_acc: 0.9890 - val_loss: 0.3986 - val_out_1_loss: 0.1835 - val_out_2_loss: 0.2150 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9510\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0742 - out_1_loss: 0.0488 - out_2_loss: 0.0253 - out_1_acc: 0.9759 - out_2_acc: 0.9886 - val_loss: 0.3950 - val_out_1_loss: 0.1823 - val_out_2_loss: 0.2127 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0734 - out_1_loss: 0.0480 - out_2_loss: 0.0255 - out_1_acc: 0.9767 - out_2_acc: 0.9886 - val_loss: 0.3989 - val_out_1_loss: 0.1843 - val_out_2_loss: 0.2146 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0758 - out_1_loss: 0.0490 - out_2_loss: 0.0268 - out_1_acc: 0.9758 - out_2_acc: 0.9878 - val_loss: 0.4072 - val_out_1_loss: 0.1867 - val_out_2_loss: 0.2205 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0751 - out_1_loss: 0.0489 - out_2_loss: 0.0262 - out_1_acc: 0.9761 - out_2_acc: 0.9879 - val_loss: 0.4017 - val_out_1_loss: 0.1861 - val_out_2_loss: 0.2156 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0742 - out_1_loss: 0.0484 - out_2_loss: 0.0258 - out_1_acc: 0.9767 - out_2_acc: 0.9881 - val_loss: 0.4024 - val_out_1_loss: 0.1857 - val_out_2_loss: 0.2167 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9526\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0747 - out_1_loss: 0.0485 - out_2_loss: 0.0263 - out_1_acc: 0.9765 - out_2_acc: 0.9881 - val_loss: 0.4030 - val_out_1_loss: 0.1875 - val_out_2_loss: 0.2155 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9514\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0728 - out_1_loss: 0.0478 - out_2_loss: 0.0249 - out_1_acc: 0.9770 - out_2_acc: 0.9888 - val_loss: 0.4031 - val_out_1_loss: 0.1879 - val_out_2_loss: 0.2152 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9517\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0700 - out_1_loss: 0.0472 - out_2_loss: 0.0228 - out_1_acc: 0.9778 - out_2_acc: 0.9902 - val_loss: 0.4052 - val_out_1_loss: 0.1880 - val_out_2_loss: 0.2172 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9518\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0679 - out_1_loss: 0.0462 - out_2_loss: 0.0217 - out_1_acc: 0.9779 - out_2_acc: 0.9908 - val_loss: 0.4091 - val_out_1_loss: 0.1889 - val_out_2_loss: 0.2202 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0672 - out_1_loss: 0.0460 - out_2_loss: 0.0212 - out_1_acc: 0.9783 - out_2_acc: 0.9909 - val_loss: 0.4143 - val_out_1_loss: 0.1906 - val_out_2_loss: 0.2237 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9535\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0681 - out_1_loss: 0.0465 - out_2_loss: 0.0216 - out_1_acc: 0.9779 - out_2_acc: 0.9909 - val_loss: 0.4175 - val_out_1_loss: 0.1917 - val_out_2_loss: 0.2257 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9527\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0668 - out_1_loss: 0.0457 - out_2_loss: 0.0211 - out_1_acc: 0.9780 - out_2_acc: 0.9911 - val_loss: 0.4163 - val_out_1_loss: 0.1918 - val_out_2_loss: 0.2245 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0663 - out_1_loss: 0.0456 - out_2_loss: 0.0207 - out_1_acc: 0.9783 - out_2_acc: 0.9913 - val_loss: 0.4162 - val_out_1_loss: 0.1918 - val_out_2_loss: 0.2244 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0658 - out_1_loss: 0.0453 - out_2_loss: 0.0204 - out_1_acc: 0.9783 - out_2_acc: 0.9912 - val_loss: 0.4186 - val_out_1_loss: 0.1927 - val_out_2_loss: 0.2259 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9529\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0659 - out_1_loss: 0.0453 - out_2_loss: 0.0206 - out_1_acc: 0.9784 - out_2_acc: 0.9913 - val_loss: 0.4212 - val_out_1_loss: 0.1933 - val_out_2_loss: 0.2279 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0666 - out_1_loss: 0.0452 - out_2_loss: 0.0214 - out_1_acc: 0.9784 - out_2_acc: 0.9910 - val_loss: 0.4178 - val_out_1_loss: 0.1937 - val_out_2_loss: 0.2241 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9520\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0674 - out_1_loss: 0.0456 - out_2_loss: 0.0218 - out_1_acc: 0.9782 - out_2_acc: 0.9904 - val_loss: 0.4209 - val_out_1_loss: 0.1946 - val_out_2_loss: 0.2263 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0662 - out_1_loss: 0.0452 - out_2_loss: 0.0211 - out_1_acc: 0.9788 - out_2_acc: 0.9907 - val_loss: 0.4269 - val_out_1_loss: 0.1972 - val_out_2_loss: 0.2298 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9528\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0653 - out_1_loss: 0.0449 - out_2_loss: 0.0204 - out_1_acc: 0.9790 - out_2_acc: 0.9913 - val_loss: 0.4263 - val_out_1_loss: 0.1973 - val_out_2_loss: 0.2290 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0630 - out_1_loss: 0.0441 - out_2_loss: 0.0190 - out_1_acc: 0.9795 - out_2_acc: 0.9921 - val_loss: 0.4293 - val_out_1_loss: 0.1971 - val_out_2_loss: 0.2321 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0621 - out_1_loss: 0.0433 - out_2_loss: 0.0188 - out_1_acc: 0.9796 - out_2_acc: 0.9922 - val_loss: 0.4332 - val_out_1_loss: 0.1989 - val_out_2_loss: 0.2343 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9516\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0622 - out_1_loss: 0.0432 - out_2_loss: 0.0190 - out_1_acc: 0.9798 - out_2_acc: 0.9918 - val_loss: 0.4316 - val_out_1_loss: 0.2005 - val_out_2_loss: 0.2310 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0597 - out_1_loss: 0.0423 - out_2_loss: 0.0174 - out_1_acc: 0.9802 - out_2_acc: 0.9927 - val_loss: 0.4370 - val_out_1_loss: 0.2020 - val_out_2_loss: 0.2350 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0595 - out_1_loss: 0.0421 - out_2_loss: 0.0174 - out_1_acc: 0.9802 - out_2_acc: 0.9929 - val_loss: 0.4404 - val_out_1_loss: 0.2039 - val_out_2_loss: 0.2365 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9532\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0590 - out_1_loss: 0.0418 - out_2_loss: 0.0172 - out_1_acc: 0.9804 - out_2_acc: 0.9928 - val_loss: 0.4439 - val_out_1_loss: 0.2034 - val_out_2_loss: 0.2405 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0587 - out_1_loss: 0.0416 - out_2_loss: 0.0171 - out_1_acc: 0.9808 - out_2_acc: 0.9932 - val_loss: 0.4430 - val_out_1_loss: 0.2040 - val_out_2_loss: 0.2391 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9528\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0574 - out_1_loss: 0.0410 - out_2_loss: 0.0164 - out_1_acc: 0.9810 - out_2_acc: 0.9933 - val_loss: 0.4426 - val_out_1_loss: 0.2051 - val_out_2_loss: 0.2375 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9532\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0599 - out_1_loss: 0.0414 - out_2_loss: 0.0185 - out_1_acc: 0.9810 - out_2_acc: 0.9926 - val_loss: 0.4417 - val_out_1_loss: 0.2046 - val_out_2_loss: 0.2371 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9530\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0590 - out_1_loss: 0.0413 - out_2_loss: 0.0176 - out_1_acc: 0.9812 - out_2_acc: 0.9925 - val_loss: 0.4445 - val_out_1_loss: 0.2060 - val_out_2_loss: 0.2385 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9524\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0577 - out_1_loss: 0.0413 - out_2_loss: 0.0164 - out_1_acc: 0.9812 - out_2_acc: 0.9932 - val_loss: 0.4486 - val_out_1_loss: 0.2065 - val_out_2_loss: 0.2421 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9526\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0553 - out_1_loss: 0.0403 - out_2_loss: 0.0150 - out_1_acc: 0.9816 - out_2_acc: 0.9940 - val_loss: 0.4535 - val_out_1_loss: 0.2086 - val_out_2_loss: 0.2450 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0541 - out_1_loss: 0.0395 - out_2_loss: 0.0146 - out_1_acc: 0.9821 - out_2_acc: 0.9942 - val_loss: 0.4591 - val_out_1_loss: 0.2093 - val_out_2_loss: 0.2498 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9522\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0538 - out_1_loss: 0.0396 - out_2_loss: 0.0142 - out_1_acc: 0.9819 - out_2_acc: 0.9944 - val_loss: 0.4646 - val_out_1_loss: 0.2113 - val_out_2_loss: 0.2533 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0535 - out_1_loss: 0.0397 - out_2_loss: 0.0138 - out_1_acc: 0.9817 - out_2_acc: 0.9945 - val_loss: 0.4693 - val_out_1_loss: 0.2130 - val_out_2_loss: 0.2563 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9519\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0537 - out_1_loss: 0.0396 - out_2_loss: 0.0142 - out_1_acc: 0.9819 - out_2_acc: 0.9945 - val_loss: 0.4707 - val_out_1_loss: 0.2137 - val_out_2_loss: 0.2571 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0520 - out_1_loss: 0.0389 - out_2_loss: 0.0131 - out_1_acc: 0.9821 - out_2_acc: 0.9947 - val_loss: 0.4790 - val_out_1_loss: 0.2155 - val_out_2_loss: 0.2635 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9519\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0531 - out_1_loss: 0.0391 - out_2_loss: 0.0140 - out_1_acc: 0.9820 - out_2_acc: 0.9944 - val_loss: 0.4777 - val_out_1_loss: 0.2164 - val_out_2_loss: 0.2613 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0546 - out_1_loss: 0.0394 - out_2_loss: 0.0152 - out_1_acc: 0.9818 - out_2_acc: 0.9937 - val_loss: 0.4833 - val_out_1_loss: 0.2185 - val_out_2_loss: 0.2649 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0531 - out_1_loss: 0.0393 - out_2_loss: 0.0138 - out_1_acc: 0.9817 - out_2_acc: 0.9944 - val_loss: 0.4878 - val_out_1_loss: 0.2194 - val_out_2_loss: 0.2683 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0540 - out_1_loss: 0.0394 - out_2_loss: 0.0146 - out_1_acc: 0.9817 - out_2_acc: 0.9940 - val_loss: 0.4900 - val_out_1_loss: 0.2223 - val_out_2_loss: 0.2677 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9522\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0541 - out_1_loss: 0.0388 - out_2_loss: 0.0153 - out_1_acc: 0.9822 - out_2_acc: 0.9938 - val_loss: 0.4902 - val_out_1_loss: 0.2225 - val_out_2_loss: 0.2677 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0519 - out_1_loss: 0.0383 - out_2_loss: 0.0136 - out_1_acc: 0.9825 - out_2_acc: 0.9947 - val_loss: 0.4959 - val_out_1_loss: 0.2237 - val_out_2_loss: 0.2722 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0507 - out_1_loss: 0.0382 - out_2_loss: 0.0125 - out_1_acc: 0.9826 - out_2_acc: 0.9952 - val_loss: 0.4997 - val_out_1_loss: 0.2262 - val_out_2_loss: 0.2735 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0510 - out_1_loss: 0.0381 - out_2_loss: 0.0129 - out_1_acc: 0.9826 - out_2_acc: 0.9948 - val_loss: 0.5030 - val_out_1_loss: 0.2280 - val_out_2_loss: 0.2750 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9526\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0519 - out_1_loss: 0.0380 - out_2_loss: 0.0139 - out_1_acc: 0.9827 - out_2_acc: 0.9944 - val_loss: 0.5069 - val_out_1_loss: 0.2274 - val_out_2_loss: 0.2795 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(3)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4785 - out_1_loss: 0.2143 - out_2_loss: 0.2641 - out_1_acc: 0.9407 - out_2_acc: 0.9525\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 100), (No 64400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 100)       64400       input_3[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 317,880\n",
      "Trainable params: 317,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3619 - out_1_loss: 3.6850 - out_2_loss: 3.6769 - out_1_acc: 0.0327 - out_2_acc: 0.0408WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.110829). Check your callbacks.\n",
      "28/28 [==============================] - 2s 64ms/step - loss: 6.5632 - out_1_loss: 3.4074 - out_2_loss: 3.1559 - out_1_acc: 0.4188 - out_2_acc: 0.4612 - val_loss: 4.8774 - val_out_1_loss: 2.7725 - val_out_2_loss: 2.1050 - val_out_1_acc: 0.4777 - val_out_2_acc: 0.5786\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 2.9026 - out_1_loss: 1.8256 - out_2_loss: 1.0769 - out_1_acc: 0.6249 - out_2_acc: 0.7966 - val_loss: 1.3755 - val_out_1_loss: 0.9788 - val_out_2_loss: 0.3967 - val_out_1_acc: 0.8009 - val_out_2_acc: 0.9329\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.9537 - out_1_loss: 0.6797 - out_2_loss: 0.2740 - out_1_acc: 0.8764 - out_2_acc: 0.9493 - val_loss: 0.6807 - val_out_1_loss: 0.4747 - val_out_2_loss: 0.2060 - val_out_1_acc: 0.9090 - val_out_2_acc: 0.9495\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.5655 - out_1_loss: 0.3967 - out_2_loss: 0.1687 - out_1_acc: 0.9241 - out_2_acc: 0.9520 - val_loss: 0.4840 - val_out_1_loss: 0.3267 - val_out_2_loss: 0.1574 - val_out_1_acc: 0.9294 - val_out_2_acc: 0.9498\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4173 - out_1_loss: 0.2834 - out_2_loss: 0.1340 - out_1_acc: 0.9323 - out_2_acc: 0.9525 - val_loss: 0.3730 - val_out_1_loss: 0.2414 - val_out_2_loss: 0.1316 - val_out_1_acc: 0.9374 - val_out_2_acc: 0.9502\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.3247 - out_1_loss: 0.2099 - out_2_loss: 0.1148 - out_1_acc: 0.9384 - out_2_acc: 0.9528 - val_loss: 0.3030 - val_out_1_loss: 0.1864 - val_out_2_loss: 0.1166 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9500\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2676 - out_1_loss: 0.1640 - out_2_loss: 0.1035 - out_1_acc: 0.9398 - out_2_acc: 0.9525 - val_loss: 0.2631 - val_out_1_loss: 0.1561 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9502\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2364 - out_1_loss: 0.1399 - out_2_loss: 0.0965 - out_1_acc: 0.9402 - out_2_acc: 0.9527 - val_loss: 0.2420 - val_out_1_loss: 0.1410 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9502\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2203 - out_1_loss: 0.1283 - out_2_loss: 0.0920 - out_1_acc: 0.9413 - out_2_acc: 0.9529 - val_loss: 0.2298 - val_out_1_loss: 0.1329 - val_out_2_loss: 0.0969 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9513\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.2108 - out_1_loss: 0.1217 - out_2_loss: 0.0891 - out_1_acc: 0.9417 - out_2_acc: 0.9533 - val_loss: 0.2218 - val_out_1_loss: 0.1278 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9521\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2043 - out_1_loss: 0.1173 - out_2_loss: 0.0870 - out_1_acc: 0.9420 - out_2_acc: 0.9537 - val_loss: 0.2164 - val_out_1_loss: 0.1241 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9521\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1997 - out_1_loss: 0.1140 - out_2_loss: 0.0856 - out_1_acc: 0.9425 - out_2_acc: 0.9538 - val_loss: 0.2124 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9522\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1962 - out_1_loss: 0.1115 - out_2_loss: 0.0847 - out_1_acc: 0.9425 - out_2_acc: 0.9542 - val_loss: 0.2094 - val_out_1_loss: 0.1190 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9521\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1934 - out_1_loss: 0.1094 - out_2_loss: 0.0840 - out_1_acc: 0.9428 - out_2_acc: 0.9543 - val_loss: 0.2071 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9521\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1911 - out_1_loss: 0.1077 - out_2_loss: 0.0833 - out_1_acc: 0.9427 - out_2_acc: 0.9546 - val_loss: 0.2052 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9521\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1892 - out_1_loss: 0.1063 - out_2_loss: 0.0829 - out_1_acc: 0.9428 - out_2_acc: 0.9545 - val_loss: 0.2036 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9525\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1875 - out_1_loss: 0.1051 - out_2_loss: 0.0824 - out_1_acc: 0.9431 - out_2_acc: 0.9546 - val_loss: 0.2023 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.0888 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9527\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1861 - out_1_loss: 0.1041 - out_2_loss: 0.0820 - out_1_acc: 0.9432 - out_2_acc: 0.9549 - val_loss: 0.2013 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9529\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1847 - out_1_loss: 0.1031 - out_2_loss: 0.0816 - out_1_acc: 0.9433 - out_2_acc: 0.9550 - val_loss: 0.2005 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.0886 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9526\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1836 - out_1_loss: 0.1023 - out_2_loss: 0.0813 - out_1_acc: 0.9435 - out_2_acc: 0.9550 - val_loss: 0.1999 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9529\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1825 - out_1_loss: 0.1016 - out_2_loss: 0.0809 - out_1_acc: 0.9437 - out_2_acc: 0.9554 - val_loss: 0.1991 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0884 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9529\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1815 - out_1_loss: 0.1009 - out_2_loss: 0.0806 - out_1_acc: 0.9441 - out_2_acc: 0.9554 - val_loss: 0.1987 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0885 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9530\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1805 - out_1_loss: 0.1002 - out_2_loss: 0.0803 - out_1_acc: 0.9444 - out_2_acc: 0.9556 - val_loss: 0.1984 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9529\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1797 - out_1_loss: 0.0997 - out_2_loss: 0.0800 - out_1_acc: 0.9447 - out_2_acc: 0.9557 - val_loss: 0.1982 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0888 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9532\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1788 - out_1_loss: 0.0991 - out_2_loss: 0.0796 - out_1_acc: 0.9450 - out_2_acc: 0.9562 - val_loss: 0.1979 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0888 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9527\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1779 - out_1_loss: 0.0986 - out_2_loss: 0.0793 - out_1_acc: 0.9451 - out_2_acc: 0.9562 - val_loss: 0.1979 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9532\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1771 - out_1_loss: 0.0982 - out_2_loss: 0.0789 - out_1_acc: 0.9454 - out_2_acc: 0.9567 - val_loss: 0.1977 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1764 - out_1_loss: 0.0977 - out_2_loss: 0.0786 - out_1_acc: 0.9455 - out_2_acc: 0.9567 - val_loss: 0.1978 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9535\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1755 - out_1_loss: 0.0973 - out_2_loss: 0.0782 - out_1_acc: 0.9456 - out_2_acc: 0.9570 - val_loss: 0.1980 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0896 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9529\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1748 - out_1_loss: 0.0969 - out_2_loss: 0.0779 - out_1_acc: 0.9460 - out_2_acc: 0.9573 - val_loss: 0.1980 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9533\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1740 - out_1_loss: 0.0965 - out_2_loss: 0.0775 - out_1_acc: 0.9463 - out_2_acc: 0.9578 - val_loss: 0.1982 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1733 - out_1_loss: 0.0961 - out_2_loss: 0.0772 - out_1_acc: 0.9465 - out_2_acc: 0.9576 - val_loss: 0.1982 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0902 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9530\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1725 - out_1_loss: 0.0958 - out_2_loss: 0.0768 - out_1_acc: 0.9465 - out_2_acc: 0.9581 - val_loss: 0.1987 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1717 - out_1_loss: 0.0954 - out_2_loss: 0.0763 - out_1_acc: 0.9468 - out_2_acc: 0.9582 - val_loss: 0.1989 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0908 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1709 - out_1_loss: 0.0950 - out_2_loss: 0.0758 - out_1_acc: 0.9469 - out_2_acc: 0.9587 - val_loss: 0.1993 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1700 - out_1_loss: 0.0947 - out_2_loss: 0.0754 - out_1_acc: 0.9471 - out_2_acc: 0.9588 - val_loss: 0.1995 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0915 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9533\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1692 - out_1_loss: 0.0943 - out_2_loss: 0.0749 - out_1_acc: 0.9474 - out_2_acc: 0.9593 - val_loss: 0.2001 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1683 - out_1_loss: 0.0939 - out_2_loss: 0.0744 - out_1_acc: 0.9477 - out_2_acc: 0.9595 - val_loss: 0.2004 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1674 - out_1_loss: 0.0936 - out_2_loss: 0.0738 - out_1_acc: 0.9480 - out_2_acc: 0.9601 - val_loss: 0.2013 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1664 - out_1_loss: 0.0932 - out_2_loss: 0.0732 - out_1_acc: 0.9482 - out_2_acc: 0.9600 - val_loss: 0.2015 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1657 - out_1_loss: 0.0928 - out_2_loss: 0.0729 - out_1_acc: 0.9484 - out_2_acc: 0.9601 - val_loss: 0.2025 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1645 - out_1_loss: 0.0925 - out_2_loss: 0.0721 - out_1_acc: 0.9486 - out_2_acc: 0.9604 - val_loss: 0.2027 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9529\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1635 - out_1_loss: 0.0921 - out_2_loss: 0.0714 - out_1_acc: 0.9489 - out_2_acc: 0.9611 - val_loss: 0.2036 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9531\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1626 - out_1_loss: 0.0917 - out_2_loss: 0.0709 - out_1_acc: 0.9492 - out_2_acc: 0.9613 - val_loss: 0.2037 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1616 - out_1_loss: 0.0913 - out_2_loss: 0.0703 - out_1_acc: 0.9496 - out_2_acc: 0.9616 - val_loss: 0.2049 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9528\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1605 - out_1_loss: 0.0909 - out_2_loss: 0.0696 - out_1_acc: 0.9498 - out_2_acc: 0.9619 - val_loss: 0.2051 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9530\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1593 - out_1_loss: 0.0905 - out_2_loss: 0.0687 - out_1_acc: 0.9499 - out_2_acc: 0.9625 - val_loss: 0.2062 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9530\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1585 - out_1_loss: 0.0901 - out_2_loss: 0.0684 - out_1_acc: 0.9504 - out_2_acc: 0.9625 - val_loss: 0.2066 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9529\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1572 - out_1_loss: 0.0897 - out_2_loss: 0.0675 - out_1_acc: 0.9507 - out_2_acc: 0.9631 - val_loss: 0.2080 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0986 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9524\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1560 - out_1_loss: 0.0892 - out_2_loss: 0.0667 - out_1_acc: 0.9510 - out_2_acc: 0.9634 - val_loss: 0.2088 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9535\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1546 - out_1_loss: 0.0889 - out_2_loss: 0.0658 - out_1_acc: 0.9512 - out_2_acc: 0.9641 - val_loss: 0.2097 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1535 - out_1_loss: 0.0884 - out_2_loss: 0.0651 - out_1_acc: 0.9515 - out_2_acc: 0.9643 - val_loss: 0.2106 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9527\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1522 - out_1_loss: 0.0879 - out_2_loss: 0.0643 - out_1_acc: 0.9519 - out_2_acc: 0.9648 - val_loss: 0.2120 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.1018 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1508 - out_1_loss: 0.0875 - out_2_loss: 0.0634 - out_1_acc: 0.9523 - out_2_acc: 0.9653 - val_loss: 0.2127 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.1023 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1497 - out_1_loss: 0.0870 - out_2_loss: 0.0626 - out_1_acc: 0.9525 - out_2_acc: 0.9659 - val_loss: 0.2143 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1034 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9533\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1484 - out_1_loss: 0.0866 - out_2_loss: 0.0618 - out_1_acc: 0.9527 - out_2_acc: 0.9663 - val_loss: 0.2157 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.1045 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9530\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1470 - out_1_loss: 0.0861 - out_2_loss: 0.0609 - out_1_acc: 0.9530 - out_2_acc: 0.9669 - val_loss: 0.2173 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.1059 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9537\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1460 - out_1_loss: 0.0857 - out_2_loss: 0.0603 - out_1_acc: 0.9533 - out_2_acc: 0.9669 - val_loss: 0.2180 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1062 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9534\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1447 - out_1_loss: 0.0852 - out_2_loss: 0.0595 - out_1_acc: 0.9537 - out_2_acc: 0.9673 - val_loss: 0.2192 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.1072 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9533\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1436 - out_1_loss: 0.0847 - out_2_loss: 0.0589 - out_1_acc: 0.9538 - out_2_acc: 0.9679 - val_loss: 0.2205 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1081 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9529\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1423 - out_1_loss: 0.0843 - out_2_loss: 0.0580 - out_1_acc: 0.9543 - out_2_acc: 0.9686 - val_loss: 0.2225 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1097 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9535\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1411 - out_1_loss: 0.0838 - out_2_loss: 0.0574 - out_1_acc: 0.9545 - out_2_acc: 0.9688 - val_loss: 0.2239 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1108 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9527\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1399 - out_1_loss: 0.0833 - out_2_loss: 0.0566 - out_1_acc: 0.9548 - out_2_acc: 0.9690 - val_loss: 0.2252 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.1116 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9532\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1388 - out_1_loss: 0.0828 - out_2_loss: 0.0560 - out_1_acc: 0.9553 - out_2_acc: 0.9696 - val_loss: 0.2276 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.1138 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9537\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1377 - out_1_loss: 0.0823 - out_2_loss: 0.0554 - out_1_acc: 0.9555 - out_2_acc: 0.9696 - val_loss: 0.2288 - val_out_1_loss: 0.1143 - val_out_2_loss: 0.1145 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9529\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1368 - out_1_loss: 0.0818 - out_2_loss: 0.0550 - out_1_acc: 0.9558 - out_2_acc: 0.9697 - val_loss: 0.2331 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.1184 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9528\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1361 - out_1_loss: 0.0813 - out_2_loss: 0.0548 - out_1_acc: 0.9563 - out_2_acc: 0.9698 - val_loss: 0.2335 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1180 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9529\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1347 - out_1_loss: 0.0808 - out_2_loss: 0.0539 - out_1_acc: 0.9564 - out_2_acc: 0.9708 - val_loss: 0.2352 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.1195 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1337 - out_1_loss: 0.0804 - out_2_loss: 0.0533 - out_1_acc: 0.9567 - out_2_acc: 0.9708 - val_loss: 0.2379 - val_out_1_loss: 0.1165 - val_out_2_loss: 0.1214 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9534\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1329 - out_1_loss: 0.0799 - out_2_loss: 0.0530 - out_1_acc: 0.9572 - out_2_acc: 0.9706 - val_loss: 0.2398 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1227 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9530\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1318 - out_1_loss: 0.0795 - out_2_loss: 0.0523 - out_1_acc: 0.9574 - out_2_acc: 0.9710 - val_loss: 0.2433 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1254 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9537\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1304 - out_1_loss: 0.0789 - out_2_loss: 0.0515 - out_1_acc: 0.9579 - out_2_acc: 0.9715 - val_loss: 0.2451 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1268 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9535\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1295 - out_1_loss: 0.0784 - out_2_loss: 0.0510 - out_1_acc: 0.9581 - out_2_acc: 0.9717 - val_loss: 0.2467 - val_out_1_loss: 0.1191 - val_out_2_loss: 0.1275 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9532\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1280 - out_1_loss: 0.0779 - out_2_loss: 0.0501 - out_1_acc: 0.9587 - out_2_acc: 0.9722 - val_loss: 0.2482 - val_out_1_loss: 0.1193 - val_out_2_loss: 0.1289 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9537\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1266 - out_1_loss: 0.0773 - out_2_loss: 0.0493 - out_1_acc: 0.9587 - out_2_acc: 0.9725 - val_loss: 0.2497 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9534\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1254 - out_1_loss: 0.0769 - out_2_loss: 0.0486 - out_1_acc: 0.9589 - out_2_acc: 0.9731 - val_loss: 0.2523 - val_out_1_loss: 0.1203 - val_out_2_loss: 0.1320 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9539\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1244 - out_1_loss: 0.0763 - out_2_loss: 0.0481 - out_1_acc: 0.9592 - out_2_acc: 0.9731 - val_loss: 0.2541 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.1331 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9531\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1230 - out_1_loss: 0.0758 - out_2_loss: 0.0473 - out_1_acc: 0.9597 - out_2_acc: 0.9742 - val_loss: 0.2566 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.1349 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9536\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1224 - out_1_loss: 0.0752 - out_2_loss: 0.0472 - out_1_acc: 0.9601 - out_2_acc: 0.9744 - val_loss: 0.2583 - val_out_1_loss: 0.1221 - val_out_2_loss: 0.1362 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9536\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1215 - out_1_loss: 0.0747 - out_2_loss: 0.0468 - out_1_acc: 0.9602 - out_2_acc: 0.9742 - val_loss: 0.2612 - val_out_1_loss: 0.1228 - val_out_2_loss: 0.1384 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1207 - out_1_loss: 0.0743 - out_2_loss: 0.0464 - out_1_acc: 0.9604 - out_2_acc: 0.9744 - val_loss: 0.2622 - val_out_1_loss: 0.1236 - val_out_2_loss: 0.1387 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9535\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1195 - out_1_loss: 0.0736 - out_2_loss: 0.0459 - out_1_acc: 0.9609 - out_2_acc: 0.9747 - val_loss: 0.2643 - val_out_1_loss: 0.1239 - val_out_2_loss: 0.1403 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9533\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1186 - out_1_loss: 0.0731 - out_2_loss: 0.0455 - out_1_acc: 0.9615 - out_2_acc: 0.9752 - val_loss: 0.2654 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.1408 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9538\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1176 - out_1_loss: 0.0727 - out_2_loss: 0.0449 - out_1_acc: 0.9616 - out_2_acc: 0.9758 - val_loss: 0.2684 - val_out_1_loss: 0.1253 - val_out_2_loss: 0.1431 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9538\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1167 - out_1_loss: 0.0721 - out_2_loss: 0.0446 - out_1_acc: 0.9620 - out_2_acc: 0.9755 - val_loss: 0.2716 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1459 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9530\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1160 - out_1_loss: 0.0716 - out_2_loss: 0.0444 - out_1_acc: 0.9622 - out_2_acc: 0.9757 - val_loss: 0.2743 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.1476 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9528\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1153 - out_1_loss: 0.0712 - out_2_loss: 0.0442 - out_1_acc: 0.9627 - out_2_acc: 0.9759 - val_loss: 0.2756 - val_out_1_loss: 0.1273 - val_out_2_loss: 0.1483 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9530\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1148 - out_1_loss: 0.0706 - out_2_loss: 0.0442 - out_1_acc: 0.9630 - out_2_acc: 0.9759 - val_loss: 0.2781 - val_out_1_loss: 0.1280 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1139 - out_1_loss: 0.0702 - out_2_loss: 0.0437 - out_1_acc: 0.9630 - out_2_acc: 0.9763 - val_loss: 0.2796 - val_out_1_loss: 0.1287 - val_out_2_loss: 0.1510 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9522\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1130 - out_1_loss: 0.0697 - out_2_loss: 0.0434 - out_1_acc: 0.9636 - out_2_acc: 0.9764 - val_loss: 0.2812 - val_out_1_loss: 0.1299 - val_out_2_loss: 0.1512 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1120 - out_1_loss: 0.0692 - out_2_loss: 0.0428 - out_1_acc: 0.9636 - out_2_acc: 0.9770 - val_loss: 0.2838 - val_out_1_loss: 0.1305 - val_out_2_loss: 0.1533 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9534\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1110 - out_1_loss: 0.0687 - out_2_loss: 0.0424 - out_1_acc: 0.9639 - out_2_acc: 0.9771 - val_loss: 0.2862 - val_out_1_loss: 0.1314 - val_out_2_loss: 0.1548 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9528\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1099 - out_1_loss: 0.0682 - out_2_loss: 0.0417 - out_1_acc: 0.9644 - out_2_acc: 0.9776 - val_loss: 0.2881 - val_out_1_loss: 0.1323 - val_out_2_loss: 0.1558 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9529\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1088 - out_1_loss: 0.0676 - out_2_loss: 0.0412 - out_1_acc: 0.9648 - out_2_acc: 0.9785 - val_loss: 0.2906 - val_out_1_loss: 0.1328 - val_out_2_loss: 0.1577 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9538\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1088 - out_1_loss: 0.0673 - out_2_loss: 0.0415 - out_1_acc: 0.9651 - out_2_acc: 0.9777 - val_loss: 0.2924 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1582 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9528\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1080 - out_1_loss: 0.0668 - out_2_loss: 0.0412 - out_1_acc: 0.9649 - out_2_acc: 0.9782 - val_loss: 0.2930 - val_out_1_loss: 0.1343 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1075 - out_1_loss: 0.0664 - out_2_loss: 0.0411 - out_1_acc: 0.9651 - out_2_acc: 0.9784 - val_loss: 0.2933 - val_out_1_loss: 0.1347 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1062 - out_1_loss: 0.0658 - out_2_loss: 0.0404 - out_1_acc: 0.9661 - out_2_acc: 0.9788 - val_loss: 0.2955 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1600 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9530\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1052 - out_1_loss: 0.0652 - out_2_loss: 0.0400 - out_1_acc: 0.9660 - out_2_acc: 0.9788 - val_loss: 0.2978 - val_out_1_loss: 0.1359 - val_out_2_loss: 0.1619 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1043 - out_1_loss: 0.0648 - out_2_loss: 0.0396 - out_1_acc: 0.9665 - out_2_acc: 0.9793 - val_loss: 0.3015 - val_out_1_loss: 0.1368 - val_out_2_loss: 0.1646 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1042 - out_1_loss: 0.0644 - out_2_loss: 0.0398 - out_1_acc: 0.9667 - out_2_acc: 0.9792 - val_loss: 0.3034 - val_out_1_loss: 0.1381 - val_out_2_loss: 0.1652 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1034 - out_1_loss: 0.0638 - out_2_loss: 0.0396 - out_1_acc: 0.9670 - out_2_acc: 0.9795 - val_loss: 0.3060 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1667 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1025 - out_1_loss: 0.0636 - out_2_loss: 0.0389 - out_1_acc: 0.9671 - out_2_acc: 0.9800 - val_loss: 0.3067 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1662 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9533\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1014 - out_1_loss: 0.0633 - out_2_loss: 0.0381 - out_1_acc: 0.9674 - out_2_acc: 0.9804 - val_loss: 0.3095 - val_out_1_loss: 0.1416 - val_out_2_loss: 0.1679 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1008 - out_1_loss: 0.0628 - out_2_loss: 0.0380 - out_1_acc: 0.9675 - out_2_acc: 0.9804 - val_loss: 0.3114 - val_out_1_loss: 0.1423 - val_out_2_loss: 0.1690 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9526\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0996 - out_1_loss: 0.0622 - out_2_loss: 0.0374 - out_1_acc: 0.9679 - out_2_acc: 0.9811 - val_loss: 0.3131 - val_out_1_loss: 0.1436 - val_out_2_loss: 0.1695 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9535\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0994 - out_1_loss: 0.0618 - out_2_loss: 0.0376 - out_1_acc: 0.9680 - out_2_acc: 0.9807 - val_loss: 0.3150 - val_out_1_loss: 0.1440 - val_out_2_loss: 0.1710 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9532\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0981 - out_1_loss: 0.0615 - out_2_loss: 0.0366 - out_1_acc: 0.9682 - out_2_acc: 0.9814 - val_loss: 0.3181 - val_out_1_loss: 0.1458 - val_out_2_loss: 0.1723 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0977 - out_1_loss: 0.0612 - out_2_loss: 0.0365 - out_1_acc: 0.9687 - out_2_acc: 0.9812 - val_loss: 0.3201 - val_out_1_loss: 0.1464 - val_out_2_loss: 0.1738 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9533\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0968 - out_1_loss: 0.0607 - out_2_loss: 0.0361 - out_1_acc: 0.9687 - out_2_acc: 0.9814 - val_loss: 0.3220 - val_out_1_loss: 0.1468 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9529\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0965 - out_1_loss: 0.0604 - out_2_loss: 0.0361 - out_1_acc: 0.9689 - out_2_acc: 0.9815 - val_loss: 0.3246 - val_out_1_loss: 0.1470 - val_out_2_loss: 0.1776 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0968 - out_1_loss: 0.0601 - out_2_loss: 0.0367 - out_1_acc: 0.9692 - out_2_acc: 0.9812 - val_loss: 0.3253 - val_out_1_loss: 0.1481 - val_out_2_loss: 0.1772 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0965 - out_1_loss: 0.0599 - out_2_loss: 0.0366 - out_1_acc: 0.9693 - out_2_acc: 0.9814 - val_loss: 0.3270 - val_out_1_loss: 0.1494 - val_out_2_loss: 0.1776 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9517\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0965 - out_1_loss: 0.0594 - out_2_loss: 0.0371 - out_1_acc: 0.9700 - out_2_acc: 0.9813 - val_loss: 0.3274 - val_out_1_loss: 0.1495 - val_out_2_loss: 0.1779 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0941 - out_1_loss: 0.0588 - out_2_loss: 0.0353 - out_1_acc: 0.9701 - out_2_acc: 0.9821 - val_loss: 0.3286 - val_out_1_loss: 0.1502 - val_out_2_loss: 0.1785 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0936 - out_1_loss: 0.0582 - out_2_loss: 0.0354 - out_1_acc: 0.9708 - out_2_acc: 0.9823 - val_loss: 0.3317 - val_out_1_loss: 0.1519 - val_out_2_loss: 0.1798 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0925 - out_1_loss: 0.0579 - out_2_loss: 0.0346 - out_1_acc: 0.9709 - out_2_acc: 0.9826 - val_loss: 0.3350 - val_out_1_loss: 0.1524 - val_out_2_loss: 0.1826 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9527\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0922 - out_1_loss: 0.0575 - out_2_loss: 0.0347 - out_1_acc: 0.9711 - out_2_acc: 0.9830 - val_loss: 0.3365 - val_out_1_loss: 0.1541 - val_out_2_loss: 0.1824 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9528\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0917 - out_1_loss: 0.0573 - out_2_loss: 0.0343 - out_1_acc: 0.9713 - out_2_acc: 0.9829 - val_loss: 0.3371 - val_out_1_loss: 0.1547 - val_out_2_loss: 0.1824 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9532\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0913 - out_1_loss: 0.0571 - out_2_loss: 0.0342 - out_1_acc: 0.9710 - out_2_acc: 0.9828 - val_loss: 0.3393 - val_out_1_loss: 0.1550 - val_out_2_loss: 0.1843 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0909 - out_1_loss: 0.0571 - out_2_loss: 0.0338 - out_1_acc: 0.9712 - out_2_acc: 0.9830 - val_loss: 0.3405 - val_out_1_loss: 0.1558 - val_out_2_loss: 0.1847 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9528\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0910 - out_1_loss: 0.0569 - out_2_loss: 0.0341 - out_1_acc: 0.9710 - out_2_acc: 0.9828 - val_loss: 0.3447 - val_out_1_loss: 0.1563 - val_out_2_loss: 0.1884 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9529\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0915 - out_1_loss: 0.0567 - out_2_loss: 0.0348 - out_1_acc: 0.9710 - out_2_acc: 0.9826 - val_loss: 0.3432 - val_out_1_loss: 0.1565 - val_out_2_loss: 0.1867 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0902 - out_1_loss: 0.0564 - out_2_loss: 0.0338 - out_1_acc: 0.9718 - out_2_acc: 0.9832 - val_loss: 0.3446 - val_out_1_loss: 0.1567 - val_out_2_loss: 0.1879 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0892 - out_1_loss: 0.0560 - out_2_loss: 0.0332 - out_1_acc: 0.9717 - out_2_acc: 0.9833 - val_loss: 0.3488 - val_out_1_loss: 0.1574 - val_out_2_loss: 0.1914 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9524\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0896 - out_1_loss: 0.0555 - out_2_loss: 0.0340 - out_1_acc: 0.9722 - out_2_acc: 0.9832 - val_loss: 0.3490 - val_out_1_loss: 0.1584 - val_out_2_loss: 0.1906 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9531\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0892 - out_1_loss: 0.0558 - out_2_loss: 0.0333 - out_1_acc: 0.9724 - out_2_acc: 0.9835 - val_loss: 0.3472 - val_out_1_loss: 0.1586 - val_out_2_loss: 0.1886 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0889 - out_1_loss: 0.0553 - out_2_loss: 0.0335 - out_1_acc: 0.9723 - out_2_acc: 0.9834 - val_loss: 0.3496 - val_out_1_loss: 0.1591 - val_out_2_loss: 0.1905 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9518\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0900 - out_1_loss: 0.0552 - out_2_loss: 0.0348 - out_1_acc: 0.9724 - out_2_acc: 0.9824 - val_loss: 0.3473 - val_out_1_loss: 0.1599 - val_out_2_loss: 0.1874 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0877 - out_1_loss: 0.0546 - out_2_loss: 0.0332 - out_1_acc: 0.9731 - out_2_acc: 0.9837 - val_loss: 0.3515 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1909 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9527\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0871 - out_1_loss: 0.0541 - out_2_loss: 0.0330 - out_1_acc: 0.9733 - out_2_acc: 0.9835 - val_loss: 0.3560 - val_out_1_loss: 0.1625 - val_out_2_loss: 0.1935 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0871 - out_1_loss: 0.0539 - out_2_loss: 0.0332 - out_1_acc: 0.9732 - out_2_acc: 0.9834 - val_loss: 0.3584 - val_out_1_loss: 0.1640 - val_out_2_loss: 0.1943 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0859 - out_1_loss: 0.0534 - out_2_loss: 0.0325 - out_1_acc: 0.9737 - out_2_acc: 0.9837 - val_loss: 0.3591 - val_out_1_loss: 0.1644 - val_out_2_loss: 0.1947 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0856 - out_1_loss: 0.0531 - out_2_loss: 0.0324 - out_1_acc: 0.9740 - out_2_acc: 0.9836 - val_loss: 0.3612 - val_out_1_loss: 0.1663 - val_out_2_loss: 0.1949 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0852 - out_1_loss: 0.0531 - out_2_loss: 0.0321 - out_1_acc: 0.9738 - out_2_acc: 0.9842 - val_loss: 0.3638 - val_out_1_loss: 0.1663 - val_out_2_loss: 0.1975 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9515\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0844 - out_1_loss: 0.0526 - out_2_loss: 0.0319 - out_1_acc: 0.9743 - out_2_acc: 0.9842 - val_loss: 0.3658 - val_out_1_loss: 0.1680 - val_out_2_loss: 0.1979 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0823 - out_1_loss: 0.0522 - out_2_loss: 0.0301 - out_1_acc: 0.9746 - out_2_acc: 0.9855 - val_loss: 0.3687 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.1995 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0817 - out_1_loss: 0.0519 - out_2_loss: 0.0297 - out_1_acc: 0.9746 - out_2_acc: 0.9859 - val_loss: 0.3712 - val_out_1_loss: 0.1712 - val_out_2_loss: 0.2001 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9519\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0816 - out_1_loss: 0.0520 - out_2_loss: 0.0296 - out_1_acc: 0.9746 - out_2_acc: 0.9862 - val_loss: 0.3755 - val_out_1_loss: 0.1726 - val_out_2_loss: 0.2028 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0805 - out_1_loss: 0.0516 - out_2_loss: 0.0289 - out_1_acc: 0.9745 - out_2_acc: 0.9863 - val_loss: 0.3800 - val_out_1_loss: 0.1737 - val_out_2_loss: 0.2063 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9518\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0791 - out_1_loss: 0.0509 - out_2_loss: 0.0282 - out_1_acc: 0.9751 - out_2_acc: 0.9869 - val_loss: 0.3800 - val_out_1_loss: 0.1751 - val_out_2_loss: 0.2049 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9518\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0773 - out_1_loss: 0.0503 - out_2_loss: 0.0271 - out_1_acc: 0.9758 - out_2_acc: 0.9873 - val_loss: 0.3809 - val_out_1_loss: 0.1761 - val_out_2_loss: 0.2048 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0767 - out_1_loss: 0.0503 - out_2_loss: 0.0264 - out_1_acc: 0.9756 - out_2_acc: 0.9879 - val_loss: 0.3834 - val_out_1_loss: 0.1772 - val_out_2_loss: 0.2062 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0751 - out_1_loss: 0.0498 - out_2_loss: 0.0253 - out_1_acc: 0.9762 - out_2_acc: 0.9887 - val_loss: 0.3876 - val_out_1_loss: 0.1781 - val_out_2_loss: 0.2095 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0742 - out_1_loss: 0.0493 - out_2_loss: 0.0249 - out_1_acc: 0.9764 - out_2_acc: 0.9886 - val_loss: 0.3950 - val_out_1_loss: 0.1802 - val_out_2_loss: 0.2147 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9522\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0742 - out_1_loss: 0.0490 - out_2_loss: 0.0252 - out_1_acc: 0.9768 - out_2_acc: 0.9887 - val_loss: 0.4005 - val_out_1_loss: 0.1817 - val_out_2_loss: 0.2187 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0748 - out_1_loss: 0.0487 - out_2_loss: 0.0261 - out_1_acc: 0.9771 - out_2_acc: 0.9880 - val_loss: 0.4021 - val_out_1_loss: 0.1832 - val_out_2_loss: 0.2189 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9526\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0741 - out_1_loss: 0.0485 - out_2_loss: 0.0257 - out_1_acc: 0.9772 - out_2_acc: 0.9882 - val_loss: 0.4033 - val_out_1_loss: 0.1844 - val_out_2_loss: 0.2188 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9522\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0734 - out_1_loss: 0.0482 - out_2_loss: 0.0252 - out_1_acc: 0.9773 - out_2_acc: 0.9883 - val_loss: 0.4058 - val_out_1_loss: 0.1852 - val_out_2_loss: 0.2206 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0734 - out_1_loss: 0.0482 - out_2_loss: 0.0252 - out_1_acc: 0.9770 - out_2_acc: 0.9883 - val_loss: 0.4076 - val_out_1_loss: 0.1861 - val_out_2_loss: 0.2215 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0734 - out_1_loss: 0.0480 - out_2_loss: 0.0254 - out_1_acc: 0.9775 - out_2_acc: 0.9883 - val_loss: 0.4130 - val_out_1_loss: 0.1868 - val_out_2_loss: 0.2262 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0718 - out_1_loss: 0.0474 - out_2_loss: 0.0244 - out_1_acc: 0.9778 - out_2_acc: 0.9892 - val_loss: 0.4084 - val_out_1_loss: 0.1868 - val_out_2_loss: 0.2216 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0717 - out_1_loss: 0.0473 - out_2_loss: 0.0244 - out_1_acc: 0.9776 - out_2_acc: 0.9887 - val_loss: 0.4122 - val_out_1_loss: 0.1870 - val_out_2_loss: 0.2252 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9517\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0718 - out_1_loss: 0.0472 - out_2_loss: 0.0246 - out_1_acc: 0.9775 - out_2_acc: 0.9890 - val_loss: 0.4138 - val_out_1_loss: 0.1895 - val_out_2_loss: 0.2243 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0707 - out_1_loss: 0.0465 - out_2_loss: 0.0242 - out_1_acc: 0.9782 - out_2_acc: 0.9890 - val_loss: 0.4113 - val_out_1_loss: 0.1886 - val_out_2_loss: 0.2227 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9527\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0724 - out_1_loss: 0.0471 - out_2_loss: 0.0253 - out_1_acc: 0.9777 - out_2_acc: 0.9884 - val_loss: 0.4129 - val_out_1_loss: 0.1900 - val_out_2_loss: 0.2229 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9519\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0704 - out_1_loss: 0.0465 - out_2_loss: 0.0239 - out_1_acc: 0.9784 - out_2_acc: 0.9894 - val_loss: 0.4148 - val_out_1_loss: 0.1924 - val_out_2_loss: 0.2223 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0691 - out_1_loss: 0.0458 - out_2_loss: 0.0232 - out_1_acc: 0.9788 - out_2_acc: 0.9897 - val_loss: 0.4205 - val_out_1_loss: 0.1928 - val_out_2_loss: 0.2277 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0701 - out_1_loss: 0.0458 - out_2_loss: 0.0242 - out_1_acc: 0.9787 - out_2_acc: 0.9893 - val_loss: 0.4186 - val_out_1_loss: 0.1931 - val_out_2_loss: 0.2255 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0686 - out_1_loss: 0.0455 - out_2_loss: 0.0231 - out_1_acc: 0.9785 - out_2_acc: 0.9898 - val_loss: 0.4265 - val_out_1_loss: 0.1970 - val_out_2_loss: 0.2294 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9522\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0672 - out_1_loss: 0.0452 - out_2_loss: 0.0220 - out_1_acc: 0.9792 - out_2_acc: 0.9901 - val_loss: 0.4293 - val_out_1_loss: 0.1979 - val_out_2_loss: 0.2315 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0662 - out_1_loss: 0.0451 - out_2_loss: 0.0211 - out_1_acc: 0.9789 - out_2_acc: 0.9909 - val_loss: 0.4336 - val_out_1_loss: 0.1981 - val_out_2_loss: 0.2355 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0682 - out_1_loss: 0.0454 - out_2_loss: 0.0228 - out_1_acc: 0.9786 - out_2_acc: 0.9901 - val_loss: 0.4366 - val_out_1_loss: 0.1984 - val_out_2_loss: 0.2383 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0657 - out_1_loss: 0.0449 - out_2_loss: 0.0208 - out_1_acc: 0.9791 - out_2_acc: 0.9911 - val_loss: 0.4392 - val_out_1_loss: 0.2007 - val_out_2_loss: 0.2385 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0658 - out_1_loss: 0.0444 - out_2_loss: 0.0214 - out_1_acc: 0.9796 - out_2_acc: 0.9910 - val_loss: 0.4389 - val_out_1_loss: 0.2032 - val_out_2_loss: 0.2357 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0649 - out_1_loss: 0.0439 - out_2_loss: 0.0209 - out_1_acc: 0.9794 - out_2_acc: 0.9911 - val_loss: 0.4392 - val_out_1_loss: 0.2023 - val_out_2_loss: 0.2369 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9524\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0627 - out_1_loss: 0.0432 - out_2_loss: 0.0195 - out_1_acc: 0.9802 - out_2_acc: 0.9918 - val_loss: 0.4450 - val_out_1_loss: 0.2048 - val_out_2_loss: 0.2402 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9524\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0626 - out_1_loss: 0.0432 - out_2_loss: 0.0194 - out_1_acc: 0.9802 - out_2_acc: 0.9919 - val_loss: 0.4478 - val_out_1_loss: 0.2065 - val_out_2_loss: 0.2413 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0621 - out_1_loss: 0.0433 - out_2_loss: 0.0188 - out_1_acc: 0.9799 - out_2_acc: 0.9919 - val_loss: 0.4541 - val_out_1_loss: 0.2088 - val_out_2_loss: 0.2453 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0627 - out_1_loss: 0.0439 - out_2_loss: 0.0188 - out_1_acc: 0.9796 - out_2_acc: 0.9923 - val_loss: 0.4528 - val_out_1_loss: 0.2077 - val_out_2_loss: 0.2451 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0631 - out_1_loss: 0.0437 - out_2_loss: 0.0194 - out_1_acc: 0.9798 - out_2_acc: 0.9919 - val_loss: 0.4538 - val_out_1_loss: 0.2092 - val_out_2_loss: 0.2446 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9530\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0622 - out_1_loss: 0.0440 - out_2_loss: 0.0182 - out_1_acc: 0.9792 - out_2_acc: 0.9927 - val_loss: 0.4525 - val_out_1_loss: 0.2078 - val_out_2_loss: 0.2446 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0609 - out_1_loss: 0.0434 - out_2_loss: 0.0176 - out_1_acc: 0.9795 - out_2_acc: 0.9929 - val_loss: 0.4522 - val_out_1_loss: 0.2083 - val_out_2_loss: 0.2439 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9528\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0610 - out_1_loss: 0.0427 - out_2_loss: 0.0182 - out_1_acc: 0.9801 - out_2_acc: 0.9927 - val_loss: 0.4568 - val_out_1_loss: 0.2075 - val_out_2_loss: 0.2493 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0606 - out_1_loss: 0.0425 - out_2_loss: 0.0180 - out_1_acc: 0.9801 - out_2_acc: 0.9925 - val_loss: 0.4590 - val_out_1_loss: 0.2101 - val_out_2_loss: 0.2488 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0594 - out_1_loss: 0.0425 - out_2_loss: 0.0169 - out_1_acc: 0.9806 - out_2_acc: 0.9932 - val_loss: 0.4637 - val_out_1_loss: 0.2102 - val_out_2_loss: 0.2535 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0602 - out_1_loss: 0.0420 - out_2_loss: 0.0182 - out_1_acc: 0.9808 - out_2_acc: 0.9926 - val_loss: 0.4668 - val_out_1_loss: 0.2117 - val_out_2_loss: 0.2552 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0600 - out_1_loss: 0.0412 - out_2_loss: 0.0188 - out_1_acc: 0.9810 - out_2_acc: 0.9921 - val_loss: 0.4672 - val_out_1_loss: 0.2142 - val_out_2_loss: 0.2531 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 179/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0592 - out_1_loss: 0.0423 - out_2_loss: 0.0169 - out_1_acc: 0.9806 - out_2_acc: 0.9934 - val_loss: 0.4709 - val_out_1_loss: 0.2150 - val_out_2_loss: 0.2559 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9520\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0608 - out_1_loss: 0.0430 - out_2_loss: 0.0178 - out_1_acc: 0.9799 - out_2_acc: 0.9927 - val_loss: 0.4743 - val_out_1_loss: 0.2139 - val_out_2_loss: 0.2604 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0624 - out_1_loss: 0.0436 - out_2_loss: 0.0187 - out_1_acc: 0.9793 - out_2_acc: 0.9922 - val_loss: 0.4725 - val_out_1_loss: 0.2159 - val_out_2_loss: 0.2566 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0652 - out_1_loss: 0.0449 - out_2_loss: 0.0203 - out_1_acc: 0.9787 - out_2_acc: 0.9918 - val_loss: 0.4713 - val_out_1_loss: 0.2147 - val_out_2_loss: 0.2567 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0650 - out_1_loss: 0.0456 - out_2_loss: 0.0195 - out_1_acc: 0.9781 - out_2_acc: 0.9917 - val_loss: 0.4720 - val_out_1_loss: 0.2146 - val_out_2_loss: 0.2575 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0684 - out_1_loss: 0.0482 - out_2_loss: 0.0202 - out_1_acc: 0.9770 - out_2_acc: 0.9917 - val_loss: 0.4924 - val_out_1_loss: 0.2228 - val_out_2_loss: 0.2696 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9529\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0709 - out_1_loss: 0.0489 - out_2_loss: 0.0220 - out_1_acc: 0.9770 - out_2_acc: 0.9911 - val_loss: 0.5007 - val_out_1_loss: 0.2292 - val_out_2_loss: 0.2715 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9534\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0738 - out_1_loss: 0.0498 - out_2_loss: 0.0240 - out_1_acc: 0.9768 - out_2_acc: 0.9902 - val_loss: 0.4837 - val_out_1_loss: 0.2204 - val_out_2_loss: 0.2633 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0719 - out_1_loss: 0.0474 - out_2_loss: 0.0246 - out_1_acc: 0.9776 - out_2_acc: 0.9895 - val_loss: 0.4750 - val_out_1_loss: 0.2183 - val_out_2_loss: 0.2567 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0692 - out_1_loss: 0.0450 - out_2_loss: 0.0241 - out_1_acc: 0.9793 - out_2_acc: 0.9895 - val_loss: 0.4834 - val_out_1_loss: 0.2186 - val_out_2_loss: 0.2648 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0651 - out_1_loss: 0.0430 - out_2_loss: 0.0221 - out_1_acc: 0.9807 - out_2_acc: 0.9907 - val_loss: 0.4834 - val_out_1_loss: 0.2198 - val_out_2_loss: 0.2636 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(3)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4604 - out_1_loss: 0.2095 - out_2_loss: 0.2509 - out_1_acc: 0.9426 - out_2_acc: 0.9535\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 200), (No 208800      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 200)       208800      input_4[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,155,680\n",
      "Trainable params: 1,155,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3486 - out_1_loss: 3.6813 - out_2_loss: 3.6672 - out_1_acc: 0.0543 - out_2_acc: 0.1335WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.110310). Check your callbacks.\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 5.3624 - out_1_loss: 3.0004 - out_2_loss: 2.3620 - out_1_acc: 0.5596 - out_2_acc: 0.6911 - val_loss: 2.0984 - val_out_1_loss: 1.5062 - val_out_2_loss: 0.5921 - val_out_1_acc: 0.7008 - val_out_2_acc: 0.8830\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.1265 - out_1_loss: 0.8194 - out_2_loss: 0.3071 - out_1_acc: 0.8430 - out_2_acc: 0.9407 - val_loss: 0.6452 - val_out_1_loss: 0.4530 - val_out_2_loss: 0.1922 - val_out_1_acc: 0.9148 - val_out_2_acc: 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4954 - out_1_loss: 0.3457 - out_2_loss: 0.1498 - out_1_acc: 0.9276 - out_2_acc: 0.9517 - val_loss: 0.3861 - val_out_1_loss: 0.2506 - val_out_2_loss: 0.1355 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9507\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3168 - out_1_loss: 0.2002 - out_2_loss: 0.1166 - out_1_acc: 0.9382 - out_2_acc: 0.9520 - val_loss: 0.2811 - val_out_1_loss: 0.1660 - val_out_2_loss: 0.1150 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9512\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2475 - out_1_loss: 0.1445 - out_2_loss: 0.1031 - out_1_acc: 0.9395 - out_2_acc: 0.9523 - val_loss: 0.2445 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2229 - out_1_loss: 0.1270 - out_2_loss: 0.0959 - out_1_acc: 0.9403 - out_2_acc: 0.9526 - val_loss: 0.2299 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.0992 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9510\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2113 - out_1_loss: 0.1200 - out_2_loss: 0.0913 - out_1_acc: 0.9407 - out_2_acc: 0.9527 - val_loss: 0.2209 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9514\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2039 - out_1_loss: 0.1157 - out_2_loss: 0.0882 - out_1_acc: 0.9412 - out_2_acc: 0.9532 - val_loss: 0.2151 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.0929 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9510\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1986 - out_1_loss: 0.1124 - out_2_loss: 0.0862 - out_1_acc: 0.9415 - out_2_acc: 0.9534 - val_loss: 0.2108 - val_out_1_loss: 0.1195 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9514\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1946 - out_1_loss: 0.1098 - out_2_loss: 0.0848 - out_1_acc: 0.9418 - out_2_acc: 0.9534 - val_loss: 0.2076 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9510\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1915 - out_1_loss: 0.1077 - out_2_loss: 0.0838 - out_1_acc: 0.9422 - out_2_acc: 0.9537 - val_loss: 0.2051 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9514\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1889 - out_1_loss: 0.1059 - out_2_loss: 0.0830 - out_1_acc: 0.9425 - out_2_acc: 0.9540 - val_loss: 0.2034 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9513\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1869 - out_1_loss: 0.1044 - out_2_loss: 0.0825 - out_1_acc: 0.9429 - out_2_acc: 0.9540 - val_loss: 0.2023 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1852 - out_1_loss: 0.1032 - out_2_loss: 0.0819 - out_1_acc: 0.9433 - out_2_acc: 0.9544 - val_loss: 0.2015 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9515\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1837 - out_1_loss: 0.1022 - out_2_loss: 0.0814 - out_1_acc: 0.9436 - out_2_acc: 0.9546 - val_loss: 0.2008 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9515\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1823 - out_1_loss: 0.1013 - out_2_loss: 0.0809 - out_1_acc: 0.9438 - out_2_acc: 0.9546 - val_loss: 0.2003 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0889 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1810 - out_1_loss: 0.1005 - out_2_loss: 0.0804 - out_1_acc: 0.9439 - out_2_acc: 0.9551 - val_loss: 0.2001 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9521\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1797 - out_1_loss: 0.0998 - out_2_loss: 0.0799 - out_1_acc: 0.9443 - out_2_acc: 0.9554 - val_loss: 0.2000 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0893 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1786 - out_1_loss: 0.0992 - out_2_loss: 0.0794 - out_1_acc: 0.9445 - out_2_acc: 0.9558 - val_loss: 0.2001 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1774 - out_1_loss: 0.0986 - out_2_loss: 0.0788 - out_1_acc: 0.9447 - out_2_acc: 0.9559 - val_loss: 0.2002 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0897 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9523\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1762 - out_1_loss: 0.0981 - out_2_loss: 0.0782 - out_1_acc: 0.9452 - out_2_acc: 0.9563 - val_loss: 0.2004 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9524\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1752 - out_1_loss: 0.0975 - out_2_loss: 0.0777 - out_1_acc: 0.9453 - out_2_acc: 0.9566 - val_loss: 0.2008 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9523\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1740 - out_1_loss: 0.0970 - out_2_loss: 0.0770 - out_1_acc: 0.9455 - out_2_acc: 0.9570 - val_loss: 0.2010 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1727 - out_1_loss: 0.0965 - out_2_loss: 0.0762 - out_1_acc: 0.9457 - out_2_acc: 0.9572 - val_loss: 0.2015 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1714 - out_1_loss: 0.0960 - out_2_loss: 0.0754 - out_1_acc: 0.9459 - out_2_acc: 0.9577 - val_loss: 0.2020 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1701 - out_1_loss: 0.0955 - out_2_loss: 0.0746 - out_1_acc: 0.9463 - out_2_acc: 0.9580 - val_loss: 0.2024 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0919 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1686 - out_1_loss: 0.0949 - out_2_loss: 0.0737 - out_1_acc: 0.9467 - out_2_acc: 0.9586 - val_loss: 0.2027 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1673 - out_1_loss: 0.0945 - out_2_loss: 0.0728 - out_1_acc: 0.9471 - out_2_acc: 0.9588 - val_loss: 0.2037 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0930 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1656 - out_1_loss: 0.0939 - out_2_loss: 0.0717 - out_1_acc: 0.9473 - out_2_acc: 0.9592 - val_loss: 0.2041 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.0934 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1642 - out_1_loss: 0.0934 - out_2_loss: 0.0708 - out_1_acc: 0.9477 - out_2_acc: 0.9599 - val_loss: 0.2047 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.0939 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9527\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1623 - out_1_loss: 0.0928 - out_2_loss: 0.0696 - out_1_acc: 0.9480 - out_2_acc: 0.9607 - val_loss: 0.2060 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1612 - out_1_loss: 0.0922 - out_2_loss: 0.0689 - out_1_acc: 0.9482 - out_2_acc: 0.9608 - val_loss: 0.2070 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1592 - out_1_loss: 0.0916 - out_2_loss: 0.0676 - out_1_acc: 0.9486 - out_2_acc: 0.9614 - val_loss: 0.2071 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9526\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1574 - out_1_loss: 0.0910 - out_2_loss: 0.0664 - out_1_acc: 0.9488 - out_2_acc: 0.9621 - val_loss: 0.2086 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0970 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9526\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1556 - out_1_loss: 0.0903 - out_2_loss: 0.0653 - out_1_acc: 0.9494 - out_2_acc: 0.9628 - val_loss: 0.2099 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1537 - out_1_loss: 0.0897 - out_2_loss: 0.0639 - out_1_acc: 0.9497 - out_2_acc: 0.9633 - val_loss: 0.2113 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.0991 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9529\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1521 - out_1_loss: 0.0890 - out_2_loss: 0.0631 - out_1_acc: 0.9502 - out_2_acc: 0.9635 - val_loss: 0.2131 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.1005 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1502 - out_1_loss: 0.0884 - out_2_loss: 0.0618 - out_1_acc: 0.9507 - out_2_acc: 0.9643 - val_loss: 0.2139 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9524\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1482 - out_1_loss: 0.0877 - out_2_loss: 0.0605 - out_1_acc: 0.9509 - out_2_acc: 0.9652 - val_loss: 0.2164 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1031 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1464 - out_1_loss: 0.0870 - out_2_loss: 0.0594 - out_1_acc: 0.9514 - out_2_acc: 0.9656 - val_loss: 0.2182 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.1041 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1449 - out_1_loss: 0.0863 - out_2_loss: 0.0586 - out_1_acc: 0.9520 - out_2_acc: 0.9659 - val_loss: 0.2205 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.1057 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1431 - out_1_loss: 0.0856 - out_2_loss: 0.0575 - out_1_acc: 0.9522 - out_2_acc: 0.9661 - val_loss: 0.2225 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.1073 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1415 - out_1_loss: 0.0848 - out_2_loss: 0.0567 - out_1_acc: 0.9527 - out_2_acc: 0.9668 - val_loss: 0.2256 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1101 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9529\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1403 - out_1_loss: 0.0841 - out_2_loss: 0.0562 - out_1_acc: 0.9532 - out_2_acc: 0.9668 - val_loss: 0.2286 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.1124 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9524\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1387 - out_1_loss: 0.0832 - out_2_loss: 0.0555 - out_1_acc: 0.9538 - out_2_acc: 0.9677 - val_loss: 0.2355 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1181 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1380 - out_1_loss: 0.0825 - out_2_loss: 0.0555 - out_1_acc: 0.9539 - out_2_acc: 0.9673 - val_loss: 0.2398 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1215 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9524\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1379 - out_1_loss: 0.0818 - out_2_loss: 0.0561 - out_1_acc: 0.9544 - out_2_acc: 0.9669 - val_loss: 0.2403 - val_out_1_loss: 0.1192 - val_out_2_loss: 0.1211 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9530\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1376 - out_1_loss: 0.0810 - out_2_loss: 0.0565 - out_1_acc: 0.9550 - out_2_acc: 0.9668 - val_loss: 0.2475 - val_out_1_loss: 0.1195 - val_out_2_loss: 0.1280 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1357 - out_1_loss: 0.0803 - out_2_loss: 0.0554 - out_1_acc: 0.9555 - out_2_acc: 0.9674 - val_loss: 0.2431 - val_out_1_loss: 0.1203 - val_out_2_loss: 0.1228 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9533\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1327 - out_1_loss: 0.0794 - out_2_loss: 0.0532 - out_1_acc: 0.9557 - out_2_acc: 0.9681 - val_loss: 0.2465 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1252 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9537\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1302 - out_1_loss: 0.0786 - out_2_loss: 0.0516 - out_1_acc: 0.9565 - out_2_acc: 0.9692 - val_loss: 0.2481 - val_out_1_loss: 0.1225 - val_out_2_loss: 0.1256 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9528\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1285 - out_1_loss: 0.0778 - out_2_loss: 0.0507 - out_1_acc: 0.9566 - out_2_acc: 0.9699 - val_loss: 0.2490 - val_out_1_loss: 0.1221 - val_out_2_loss: 0.1269 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9528\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1269 - out_1_loss: 0.0768 - out_2_loss: 0.0501 - out_1_acc: 0.9575 - out_2_acc: 0.9700 - val_loss: 0.2524 - val_out_1_loss: 0.1235 - val_out_2_loss: 0.1289 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9529\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1258 - out_1_loss: 0.0761 - out_2_loss: 0.0497 - out_1_acc: 0.9577 - out_2_acc: 0.9701 - val_loss: 0.2534 - val_out_1_loss: 0.1244 - val_out_2_loss: 0.1290 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9530\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1245 - out_1_loss: 0.0754 - out_2_loss: 0.0492 - out_1_acc: 0.9581 - out_2_acc: 0.9704 - val_loss: 0.2570 - val_out_1_loss: 0.1252 - val_out_2_loss: 0.1318 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9530\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1234 - out_1_loss: 0.0743 - out_2_loss: 0.0491 - out_1_acc: 0.9591 - out_2_acc: 0.9700 - val_loss: 0.2585 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1328 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9534\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1224 - out_1_loss: 0.0737 - out_2_loss: 0.0487 - out_1_acc: 0.9592 - out_2_acc: 0.9708 - val_loss: 0.2619 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1347 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1212 - out_1_loss: 0.0730 - out_2_loss: 0.0482 - out_1_acc: 0.9597 - out_2_acc: 0.9709 - val_loss: 0.2616 - val_out_1_loss: 0.1281 - val_out_2_loss: 0.1335 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9532\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1202 - out_1_loss: 0.0723 - out_2_loss: 0.0478 - out_1_acc: 0.9597 - out_2_acc: 0.9711 - val_loss: 0.2637 - val_out_1_loss: 0.1287 - val_out_2_loss: 0.1350 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9533\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1192 - out_1_loss: 0.0714 - out_2_loss: 0.0478 - out_1_acc: 0.9606 - out_2_acc: 0.9714 - val_loss: 0.2660 - val_out_1_loss: 0.1300 - val_out_2_loss: 0.1360 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1183 - out_1_loss: 0.0707 - out_2_loss: 0.0476 - out_1_acc: 0.9606 - out_2_acc: 0.9714 - val_loss: 0.2673 - val_out_1_loss: 0.1310 - val_out_2_loss: 0.1364 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9537\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1172 - out_1_loss: 0.0701 - out_2_loss: 0.0472 - out_1_acc: 0.9614 - out_2_acc: 0.9721 - val_loss: 0.2699 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1377 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9531\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1166 - out_1_loss: 0.0695 - out_2_loss: 0.0472 - out_1_acc: 0.9616 - out_2_acc: 0.9719 - val_loss: 0.2707 - val_out_1_loss: 0.1331 - val_out_2_loss: 0.1376 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1156 - out_1_loss: 0.0687 - out_2_loss: 0.0469 - out_1_acc: 0.9620 - out_2_acc: 0.9724 - val_loss: 0.2730 - val_out_1_loss: 0.1335 - val_out_2_loss: 0.1394 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1148 - out_1_loss: 0.0679 - out_2_loss: 0.0468 - out_1_acc: 0.9625 - out_2_acc: 0.9721 - val_loss: 0.2752 - val_out_1_loss: 0.1349 - val_out_2_loss: 0.1403 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9528\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1142 - out_1_loss: 0.0676 - out_2_loss: 0.0467 - out_1_acc: 0.9629 - out_2_acc: 0.9723 - val_loss: 0.2760 - val_out_1_loss: 0.1361 - val_out_2_loss: 0.1399 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9536\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1130 - out_1_loss: 0.0668 - out_2_loss: 0.0462 - out_1_acc: 0.9635 - out_2_acc: 0.9727 - val_loss: 0.2802 - val_out_1_loss: 0.1381 - val_out_2_loss: 0.1421 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9527\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1125 - out_1_loss: 0.0665 - out_2_loss: 0.0460 - out_1_acc: 0.9634 - out_2_acc: 0.9728 - val_loss: 0.2810 - val_out_1_loss: 0.1391 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1120 - out_1_loss: 0.0662 - out_2_loss: 0.0458 - out_1_acc: 0.9638 - out_2_acc: 0.9734 - val_loss: 0.2843 - val_out_1_loss: 0.1412 - val_out_2_loss: 0.1431 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1115 - out_1_loss: 0.0661 - out_2_loss: 0.0454 - out_1_acc: 0.9635 - out_2_acc: 0.9736 - val_loss: 0.2871 - val_out_1_loss: 0.1432 - val_out_2_loss: 0.1438 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1111 - out_1_loss: 0.0656 - out_2_loss: 0.0455 - out_1_acc: 0.9639 - out_2_acc: 0.9736 - val_loss: 0.2909 - val_out_1_loss: 0.1451 - val_out_2_loss: 0.1458 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1104 - out_1_loss: 0.0650 - out_2_loss: 0.0454 - out_1_acc: 0.9643 - out_2_acc: 0.9737 - val_loss: 0.2927 - val_out_1_loss: 0.1469 - val_out_2_loss: 0.1459 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9529\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1104 - out_1_loss: 0.0654 - out_2_loss: 0.0450 - out_1_acc: 0.9639 - out_2_acc: 0.9738 - val_loss: 0.2928 - val_out_1_loss: 0.1463 - val_out_2_loss: 0.1465 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1092 - out_1_loss: 0.0645 - out_2_loss: 0.0448 - out_1_acc: 0.9645 - out_2_acc: 0.9741 - val_loss: 0.2958 - val_out_1_loss: 0.1498 - val_out_2_loss: 0.1460 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9527\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1091 - out_1_loss: 0.0646 - out_2_loss: 0.0445 - out_1_acc: 0.9645 - out_2_acc: 0.9742 - val_loss: 0.2987 - val_out_1_loss: 0.1494 - val_out_2_loss: 0.1493 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9537\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1084 - out_1_loss: 0.0641 - out_2_loss: 0.0442 - out_1_acc: 0.9652 - out_2_acc: 0.9748 - val_loss: 0.3012 - val_out_1_loss: 0.1507 - val_out_2_loss: 0.1505 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9522\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1068 - out_1_loss: 0.0629 - out_2_loss: 0.0439 - out_1_acc: 0.9656 - out_2_acc: 0.9751 - val_loss: 0.3025 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1495 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9525\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1055 - out_1_loss: 0.0628 - out_2_loss: 0.0427 - out_1_acc: 0.9654 - out_2_acc: 0.9760 - val_loss: 0.3082 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1544 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9530\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1051 - out_1_loss: 0.0619 - out_2_loss: 0.0431 - out_1_acc: 0.9659 - out_2_acc: 0.9757 - val_loss: 0.3091 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1549 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9523\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1040 - out_1_loss: 0.0614 - out_2_loss: 0.0426 - out_1_acc: 0.9660 - out_2_acc: 0.9765 - val_loss: 0.3102 - val_out_1_loss: 0.1543 - val_out_2_loss: 0.1559 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9526\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1029 - out_1_loss: 0.0610 - out_2_loss: 0.0419 - out_1_acc: 0.9664 - out_2_acc: 0.9767 - val_loss: 0.3094 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1565 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9527\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1019 - out_1_loss: 0.0602 - out_2_loss: 0.0416 - out_1_acc: 0.9669 - out_2_acc: 0.9767 - val_loss: 0.3081 - val_out_1_loss: 0.1530 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9425 - val_out_2_acc: 0.9528\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1025 - out_1_loss: 0.0601 - out_2_loss: 0.0424 - out_1_acc: 0.9673 - out_2_acc: 0.9764 - val_loss: 0.3123 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1581 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9526\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1025 - out_1_loss: 0.0600 - out_2_loss: 0.0425 - out_1_acc: 0.9676 - out_2_acc: 0.9763 - val_loss: 0.3120 - val_out_1_loss: 0.1545 - val_out_2_loss: 0.1575 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9531\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1005 - out_1_loss: 0.0586 - out_2_loss: 0.0419 - out_1_acc: 0.9683 - out_2_acc: 0.9769 - val_loss: 0.3123 - val_out_1_loss: 0.1549 - val_out_2_loss: 0.1574 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9522\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0992 - out_1_loss: 0.0586 - out_2_loss: 0.0407 - out_1_acc: 0.9682 - out_2_acc: 0.9777 - val_loss: 0.3162 - val_out_1_loss: 0.1563 - val_out_2_loss: 0.1599 - val_out_1_acc: 0.9424 - val_out_2_acc: 0.9530\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0986 - out_1_loss: 0.0579 - out_2_loss: 0.0407 - out_1_acc: 0.9689 - out_2_acc: 0.9777 - val_loss: 0.3155 - val_out_1_loss: 0.1560 - val_out_2_loss: 0.1595 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9526\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0974 - out_1_loss: 0.0572 - out_2_loss: 0.0402 - out_1_acc: 0.9690 - out_2_acc: 0.9784 - val_loss: 0.3173 - val_out_1_loss: 0.1584 - val_out_2_loss: 0.1589 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9525\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0968 - out_1_loss: 0.0570 - out_2_loss: 0.0398 - out_1_acc: 0.9693 - out_2_acc: 0.9783 - val_loss: 0.3157 - val_out_1_loss: 0.1569 - val_out_2_loss: 0.1588 - val_out_1_acc: 0.9424 - val_out_2_acc: 0.9536\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 39ms/step - loss: 0.0954 - out_1_loss: 0.0557 - out_2_loss: 0.0397 - out_1_acc: 0.9704 - out_2_acc: 0.9788 - val_loss: 0.3216 - val_out_1_loss: 0.1589 - val_out_2_loss: 0.1628 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9521\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0945 - out_1_loss: 0.0555 - out_2_loss: 0.0390 - out_1_acc: 0.9708 - out_2_acc: 0.9793 - val_loss: 0.3244 - val_out_1_loss: 0.1621 - val_out_2_loss: 0.1623 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9513\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0946 - out_1_loss: 0.0556 - out_2_loss: 0.0390 - out_1_acc: 0.9705 - out_2_acc: 0.9797 - val_loss: 0.3254 - val_out_1_loss: 0.1620 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0927 - out_1_loss: 0.0548 - out_2_loss: 0.0379 - out_1_acc: 0.9711 - out_2_acc: 0.9802 - val_loss: 0.3279 - val_out_1_loss: 0.1634 - val_out_2_loss: 0.1645 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9511\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0931 - out_1_loss: 0.0549 - out_2_loss: 0.0382 - out_1_acc: 0.9710 - out_2_acc: 0.9798 - val_loss: 0.3296 - val_out_1_loss: 0.1635 - val_out_2_loss: 0.1661 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9516\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0917 - out_1_loss: 0.0542 - out_2_loss: 0.0375 - out_1_acc: 0.9717 - out_2_acc: 0.9804 - val_loss: 0.3343 - val_out_1_loss: 0.1664 - val_out_2_loss: 0.1679 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9514\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0902 - out_1_loss: 0.0534 - out_2_loss: 0.0367 - out_1_acc: 0.9721 - out_2_acc: 0.9810 - val_loss: 0.3368 - val_out_1_loss: 0.1652 - val_out_2_loss: 0.1716 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9525\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0892 - out_1_loss: 0.0533 - out_2_loss: 0.0359 - out_1_acc: 0.9722 - out_2_acc: 0.9816 - val_loss: 0.3440 - val_out_1_loss: 0.1710 - val_out_2_loss: 0.1730 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9518\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0900 - out_1_loss: 0.0539 - out_2_loss: 0.0361 - out_1_acc: 0.9716 - out_2_acc: 0.9817 - val_loss: 0.3358 - val_out_1_loss: 0.1680 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9528\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0893 - out_1_loss: 0.0532 - out_2_loss: 0.0362 - out_1_acc: 0.9724 - out_2_acc: 0.9816 - val_loss: 0.3406 - val_out_1_loss: 0.1700 - val_out_2_loss: 0.1706 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0881 - out_1_loss: 0.0525 - out_2_loss: 0.0356 - out_1_acc: 0.9727 - out_2_acc: 0.9821 - val_loss: 0.3388 - val_out_1_loss: 0.1679 - val_out_2_loss: 0.1709 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9529\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0863 - out_1_loss: 0.0519 - out_2_loss: 0.0343 - out_1_acc: 0.9731 - out_2_acc: 0.9829 - val_loss: 0.3425 - val_out_1_loss: 0.1702 - val_out_2_loss: 0.1723 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0856 - out_1_loss: 0.0522 - out_2_loss: 0.0334 - out_1_acc: 0.9728 - out_2_acc: 0.9833 - val_loss: 0.3472 - val_out_1_loss: 0.1730 - val_out_2_loss: 0.1742 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0852 - out_1_loss: 0.0522 - out_2_loss: 0.0330 - out_1_acc: 0.9733 - out_2_acc: 0.9835 - val_loss: 0.3514 - val_out_1_loss: 0.1723 - val_out_2_loss: 0.1791 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9520\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0836 - out_1_loss: 0.0512 - out_2_loss: 0.0325 - out_1_acc: 0.9741 - out_2_acc: 0.9840 - val_loss: 0.3514 - val_out_1_loss: 0.1742 - val_out_2_loss: 0.1772 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0815 - out_1_loss: 0.0503 - out_2_loss: 0.0311 - out_1_acc: 0.9744 - out_2_acc: 0.9849 - val_loss: 0.3522 - val_out_1_loss: 0.1747 - val_out_2_loss: 0.1775 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0814 - out_1_loss: 0.0503 - out_2_loss: 0.0311 - out_1_acc: 0.9746 - out_2_acc: 0.9851 - val_loss: 0.3530 - val_out_1_loss: 0.1751 - val_out_2_loss: 0.1779 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9526\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0821 - out_1_loss: 0.0505 - out_2_loss: 0.0316 - out_1_acc: 0.9741 - out_2_acc: 0.9847 - val_loss: 0.3593 - val_out_1_loss: 0.1736 - val_out_2_loss: 0.1857 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0797 - out_1_loss: 0.0488 - out_2_loss: 0.0309 - out_1_acc: 0.9751 - out_2_acc: 0.9849 - val_loss: 0.3542 - val_out_1_loss: 0.1752 - val_out_2_loss: 0.1791 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9535\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0782 - out_1_loss: 0.0480 - out_2_loss: 0.0302 - out_1_acc: 0.9755 - out_2_acc: 0.9854 - val_loss: 0.3549 - val_out_1_loss: 0.1748 - val_out_2_loss: 0.1801 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9538\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0767 - out_1_loss: 0.0475 - out_2_loss: 0.0292 - out_1_acc: 0.9760 - out_2_acc: 0.9861 - val_loss: 0.3646 - val_out_1_loss: 0.1773 - val_out_2_loss: 0.1873 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9529\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0784 - out_1_loss: 0.0477 - out_2_loss: 0.0307 - out_1_acc: 0.9763 - out_2_acc: 0.9849 - val_loss: 0.3661 - val_out_1_loss: 0.1775 - val_out_2_loss: 0.1886 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9529\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0789 - out_1_loss: 0.0478 - out_2_loss: 0.0311 - out_1_acc: 0.9759 - out_2_acc: 0.9848 - val_loss: 0.3642 - val_out_1_loss: 0.1789 - val_out_2_loss: 0.1852 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9531\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0770 - out_1_loss: 0.0472 - out_2_loss: 0.0298 - out_1_acc: 0.9760 - out_2_acc: 0.9853 - val_loss: 0.3707 - val_out_1_loss: 0.1803 - val_out_2_loss: 0.1904 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9534\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0782 - out_1_loss: 0.0475 - out_2_loss: 0.0307 - out_1_acc: 0.9762 - out_2_acc: 0.9851 - val_loss: 0.3699 - val_out_1_loss: 0.1816 - val_out_2_loss: 0.1883 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9529\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0799 - out_1_loss: 0.0476 - out_2_loss: 0.0323 - out_1_acc: 0.9760 - out_2_acc: 0.9842 - val_loss: 0.3685 - val_out_1_loss: 0.1817 - val_out_2_loss: 0.1868 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0779 - out_1_loss: 0.0470 - out_2_loss: 0.0309 - out_1_acc: 0.9763 - out_2_acc: 0.9847 - val_loss: 0.3751 - val_out_1_loss: 0.1854 - val_out_2_loss: 0.1897 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9533\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0796 - out_1_loss: 0.0476 - out_2_loss: 0.0319 - out_1_acc: 0.9760 - out_2_acc: 0.9846 - val_loss: 0.3787 - val_out_1_loss: 0.1872 - val_out_2_loss: 0.1915 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0751 - out_1_loss: 0.0457 - out_2_loss: 0.0294 - out_1_acc: 0.9777 - out_2_acc: 0.9857 - val_loss: 0.3840 - val_out_1_loss: 0.1911 - val_out_2_loss: 0.1929 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0729 - out_1_loss: 0.0451 - out_2_loss: 0.0278 - out_1_acc: 0.9780 - out_2_acc: 0.9871 - val_loss: 0.3899 - val_out_1_loss: 0.1928 - val_out_2_loss: 0.1971 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0727 - out_1_loss: 0.0451 - out_2_loss: 0.0276 - out_1_acc: 0.9783 - out_2_acc: 0.9871 - val_loss: 0.3883 - val_out_1_loss: 0.1903 - val_out_2_loss: 0.1980 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0719 - out_1_loss: 0.0447 - out_2_loss: 0.0272 - out_1_acc: 0.9784 - out_2_acc: 0.9872 - val_loss: 0.3914 - val_out_1_loss: 0.1930 - val_out_2_loss: 0.1983 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9519\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0705 - out_1_loss: 0.0439 - out_2_loss: 0.0266 - out_1_acc: 0.9784 - out_2_acc: 0.9875 - val_loss: 0.3915 - val_out_1_loss: 0.1937 - val_out_2_loss: 0.1979 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9534\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0684 - out_1_loss: 0.0428 - out_2_loss: 0.0257 - out_1_acc: 0.9791 - out_2_acc: 0.9881 - val_loss: 0.4000 - val_out_1_loss: 0.1976 - val_out_2_loss: 0.2024 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9538\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0697 - out_1_loss: 0.0431 - out_2_loss: 0.0265 - out_1_acc: 0.9786 - out_2_acc: 0.9875 - val_loss: 0.4052 - val_out_1_loss: 0.1984 - val_out_2_loss: 0.2067 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0705 - out_1_loss: 0.0435 - out_2_loss: 0.0269 - out_1_acc: 0.9786 - out_2_acc: 0.9875 - val_loss: 0.4120 - val_out_1_loss: 0.2073 - val_out_2_loss: 0.2048 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0702 - out_1_loss: 0.0444 - out_2_loss: 0.0258 - out_1_acc: 0.9783 - out_2_acc: 0.9881 - val_loss: 0.4117 - val_out_1_loss: 0.2033 - val_out_2_loss: 0.2084 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0682 - out_1_loss: 0.0437 - out_2_loss: 0.0245 - out_1_acc: 0.9783 - out_2_acc: 0.9891 - val_loss: 0.4074 - val_out_1_loss: 0.2019 - val_out_2_loss: 0.2055 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9522\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0652 - out_1_loss: 0.0426 - out_2_loss: 0.0226 - out_1_acc: 0.9791 - out_2_acc: 0.9898 - val_loss: 0.4139 - val_out_1_loss: 0.2042 - val_out_2_loss: 0.2096 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9530\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0670 - out_1_loss: 0.0436 - out_2_loss: 0.0234 - out_1_acc: 0.9789 - out_2_acc: 0.9893 - val_loss: 0.4169 - val_out_1_loss: 0.2075 - val_out_2_loss: 0.2094 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0654 - out_1_loss: 0.0437 - out_2_loss: 0.0217 - out_1_acc: 0.9787 - out_2_acc: 0.9905 - val_loss: 0.4264 - val_out_1_loss: 0.2079 - val_out_2_loss: 0.2185 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0691 - out_1_loss: 0.0470 - out_2_loss: 0.0221 - out_1_acc: 0.9769 - out_2_acc: 0.9899 - val_loss: 0.4263 - val_out_1_loss: 0.2060 - val_out_2_loss: 0.2203 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9517\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0704 - out_1_loss: 0.0472 - out_2_loss: 0.0232 - out_1_acc: 0.9768 - out_2_acc: 0.9896 - val_loss: 0.4283 - val_out_1_loss: 0.2039 - val_out_2_loss: 0.2244 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9524\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0750 - out_1_loss: 0.0493 - out_2_loss: 0.0257 - out_1_acc: 0.9764 - out_2_acc: 0.9885 - val_loss: 0.4247 - val_out_1_loss: 0.2044 - val_out_2_loss: 0.2202 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9524\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0739 - out_1_loss: 0.0483 - out_2_loss: 0.0256 - out_1_acc: 0.9768 - out_2_acc: 0.9884 - val_loss: 0.4180 - val_out_1_loss: 0.2013 - val_out_2_loss: 0.2167 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9524\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0771 - out_1_loss: 0.0495 - out_2_loss: 0.0276 - out_1_acc: 0.9759 - out_2_acc: 0.9874 - val_loss: 0.4219 - val_out_1_loss: 0.2070 - val_out_2_loss: 0.2149 - val_out_1_acc: 0.9425 - val_out_2_acc: 0.9536\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0731 - out_1_loss: 0.0480 - out_2_loss: 0.0251 - out_1_acc: 0.9771 - out_2_acc: 0.9887 - val_loss: 0.4183 - val_out_1_loss: 0.2084 - val_out_2_loss: 0.2099 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0698 - out_1_loss: 0.0461 - out_2_loss: 0.0236 - out_1_acc: 0.9782 - out_2_acc: 0.9898 - val_loss: 0.4215 - val_out_1_loss: 0.2078 - val_out_2_loss: 0.2137 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9535\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0638 - out_1_loss: 0.0430 - out_2_loss: 0.0208 - out_1_acc: 0.9796 - out_2_acc: 0.9909 - val_loss: 0.4210 - val_out_1_loss: 0.2028 - val_out_2_loss: 0.2183 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9530\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0594 - out_1_loss: 0.0403 - out_2_loss: 0.0191 - out_1_acc: 0.9810 - out_2_acc: 0.9918 - val_loss: 0.4238 - val_out_1_loss: 0.2044 - val_out_2_loss: 0.2194 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9534\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0563 - out_1_loss: 0.0385 - out_2_loss: 0.0178 - out_1_acc: 0.9822 - out_2_acc: 0.9924 - val_loss: 0.4305 - val_out_1_loss: 0.2066 - val_out_2_loss: 0.2239 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9528\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0553 - out_1_loss: 0.0379 - out_2_loss: 0.0174 - out_1_acc: 0.9822 - out_2_acc: 0.9926 - val_loss: 0.4383 - val_out_1_loss: 0.2109 - val_out_2_loss: 0.2274 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0536 - out_1_loss: 0.0368 - out_2_loss: 0.0168 - out_1_acc: 0.9831 - out_2_acc: 0.9930 - val_loss: 0.4355 - val_out_1_loss: 0.2096 - val_out_2_loss: 0.2259 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9524\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0496 - out_1_loss: 0.0350 - out_2_loss: 0.0146 - out_1_acc: 0.9842 - out_2_acc: 0.9941 - val_loss: 0.4388 - val_out_1_loss: 0.2113 - val_out_2_loss: 0.2275 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9523\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0493 - out_1_loss: 0.0347 - out_2_loss: 0.0146 - out_1_acc: 0.9839 - out_2_acc: 0.9942 - val_loss: 0.4433 - val_out_1_loss: 0.2131 - val_out_2_loss: 0.2302 - val_out_1_acc: 0.9426 - val_out_2_acc: 0.9524\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0492 - out_1_loss: 0.0346 - out_2_loss: 0.0146 - out_1_acc: 0.9843 - out_2_acc: 0.9940 - val_loss: 0.4536 - val_out_1_loss: 0.2168 - val_out_2_loss: 0.2367 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9529\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0502 - out_1_loss: 0.0356 - out_2_loss: 0.0146 - out_1_acc: 0.9839 - out_2_acc: 0.9941 - val_loss: 0.4587 - val_out_1_loss: 0.2204 - val_out_2_loss: 0.2383 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9533\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0482 - out_1_loss: 0.0343 - out_2_loss: 0.0139 - out_1_acc: 0.9848 - out_2_acc: 0.9942 - val_loss: 0.4551 - val_out_1_loss: 0.2180 - val_out_2_loss: 0.2371 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9531\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0452 - out_1_loss: 0.0324 - out_2_loss: 0.0128 - out_1_acc: 0.9858 - out_2_acc: 0.9947 - val_loss: 0.4655 - val_out_1_loss: 0.2244 - val_out_2_loss: 0.2411 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0450 - out_1_loss: 0.0322 - out_2_loss: 0.0127 - out_1_acc: 0.9858 - out_2_acc: 0.9950 - val_loss: 0.4740 - val_out_1_loss: 0.2281 - val_out_2_loss: 0.2460 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0450 - out_1_loss: 0.0317 - out_2_loss: 0.0133 - out_1_acc: 0.9862 - out_2_acc: 0.9946 - val_loss: 0.4761 - val_out_1_loss: 0.2282 - val_out_2_loss: 0.2479 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(3)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4487 - out_1_loss: 0.2126 - out_2_loss: 0.2361 - out_1_acc: 0.9424 - out_2_acc: 0.9548\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 200), (No 208800      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 200)       208800      input_5[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,155,680\n",
      "Trainable params: 1,155,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3426 - out_1_loss: 3.6739 - out_2_loss: 3.6688 - out_1_acc: 0.1182 - out_2_acc: 0.1061WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.110487). Check your callbacks.\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 5.3259 - out_1_loss: 2.9496 - out_2_loss: 2.3763 - out_1_acc: 0.5860 - out_2_acc: 0.6641 - val_loss: 2.0463 - val_out_1_loss: 1.4931 - val_out_2_loss: 0.5531 - val_out_1_acc: 0.6927 - val_out_2_acc: 0.8853\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.1253 - out_1_loss: 0.8285 - out_2_loss: 0.2968 - out_1_acc: 0.8490 - out_2_acc: 0.9418 - val_loss: 0.6627 - val_out_1_loss: 0.4768 - val_out_2_loss: 0.1858 - val_out_1_acc: 0.9135 - val_out_2_acc: 0.9490\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.5147 - out_1_loss: 0.3679 - out_2_loss: 0.1467 - out_1_acc: 0.9244 - out_2_acc: 0.9521 - val_loss: 0.4033 - val_out_1_loss: 0.2714 - val_out_2_loss: 0.1319 - val_out_1_acc: 0.9333 - val_out_2_acc: 0.9506\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3337 - out_1_loss: 0.2181 - out_2_loss: 0.1156 - out_1_acc: 0.9376 - out_2_acc: 0.9521 - val_loss: 0.2929 - val_out_1_loss: 0.1795 - val_out_2_loss: 0.1134 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9509\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2557 - out_1_loss: 0.1533 - out_2_loss: 0.1023 - out_1_acc: 0.9395 - out_2_acc: 0.9526 - val_loss: 0.2481 - val_out_1_loss: 0.1444 - val_out_2_loss: 0.1037 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9505\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2249 - out_1_loss: 0.1302 - out_2_loss: 0.0947 - out_1_acc: 0.9402 - out_2_acc: 0.9524 - val_loss: 0.2293 - val_out_1_loss: 0.1316 - val_out_2_loss: 0.0977 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9504\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2108 - out_1_loss: 0.1206 - out_2_loss: 0.0901 - out_1_acc: 0.9410 - out_2_acc: 0.9525 - val_loss: 0.2196 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.0943 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2027 - out_1_loss: 0.1153 - out_2_loss: 0.0874 - out_1_acc: 0.9410 - out_2_acc: 0.9526 - val_loss: 0.2131 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.0919 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9506\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1972 - out_1_loss: 0.1116 - out_2_loss: 0.0856 - out_1_acc: 0.9414 - out_2_acc: 0.9529 - val_loss: 0.2087 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9507\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1932 - out_1_loss: 0.1089 - out_2_loss: 0.0843 - out_1_acc: 0.9418 - out_2_acc: 0.9532 - val_loss: 0.2055 - val_out_1_loss: 0.1163 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9506\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1904 - out_1_loss: 0.1069 - out_2_loss: 0.0835 - out_1_acc: 0.9421 - out_2_acc: 0.9534 - val_loss: 0.2034 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9508\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1882 - out_1_loss: 0.1054 - out_2_loss: 0.0828 - out_1_acc: 0.9424 - out_2_acc: 0.9537 - val_loss: 0.2018 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.0883 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9511\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1863 - out_1_loss: 0.1041 - out_2_loss: 0.0823 - out_1_acc: 0.9424 - out_2_acc: 0.9538 - val_loss: 0.2006 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.0881 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9509\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1847 - out_1_loss: 0.1030 - out_2_loss: 0.0818 - out_1_acc: 0.9427 - out_2_acc: 0.9540 - val_loss: 0.1999 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0881 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1833 - out_1_loss: 0.1020 - out_2_loss: 0.0813 - out_1_acc: 0.9428 - out_2_acc: 0.9543 - val_loss: 0.1993 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0882 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1820 - out_1_loss: 0.1012 - out_2_loss: 0.0808 - out_1_acc: 0.9431 - out_2_acc: 0.9545 - val_loss: 0.1992 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0885 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1808 - out_1_loss: 0.1005 - out_2_loss: 0.0803 - out_1_acc: 0.9436 - out_2_acc: 0.9548 - val_loss: 0.1990 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0887 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1795 - out_1_loss: 0.0998 - out_2_loss: 0.0797 - out_1_acc: 0.9438 - out_2_acc: 0.9552 - val_loss: 0.1989 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1784 - out_1_loss: 0.0992 - out_2_loss: 0.0791 - out_1_acc: 0.9440 - out_2_acc: 0.9555 - val_loss: 0.1989 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1772 - out_1_loss: 0.0987 - out_2_loss: 0.0785 - out_1_acc: 0.9443 - out_2_acc: 0.9557 - val_loss: 0.1990 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1760 - out_1_loss: 0.0981 - out_2_loss: 0.0779 - out_1_acc: 0.9443 - out_2_acc: 0.9561 - val_loss: 0.1992 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0899 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1748 - out_1_loss: 0.0976 - out_2_loss: 0.0772 - out_1_acc: 0.9445 - out_2_acc: 0.9565 - val_loss: 0.1993 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1736 - out_1_loss: 0.0971 - out_2_loss: 0.0764 - out_1_acc: 0.9447 - out_2_acc: 0.9568 - val_loss: 0.1997 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1723 - out_1_loss: 0.0966 - out_2_loss: 0.0756 - out_1_acc: 0.9448 - out_2_acc: 0.9572 - val_loss: 0.1999 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9519\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1709 - out_1_loss: 0.0962 - out_2_loss: 0.0747 - out_1_acc: 0.9453 - out_2_acc: 0.9574 - val_loss: 0.2006 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9514\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1695 - out_1_loss: 0.0957 - out_2_loss: 0.0738 - out_1_acc: 0.9456 - out_2_acc: 0.9580 - val_loss: 0.2007 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1681 - out_1_loss: 0.0952 - out_2_loss: 0.0729 - out_1_acc: 0.9458 - out_2_acc: 0.9584 - val_loss: 0.2015 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1666 - out_1_loss: 0.0947 - out_2_loss: 0.0719 - out_1_acc: 0.9463 - out_2_acc: 0.9588 - val_loss: 0.2016 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0924 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1651 - out_1_loss: 0.0942 - out_2_loss: 0.0709 - out_1_acc: 0.9464 - out_2_acc: 0.9591 - val_loss: 0.2027 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0934 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1634 - out_1_loss: 0.0936 - out_2_loss: 0.0697 - out_1_acc: 0.9468 - out_2_acc: 0.9595 - val_loss: 0.2032 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0939 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1618 - out_1_loss: 0.0931 - out_2_loss: 0.0687 - out_1_acc: 0.9471 - out_2_acc: 0.9606 - val_loss: 0.2041 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1600 - out_1_loss: 0.0925 - out_2_loss: 0.0676 - out_1_acc: 0.9475 - out_2_acc: 0.9609 - val_loss: 0.2048 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9528\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1584 - out_1_loss: 0.0919 - out_2_loss: 0.0665 - out_1_acc: 0.9479 - out_2_acc: 0.9611 - val_loss: 0.2061 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1564 - out_1_loss: 0.0912 - out_2_loss: 0.0652 - out_1_acc: 0.9485 - out_2_acc: 0.9620 - val_loss: 0.2072 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1547 - out_1_loss: 0.0906 - out_2_loss: 0.0641 - out_1_acc: 0.9488 - out_2_acc: 0.9624 - val_loss: 0.2088 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0984 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1530 - out_1_loss: 0.0900 - out_2_loss: 0.0630 - out_1_acc: 0.9492 - out_2_acc: 0.9633 - val_loss: 0.2103 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0996 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1510 - out_1_loss: 0.0893 - out_2_loss: 0.0617 - out_1_acc: 0.9498 - out_2_acc: 0.9637 - val_loss: 0.2122 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1493 - out_1_loss: 0.0886 - out_2_loss: 0.0607 - out_1_acc: 0.9504 - out_2_acc: 0.9640 - val_loss: 0.2144 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.1027 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1473 - out_1_loss: 0.0879 - out_2_loss: 0.0595 - out_1_acc: 0.9507 - out_2_acc: 0.9651 - val_loss: 0.2158 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.1037 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1454 - out_1_loss: 0.0870 - out_2_loss: 0.0584 - out_1_acc: 0.9514 - out_2_acc: 0.9658 - val_loss: 0.2176 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1436 - out_1_loss: 0.0863 - out_2_loss: 0.0573 - out_1_acc: 0.9516 - out_2_acc: 0.9661 - val_loss: 0.2201 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1421 - out_1_loss: 0.0856 - out_2_loss: 0.0565 - out_1_acc: 0.9522 - out_2_acc: 0.9663 - val_loss: 0.2220 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1086 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1407 - out_1_loss: 0.0848 - out_2_loss: 0.0559 - out_1_acc: 0.9527 - out_2_acc: 0.9664 - val_loss: 0.2249 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.1108 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1391 - out_1_loss: 0.0841 - out_2_loss: 0.0550 - out_1_acc: 0.9530 - out_2_acc: 0.9673 - val_loss: 0.2266 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1121 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1377 - out_1_loss: 0.0833 - out_2_loss: 0.0544 - out_1_acc: 0.9534 - out_2_acc: 0.9672 - val_loss: 0.2302 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1147 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9528\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1365 - out_1_loss: 0.0825 - out_2_loss: 0.0540 - out_1_acc: 0.9536 - out_2_acc: 0.9679 - val_loss: 0.2327 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1167 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1353 - out_1_loss: 0.0817 - out_2_loss: 0.0536 - out_1_acc: 0.9541 - out_2_acc: 0.9679 - val_loss: 0.2381 - val_out_1_loss: 0.1165 - val_out_2_loss: 0.1216 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9531\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1343 - out_1_loss: 0.0808 - out_2_loss: 0.0534 - out_1_acc: 0.9548 - out_2_acc: 0.9682 - val_loss: 0.2442 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1342 - out_1_loss: 0.0802 - out_2_loss: 0.0539 - out_1_acc: 0.9549 - out_2_acc: 0.9674 - val_loss: 0.2400 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1219 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9529\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1330 - out_1_loss: 0.0795 - out_2_loss: 0.0535 - out_1_acc: 0.9555 - out_2_acc: 0.9678 - val_loss: 0.2408 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1225 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1301 - out_1_loss: 0.0784 - out_2_loss: 0.0516 - out_1_acc: 0.9560 - out_2_acc: 0.9686 - val_loss: 0.2406 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1223 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9532\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1284 - out_1_loss: 0.0774 - out_2_loss: 0.0509 - out_1_acc: 0.9568 - out_2_acc: 0.9685 - val_loss: 0.2439 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1237 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9536\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1269 - out_1_loss: 0.0767 - out_2_loss: 0.0501 - out_1_acc: 0.9569 - out_2_acc: 0.9692 - val_loss: 0.2453 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1246 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9528\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1257 - out_1_loss: 0.0756 - out_2_loss: 0.0500 - out_1_acc: 0.9577 - out_2_acc: 0.9695 - val_loss: 0.2460 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.1245 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9530\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1247 - out_1_loss: 0.0750 - out_2_loss: 0.0496 - out_1_acc: 0.9578 - out_2_acc: 0.9697 - val_loss: 0.2500 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.1278 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1236 - out_1_loss: 0.0742 - out_2_loss: 0.0494 - out_1_acc: 0.9583 - out_2_acc: 0.9697 - val_loss: 0.2533 - val_out_1_loss: 0.1235 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1225 - out_1_loss: 0.0734 - out_2_loss: 0.0491 - out_1_acc: 0.9592 - out_2_acc: 0.9701 - val_loss: 0.2555 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1308 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1217 - out_1_loss: 0.0727 - out_2_loss: 0.0489 - out_1_acc: 0.9595 - out_2_acc: 0.9702 - val_loss: 0.2565 - val_out_1_loss: 0.1264 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9528\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1205 - out_1_loss: 0.0721 - out_2_loss: 0.0484 - out_1_acc: 0.9600 - out_2_acc: 0.9700 - val_loss: 0.2594 - val_out_1_loss: 0.1279 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9522\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1195 - out_1_loss: 0.0713 - out_2_loss: 0.0482 - out_1_acc: 0.9599 - out_2_acc: 0.9705 - val_loss: 0.2599 - val_out_1_loss: 0.1285 - val_out_2_loss: 0.1314 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9526\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1184 - out_1_loss: 0.0706 - out_2_loss: 0.0478 - out_1_acc: 0.9605 - out_2_acc: 0.9712 - val_loss: 0.2632 - val_out_1_loss: 0.1292 - val_out_2_loss: 0.1339 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9527\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1177 - out_1_loss: 0.0701 - out_2_loss: 0.0477 - out_1_acc: 0.9608 - out_2_acc: 0.9711 - val_loss: 0.2646 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1339 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9530\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1165 - out_1_loss: 0.0691 - out_2_loss: 0.0474 - out_1_acc: 0.9614 - out_2_acc: 0.9715 - val_loss: 0.2650 - val_out_1_loss: 0.1314 - val_out_2_loss: 0.1336 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9525\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.1159 - out_1_loss: 0.0685 - out_2_loss: 0.0475 - out_1_acc: 0.9617 - out_2_acc: 0.9716 - val_loss: 0.2669 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1348 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1149 - out_1_loss: 0.0679 - out_2_loss: 0.0470 - out_1_acc: 0.9621 - out_2_acc: 0.9719 - val_loss: 0.2690 - val_out_1_loss: 0.1335 - val_out_2_loss: 0.1355 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9525\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1141 - out_1_loss: 0.0673 - out_2_loss: 0.0468 - out_1_acc: 0.9625 - out_2_acc: 0.9720 - val_loss: 0.2707 - val_out_1_loss: 0.1351 - val_out_2_loss: 0.1357 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1134 - out_1_loss: 0.0667 - out_2_loss: 0.0467 - out_1_acc: 0.9626 - out_2_acc: 0.9726 - val_loss: 0.2741 - val_out_1_loss: 0.1363 - val_out_2_loss: 0.1378 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1124 - out_1_loss: 0.0663 - out_2_loss: 0.0462 - out_1_acc: 0.9631 - out_2_acc: 0.9727 - val_loss: 0.2767 - val_out_1_loss: 0.1380 - val_out_2_loss: 0.1387 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9519\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1122 - out_1_loss: 0.0662 - out_2_loss: 0.0461 - out_1_acc: 0.9631 - out_2_acc: 0.9726 - val_loss: 0.2786 - val_out_1_loss: 0.1382 - val_out_2_loss: 0.1404 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9527\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1118 - out_1_loss: 0.0658 - out_2_loss: 0.0460 - out_1_acc: 0.9633 - out_2_acc: 0.9727 - val_loss: 0.2803 - val_out_1_loss: 0.1397 - val_out_2_loss: 0.1406 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1114 - out_1_loss: 0.0655 - out_2_loss: 0.0459 - out_1_acc: 0.9641 - out_2_acc: 0.9732 - val_loss: 0.2813 - val_out_1_loss: 0.1410 - val_out_2_loss: 0.1403 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1110 - out_1_loss: 0.0652 - out_2_loss: 0.0458 - out_1_acc: 0.9637 - out_2_acc: 0.9729 - val_loss: 0.2818 - val_out_1_loss: 0.1419 - val_out_2_loss: 0.1399 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9529\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1095 - out_1_loss: 0.0641 - out_2_loss: 0.0454 - out_1_acc: 0.9647 - out_2_acc: 0.9735 - val_loss: 0.2850 - val_out_1_loss: 0.1428 - val_out_2_loss: 0.1422 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1088 - out_1_loss: 0.0634 - out_2_loss: 0.0454 - out_1_acc: 0.9652 - out_2_acc: 0.9735 - val_loss: 0.2877 - val_out_1_loss: 0.1443 - val_out_2_loss: 0.1434 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1074 - out_1_loss: 0.0628 - out_2_loss: 0.0446 - out_1_acc: 0.9659 - out_2_acc: 0.9743 - val_loss: 0.2913 - val_out_1_loss: 0.1463 - val_out_2_loss: 0.1450 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1069 - out_1_loss: 0.0624 - out_2_loss: 0.0445 - out_1_acc: 0.9663 - out_2_acc: 0.9740 - val_loss: 0.2939 - val_out_1_loss: 0.1481 - val_out_2_loss: 0.1458 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1057 - out_1_loss: 0.0619 - out_2_loss: 0.0437 - out_1_acc: 0.9662 - out_2_acc: 0.9752 - val_loss: 0.2952 - val_out_1_loss: 0.1483 - val_out_2_loss: 0.1469 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9522\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1056 - out_1_loss: 0.0614 - out_2_loss: 0.0442 - out_1_acc: 0.9666 - out_2_acc: 0.9745 - val_loss: 0.2971 - val_out_1_loss: 0.1495 - val_out_2_loss: 0.1476 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9525\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1046 - out_1_loss: 0.0610 - out_2_loss: 0.0436 - out_1_acc: 0.9670 - out_2_acc: 0.9750 - val_loss: 0.2992 - val_out_1_loss: 0.1507 - val_out_2_loss: 0.1486 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9518\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1038 - out_1_loss: 0.0601 - out_2_loss: 0.0437 - out_1_acc: 0.9676 - out_2_acc: 0.9753 - val_loss: 0.3028 - val_out_1_loss: 0.1530 - val_out_2_loss: 0.1498 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9517\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1032 - out_1_loss: 0.0598 - out_2_loss: 0.0434 - out_1_acc: 0.9677 - out_2_acc: 0.9753 - val_loss: 0.3056 - val_out_1_loss: 0.1536 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9515\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1020 - out_1_loss: 0.0593 - out_2_loss: 0.0426 - out_1_acc: 0.9680 - out_2_acc: 0.9763 - val_loss: 0.3027 - val_out_1_loss: 0.1531 - val_out_2_loss: 0.1497 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1006 - out_1_loss: 0.0585 - out_2_loss: 0.0421 - out_1_acc: 0.9684 - out_2_acc: 0.9768 - val_loss: 0.3062 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9517\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1002 - out_1_loss: 0.0581 - out_2_loss: 0.0421 - out_1_acc: 0.9689 - out_2_acc: 0.9764 - val_loss: 0.3080 - val_out_1_loss: 0.1559 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9509\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0990 - out_1_loss: 0.0579 - out_2_loss: 0.0411 - out_1_acc: 0.9691 - out_2_acc: 0.9774 - val_loss: 0.3075 - val_out_1_loss: 0.1561 - val_out_2_loss: 0.1514 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0985 - out_1_loss: 0.0579 - out_2_loss: 0.0406 - out_1_acc: 0.9689 - out_2_acc: 0.9782 - val_loss: 0.3095 - val_out_1_loss: 0.1559 - val_out_2_loss: 0.1536 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0983 - out_1_loss: 0.0574 - out_2_loss: 0.0410 - out_1_acc: 0.9694 - out_2_acc: 0.9776 - val_loss: 0.3116 - val_out_1_loss: 0.1580 - val_out_2_loss: 0.1537 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9513\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0976 - out_1_loss: 0.0568 - out_2_loss: 0.0408 - out_1_acc: 0.9697 - out_2_acc: 0.9778 - val_loss: 0.3146 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1540 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9523\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0971 - out_1_loss: 0.0567 - out_2_loss: 0.0405 - out_1_acc: 0.9699 - out_2_acc: 0.9780 - val_loss: 0.3172 - val_out_1_loss: 0.1620 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9516\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0963 - out_1_loss: 0.0566 - out_2_loss: 0.0397 - out_1_acc: 0.9699 - out_2_acc: 0.9787 - val_loss: 0.3192 - val_out_1_loss: 0.1628 - val_out_2_loss: 0.1564 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0963 - out_1_loss: 0.0562 - out_2_loss: 0.0401 - out_1_acc: 0.9699 - out_2_acc: 0.9783 - val_loss: 0.3219 - val_out_1_loss: 0.1637 - val_out_2_loss: 0.1582 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9521\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0951 - out_1_loss: 0.0553 - out_2_loss: 0.0398 - out_1_acc: 0.9705 - out_2_acc: 0.9785 - val_loss: 0.3270 - val_out_1_loss: 0.1668 - val_out_2_loss: 0.1602 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9514\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0952 - out_1_loss: 0.0556 - out_2_loss: 0.0397 - out_1_acc: 0.9705 - out_2_acc: 0.9783 - val_loss: 0.3226 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1557 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9527\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0935 - out_1_loss: 0.0546 - out_2_loss: 0.0389 - out_1_acc: 0.9711 - out_2_acc: 0.9792 - val_loss: 0.3267 - val_out_1_loss: 0.1684 - val_out_2_loss: 0.1583 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0921 - out_1_loss: 0.0540 - out_2_loss: 0.0381 - out_1_acc: 0.9712 - out_2_acc: 0.9796 - val_loss: 0.3306 - val_out_1_loss: 0.1678 - val_out_2_loss: 0.1628 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9518\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0915 - out_1_loss: 0.0536 - out_2_loss: 0.0379 - out_1_acc: 0.9720 - out_2_acc: 0.9799 - val_loss: 0.3297 - val_out_1_loss: 0.1680 - val_out_2_loss: 0.1617 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9520\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0893 - out_1_loss: 0.0526 - out_2_loss: 0.0366 - out_1_acc: 0.9725 - out_2_acc: 0.9809 - val_loss: 0.3300 - val_out_1_loss: 0.1685 - val_out_2_loss: 0.1614 - val_out_1_acc: 0.9423 - val_out_2_acc: 0.9521\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0876 - out_1_loss: 0.0522 - out_2_loss: 0.0354 - out_1_acc: 0.9729 - out_2_acc: 0.9821 - val_loss: 0.3338 - val_out_1_loss: 0.1696 - val_out_2_loss: 0.1642 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9528\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0854 - out_1_loss: 0.0509 - out_2_loss: 0.0344 - out_1_acc: 0.9735 - out_2_acc: 0.9824 - val_loss: 0.3388 - val_out_1_loss: 0.1726 - val_out_2_loss: 0.1662 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9526\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0843 - out_1_loss: 0.0504 - out_2_loss: 0.0339 - out_1_acc: 0.9742 - out_2_acc: 0.9827 - val_loss: 0.3437 - val_out_1_loss: 0.1739 - val_out_2_loss: 0.1699 - val_out_1_acc: 0.9424 - val_out_2_acc: 0.9527\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0856 - out_1_loss: 0.0506 - out_2_loss: 0.0350 - out_1_acc: 0.9740 - out_2_acc: 0.9822 - val_loss: 0.3422 - val_out_1_loss: 0.1742 - val_out_2_loss: 0.1680 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9520\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0853 - out_1_loss: 0.0504 - out_2_loss: 0.0349 - out_1_acc: 0.9742 - out_2_acc: 0.9822 - val_loss: 0.3431 - val_out_1_loss: 0.1749 - val_out_2_loss: 0.1681 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9524\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0846 - out_1_loss: 0.0502 - out_2_loss: 0.0344 - out_1_acc: 0.9742 - out_2_acc: 0.9822 - val_loss: 0.3481 - val_out_1_loss: 0.1772 - val_out_2_loss: 0.1709 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9529\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0844 - out_1_loss: 0.0500 - out_2_loss: 0.0344 - out_1_acc: 0.9746 - out_2_acc: 0.9826 - val_loss: 0.3477 - val_out_1_loss: 0.1776 - val_out_2_loss: 0.1701 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9513\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0839 - out_1_loss: 0.0490 - out_2_loss: 0.0349 - out_1_acc: 0.9753 - out_2_acc: 0.9823 - val_loss: 0.3558 - val_out_1_loss: 0.1814 - val_out_2_loss: 0.1744 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0832 - out_1_loss: 0.0486 - out_2_loss: 0.0346 - out_1_acc: 0.9756 - out_2_acc: 0.9826 - val_loss: 0.3578 - val_out_1_loss: 0.1838 - val_out_2_loss: 0.1740 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9523\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0831 - out_1_loss: 0.0490 - out_2_loss: 0.0342 - out_1_acc: 0.9753 - out_2_acc: 0.9826 - val_loss: 0.3592 - val_out_1_loss: 0.1849 - val_out_2_loss: 0.1743 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9526\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0829 - out_1_loss: 0.0494 - out_2_loss: 0.0335 - out_1_acc: 0.9753 - out_2_acc: 0.9835 - val_loss: 0.3583 - val_out_1_loss: 0.1866 - val_out_2_loss: 0.1717 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0812 - out_1_loss: 0.0482 - out_2_loss: 0.0330 - out_1_acc: 0.9762 - out_2_acc: 0.9839 - val_loss: 0.3615 - val_out_1_loss: 0.1845 - val_out_2_loss: 0.1770 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0795 - out_1_loss: 0.0471 - out_2_loss: 0.0324 - out_1_acc: 0.9766 - out_2_acc: 0.9842 - val_loss: 0.3618 - val_out_1_loss: 0.1862 - val_out_2_loss: 0.1755 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9530\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0777 - out_1_loss: 0.0466 - out_2_loss: 0.0311 - out_1_acc: 0.9771 - out_2_acc: 0.9851 - val_loss: 0.3692 - val_out_1_loss: 0.1883 - val_out_2_loss: 0.1809 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9530\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0781 - out_1_loss: 0.0464 - out_2_loss: 0.0317 - out_1_acc: 0.9771 - out_2_acc: 0.9849 - val_loss: 0.3674 - val_out_1_loss: 0.1868 - val_out_2_loss: 0.1806 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0782 - out_1_loss: 0.0466 - out_2_loss: 0.0316 - out_1_acc: 0.9771 - out_2_acc: 0.9844 - val_loss: 0.3671 - val_out_1_loss: 0.1887 - val_out_2_loss: 0.1783 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9528\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0786 - out_1_loss: 0.0471 - out_2_loss: 0.0315 - out_1_acc: 0.9773 - out_2_acc: 0.9848 - val_loss: 0.3713 - val_out_1_loss: 0.1921 - val_out_2_loss: 0.1792 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9516\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0765 - out_1_loss: 0.0462 - out_2_loss: 0.0303 - out_1_acc: 0.9772 - out_2_acc: 0.9855 - val_loss: 0.3734 - val_out_1_loss: 0.1894 - val_out_2_loss: 0.1840 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0740 - out_1_loss: 0.0452 - out_2_loss: 0.0289 - out_1_acc: 0.9782 - out_2_acc: 0.9863 - val_loss: 0.3806 - val_out_1_loss: 0.1936 - val_out_2_loss: 0.1870 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9519\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0743 - out_1_loss: 0.0454 - out_2_loss: 0.0289 - out_1_acc: 0.9778 - out_2_acc: 0.9859 - val_loss: 0.3821 - val_out_1_loss: 0.1941 - val_out_2_loss: 0.1880 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9517\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0749 - out_1_loss: 0.0458 - out_2_loss: 0.0291 - out_1_acc: 0.9776 - out_2_acc: 0.9864 - val_loss: 0.3856 - val_out_1_loss: 0.1970 - val_out_2_loss: 0.1887 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0743 - out_1_loss: 0.0453 - out_2_loss: 0.0291 - out_1_acc: 0.9780 - out_2_acc: 0.9864 - val_loss: 0.3949 - val_out_1_loss: 0.2015 - val_out_2_loss: 0.1934 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0757 - out_1_loss: 0.0461 - out_2_loss: 0.0296 - out_1_acc: 0.9773 - out_2_acc: 0.9862 - val_loss: 0.3989 - val_out_1_loss: 0.2076 - val_out_2_loss: 0.1913 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0739 - out_1_loss: 0.0454 - out_2_loss: 0.0284 - out_1_acc: 0.9779 - out_2_acc: 0.9867 - val_loss: 0.3996 - val_out_1_loss: 0.2053 - val_out_2_loss: 0.1943 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9526\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0729 - out_1_loss: 0.0458 - out_2_loss: 0.0271 - out_1_acc: 0.9774 - out_2_acc: 0.9874 - val_loss: 0.4013 - val_out_1_loss: 0.2096 - val_out_2_loss: 0.1917 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9535\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0761 - out_1_loss: 0.0481 - out_2_loss: 0.0280 - out_1_acc: 0.9764 - out_2_acc: 0.9873 - val_loss: 0.3990 - val_out_1_loss: 0.2027 - val_out_2_loss: 0.1963 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9532\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0765 - out_1_loss: 0.0486 - out_2_loss: 0.0279 - out_1_acc: 0.9765 - out_2_acc: 0.9873 - val_loss: 0.3964 - val_out_1_loss: 0.1996 - val_out_2_loss: 0.1968 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9527\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0754 - out_1_loss: 0.0484 - out_2_loss: 0.0270 - out_1_acc: 0.9769 - out_2_acc: 0.9874 - val_loss: 0.4021 - val_out_1_loss: 0.2055 - val_out_2_loss: 0.1966 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9520\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0735 - out_1_loss: 0.0463 - out_2_loss: 0.0273 - out_1_acc: 0.9776 - out_2_acc: 0.9875 - val_loss: 0.4083 - val_out_1_loss: 0.2065 - val_out_2_loss: 0.2018 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9528\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0733 - out_1_loss: 0.0451 - out_2_loss: 0.0281 - out_1_acc: 0.9781 - out_2_acc: 0.9874 - val_loss: 0.4026 - val_out_1_loss: 0.2058 - val_out_2_loss: 0.1969 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0721 - out_1_loss: 0.0450 - out_2_loss: 0.0271 - out_1_acc: 0.9785 - out_2_acc: 0.9876 - val_loss: 0.4144 - val_out_1_loss: 0.2109 - val_out_2_loss: 0.2034 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9522\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0713 - out_1_loss: 0.0445 - out_2_loss: 0.0269 - out_1_acc: 0.9785 - out_2_acc: 0.9879 - val_loss: 0.4200 - val_out_1_loss: 0.2152 - val_out_2_loss: 0.2049 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0719 - out_1_loss: 0.0446 - out_2_loss: 0.0274 - out_1_acc: 0.9783 - out_2_acc: 0.9874 - val_loss: 0.4278 - val_out_1_loss: 0.2160 - val_out_2_loss: 0.2118 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9536\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0703 - out_1_loss: 0.0443 - out_2_loss: 0.0260 - out_1_acc: 0.9784 - out_2_acc: 0.9880 - val_loss: 0.4256 - val_out_1_loss: 0.2146 - val_out_2_loss: 0.2111 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9537\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0699 - out_1_loss: 0.0435 - out_2_loss: 0.0264 - out_1_acc: 0.9792 - out_2_acc: 0.9882 - val_loss: 0.4169 - val_out_1_loss: 0.2108 - val_out_2_loss: 0.2061 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9536\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0675 - out_1_loss: 0.0420 - out_2_loss: 0.0255 - out_1_acc: 0.9799 - out_2_acc: 0.9882 - val_loss: 0.4107 - val_out_1_loss: 0.2093 - val_out_2_loss: 0.2014 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9539\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0639 - out_1_loss: 0.0402 - out_2_loss: 0.0237 - out_1_acc: 0.9813 - out_2_acc: 0.9893 - val_loss: 0.4136 - val_out_1_loss: 0.2096 - val_out_2_loss: 0.2040 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9532\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0631 - out_1_loss: 0.0405 - out_2_loss: 0.0226 - out_1_acc: 0.9816 - out_2_acc: 0.9902 - val_loss: 0.4109 - val_out_1_loss: 0.2075 - val_out_2_loss: 0.2034 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9538\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0608 - out_1_loss: 0.0388 - out_2_loss: 0.0220 - out_1_acc: 0.9825 - out_2_acc: 0.9903 - val_loss: 0.4139 - val_out_1_loss: 0.2084 - val_out_2_loss: 0.2055 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0572 - out_1_loss: 0.0368 - out_2_loss: 0.0204 - out_1_acc: 0.9839 - out_2_acc: 0.9913 - val_loss: 0.4227 - val_out_1_loss: 0.2126 - val_out_2_loss: 0.2102 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9526\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0576 - out_1_loss: 0.0377 - out_2_loss: 0.0199 - out_1_acc: 0.9828 - out_2_acc: 0.9917 - val_loss: 0.4274 - val_out_1_loss: 0.2165 - val_out_2_loss: 0.2110 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9526\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0547 - out_1_loss: 0.0372 - out_2_loss: 0.0174 - out_1_acc: 0.9829 - out_2_acc: 0.9929 - val_loss: 0.4345 - val_out_1_loss: 0.2182 - val_out_2_loss: 0.2163 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0534 - out_1_loss: 0.0365 - out_2_loss: 0.0169 - out_1_acc: 0.9832 - out_2_acc: 0.9932 - val_loss: 0.4398 - val_out_1_loss: 0.2181 - val_out_2_loss: 0.2217 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0540 - out_1_loss: 0.0363 - out_2_loss: 0.0178 - out_1_acc: 0.9836 - out_2_acc: 0.9926 - val_loss: 0.4377 - val_out_1_loss: 0.2192 - val_out_2_loss: 0.2184 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0549 - out_1_loss: 0.0362 - out_2_loss: 0.0187 - out_1_acc: 0.9834 - out_2_acc: 0.9922 - val_loss: 0.4444 - val_out_1_loss: 0.2242 - val_out_2_loss: 0.2202 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9526\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.0533 - out_1_loss: 0.0353 - out_2_loss: 0.0180 - out_1_acc: 0.9839 - out_2_acc: 0.9923 - val_loss: 0.4532 - val_out_1_loss: 0.2275 - val_out_2_loss: 0.2257 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0530 - out_1_loss: 0.0350 - out_2_loss: 0.0180 - out_1_acc: 0.9844 - out_2_acc: 0.9925 - val_loss: 0.4560 - val_out_1_loss: 0.2276 - val_out_2_loss: 0.2284 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0527 - out_1_loss: 0.0344 - out_2_loss: 0.0183 - out_1_acc: 0.9848 - out_2_acc: 0.9923 - val_loss: 0.4545 - val_out_1_loss: 0.2290 - val_out_2_loss: 0.2255 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9519\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0524 - out_1_loss: 0.0337 - out_2_loss: 0.0186 - out_1_acc: 0.9851 - out_2_acc: 0.9921 - val_loss: 0.4589 - val_out_1_loss: 0.2332 - val_out_2_loss: 0.2256 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0532 - out_1_loss: 0.0352 - out_2_loss: 0.0179 - out_1_acc: 0.9842 - out_2_acc: 0.9923 - val_loss: 0.4701 - val_out_1_loss: 0.2354 - val_out_2_loss: 0.2347 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0527 - out_1_loss: 0.0349 - out_2_loss: 0.0178 - out_1_acc: 0.9844 - out_2_acc: 0.9927 - val_loss: 0.4590 - val_out_1_loss: 0.2310 - val_out_2_loss: 0.2279 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0500 - out_1_loss: 0.0329 - out_2_loss: 0.0170 - out_1_acc: 0.9852 - out_2_acc: 0.9928 - val_loss: 0.4589 - val_out_1_loss: 0.2318 - val_out_2_loss: 0.2272 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 43ms/step - loss: 0.0478 - out_1_loss: 0.0316 - out_2_loss: 0.0161 - out_1_acc: 0.9862 - out_2_acc: 0.9933 - val_loss: 0.4663 - val_out_1_loss: 0.2332 - val_out_2_loss: 0.2332 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9518\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0455 - out_1_loss: 0.0300 - out_2_loss: 0.0156 - out_1_acc: 0.9871 - out_2_acc: 0.9936 - val_loss: 0.4750 - val_out_1_loss: 0.2401 - val_out_2_loss: 0.2349 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0449 - out_1_loss: 0.0296 - out_2_loss: 0.0153 - out_1_acc: 0.9874 - out_2_acc: 0.9937 - val_loss: 0.4815 - val_out_1_loss: 0.2433 - val_out_2_loss: 0.2382 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9535\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0444 - out_1_loss: 0.0303 - out_2_loss: 0.0141 - out_1_acc: 0.9869 - out_2_acc: 0.9940 - val_loss: 0.4825 - val_out_1_loss: 0.2440 - val_out_2_loss: 0.2385 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0430 - out_1_loss: 0.0304 - out_2_loss: 0.0126 - out_1_acc: 0.9873 - out_2_acc: 0.9950 - val_loss: 0.4912 - val_out_1_loss: 0.2469 - val_out_2_loss: 0.2443 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9531\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0417 - out_1_loss: 0.0296 - out_2_loss: 0.0121 - out_1_acc: 0.9876 - out_2_acc: 0.9955 - val_loss: 0.4871 - val_out_1_loss: 0.2454 - val_out_2_loss: 0.2417 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9531\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0384 - out_1_loss: 0.0279 - out_2_loss: 0.0104 - out_1_acc: 0.9883 - out_2_acc: 0.9959 - val_loss: 0.4957 - val_out_1_loss: 0.2483 - val_out_2_loss: 0.2474 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0347 - out_1_loss: 0.0264 - out_2_loss: 0.0083 - out_1_acc: 0.9890 - out_2_acc: 0.9971 - val_loss: 0.5050 - val_out_1_loss: 0.2517 - val_out_2_loss: 0.2533 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9537\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0347 - out_1_loss: 0.0256 - out_2_loss: 0.0091 - out_1_acc: 0.9898 - out_2_acc: 0.9967 - val_loss: 0.5018 - val_out_1_loss: 0.2515 - val_out_2_loss: 0.2503 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9527\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0330 - out_1_loss: 0.0251 - out_2_loss: 0.0079 - out_1_acc: 0.9896 - out_2_acc: 0.9972 - val_loss: 0.5126 - val_out_1_loss: 0.2554 - val_out_2_loss: 0.2572 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0323 - out_1_loss: 0.0244 - out_2_loss: 0.0079 - out_1_acc: 0.9901 - out_2_acc: 0.9972 - val_loss: 0.5154 - val_out_1_loss: 0.2567 - val_out_2_loss: 0.2587 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9529\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0295 - out_1_loss: 0.0227 - out_2_loss: 0.0068 - out_1_acc: 0.9910 - out_2_acc: 0.9976 - val_loss: 0.5188 - val_out_1_loss: 0.2575 - val_out_2_loss: 0.2613 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0295 - out_1_loss: 0.0220 - out_2_loss: 0.0075 - out_1_acc: 0.9911 - out_2_acc: 0.9973 - val_loss: 0.5252 - val_out_1_loss: 0.2624 - val_out_2_loss: 0.2629 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9533\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0299 - out_1_loss: 0.0220 - out_2_loss: 0.0079 - out_1_acc: 0.9911 - out_2_acc: 0.9971 - val_loss: 0.5301 - val_out_1_loss: 0.2665 - val_out_2_loss: 0.2636 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9532\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0275 - out_1_loss: 0.0212 - out_2_loss: 0.0064 - out_1_acc: 0.9921 - out_2_acc: 0.9979 - val_loss: 0.5366 - val_out_1_loss: 0.2685 - val_out_2_loss: 0.2681 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9535\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0281 - out_1_loss: 0.0217 - out_2_loss: 0.0064 - out_1_acc: 0.9913 - out_2_acc: 0.9977 - val_loss: 0.5316 - val_out_1_loss: 0.2706 - val_out_2_loss: 0.2610 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9531\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0269 - out_1_loss: 0.0217 - out_2_loss: 0.0052 - out_1_acc: 0.9912 - out_2_acc: 0.9983 - val_loss: 0.5427 - val_out_1_loss: 0.2721 - val_out_2_loss: 0.2706 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0290 - out_1_loss: 0.0217 - out_2_loss: 0.0074 - out_1_acc: 0.9913 - out_2_acc: 0.9976 - val_loss: 0.5538 - val_out_1_loss: 0.2773 - val_out_2_loss: 0.2765 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0347 - out_1_loss: 0.0240 - out_2_loss: 0.0107 - out_1_acc: 0.9905 - out_2_acc: 0.9964 - val_loss: 0.5506 - val_out_1_loss: 0.2774 - val_out_2_loss: 0.2733 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9513\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0309 - out_1_loss: 0.0221 - out_2_loss: 0.0088 - out_1_acc: 0.9913 - out_2_acc: 0.9966 - val_loss: 0.5493 - val_out_1_loss: 0.2768 - val_out_2_loss: 0.2725 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0288 - out_1_loss: 0.0214 - out_2_loss: 0.0074 - out_1_acc: 0.9919 - out_2_acc: 0.9972 - val_loss: 0.5518 - val_out_1_loss: 0.2797 - val_out_2_loss: 0.2720 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9529\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0268 - out_1_loss: 0.0204 - out_2_loss: 0.0064 - out_1_acc: 0.9920 - out_2_acc: 0.9979 - val_loss: 0.5657 - val_out_1_loss: 0.2820 - val_out_2_loss: 0.2837 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0276 - out_1_loss: 0.0210 - out_2_loss: 0.0066 - out_1_acc: 0.9917 - out_2_acc: 0.9979 - val_loss: 0.5660 - val_out_1_loss: 0.2820 - val_out_2_loss: 0.2839 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0252 - out_1_loss: 0.0199 - out_2_loss: 0.0053 - out_1_acc: 0.9922 - out_2_acc: 0.9983 - val_loss: 0.5635 - val_out_1_loss: 0.2864 - val_out_2_loss: 0.2771 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9534\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0252 - out_1_loss: 0.0206 - out_2_loss: 0.0046 - out_1_acc: 0.9921 - out_2_acc: 0.9986 - val_loss: 0.5699 - val_out_1_loss: 0.2882 - val_out_2_loss: 0.2817 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0260 - out_1_loss: 0.0211 - out_2_loss: 0.0049 - out_1_acc: 0.9918 - out_2_acc: 0.9984 - val_loss: 0.5741 - val_out_1_loss: 0.2891 - val_out_2_loss: 0.2850 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0245 - out_1_loss: 0.0197 - out_2_loss: 0.0048 - out_1_acc: 0.9923 - out_2_acc: 0.9986 - val_loss: 0.5848 - val_out_1_loss: 0.2994 - val_out_2_loss: 0.2854 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9535\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0246 - out_1_loss: 0.0196 - out_2_loss: 0.0050 - out_1_acc: 0.9924 - out_2_acc: 0.9983 - val_loss: 0.5942 - val_out_1_loss: 0.3044 - val_out_2_loss: 0.2898 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9533\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0250 - out_1_loss: 0.0202 - out_2_loss: 0.0047 - out_1_acc: 0.9924 - out_2_acc: 0.9984 - val_loss: 0.5924 - val_out_1_loss: 0.2992 - val_out_2_loss: 0.2932 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9534\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0252 - out_1_loss: 0.0201 - out_2_loss: 0.0051 - out_1_acc: 0.9923 - out_2_acc: 0.9982 - val_loss: 0.5884 - val_out_1_loss: 0.2966 - val_out_2_loss: 0.2919 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0239 - out_1_loss: 0.0180 - out_2_loss: 0.0058 - out_1_acc: 0.9933 - out_2_acc: 0.9979 - val_loss: 0.5996 - val_out_1_loss: 0.3052 - val_out_2_loss: 0.2944 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9534\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0244 - out_1_loss: 0.0189 - out_2_loss: 0.0056 - out_1_acc: 0.9932 - out_2_acc: 0.9981 - val_loss: 0.5950 - val_out_1_loss: 0.3040 - val_out_2_loss: 0.2910 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9534\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0226 - out_1_loss: 0.0175 - out_2_loss: 0.0051 - out_1_acc: 0.9937 - out_2_acc: 0.9982 - val_loss: 0.6107 - val_out_1_loss: 0.3094 - val_out_2_loss: 0.3014 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9522\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0253 - out_1_loss: 0.0188 - out_2_loss: 0.0065 - out_1_acc: 0.9930 - out_2_acc: 0.9978 - val_loss: 0.6081 - val_out_1_loss: 0.3123 - val_out_2_loss: 0.2958 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9539\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0240 - out_1_loss: 0.0183 - out_2_loss: 0.0057 - out_1_acc: 0.9933 - out_2_acc: 0.9979 - val_loss: 0.6139 - val_out_1_loss: 0.3182 - val_out_2_loss: 0.2957 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9532\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0230 - out_1_loss: 0.0169 - out_2_loss: 0.0061 - out_1_acc: 0.9939 - out_2_acc: 0.9979 - val_loss: 0.6038 - val_out_1_loss: 0.3142 - val_out_2_loss: 0.2897 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9538\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0225 - out_1_loss: 0.0166 - out_2_loss: 0.0059 - out_1_acc: 0.9938 - out_2_acc: 0.9980 - val_loss: 0.6148 - val_out_1_loss: 0.3186 - val_out_2_loss: 0.2962 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9534\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0234 - out_1_loss: 0.0160 - out_2_loss: 0.0074 - out_1_acc: 0.9943 - out_2_acc: 0.9974 - val_loss: 0.6379 - val_out_1_loss: 0.3267 - val_out_2_loss: 0.3111 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9521\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0223 - out_1_loss: 0.0149 - out_2_loss: 0.0074 - out_1_acc: 0.9944 - out_2_acc: 0.9975 - val_loss: 0.6293 - val_out_1_loss: 0.3309 - val_out_2_loss: 0.2984 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9530\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0209 - out_1_loss: 0.0153 - out_2_loss: 0.0056 - out_1_acc: 0.9945 - out_2_acc: 0.9978 - val_loss: 0.6306 - val_out_1_loss: 0.3310 - val_out_2_loss: 0.2996 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9528\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0192 - out_1_loss: 0.0150 - out_2_loss: 0.0042 - out_1_acc: 0.9945 - out_2_acc: 0.9986 - val_loss: 0.6381 - val_out_1_loss: 0.3313 - val_out_2_loss: 0.3067 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9519\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0197 - out_1_loss: 0.0155 - out_2_loss: 0.0042 - out_1_acc: 0.9944 - out_2_acc: 0.9985 - val_loss: 0.6403 - val_out_1_loss: 0.3355 - val_out_2_loss: 0.3048 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9518\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0218 - out_1_loss: 0.0168 - out_2_loss: 0.0050 - out_1_acc: 0.9938 - out_2_acc: 0.9982 - val_loss: 0.6425 - val_out_1_loss: 0.3401 - val_out_2_loss: 0.3023 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9519\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0213 - out_1_loss: 0.0154 - out_2_loss: 0.0059 - out_1_acc: 0.9942 - out_2_acc: 0.9980 - val_loss: 0.6534 - val_out_1_loss: 0.3476 - val_out_2_loss: 0.3058 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9517\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0211 - out_1_loss: 0.0158 - out_2_loss: 0.0053 - out_1_acc: 0.9941 - out_2_acc: 0.9981 - val_loss: 0.6542 - val_out_1_loss: 0.3421 - val_out_2_loss: 0.3121 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9527\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0186 - out_1_loss: 0.0144 - out_2_loss: 0.0042 - out_1_acc: 0.9949 - out_2_acc: 0.9985 - val_loss: 0.6555 - val_out_1_loss: 0.3439 - val_out_2_loss: 0.3115 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9523\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0177 - out_1_loss: 0.0138 - out_2_loss: 0.0039 - out_1_acc: 0.9948 - out_2_acc: 0.9986 - val_loss: 0.6670 - val_out_1_loss: 0.3461 - val_out_2_loss: 0.3209 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9518\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0185 - out_1_loss: 0.0136 - out_2_loss: 0.0049 - out_1_acc: 0.9952 - out_2_acc: 0.9983 - val_loss: 0.6606 - val_out_1_loss: 0.3491 - val_out_2_loss: 0.3115 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9535\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0175 - out_1_loss: 0.0131 - out_2_loss: 0.0043 - out_1_acc: 0.9954 - out_2_acc: 0.9984 - val_loss: 0.6625 - val_out_1_loss: 0.3503 - val_out_2_loss: 0.3122 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0178 - out_1_loss: 0.0139 - out_2_loss: 0.0040 - out_1_acc: 0.9951 - out_2_acc: 0.9987 - val_loss: 0.6712 - val_out_1_loss: 0.3558 - val_out_2_loss: 0.3154 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0178 - out_1_loss: 0.0139 - out_2_loss: 0.0039 - out_1_acc: 0.9949 - out_2_acc: 0.9986 - val_loss: 0.6805 - val_out_1_loss: 0.3585 - val_out_2_loss: 0.3220 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(3)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6537 - out_1_loss: 0.3285 - out_2_loss: 0.3253 - out_1_acc: 0.9420 - out_2_acc: 0.9532\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 200), (No 208800      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 200)       208800      input_6[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,155,680\n",
      "Trainable params: 1,155,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3372 - out_1_loss: 3.6753 - out_2_loss: 3.6618 - out_1_acc: 0.0934 - out_2_acc: 0.1426WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109092). Check your callbacks.\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 5.3240 - out_1_loss: 2.9643 - out_2_loss: 2.3597 - out_1_acc: 0.6009 - out_2_acc: 0.6573 - val_loss: 1.9949 - val_out_1_loss: 1.4097 - val_out_2_loss: 0.5852 - val_out_1_acc: 0.7405 - val_out_2_acc: 0.8872\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 1.0790 - out_1_loss: 0.7741 - out_2_loss: 0.3050 - out_1_acc: 0.8560 - out_2_acc: 0.9397 - val_loss: 0.6348 - val_out_1_loss: 0.4469 - val_out_2_loss: 0.1879 - val_out_1_acc: 0.9157 - val_out_2_acc: 0.9488\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4919 - out_1_loss: 0.3440 - out_2_loss: 0.1479 - out_1_acc: 0.9269 - out_2_acc: 0.9517 - val_loss: 0.3878 - val_out_1_loss: 0.2503 - val_out_2_loss: 0.1375 - val_out_1_acc: 0.9373 - val_out_2_acc: 0.9491\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.3177 - out_1_loss: 0.1997 - out_2_loss: 0.1180 - out_1_acc: 0.9392 - out_2_acc: 0.9519 - val_loss: 0.2846 - val_out_1_loss: 0.1666 - val_out_2_loss: 0.1180 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9486\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2489 - out_1_loss: 0.1441 - out_2_loss: 0.1048 - out_1_acc: 0.9400 - out_2_acc: 0.9521 - val_loss: 0.2455 - val_out_1_loss: 0.1388 - val_out_2_loss: 0.1066 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9501\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2236 - out_1_loss: 0.1265 - out_2_loss: 0.0971 - out_1_acc: 0.9409 - out_2_acc: 0.9525 - val_loss: 0.2299 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2114 - out_1_loss: 0.1192 - out_2_loss: 0.0922 - out_1_acc: 0.9410 - out_2_acc: 0.9526 - val_loss: 0.2217 - val_out_1_loss: 0.1251 - val_out_2_loss: 0.0966 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2038 - out_1_loss: 0.1147 - out_2_loss: 0.0890 - out_1_acc: 0.9411 - out_2_acc: 0.9528 - val_loss: 0.2158 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.0941 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9506\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1982 - out_1_loss: 0.1113 - out_2_loss: 0.0869 - out_1_acc: 0.9415 - out_2_acc: 0.9532 - val_loss: 0.2112 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9506\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1940 - out_1_loss: 0.1087 - out_2_loss: 0.0853 - out_1_acc: 0.9419 - out_2_acc: 0.9533 - val_loss: 0.2080 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9506\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1907 - out_1_loss: 0.1065 - out_2_loss: 0.0842 - out_1_acc: 0.9423 - out_2_acc: 0.9535 - val_loss: 0.2054 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9506\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1880 - out_1_loss: 0.1048 - out_2_loss: 0.0832 - out_1_acc: 0.9428 - out_2_acc: 0.9541 - val_loss: 0.2037 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1858 - out_1_loss: 0.1034 - out_2_loss: 0.0824 - out_1_acc: 0.9428 - out_2_acc: 0.9543 - val_loss: 0.2024 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.0894 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9511\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1840 - out_1_loss: 0.1023 - out_2_loss: 0.0817 - out_1_acc: 0.9432 - out_2_acc: 0.9544 - val_loss: 0.2014 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1823 - out_1_loss: 0.1013 - out_2_loss: 0.0810 - out_1_acc: 0.9435 - out_2_acc: 0.9546 - val_loss: 0.2007 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0891 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9511\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1808 - out_1_loss: 0.1005 - out_2_loss: 0.0803 - out_1_acc: 0.9436 - out_2_acc: 0.9550 - val_loss: 0.2003 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9512\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1795 - out_1_loss: 0.0998 - out_2_loss: 0.0797 - out_1_acc: 0.9438 - out_2_acc: 0.9552 - val_loss: 0.2002 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0893 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1782 - out_1_loss: 0.0992 - out_2_loss: 0.0790 - out_1_acc: 0.9440 - out_2_acc: 0.9557 - val_loss: 0.2003 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0896 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1769 - out_1_loss: 0.0986 - out_2_loss: 0.0783 - out_1_acc: 0.9443 - out_2_acc: 0.9559 - val_loss: 0.2003 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9513\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1755 - out_1_loss: 0.0980 - out_2_loss: 0.0775 - out_1_acc: 0.9446 - out_2_acc: 0.9563 - val_loss: 0.2007 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1743 - out_1_loss: 0.0974 - out_2_loss: 0.0768 - out_1_acc: 0.9448 - out_2_acc: 0.9568 - val_loss: 0.2007 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0904 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1729 - out_1_loss: 0.0969 - out_2_loss: 0.0760 - out_1_acc: 0.9453 - out_2_acc: 0.9573 - val_loss: 0.2012 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0910 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1716 - out_1_loss: 0.0964 - out_2_loss: 0.0752 - out_1_acc: 0.9454 - out_2_acc: 0.9577 - val_loss: 0.2013 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1701 - out_1_loss: 0.0959 - out_2_loss: 0.0742 - out_1_acc: 0.9458 - out_2_acc: 0.9581 - val_loss: 0.2016 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1687 - out_1_loss: 0.0954 - out_2_loss: 0.0733 - out_1_acc: 0.9459 - out_2_acc: 0.9585 - val_loss: 0.2020 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9512\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1671 - out_1_loss: 0.0948 - out_2_loss: 0.0723 - out_1_acc: 0.9462 - out_2_acc: 0.9591 - val_loss: 0.2026 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0926 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9512\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1656 - out_1_loss: 0.0943 - out_2_loss: 0.0713 - out_1_acc: 0.9465 - out_2_acc: 0.9595 - val_loss: 0.2034 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9511\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1640 - out_1_loss: 0.0937 - out_2_loss: 0.0703 - out_1_acc: 0.9469 - out_2_acc: 0.9600 - val_loss: 0.2037 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0935 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9514\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1624 - out_1_loss: 0.0932 - out_2_loss: 0.0693 - out_1_acc: 0.9473 - out_2_acc: 0.9601 - val_loss: 0.2046 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1607 - out_1_loss: 0.0926 - out_2_loss: 0.0681 - out_1_acc: 0.9477 - out_2_acc: 0.9609 - val_loss: 0.2054 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0948 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9513\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1591 - out_1_loss: 0.0920 - out_2_loss: 0.0671 - out_1_acc: 0.9480 - out_2_acc: 0.9613 - val_loss: 0.2063 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1572 - out_1_loss: 0.0914 - out_2_loss: 0.0658 - out_1_acc: 0.9483 - out_2_acc: 0.9620 - val_loss: 0.2069 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1555 - out_1_loss: 0.0908 - out_2_loss: 0.0647 - out_1_acc: 0.9486 - out_2_acc: 0.9626 - val_loss: 0.2084 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0971 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9516\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1537 - out_1_loss: 0.0901 - out_2_loss: 0.0636 - out_1_acc: 0.9491 - out_2_acc: 0.9631 - val_loss: 0.2105 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0986 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1520 - out_1_loss: 0.0895 - out_2_loss: 0.0625 - out_1_acc: 0.9495 - out_2_acc: 0.9637 - val_loss: 0.2116 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0994 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9512\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1502 - out_1_loss: 0.0888 - out_2_loss: 0.0613 - out_1_acc: 0.9498 - out_2_acc: 0.9641 - val_loss: 0.2135 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9512\n",
      "Epoch 37/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1484 - out_1_loss: 0.0882 - out_2_loss: 0.0602 - out_1_acc: 0.9502 - out_2_acc: 0.9643 - val_loss: 0.2153 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1025 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1467 - out_1_loss: 0.0876 - out_2_loss: 0.0592 - out_1_acc: 0.9506 - out_2_acc: 0.9648 - val_loss: 0.2176 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.1040 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9510\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1450 - out_1_loss: 0.0868 - out_2_loss: 0.0582 - out_1_acc: 0.9512 - out_2_acc: 0.9652 - val_loss: 0.2191 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1053 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9520\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1431 - out_1_loss: 0.0861 - out_2_loss: 0.0570 - out_1_acc: 0.9514 - out_2_acc: 0.9654 - val_loss: 0.2219 - val_out_1_loss: 0.1144 - val_out_2_loss: 0.1075 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1415 - out_1_loss: 0.0853 - out_2_loss: 0.0561 - out_1_acc: 0.9520 - out_2_acc: 0.9661 - val_loss: 0.2231 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1085 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1400 - out_1_loss: 0.0846 - out_2_loss: 0.0554 - out_1_acc: 0.9523 - out_2_acc: 0.9663 - val_loss: 0.2256 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1105 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1383 - out_1_loss: 0.0838 - out_2_loss: 0.0546 - out_1_acc: 0.9528 - out_2_acc: 0.9671 - val_loss: 0.2277 - val_out_1_loss: 0.1154 - val_out_2_loss: 0.1123 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1368 - out_1_loss: 0.0830 - out_2_loss: 0.0538 - out_1_acc: 0.9533 - out_2_acc: 0.9674 - val_loss: 0.2303 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.1145 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1356 - out_1_loss: 0.0823 - out_2_loss: 0.0533 - out_1_acc: 0.9538 - out_2_acc: 0.9676 - val_loss: 0.2342 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.1178 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1344 - out_1_loss: 0.0815 - out_2_loss: 0.0529 - out_1_acc: 0.9542 - out_2_acc: 0.9680 - val_loss: 0.2408 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1236 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1335 - out_1_loss: 0.0808 - out_2_loss: 0.0527 - out_1_acc: 0.9545 - out_2_acc: 0.9679 - val_loss: 0.2403 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1229 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1324 - out_1_loss: 0.0800 - out_2_loss: 0.0524 - out_1_acc: 0.9553 - out_2_acc: 0.9685 - val_loss: 0.2410 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1231 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9514\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1317 - out_1_loss: 0.0793 - out_2_loss: 0.0524 - out_1_acc: 0.9555 - out_2_acc: 0.9682 - val_loss: 0.2433 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1250 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9518\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1306 - out_1_loss: 0.0785 - out_2_loss: 0.0520 - out_1_acc: 0.9564 - out_2_acc: 0.9686 - val_loss: 0.2419 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1235 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1283 - out_1_loss: 0.0776 - out_2_loss: 0.0507 - out_1_acc: 0.9567 - out_2_acc: 0.9696 - val_loss: 0.2474 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1278 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1272 - out_1_loss: 0.0770 - out_2_loss: 0.0502 - out_1_acc: 0.9572 - out_2_acc: 0.9692 - val_loss: 0.2493 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9517\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1258 - out_1_loss: 0.0760 - out_2_loss: 0.0498 - out_1_acc: 0.9580 - out_2_acc: 0.9697 - val_loss: 0.2513 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9522\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1248 - out_1_loss: 0.0752 - out_2_loss: 0.0497 - out_1_acc: 0.9582 - out_2_acc: 0.9697 - val_loss: 0.2532 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1316 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1242 - out_1_loss: 0.0745 - out_2_loss: 0.0497 - out_1_acc: 0.9587 - out_2_acc: 0.9696 - val_loss: 0.2575 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1353 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9519\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1230 - out_1_loss: 0.0738 - out_2_loss: 0.0493 - out_1_acc: 0.9590 - out_2_acc: 0.9702 - val_loss: 0.2602 - val_out_1_loss: 0.1228 - val_out_2_loss: 0.1374 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1215 - out_1_loss: 0.0730 - out_2_loss: 0.0484 - out_1_acc: 0.9595 - out_2_acc: 0.9708 - val_loss: 0.2635 - val_out_1_loss: 0.1240 - val_out_2_loss: 0.1395 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9505\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1208 - out_1_loss: 0.0722 - out_2_loss: 0.0485 - out_1_acc: 0.9599 - out_2_acc: 0.9706 - val_loss: 0.2606 - val_out_1_loss: 0.1248 - val_out_2_loss: 0.1357 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1196 - out_1_loss: 0.0714 - out_2_loss: 0.0482 - out_1_acc: 0.9603 - out_2_acc: 0.9708 - val_loss: 0.2603 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1347 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9526\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1186 - out_1_loss: 0.0708 - out_2_loss: 0.0479 - out_1_acc: 0.9609 - out_2_acc: 0.9713 - val_loss: 0.2623 - val_out_1_loss: 0.1271 - val_out_2_loss: 0.1352 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9523\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1174 - out_1_loss: 0.0701 - out_2_loss: 0.0474 - out_1_acc: 0.9613 - out_2_acc: 0.9718 - val_loss: 0.2643 - val_out_1_loss: 0.1276 - val_out_2_loss: 0.1367 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9519\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1161 - out_1_loss: 0.0692 - out_2_loss: 0.0469 - out_1_acc: 0.9620 - out_2_acc: 0.9722 - val_loss: 0.2664 - val_out_1_loss: 0.1288 - val_out_2_loss: 0.1376 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9525\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1154 - out_1_loss: 0.0686 - out_2_loss: 0.0469 - out_1_acc: 0.9623 - out_2_acc: 0.9720 - val_loss: 0.2676 - val_out_1_loss: 0.1301 - val_out_2_loss: 0.1375 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1146 - out_1_loss: 0.0679 - out_2_loss: 0.0466 - out_1_acc: 0.9626 - out_2_acc: 0.9725 - val_loss: 0.2695 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1388 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9529\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1134 - out_1_loss: 0.0673 - out_2_loss: 0.0462 - out_1_acc: 0.9629 - out_2_acc: 0.9729 - val_loss: 0.2733 - val_out_1_loss: 0.1327 - val_out_2_loss: 0.1407 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9525\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1129 - out_1_loss: 0.0668 - out_2_loss: 0.0461 - out_1_acc: 0.9635 - out_2_acc: 0.9730 - val_loss: 0.2755 - val_out_1_loss: 0.1335 - val_out_2_loss: 0.1420 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1121 - out_1_loss: 0.0659 - out_2_loss: 0.0462 - out_1_acc: 0.9641 - out_2_acc: 0.9730 - val_loss: 0.2770 - val_out_1_loss: 0.1348 - val_out_2_loss: 0.1422 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1107 - out_1_loss: 0.0653 - out_2_loss: 0.0454 - out_1_acc: 0.9645 - out_2_acc: 0.9737 - val_loss: 0.2784 - val_out_1_loss: 0.1361 - val_out_2_loss: 0.1423 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9534\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1097 - out_1_loss: 0.0647 - out_2_loss: 0.0450 - out_1_acc: 0.9647 - out_2_acc: 0.9737 - val_loss: 0.2814 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9525\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1095 - out_1_loss: 0.0643 - out_2_loss: 0.0451 - out_1_acc: 0.9650 - out_2_acc: 0.9740 - val_loss: 0.2826 - val_out_1_loss: 0.1387 - val_out_2_loss: 0.1439 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1086 - out_1_loss: 0.0635 - out_2_loss: 0.0451 - out_1_acc: 0.9653 - out_2_acc: 0.9743 - val_loss: 0.2847 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1453 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9517\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1079 - out_1_loss: 0.0633 - out_2_loss: 0.0446 - out_1_acc: 0.9655 - out_2_acc: 0.9749 - val_loss: 0.2891 - val_out_1_loss: 0.1415 - val_out_2_loss: 0.1476 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1070 - out_1_loss: 0.0626 - out_2_loss: 0.0444 - out_1_acc: 0.9658 - out_2_acc: 0.9750 - val_loss: 0.2882 - val_out_1_loss: 0.1409 - val_out_2_loss: 0.1473 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1058 - out_1_loss: 0.0620 - out_2_loss: 0.0439 - out_1_acc: 0.9664 - out_2_acc: 0.9754 - val_loss: 0.2909 - val_out_1_loss: 0.1428 - val_out_2_loss: 0.1481 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9518\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1046 - out_1_loss: 0.0614 - out_2_loss: 0.0432 - out_1_acc: 0.9668 - out_2_acc: 0.9759 - val_loss: 0.2939 - val_out_1_loss: 0.1436 - val_out_2_loss: 0.1503 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9515\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.1036 - out_1_loss: 0.0607 - out_2_loss: 0.0429 - out_1_acc: 0.9671 - out_2_acc: 0.9764 - val_loss: 0.2951 - val_out_1_loss: 0.1445 - val_out_2_loss: 0.1506 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1040 - out_1_loss: 0.0603 - out_2_loss: 0.0437 - out_1_acc: 0.9676 - out_2_acc: 0.9757 - val_loss: 0.2951 - val_out_1_loss: 0.1459 - val_out_2_loss: 0.1492 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9530\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1028 - out_1_loss: 0.0599 - out_2_loss: 0.0429 - out_1_acc: 0.9679 - out_2_acc: 0.9763 - val_loss: 0.2991 - val_out_1_loss: 0.1472 - val_out_2_loss: 0.1519 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9507\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1014 - out_1_loss: 0.0596 - out_2_loss: 0.0418 - out_1_acc: 0.9684 - out_2_acc: 0.9772 - val_loss: 0.3009 - val_out_1_loss: 0.1483 - val_out_2_loss: 0.1526 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1013 - out_1_loss: 0.0592 - out_2_loss: 0.0421 - out_1_acc: 0.9683 - out_2_acc: 0.9771 - val_loss: 0.3077 - val_out_1_loss: 0.1524 - val_out_2_loss: 0.1554 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9510\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1006 - out_1_loss: 0.0587 - out_2_loss: 0.0419 - out_1_acc: 0.9684 - out_2_acc: 0.9772 - val_loss: 0.3077 - val_out_1_loss: 0.1513 - val_out_2_loss: 0.1564 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9512\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.1002 - out_1_loss: 0.0583 - out_2_loss: 0.0419 - out_1_acc: 0.9687 - out_2_acc: 0.9772 - val_loss: 0.3078 - val_out_1_loss: 0.1523 - val_out_2_loss: 0.1556 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0990 - out_1_loss: 0.0578 - out_2_loss: 0.0412 - out_1_acc: 0.9691 - out_2_acc: 0.9778 - val_loss: 0.3106 - val_out_1_loss: 0.1555 - val_out_2_loss: 0.1551 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0974 - out_1_loss: 0.0572 - out_2_loss: 0.0403 - out_1_acc: 0.9693 - out_2_acc: 0.9783 - val_loss: 0.3170 - val_out_1_loss: 0.1560 - val_out_2_loss: 0.1610 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9507\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0971 - out_1_loss: 0.0570 - out_2_loss: 0.0401 - out_1_acc: 0.9696 - out_2_acc: 0.9784 - val_loss: 0.3196 - val_out_1_loss: 0.1583 - val_out_2_loss: 0.1613 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0964 - out_1_loss: 0.0566 - out_2_loss: 0.0398 - out_1_acc: 0.9701 - out_2_acc: 0.9786 - val_loss: 0.3218 - val_out_1_loss: 0.1594 - val_out_2_loss: 0.1624 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9514\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0962 - out_1_loss: 0.0564 - out_2_loss: 0.0398 - out_1_acc: 0.9703 - out_2_acc: 0.9787 - val_loss: 0.3267 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1660 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9513\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0946 - out_1_loss: 0.0557 - out_2_loss: 0.0388 - out_1_acc: 0.9705 - out_2_acc: 0.9796 - val_loss: 0.3263 - val_out_1_loss: 0.1611 - val_out_2_loss: 0.1651 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0946 - out_1_loss: 0.0560 - out_2_loss: 0.0387 - out_1_acc: 0.9702 - out_2_acc: 0.9800 - val_loss: 0.3243 - val_out_1_loss: 0.1592 - val_out_2_loss: 0.1651 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9509\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0930 - out_1_loss: 0.0551 - out_2_loss: 0.0379 - out_1_acc: 0.9712 - out_2_acc: 0.9804 - val_loss: 0.3267 - val_out_1_loss: 0.1610 - val_out_2_loss: 0.1657 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9509\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0917 - out_1_loss: 0.0545 - out_2_loss: 0.0372 - out_1_acc: 0.9713 - out_2_acc: 0.9810 - val_loss: 0.3299 - val_out_1_loss: 0.1615 - val_out_2_loss: 0.1684 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9513\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0911 - out_1_loss: 0.0538 - out_2_loss: 0.0373 - out_1_acc: 0.9720 - out_2_acc: 0.9804 - val_loss: 0.3325 - val_out_1_loss: 0.1629 - val_out_2_loss: 0.1696 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0899 - out_1_loss: 0.0533 - out_2_loss: 0.0366 - out_1_acc: 0.9721 - out_2_acc: 0.9813 - val_loss: 0.3342 - val_out_1_loss: 0.1637 - val_out_2_loss: 0.1705 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9519\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0889 - out_1_loss: 0.0528 - out_2_loss: 0.0361 - out_1_acc: 0.9724 - out_2_acc: 0.9812 - val_loss: 0.3359 - val_out_1_loss: 0.1653 - val_out_2_loss: 0.1705 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0882 - out_1_loss: 0.0525 - out_2_loss: 0.0357 - out_1_acc: 0.9728 - out_2_acc: 0.9816 - val_loss: 0.3377 - val_out_1_loss: 0.1653 - val_out_2_loss: 0.1725 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0873 - out_1_loss: 0.0522 - out_2_loss: 0.0351 - out_1_acc: 0.9731 - out_2_acc: 0.9821 - val_loss: 0.3377 - val_out_1_loss: 0.1667 - val_out_2_loss: 0.1710 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0868 - out_1_loss: 0.0520 - out_2_loss: 0.0348 - out_1_acc: 0.9733 - out_2_acc: 0.9821 - val_loss: 0.3438 - val_out_1_loss: 0.1681 - val_out_2_loss: 0.1757 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9523\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0886 - out_1_loss: 0.0520 - out_2_loss: 0.0366 - out_1_acc: 0.9732 - out_2_acc: 0.9811 - val_loss: 0.3404 - val_out_1_loss: 0.1684 - val_out_2_loss: 0.1720 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0870 - out_1_loss: 0.0517 - out_2_loss: 0.0353 - out_1_acc: 0.9733 - out_2_acc: 0.9820 - val_loss: 0.3435 - val_out_1_loss: 0.1693 - val_out_2_loss: 0.1742 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9526\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0867 - out_1_loss: 0.0516 - out_2_loss: 0.0352 - out_1_acc: 0.9735 - out_2_acc: 0.9819 - val_loss: 0.3493 - val_out_1_loss: 0.1742 - val_out_2_loss: 0.1751 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0861 - out_1_loss: 0.0514 - out_2_loss: 0.0346 - out_1_acc: 0.9736 - out_2_acc: 0.9825 - val_loss: 0.3507 - val_out_1_loss: 0.1755 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9518\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0856 - out_1_loss: 0.0514 - out_2_loss: 0.0342 - out_1_acc: 0.9738 - out_2_acc: 0.9833 - val_loss: 0.3525 - val_out_1_loss: 0.1789 - val_out_2_loss: 0.1736 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0838 - out_1_loss: 0.0504 - out_2_loss: 0.0334 - out_1_acc: 0.9744 - out_2_acc: 0.9835 - val_loss: 0.3555 - val_out_1_loss: 0.1798 - val_out_2_loss: 0.1756 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0835 - out_1_loss: 0.0504 - out_2_loss: 0.0331 - out_1_acc: 0.9744 - out_2_acc: 0.9834 - val_loss: 0.3675 - val_out_1_loss: 0.1833 - val_out_2_loss: 0.1842 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0827 - out_1_loss: 0.0499 - out_2_loss: 0.0328 - out_1_acc: 0.9746 - out_2_acc: 0.9839 - val_loss: 0.3659 - val_out_1_loss: 0.1851 - val_out_2_loss: 0.1808 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9522\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0812 - out_1_loss: 0.0496 - out_2_loss: 0.0316 - out_1_acc: 0.9747 - out_2_acc: 0.9846 - val_loss: 0.3677 - val_out_1_loss: 0.1859 - val_out_2_loss: 0.1818 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9507\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0780 - out_1_loss: 0.0488 - out_2_loss: 0.0292 - out_1_acc: 0.9754 - out_2_acc: 0.9859 - val_loss: 0.3690 - val_out_1_loss: 0.1848 - val_out_2_loss: 0.1842 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9510\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0778 - out_1_loss: 0.0487 - out_2_loss: 0.0291 - out_1_acc: 0.9755 - out_2_acc: 0.9860 - val_loss: 0.3735 - val_out_1_loss: 0.1867 - val_out_2_loss: 0.1868 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0776 - out_1_loss: 0.0479 - out_2_loss: 0.0296 - out_1_acc: 0.9761 - out_2_acc: 0.9860 - val_loss: 0.3745 - val_out_1_loss: 0.1889 - val_out_2_loss: 0.1855 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0757 - out_1_loss: 0.0470 - out_2_loss: 0.0287 - out_1_acc: 0.9764 - out_2_acc: 0.9864 - val_loss: 0.3785 - val_out_1_loss: 0.1895 - val_out_2_loss: 0.1890 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9512\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0739 - out_1_loss: 0.0460 - out_2_loss: 0.0280 - out_1_acc: 0.9774 - out_2_acc: 0.9866 - val_loss: 0.3836 - val_out_1_loss: 0.1907 - val_out_2_loss: 0.1929 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9515\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0734 - out_1_loss: 0.0463 - out_2_loss: 0.0271 - out_1_acc: 0.9774 - out_2_acc: 0.9876 - val_loss: 0.3954 - val_out_1_loss: 0.1955 - val_out_2_loss: 0.1999 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9516\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0734 - out_1_loss: 0.0460 - out_2_loss: 0.0273 - out_1_acc: 0.9772 - out_2_acc: 0.9874 - val_loss: 0.3977 - val_out_1_loss: 0.1980 - val_out_2_loss: 0.1997 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0748 - out_1_loss: 0.0462 - out_2_loss: 0.0285 - out_1_acc: 0.9773 - out_2_acc: 0.9866 - val_loss: 0.4066 - val_out_1_loss: 0.2058 - val_out_2_loss: 0.2009 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9524\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0772 - out_1_loss: 0.0477 - out_2_loss: 0.0296 - out_1_acc: 0.9765 - out_2_acc: 0.9859 - val_loss: 0.4024 - val_out_1_loss: 0.2008 - val_out_2_loss: 0.2016 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9517\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0759 - out_1_loss: 0.0473 - out_2_loss: 0.0286 - out_1_acc: 0.9766 - out_2_acc: 0.9867 - val_loss: 0.4034 - val_out_1_loss: 0.2008 - val_out_2_loss: 0.2027 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0755 - out_1_loss: 0.0481 - out_2_loss: 0.0274 - out_1_acc: 0.9762 - out_2_acc: 0.9874 - val_loss: 0.4060 - val_out_1_loss: 0.2050 - val_out_2_loss: 0.2009 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.0755 - out_1_loss: 0.0492 - out_2_loss: 0.0263 - out_1_acc: 0.9756 - out_2_acc: 0.9878 - val_loss: 0.4099 - val_out_1_loss: 0.2009 - val_out_2_loss: 0.2090 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0790 - out_1_loss: 0.0516 - out_2_loss: 0.0274 - out_1_acc: 0.9748 - out_2_acc: 0.9874 - val_loss: 0.3978 - val_out_1_loss: 0.1975 - val_out_2_loss: 0.2003 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9530\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0793 - out_1_loss: 0.0526 - out_2_loss: 0.0267 - out_1_acc: 0.9742 - out_2_acc: 0.9875 - val_loss: 0.3980 - val_out_1_loss: 0.1932 - val_out_2_loss: 0.2048 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9525\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0782 - out_1_loss: 0.0509 - out_2_loss: 0.0273 - out_1_acc: 0.9751 - out_2_acc: 0.9874 - val_loss: 0.3962 - val_out_1_loss: 0.1930 - val_out_2_loss: 0.2032 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.0762 - out_1_loss: 0.0479 - out_2_loss: 0.0283 - out_1_acc: 0.9763 - out_2_acc: 0.9866 - val_loss: 0.3936 - val_out_1_loss: 0.1904 - val_out_2_loss: 0.2032 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9519\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(3)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3742 - out_1_loss: 0.1835 - out_2_loss: 0.1907 - out_1_acc: 0.9406 - out_2_acc: 0.9532\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 300), (No 433200      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 300)       433200      input_7[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,513,480\n",
      "Trainable params: 2,513,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3279 - out_1_loss: 3.6694 - out_2_loss: 3.6585 - out_1_acc: 0.1807 - out_2_acc: 0.2446WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.106439). Check your callbacks.\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 4.3585 - out_1_loss: 2.4992 - out_2_loss: 1.8592 - out_1_acc: 0.6803 - out_2_acc: 0.7581 - val_loss: 1.1806 - val_out_1_loss: 0.8653 - val_out_2_loss: 0.3153 - val_out_1_acc: 0.8393 - val_out_2_acc: 0.9394\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.7626 - out_1_loss: 0.5596 - out_2_loss: 0.2030 - out_1_acc: 0.8974 - out_2_acc: 0.9503 - val_loss: 0.4982 - val_out_1_loss: 0.3452 - val_out_2_loss: 0.1531 - val_out_1_acc: 0.9290 - val_out_2_acc: 0.9496\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.3785 - out_1_loss: 0.2524 - out_2_loss: 0.1262 - out_1_acc: 0.9340 - out_2_acc: 0.9517 - val_loss: 0.3034 - val_out_1_loss: 0.1815 - val_out_2_loss: 0.1219 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9507\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.2569 - out_1_loss: 0.1506 - out_2_loss: 0.1063 - out_1_acc: 0.9396 - out_2_acc: 0.9521 - val_loss: 0.2495 - val_out_1_loss: 0.1421 - val_out_2_loss: 0.1074 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9511\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.2239 - out_1_loss: 0.1271 - out_2_loss: 0.0968 - out_1_acc: 0.9402 - out_2_acc: 0.9527 - val_loss: 0.2321 - val_out_1_loss: 0.1315 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2109 - out_1_loss: 0.1192 - out_2_loss: 0.0917 - out_1_acc: 0.9402 - out_2_acc: 0.9528 - val_loss: 0.2222 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.0968 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2034 - out_1_loss: 0.1147 - out_2_loss: 0.0887 - out_1_acc: 0.9407 - out_2_acc: 0.9528 - val_loss: 0.2154 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1978 - out_1_loss: 0.1114 - out_2_loss: 0.0864 - out_1_acc: 0.9413 - out_2_acc: 0.9527 - val_loss: 0.2105 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1935 - out_1_loss: 0.1088 - out_2_loss: 0.0847 - out_1_acc: 0.9419 - out_2_acc: 0.9531 - val_loss: 0.2069 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.0910 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9526\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1902 - out_1_loss: 0.1068 - out_2_loss: 0.0834 - out_1_acc: 0.9422 - out_2_acc: 0.9533 - val_loss: 0.2045 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1875 - out_1_loss: 0.1051 - out_2_loss: 0.0824 - out_1_acc: 0.9422 - out_2_acc: 0.9537 - val_loss: 0.2028 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1853 - out_1_loss: 0.1037 - out_2_loss: 0.0815 - out_1_acc: 0.9425 - out_2_acc: 0.9540 - val_loss: 0.2017 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1833 - out_1_loss: 0.1026 - out_2_loss: 0.0806 - out_1_acc: 0.9427 - out_2_acc: 0.9545 - val_loss: 0.2008 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1815 - out_1_loss: 0.1017 - out_2_loss: 0.0798 - out_1_acc: 0.9430 - out_2_acc: 0.9549 - val_loss: 0.2002 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0906 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9521\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1798 - out_1_loss: 0.1009 - out_2_loss: 0.0789 - out_1_acc: 0.9433 - out_2_acc: 0.9556 - val_loss: 0.2003 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1781 - out_1_loss: 0.1002 - out_2_loss: 0.0780 - out_1_acc: 0.9435 - out_2_acc: 0.9558 - val_loss: 0.2005 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1764 - out_1_loss: 0.0995 - out_2_loss: 0.0769 - out_1_acc: 0.9439 - out_2_acc: 0.9566 - val_loss: 0.2009 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1747 - out_1_loss: 0.0988 - out_2_loss: 0.0758 - out_1_acc: 0.9442 - out_2_acc: 0.9566 - val_loss: 0.2005 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1729 - out_1_loss: 0.0983 - out_2_loss: 0.0746 - out_1_acc: 0.9445 - out_2_acc: 0.9573 - val_loss: 0.2014 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1710 - out_1_loss: 0.0977 - out_2_loss: 0.0733 - out_1_acc: 0.9448 - out_2_acc: 0.9578 - val_loss: 0.2019 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0933 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1691 - out_1_loss: 0.0972 - out_2_loss: 0.0719 - out_1_acc: 0.9449 - out_2_acc: 0.9585 - val_loss: 0.2031 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1671 - out_1_loss: 0.0966 - out_2_loss: 0.0705 - out_1_acc: 0.9451 - out_2_acc: 0.9593 - val_loss: 0.2042 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9513\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1651 - out_1_loss: 0.0961 - out_2_loss: 0.0690 - out_1_acc: 0.9455 - out_2_acc: 0.9601 - val_loss: 0.2054 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1631 - out_1_loss: 0.0955 - out_2_loss: 0.0677 - out_1_acc: 0.9457 - out_2_acc: 0.9606 - val_loss: 0.2069 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9513\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1610 - out_1_loss: 0.0949 - out_2_loss: 0.0661 - out_1_acc: 0.9460 - out_2_acc: 0.9613 - val_loss: 0.2082 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1588 - out_1_loss: 0.0943 - out_2_loss: 0.0645 - out_1_acc: 0.9464 - out_2_acc: 0.9617 - val_loss: 0.2098 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0994 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1566 - out_1_loss: 0.0936 - out_2_loss: 0.0630 - out_1_acc: 0.9470 - out_2_acc: 0.9629 - val_loss: 0.2119 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.1011 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1544 - out_1_loss: 0.0929 - out_2_loss: 0.0616 - out_1_acc: 0.9475 - out_2_acc: 0.9630 - val_loss: 0.2139 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.1026 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1521 - out_1_loss: 0.0921 - out_2_loss: 0.0599 - out_1_acc: 0.9478 - out_2_acc: 0.9640 - val_loss: 0.2160 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.1045 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9512\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1500 - out_1_loss: 0.0913 - out_2_loss: 0.0586 - out_1_acc: 0.9483 - out_2_acc: 0.9646 - val_loss: 0.2179 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.1061 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1478 - out_1_loss: 0.0905 - out_2_loss: 0.0573 - out_1_acc: 0.9489 - out_2_acc: 0.9653 - val_loss: 0.2208 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.1085 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9512\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1460 - out_1_loss: 0.0897 - out_2_loss: 0.0563 - out_1_acc: 0.9497 - out_2_acc: 0.9654 - val_loss: 0.2233 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1109 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1446 - out_1_loss: 0.0887 - out_2_loss: 0.0559 - out_1_acc: 0.9503 - out_2_acc: 0.9659 - val_loss: 0.2250 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.1120 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9511\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1437 - out_1_loss: 0.0878 - out_2_loss: 0.0559 - out_1_acc: 0.9507 - out_2_acc: 0.9662 - val_loss: 0.2282 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1147 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1428 - out_1_loss: 0.0869 - out_2_loss: 0.0559 - out_1_acc: 0.9510 - out_2_acc: 0.9657 - val_loss: 0.2315 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1178 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9516\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1415 - out_1_loss: 0.0860 - out_2_loss: 0.0555 - out_1_acc: 0.9515 - out_2_acc: 0.9657 - val_loss: 0.2303 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1154 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9505\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1389 - out_1_loss: 0.0852 - out_2_loss: 0.0537 - out_1_acc: 0.9517 - out_2_acc: 0.9669 - val_loss: 0.2322 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1162 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1372 - out_1_loss: 0.0842 - out_2_loss: 0.0531 - out_1_acc: 0.9522 - out_2_acc: 0.9669 - val_loss: 0.2331 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1165 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1356 - out_1_loss: 0.0832 - out_2_loss: 0.0524 - out_1_acc: 0.9528 - out_2_acc: 0.9672 - val_loss: 0.2357 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1185 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1346 - out_1_loss: 0.0824 - out_2_loss: 0.0522 - out_1_acc: 0.9533 - out_2_acc: 0.9672 - val_loss: 0.2384 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1203 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1331 - out_1_loss: 0.0814 - out_2_loss: 0.0517 - out_1_acc: 0.9540 - out_2_acc: 0.9677 - val_loss: 0.2416 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.1227 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1316 - out_1_loss: 0.0803 - out_2_loss: 0.0514 - out_1_acc: 0.9547 - out_2_acc: 0.9674 - val_loss: 0.2432 - val_out_1_loss: 0.1200 - val_out_2_loss: 0.1232 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1301 - out_1_loss: 0.0792 - out_2_loss: 0.0510 - out_1_acc: 0.9551 - out_2_acc: 0.9681 - val_loss: 0.2452 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.1251 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9519\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1287 - out_1_loss: 0.0780 - out_2_loss: 0.0507 - out_1_acc: 0.9557 - out_2_acc: 0.9681 - val_loss: 0.2472 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1256 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1274 - out_1_loss: 0.0769 - out_2_loss: 0.0504 - out_1_acc: 0.9568 - out_2_acc: 0.9685 - val_loss: 0.2486 - val_out_1_loss: 0.1224 - val_out_2_loss: 0.1263 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9523\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.1261 - out_1_loss: 0.0760 - out_2_loss: 0.0501 - out_1_acc: 0.9570 - out_2_acc: 0.9689 - val_loss: 0.2517 - val_out_1_loss: 0.1238 - val_out_2_loss: 0.1279 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1250 - out_1_loss: 0.0752 - out_2_loss: 0.0499 - out_1_acc: 0.9576 - out_2_acc: 0.9686 - val_loss: 0.2574 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1317 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1241 - out_1_loss: 0.0744 - out_2_loss: 0.0497 - out_1_acc: 0.9577 - out_2_acc: 0.9694 - val_loss: 0.2556 - val_out_1_loss: 0.1263 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9505\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1234 - out_1_loss: 0.0735 - out_2_loss: 0.0499 - out_1_acc: 0.9582 - out_2_acc: 0.9691 - val_loss: 0.2560 - val_out_1_loss: 0.1274 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9509\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1218 - out_1_loss: 0.0723 - out_2_loss: 0.0495 - out_1_acc: 0.9589 - out_2_acc: 0.9696 - val_loss: 0.2576 - val_out_1_loss: 0.1285 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9510\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1205 - out_1_loss: 0.0715 - out_2_loss: 0.0491 - out_1_acc: 0.9598 - out_2_acc: 0.9696 - val_loss: 0.2605 - val_out_1_loss: 0.1309 - val_out_2_loss: 0.1296 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9520\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1196 - out_1_loss: 0.0709 - out_2_loss: 0.0487 - out_1_acc: 0.9599 - out_2_acc: 0.9702 - val_loss: 0.2630 - val_out_1_loss: 0.1323 - val_out_2_loss: 0.1308 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9511\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1187 - out_1_loss: 0.0701 - out_2_loss: 0.0486 - out_1_acc: 0.9601 - out_2_acc: 0.9705 - val_loss: 0.2655 - val_out_1_loss: 0.1341 - val_out_2_loss: 0.1314 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9511\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1181 - out_1_loss: 0.0696 - out_2_loss: 0.0485 - out_1_acc: 0.9601 - out_2_acc: 0.9700 - val_loss: 0.2679 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1327 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1170 - out_1_loss: 0.0687 - out_2_loss: 0.0484 - out_1_acc: 0.9609 - out_2_acc: 0.9709 - val_loss: 0.2693 - val_out_1_loss: 0.1361 - val_out_2_loss: 0.1332 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9516\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1156 - out_1_loss: 0.0677 - out_2_loss: 0.0480 - out_1_acc: 0.9616 - out_2_acc: 0.9708 - val_loss: 0.2705 - val_out_1_loss: 0.1371 - val_out_2_loss: 0.1334 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9525\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1154 - out_1_loss: 0.0673 - out_2_loss: 0.0481 - out_1_acc: 0.9620 - out_2_acc: 0.9708 - val_loss: 0.2712 - val_out_1_loss: 0.1389 - val_out_2_loss: 0.1324 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9517\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1137 - out_1_loss: 0.0664 - out_2_loss: 0.0473 - out_1_acc: 0.9628 - out_2_acc: 0.9719 - val_loss: 0.2740 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1346 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9510\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1131 - out_1_loss: 0.0657 - out_2_loss: 0.0474 - out_1_acc: 0.9632 - out_2_acc: 0.9717 - val_loss: 0.2778 - val_out_1_loss: 0.1404 - val_out_2_loss: 0.1374 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9517\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1123 - out_1_loss: 0.0652 - out_2_loss: 0.0471 - out_1_acc: 0.9633 - out_2_acc: 0.9719 - val_loss: 0.2796 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1361 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9516\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1114 - out_1_loss: 0.0645 - out_2_loss: 0.0469 - out_1_acc: 0.9638 - out_2_acc: 0.9722 - val_loss: 0.2821 - val_out_1_loss: 0.1453 - val_out_2_loss: 0.1367 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1104 - out_1_loss: 0.0639 - out_2_loss: 0.0464 - out_1_acc: 0.9644 - out_2_acc: 0.9728 - val_loss: 0.2824 - val_out_1_loss: 0.1459 - val_out_2_loss: 0.1366 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1090 - out_1_loss: 0.0634 - out_2_loss: 0.0456 - out_1_acc: 0.9647 - out_2_acc: 0.9732 - val_loss: 0.2886 - val_out_1_loss: 0.1486 - val_out_2_loss: 0.1400 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9507\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1087 - out_1_loss: 0.0629 - out_2_loss: 0.0458 - out_1_acc: 0.9645 - out_2_acc: 0.9736 - val_loss: 0.2905 - val_out_1_loss: 0.1512 - val_out_2_loss: 0.1393 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9513\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1080 - out_1_loss: 0.0623 - out_2_loss: 0.0457 - out_1_acc: 0.9652 - out_2_acc: 0.9735 - val_loss: 0.2970 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1432 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9511\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1066 - out_1_loss: 0.0617 - out_2_loss: 0.0448 - out_1_acc: 0.9653 - out_2_acc: 0.9745 - val_loss: 0.2945 - val_out_1_loss: 0.1525 - val_out_2_loss: 0.1420 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1060 - out_1_loss: 0.0610 - out_2_loss: 0.0450 - out_1_acc: 0.9662 - out_2_acc: 0.9741 - val_loss: 0.2989 - val_out_1_loss: 0.1547 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9520\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1055 - out_1_loss: 0.0608 - out_2_loss: 0.0447 - out_1_acc: 0.9658 - out_2_acc: 0.9744 - val_loss: 0.2959 - val_out_1_loss: 0.1540 - val_out_2_loss: 0.1418 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9512\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1035 - out_1_loss: 0.0600 - out_2_loss: 0.0435 - out_1_acc: 0.9667 - out_2_acc: 0.9751 - val_loss: 0.3001 - val_out_1_loss: 0.1557 - val_out_2_loss: 0.1444 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9523\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1029 - out_1_loss: 0.0597 - out_2_loss: 0.0433 - out_1_acc: 0.9675 - out_2_acc: 0.9757 - val_loss: 0.3016 - val_out_1_loss: 0.1546 - val_out_2_loss: 0.1470 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1029 - out_1_loss: 0.0596 - out_2_loss: 0.0434 - out_1_acc: 0.9678 - out_2_acc: 0.9750 - val_loss: 0.3053 - val_out_1_loss: 0.1575 - val_out_2_loss: 0.1478 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1013 - out_1_loss: 0.0584 - out_2_loss: 0.0429 - out_1_acc: 0.9679 - out_2_acc: 0.9758 - val_loss: 0.3117 - val_out_1_loss: 0.1604 - val_out_2_loss: 0.1512 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1019 - out_1_loss: 0.0586 - out_2_loss: 0.0433 - out_1_acc: 0.9679 - out_2_acc: 0.9754 - val_loss: 0.3107 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9510\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1010 - out_1_loss: 0.0580 - out_2_loss: 0.0431 - out_1_acc: 0.9681 - out_2_acc: 0.9759 - val_loss: 0.3140 - val_out_1_loss: 0.1646 - val_out_2_loss: 0.1494 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9519\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1003 - out_1_loss: 0.0579 - out_2_loss: 0.0425 - out_1_acc: 0.9684 - out_2_acc: 0.9760 - val_loss: 0.3150 - val_out_1_loss: 0.1650 - val_out_2_loss: 0.1500 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9513\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0999 - out_1_loss: 0.0574 - out_2_loss: 0.0425 - out_1_acc: 0.9681 - out_2_acc: 0.9765 - val_loss: 0.3162 - val_out_1_loss: 0.1628 - val_out_2_loss: 0.1534 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0988 - out_1_loss: 0.0570 - out_2_loss: 0.0419 - out_1_acc: 0.9693 - out_2_acc: 0.9772 - val_loss: 0.3157 - val_out_1_loss: 0.1618 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9507\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0962 - out_1_loss: 0.0553 - out_2_loss: 0.0409 - out_1_acc: 0.9699 - out_2_acc: 0.9778 - val_loss: 0.3175 - val_out_1_loss: 0.1640 - val_out_2_loss: 0.1535 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0969 - out_1_loss: 0.0559 - out_2_loss: 0.0410 - out_1_acc: 0.9696 - out_2_acc: 0.9773 - val_loss: 0.3200 - val_out_1_loss: 0.1655 - val_out_2_loss: 0.1545 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0977 - out_1_loss: 0.0561 - out_2_loss: 0.0416 - out_1_acc: 0.9700 - out_2_acc: 0.9776 - val_loss: 0.3217 - val_out_1_loss: 0.1666 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0947 - out_1_loss: 0.0544 - out_2_loss: 0.0403 - out_1_acc: 0.9712 - out_2_acc: 0.9786 - val_loss: 0.3257 - val_out_1_loss: 0.1681 - val_out_2_loss: 0.1575 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0935 - out_1_loss: 0.0540 - out_2_loss: 0.0394 - out_1_acc: 0.9715 - out_2_acc: 0.9794 - val_loss: 0.3275 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.1583 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0927 - out_1_loss: 0.0536 - out_2_loss: 0.0391 - out_1_acc: 0.9711 - out_2_acc: 0.9795 - val_loss: 0.3339 - val_out_1_loss: 0.1719 - val_out_2_loss: 0.1620 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9516\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0931 - out_1_loss: 0.0537 - out_2_loss: 0.0394 - out_1_acc: 0.9717 - out_2_acc: 0.9789 - val_loss: 0.3375 - val_out_1_loss: 0.1725 - val_out_2_loss: 0.1650 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0912 - out_1_loss: 0.0531 - out_2_loss: 0.0382 - out_1_acc: 0.9724 - out_2_acc: 0.9799 - val_loss: 0.3358 - val_out_1_loss: 0.1730 - val_out_2_loss: 0.1628 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0923 - out_1_loss: 0.0536 - out_2_loss: 0.0386 - out_1_acc: 0.9721 - out_2_acc: 0.9799 - val_loss: 0.3403 - val_out_1_loss: 0.1764 - val_out_2_loss: 0.1638 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9511\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0951 - out_1_loss: 0.0551 - out_2_loss: 0.0401 - out_1_acc: 0.9712 - out_2_acc: 0.9790 - val_loss: 0.3403 - val_out_1_loss: 0.1752 - val_out_2_loss: 0.1651 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9509\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0924 - out_1_loss: 0.0533 - out_2_loss: 0.0391 - out_1_acc: 0.9724 - out_2_acc: 0.9798 - val_loss: 0.3418 - val_out_1_loss: 0.1770 - val_out_2_loss: 0.1648 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9503\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0903 - out_1_loss: 0.0527 - out_2_loss: 0.0376 - out_1_acc: 0.9724 - out_2_acc: 0.9811 - val_loss: 0.3389 - val_out_1_loss: 0.1761 - val_out_2_loss: 0.1628 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9516\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0923 - out_1_loss: 0.0541 - out_2_loss: 0.0382 - out_1_acc: 0.9713 - out_2_acc: 0.9809 - val_loss: 0.3409 - val_out_1_loss: 0.1758 - val_out_2_loss: 0.1652 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9511\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0902 - out_1_loss: 0.0533 - out_2_loss: 0.0368 - out_1_acc: 0.9722 - out_2_acc: 0.9817 - val_loss: 0.3479 - val_out_1_loss: 0.1801 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0882 - out_1_loss: 0.0520 - out_2_loss: 0.0361 - out_1_acc: 0.9733 - out_2_acc: 0.9817 - val_loss: 0.3443 - val_out_1_loss: 0.1784 - val_out_2_loss: 0.1659 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0861 - out_1_loss: 0.0503 - out_2_loss: 0.0358 - out_1_acc: 0.9746 - out_2_acc: 0.9820 - val_loss: 0.3513 - val_out_1_loss: 0.1831 - val_out_2_loss: 0.1681 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9528\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0849 - out_1_loss: 0.0502 - out_2_loss: 0.0347 - out_1_acc: 0.9746 - out_2_acc: 0.9827 - val_loss: 0.3572 - val_out_1_loss: 0.1854 - val_out_2_loss: 0.1718 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0834 - out_1_loss: 0.0500 - out_2_loss: 0.0334 - out_1_acc: 0.9750 - out_2_acc: 0.9840 - val_loss: 0.3602 - val_out_1_loss: 0.1875 - val_out_2_loss: 0.1728 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0820 - out_1_loss: 0.0491 - out_2_loss: 0.0329 - out_1_acc: 0.9751 - out_2_acc: 0.9843 - val_loss: 0.3630 - val_out_1_loss: 0.1893 - val_out_2_loss: 0.1736 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0822 - out_1_loss: 0.0496 - out_2_loss: 0.0325 - out_1_acc: 0.9750 - out_2_acc: 0.9842 - val_loss: 0.3734 - val_out_1_loss: 0.1943 - val_out_2_loss: 0.1791 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0811 - out_1_loss: 0.0492 - out_2_loss: 0.0319 - out_1_acc: 0.9757 - out_2_acc: 0.9841 - val_loss: 0.3715 - val_out_1_loss: 0.1926 - val_out_2_loss: 0.1789 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0790 - out_1_loss: 0.0481 - out_2_loss: 0.0310 - out_1_acc: 0.9762 - out_2_acc: 0.9847 - val_loss: 0.3710 - val_out_1_loss: 0.1927 - val_out_2_loss: 0.1784 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0782 - out_1_loss: 0.0476 - out_2_loss: 0.0306 - out_1_acc: 0.9767 - out_2_acc: 0.9852 - val_loss: 0.3730 - val_out_1_loss: 0.1920 - val_out_2_loss: 0.1809 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0760 - out_1_loss: 0.0464 - out_2_loss: 0.0296 - out_1_acc: 0.9773 - out_2_acc: 0.9857 - val_loss: 0.3838 - val_out_1_loss: 0.1959 - val_out_2_loss: 0.1878 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9520\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0750 - out_1_loss: 0.0464 - out_2_loss: 0.0286 - out_1_acc: 0.9767 - out_2_acc: 0.9861 - val_loss: 0.3855 - val_out_1_loss: 0.1979 - val_out_2_loss: 0.1876 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9530\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0761 - out_1_loss: 0.0463 - out_2_loss: 0.0299 - out_1_acc: 0.9772 - out_2_acc: 0.9859 - val_loss: 0.3883 - val_out_1_loss: 0.1987 - val_out_2_loss: 0.1896 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0764 - out_1_loss: 0.0476 - out_2_loss: 0.0288 - out_1_acc: 0.9773 - out_2_acc: 0.9862 - val_loss: 0.3902 - val_out_1_loss: 0.1992 - val_out_2_loss: 0.1910 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0730 - out_1_loss: 0.0454 - out_2_loss: 0.0276 - out_1_acc: 0.9784 - out_2_acc: 0.9869 - val_loss: 0.3894 - val_out_1_loss: 0.1999 - val_out_2_loss: 0.1894 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9522\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0725 - out_1_loss: 0.0453 - out_2_loss: 0.0272 - out_1_acc: 0.9782 - out_2_acc: 0.9874 - val_loss: 0.3833 - val_out_1_loss: 0.1972 - val_out_2_loss: 0.1861 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0729 - out_1_loss: 0.0446 - out_2_loss: 0.0283 - out_1_acc: 0.9787 - out_2_acc: 0.9870 - val_loss: 0.3838 - val_out_1_loss: 0.1980 - val_out_2_loss: 0.1858 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0723 - out_1_loss: 0.0443 - out_2_loss: 0.0280 - out_1_acc: 0.9787 - out_2_acc: 0.9867 - val_loss: 0.3892 - val_out_1_loss: 0.1973 - val_out_2_loss: 0.1920 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9538\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0713 - out_1_loss: 0.0443 - out_2_loss: 0.0270 - out_1_acc: 0.9784 - out_2_acc: 0.9876 - val_loss: 0.3967 - val_out_1_loss: 0.1988 - val_out_2_loss: 0.1979 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9530\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0731 - out_1_loss: 0.0451 - out_2_loss: 0.0279 - out_1_acc: 0.9780 - out_2_acc: 0.9869 - val_loss: 0.4001 - val_out_1_loss: 0.2013 - val_out_2_loss: 0.1988 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9528\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0726 - out_1_loss: 0.0461 - out_2_loss: 0.0265 - out_1_acc: 0.9775 - out_2_acc: 0.9881 - val_loss: 0.4001 - val_out_1_loss: 0.2020 - val_out_2_loss: 0.1981 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9529\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0744 - out_1_loss: 0.0467 - out_2_loss: 0.0277 - out_1_acc: 0.9774 - out_2_acc: 0.9877 - val_loss: 0.3957 - val_out_1_loss: 0.1999 - val_out_2_loss: 0.1958 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9538\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0765 - out_1_loss: 0.0478 - out_2_loss: 0.0287 - out_1_acc: 0.9767 - out_2_acc: 0.9866 - val_loss: 0.3966 - val_out_1_loss: 0.1997 - val_out_2_loss: 0.1969 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0737 - out_1_loss: 0.0482 - out_2_loss: 0.0255 - out_1_acc: 0.9764 - out_2_acc: 0.9887 - val_loss: 0.4009 - val_out_1_loss: 0.2027 - val_out_2_loss: 0.1981 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0762 - out_1_loss: 0.0502 - out_2_loss: 0.0260 - out_1_acc: 0.9758 - out_2_acc: 0.9882 - val_loss: 0.4127 - val_out_1_loss: 0.2105 - val_out_2_loss: 0.2022 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9532\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0729 - out_1_loss: 0.0465 - out_2_loss: 0.0264 - out_1_acc: 0.9780 - out_2_acc: 0.9882 - val_loss: 0.4076 - val_out_1_loss: 0.2059 - val_out_2_loss: 0.2017 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9532\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0685 - out_1_loss: 0.0426 - out_2_loss: 0.0260 - out_1_acc: 0.9799 - out_2_acc: 0.9882 - val_loss: 0.4040 - val_out_1_loss: 0.2024 - val_out_2_loss: 0.2017 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9538\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0638 - out_1_loss: 0.0395 - out_2_loss: 0.0243 - out_1_acc: 0.9816 - out_2_acc: 0.9893 - val_loss: 0.4026 - val_out_1_loss: 0.2034 - val_out_2_loss: 0.1992 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0594 - out_1_loss: 0.0374 - out_2_loss: 0.0220 - out_1_acc: 0.9829 - out_2_acc: 0.9905 - val_loss: 0.4111 - val_out_1_loss: 0.2050 - val_out_2_loss: 0.2061 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0573 - out_1_loss: 0.0357 - out_2_loss: 0.0216 - out_1_acc: 0.9838 - out_2_acc: 0.9903 - val_loss: 0.4217 - val_out_1_loss: 0.2119 - val_out_2_loss: 0.2098 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9528\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0574 - out_1_loss: 0.0359 - out_2_loss: 0.0215 - out_1_acc: 0.9834 - out_2_acc: 0.9905 - val_loss: 0.4271 - val_out_1_loss: 0.2130 - val_out_2_loss: 0.2141 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0559 - out_1_loss: 0.0355 - out_2_loss: 0.0204 - out_1_acc: 0.9840 - out_2_acc: 0.9915 - val_loss: 0.4252 - val_out_1_loss: 0.2131 - val_out_2_loss: 0.2122 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0545 - out_1_loss: 0.0355 - out_2_loss: 0.0190 - out_1_acc: 0.9842 - out_2_acc: 0.9919 - val_loss: 0.4322 - val_out_1_loss: 0.2158 - val_out_2_loss: 0.2164 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0520 - out_1_loss: 0.0337 - out_2_loss: 0.0183 - out_1_acc: 0.9850 - out_2_acc: 0.9922 - val_loss: 0.4367 - val_out_1_loss: 0.2170 - val_out_2_loss: 0.2197 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0497 - out_1_loss: 0.0332 - out_2_loss: 0.0165 - out_1_acc: 0.9856 - out_2_acc: 0.9933 - val_loss: 0.4437 - val_out_1_loss: 0.2191 - val_out_2_loss: 0.2246 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0489 - out_1_loss: 0.0333 - out_2_loss: 0.0156 - out_1_acc: 0.9851 - out_2_acc: 0.9937 - val_loss: 0.4435 - val_out_1_loss: 0.2211 - val_out_2_loss: 0.2224 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9523\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0461 - out_1_loss: 0.0315 - out_2_loss: 0.0147 - out_1_acc: 0.9862 - out_2_acc: 0.9944 - val_loss: 0.4493 - val_out_1_loss: 0.2219 - val_out_2_loss: 0.2273 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9519\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0448 - out_1_loss: 0.0311 - out_2_loss: 0.0137 - out_1_acc: 0.9866 - out_2_acc: 0.9945 - val_loss: 0.4556 - val_out_1_loss: 0.2234 - val_out_2_loss: 0.2322 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9511\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0421 - out_1_loss: 0.0290 - out_2_loss: 0.0131 - out_1_acc: 0.9876 - out_2_acc: 0.9948 - val_loss: 0.4769 - val_out_1_loss: 0.2329 - val_out_2_loss: 0.2440 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9512\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0416 - out_1_loss: 0.0279 - out_2_loss: 0.0137 - out_1_acc: 0.9883 - out_2_acc: 0.9946 - val_loss: 0.4848 - val_out_1_loss: 0.2384 - val_out_2_loss: 0.2464 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9527\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0413 - out_1_loss: 0.0281 - out_2_loss: 0.0132 - out_1_acc: 0.9887 - out_2_acc: 0.9948 - val_loss: 0.4756 - val_out_1_loss: 0.2365 - val_out_2_loss: 0.2391 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0378 - out_1_loss: 0.0257 - out_2_loss: 0.0122 - out_1_acc: 0.9895 - out_2_acc: 0.9954 - val_loss: 0.4871 - val_out_1_loss: 0.2454 - val_out_2_loss: 0.2418 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9527\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0340 - out_1_loss: 0.0242 - out_2_loss: 0.0098 - out_1_acc: 0.9903 - out_2_acc: 0.9964 - val_loss: 0.4985 - val_out_1_loss: 0.2457 - val_out_2_loss: 0.2528 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9516\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0328 - out_1_loss: 0.0235 - out_2_loss: 0.0093 - out_1_acc: 0.9907 - out_2_acc: 0.9966 - val_loss: 0.4985 - val_out_1_loss: 0.2486 - val_out_2_loss: 0.2499 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0328 - out_1_loss: 0.0232 - out_2_loss: 0.0095 - out_1_acc: 0.9907 - out_2_acc: 0.9963 - val_loss: 0.5054 - val_out_1_loss: 0.2536 - val_out_2_loss: 0.2518 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 136/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0317 - out_1_loss: 0.0223 - out_2_loss: 0.0094 - out_1_acc: 0.9912 - out_2_acc: 0.9965 - val_loss: 0.5122 - val_out_1_loss: 0.2531 - val_out_2_loss: 0.2591 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9510\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0283 - out_1_loss: 0.0205 - out_2_loss: 0.0078 - out_1_acc: 0.9924 - out_2_acc: 0.9970 - val_loss: 0.5219 - val_out_1_loss: 0.2590 - val_out_2_loss: 0.2628 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0268 - out_1_loss: 0.0199 - out_2_loss: 0.0069 - out_1_acc: 0.9921 - out_2_acc: 0.9975 - val_loss: 0.5241 - val_out_1_loss: 0.2607 - val_out_2_loss: 0.2634 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9531\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0252 - out_1_loss: 0.0193 - out_2_loss: 0.0059 - out_1_acc: 0.9928 - out_2_acc: 0.9979 - val_loss: 0.5328 - val_out_1_loss: 0.2638 - val_out_2_loss: 0.2690 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0263 - out_1_loss: 0.0194 - out_2_loss: 0.0068 - out_1_acc: 0.9927 - out_2_acc: 0.9975 - val_loss: 0.5322 - val_out_1_loss: 0.2610 - val_out_2_loss: 0.2712 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0240 - out_1_loss: 0.0181 - out_2_loss: 0.0059 - out_1_acc: 0.9932 - out_2_acc: 0.9979 - val_loss: 0.5331 - val_out_1_loss: 0.2604 - val_out_2_loss: 0.2727 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0257 - out_1_loss: 0.0193 - out_2_loss: 0.0064 - out_1_acc: 0.9927 - out_2_acc: 0.9976 - val_loss: 0.5322 - val_out_1_loss: 0.2653 - val_out_2_loss: 0.2669 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0248 - out_1_loss: 0.0184 - out_2_loss: 0.0064 - out_1_acc: 0.9931 - out_2_acc: 0.9974 - val_loss: 0.5322 - val_out_1_loss: 0.2688 - val_out_2_loss: 0.2634 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0219 - out_1_loss: 0.0173 - out_2_loss: 0.0045 - out_1_acc: 0.9934 - out_2_acc: 0.9983 - val_loss: 0.5494 - val_out_1_loss: 0.2768 - val_out_2_loss: 0.2726 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9516\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0207 - out_1_loss: 0.0167 - out_2_loss: 0.0040 - out_1_acc: 0.9937 - out_2_acc: 0.9986 - val_loss: 0.5476 - val_out_1_loss: 0.2755 - val_out_2_loss: 0.2721 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9525\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0198 - out_1_loss: 0.0161 - out_2_loss: 0.0036 - out_1_acc: 0.9940 - out_2_acc: 0.9988 - val_loss: 0.5689 - val_out_1_loss: 0.2884 - val_out_2_loss: 0.2805 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9517\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0192 - out_1_loss: 0.0155 - out_2_loss: 0.0037 - out_1_acc: 0.9943 - out_2_acc: 0.9987 - val_loss: 0.5662 - val_out_1_loss: 0.2866 - val_out_2_loss: 0.2796 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0208 - out_1_loss: 0.0160 - out_2_loss: 0.0048 - out_1_acc: 0.9942 - out_2_acc: 0.9983 - val_loss: 0.5676 - val_out_1_loss: 0.2853 - val_out_2_loss: 0.2823 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0202 - out_1_loss: 0.0155 - out_2_loss: 0.0047 - out_1_acc: 0.9942 - out_2_acc: 0.9982 - val_loss: 0.5753 - val_out_1_loss: 0.2875 - val_out_2_loss: 0.2878 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9523\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0192 - out_1_loss: 0.0145 - out_2_loss: 0.0047 - out_1_acc: 0.9948 - out_2_acc: 0.9984 - val_loss: 0.5819 - val_out_1_loss: 0.2931 - val_out_2_loss: 0.2888 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(3)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5567 - out_1_loss: 0.2782 - out_2_loss: 0.2785 - out_1_acc: 0.9410 - out_2_acc: 0.9523\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 300), (No 433200      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 300)       433200      input_8[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,513,480\n",
      "Trainable params: 2,513,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3343 - out_1_loss: 3.6677 - out_2_loss: 3.6666 - out_1_acc: 0.2279 - out_2_acc: 0.2123WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112685). Check your callbacks.\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 4.3860 - out_1_loss: 2.4878 - out_2_loss: 1.8982 - out_1_acc: 0.7026 - out_2_acc: 0.7826 - val_loss: 1.2166 - val_out_1_loss: 0.8849 - val_out_2_loss: 0.3317 - val_out_1_acc: 0.8267 - val_out_2_acc: 0.9379\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.7756 - out_1_loss: 0.5683 - out_2_loss: 0.2073 - out_1_acc: 0.8989 - out_2_acc: 0.9510 - val_loss: 0.5081 - val_out_1_loss: 0.3562 - val_out_2_loss: 0.1519 - val_out_1_acc: 0.9289 - val_out_2_acc: 0.9494\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.3915 - out_1_loss: 0.2647 - out_2_loss: 0.1268 - out_1_acc: 0.9337 - out_2_acc: 0.9519 - val_loss: 0.3130 - val_out_1_loss: 0.1905 - val_out_2_loss: 0.1224 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2621 - out_1_loss: 0.1550 - out_2_loss: 0.1071 - out_1_acc: 0.9402 - out_2_acc: 0.9522 - val_loss: 0.2482 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1089 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9509\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.2241 - out_1_loss: 0.1261 - out_2_loss: 0.0980 - out_1_acc: 0.9405 - out_2_acc: 0.9524 - val_loss: 0.2294 - val_out_1_loss: 0.1278 - val_out_2_loss: 0.1016 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9506\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.2104 - out_1_loss: 0.1176 - out_2_loss: 0.0928 - out_1_acc: 0.9407 - out_2_acc: 0.9522 - val_loss: 0.2181 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9508\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2022 - out_1_loss: 0.1129 - out_2_loss: 0.0893 - out_1_acc: 0.9411 - out_2_acc: 0.9526 - val_loss: 0.2111 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1964 - out_1_loss: 0.1096 - out_2_loss: 0.0867 - out_1_acc: 0.9418 - out_2_acc: 0.9525 - val_loss: 0.2069 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.0909 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9513\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1923 - out_1_loss: 0.1072 - out_2_loss: 0.0851 - out_1_acc: 0.9423 - out_2_acc: 0.9525 - val_loss: 0.2048 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.0901 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9512\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1896 - out_1_loss: 0.1055 - out_2_loss: 0.0841 - out_1_acc: 0.9426 - out_2_acc: 0.9527 - val_loss: 0.2034 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1875 - out_1_loss: 0.1041 - out_2_loss: 0.0833 - out_1_acc: 0.9426 - out_2_acc: 0.9530 - val_loss: 0.2025 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1856 - out_1_loss: 0.1030 - out_2_loss: 0.0826 - out_1_acc: 0.9427 - out_2_acc: 0.9534 - val_loss: 0.2021 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.0890 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1839 - out_1_loss: 0.1021 - out_2_loss: 0.0818 - out_1_acc: 0.9431 - out_2_acc: 0.9537 - val_loss: 0.2018 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.0892 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9525\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1825 - out_1_loss: 0.1013 - out_2_loss: 0.0811 - out_1_acc: 0.9433 - out_2_acc: 0.9542 - val_loss: 0.2016 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.0894 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1811 - out_1_loss: 0.1006 - out_2_loss: 0.0805 - out_1_acc: 0.9437 - out_2_acc: 0.9545 - val_loss: 0.2011 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0895 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9526\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1796 - out_1_loss: 0.0998 - out_2_loss: 0.0798 - out_1_acc: 0.9440 - out_2_acc: 0.9548 - val_loss: 0.2010 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0898 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9529\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1782 - out_1_loss: 0.0992 - out_2_loss: 0.0790 - out_1_acc: 0.9440 - out_2_acc: 0.9553 - val_loss: 0.2010 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0900 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9526\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1766 - out_1_loss: 0.0986 - out_2_loss: 0.0780 - out_1_acc: 0.9444 - out_2_acc: 0.9556 - val_loss: 0.2012 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0902 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9530\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1751 - out_1_loss: 0.0980 - out_2_loss: 0.0771 - out_1_acc: 0.9448 - out_2_acc: 0.9561 - val_loss: 0.2014 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0905 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1734 - out_1_loss: 0.0974 - out_2_loss: 0.0760 - out_1_acc: 0.9450 - out_2_acc: 0.9565 - val_loss: 0.2018 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9530\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1717 - out_1_loss: 0.0969 - out_2_loss: 0.0748 - out_1_acc: 0.9453 - out_2_acc: 0.9572 - val_loss: 0.2025 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1701 - out_1_loss: 0.0963 - out_2_loss: 0.0738 - out_1_acc: 0.9456 - out_2_acc: 0.9573 - val_loss: 0.2031 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0917 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9530\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1683 - out_1_loss: 0.0958 - out_2_loss: 0.0725 - out_1_acc: 0.9461 - out_2_acc: 0.9578 - val_loss: 0.2042 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1666 - out_1_loss: 0.0953 - out_2_loss: 0.0713 - out_1_acc: 0.9463 - out_2_acc: 0.9585 - val_loss: 0.2053 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.0930 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1645 - out_1_loss: 0.0947 - out_2_loss: 0.0698 - out_1_acc: 0.9467 - out_2_acc: 0.9592 - val_loss: 0.2068 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1625 - out_1_loss: 0.0941 - out_2_loss: 0.0685 - out_1_acc: 0.9468 - out_2_acc: 0.9600 - val_loss: 0.2087 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1605 - out_1_loss: 0.0935 - out_2_loss: 0.0670 - out_1_acc: 0.9472 - out_2_acc: 0.9608 - val_loss: 0.2107 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.0966 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1584 - out_1_loss: 0.0929 - out_2_loss: 0.0655 - out_1_acc: 0.9474 - out_2_acc: 0.9613 - val_loss: 0.2126 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1561 - out_1_loss: 0.0922 - out_2_loss: 0.0639 - out_1_acc: 0.9477 - out_2_acc: 0.9625 - val_loss: 0.2147 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.0995 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1540 - out_1_loss: 0.0915 - out_2_loss: 0.0625 - out_1_acc: 0.9482 - out_2_acc: 0.9628 - val_loss: 0.2179 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1020 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9525\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1519 - out_1_loss: 0.0909 - out_2_loss: 0.0610 - out_1_acc: 0.9484 - out_2_acc: 0.9633 - val_loss: 0.2203 - val_out_1_loss: 0.1167 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9527\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1495 - out_1_loss: 0.0901 - out_2_loss: 0.0594 - out_1_acc: 0.9489 - out_2_acc: 0.9640 - val_loss: 0.2240 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1477 - out_1_loss: 0.0895 - out_2_loss: 0.0582 - out_1_acc: 0.9495 - out_2_acc: 0.9645 - val_loss: 0.2276 - val_out_1_loss: 0.1177 - val_out_2_loss: 0.1099 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9525\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1462 - out_1_loss: 0.0889 - out_2_loss: 0.0574 - out_1_acc: 0.9501 - out_2_acc: 0.9649 - val_loss: 0.2328 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1153 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1456 - out_1_loss: 0.0882 - out_2_loss: 0.0574 - out_1_acc: 0.9505 - out_2_acc: 0.9648 - val_loss: 0.2353 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1177 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1458 - out_1_loss: 0.0875 - out_2_loss: 0.0582 - out_1_acc: 0.9508 - out_2_acc: 0.9646 - val_loss: 0.2326 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1150 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9529\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1445 - out_1_loss: 0.0868 - out_2_loss: 0.0577 - out_1_acc: 0.9510 - out_2_acc: 0.9649 - val_loss: 0.2337 - val_out_1_loss: 0.1186 - val_out_2_loss: 0.1151 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1412 - out_1_loss: 0.0855 - out_2_loss: 0.0558 - out_1_acc: 0.9517 - out_2_acc: 0.9658 - val_loss: 0.2401 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.1213 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9527\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1393 - out_1_loss: 0.0842 - out_2_loss: 0.0551 - out_1_acc: 0.9521 - out_2_acc: 0.9658 - val_loss: 0.2386 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1184 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1371 - out_1_loss: 0.0835 - out_2_loss: 0.0537 - out_1_acc: 0.9524 - out_2_acc: 0.9662 - val_loss: 0.2403 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.1194 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1349 - out_1_loss: 0.0821 - out_2_loss: 0.0528 - out_1_acc: 0.9530 - out_2_acc: 0.9670 - val_loss: 0.2392 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1181 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9531\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1328 - out_1_loss: 0.0808 - out_2_loss: 0.0520 - out_1_acc: 0.9542 - out_2_acc: 0.9670 - val_loss: 0.2405 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.1187 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9527\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1313 - out_1_loss: 0.0797 - out_2_loss: 0.0516 - out_1_acc: 0.9547 - out_2_acc: 0.9668 - val_loss: 0.2453 - val_out_1_loss: 0.1228 - val_out_2_loss: 0.1225 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1297 - out_1_loss: 0.0786 - out_2_loss: 0.0512 - out_1_acc: 0.9550 - out_2_acc: 0.9673 - val_loss: 0.2491 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1283 - out_1_loss: 0.0777 - out_2_loss: 0.0506 - out_1_acc: 0.9554 - out_2_acc: 0.9676 - val_loss: 0.2506 - val_out_1_loss: 0.1251 - val_out_2_loss: 0.1255 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9533\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1273 - out_1_loss: 0.0766 - out_2_loss: 0.0507 - out_1_acc: 0.9562 - out_2_acc: 0.9677 - val_loss: 0.2522 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.1255 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9538\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1259 - out_1_loss: 0.0758 - out_2_loss: 0.0501 - out_1_acc: 0.9573 - out_2_acc: 0.9685 - val_loss: 0.2533 - val_out_1_loss: 0.1277 - val_out_2_loss: 0.1256 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9544\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1250 - out_1_loss: 0.0748 - out_2_loss: 0.0501 - out_1_acc: 0.9573 - out_2_acc: 0.9679 - val_loss: 0.2561 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1268 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9537\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1237 - out_1_loss: 0.0738 - out_2_loss: 0.0499 - out_1_acc: 0.9577 - out_2_acc: 0.9686 - val_loss: 0.2557 - val_out_1_loss: 0.1284 - val_out_2_loss: 0.1273 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9540\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1223 - out_1_loss: 0.0727 - out_2_loss: 0.0496 - out_1_acc: 0.9584 - out_2_acc: 0.9688 - val_loss: 0.2610 - val_out_1_loss: 0.1320 - val_out_2_loss: 0.1290 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9532\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1218 - out_1_loss: 0.0722 - out_2_loss: 0.0496 - out_1_acc: 0.9586 - out_2_acc: 0.9687 - val_loss: 0.2604 - val_out_1_loss: 0.1311 - val_out_2_loss: 0.1292 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9539\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1199 - out_1_loss: 0.0709 - out_2_loss: 0.0491 - out_1_acc: 0.9595 - out_2_acc: 0.9691 - val_loss: 0.2644 - val_out_1_loss: 0.1333 - val_out_2_loss: 0.1311 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1196 - out_1_loss: 0.0704 - out_2_loss: 0.0492 - out_1_acc: 0.9595 - out_2_acc: 0.9693 - val_loss: 0.2669 - val_out_1_loss: 0.1351 - val_out_2_loss: 0.1319 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9539\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1185 - out_1_loss: 0.0695 - out_2_loss: 0.0490 - out_1_acc: 0.9601 - out_2_acc: 0.9695 - val_loss: 0.2683 - val_out_1_loss: 0.1369 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9533\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1176 - out_1_loss: 0.0689 - out_2_loss: 0.0487 - out_1_acc: 0.9607 - out_2_acc: 0.9699 - val_loss: 0.2686 - val_out_1_loss: 0.1370 - val_out_2_loss: 0.1317 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9530\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1162 - out_1_loss: 0.0677 - out_2_loss: 0.0485 - out_1_acc: 0.9615 - out_2_acc: 0.9704 - val_loss: 0.2690 - val_out_1_loss: 0.1374 - val_out_2_loss: 0.1316 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9535\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1150 - out_1_loss: 0.0670 - out_2_loss: 0.0479 - out_1_acc: 0.9617 - out_2_acc: 0.9710 - val_loss: 0.2713 - val_out_1_loss: 0.1391 - val_out_2_loss: 0.1322 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1140 - out_1_loss: 0.0663 - out_2_loss: 0.0478 - out_1_acc: 0.9625 - out_2_acc: 0.9712 - val_loss: 0.2737 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1344 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9531\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1139 - out_1_loss: 0.0661 - out_2_loss: 0.0478 - out_1_acc: 0.9623 - out_2_acc: 0.9708 - val_loss: 0.2748 - val_out_1_loss: 0.1413 - val_out_2_loss: 0.1335 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9527\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1134 - out_1_loss: 0.0656 - out_2_loss: 0.0478 - out_1_acc: 0.9626 - out_2_acc: 0.9711 - val_loss: 0.2775 - val_out_1_loss: 0.1432 - val_out_2_loss: 0.1343 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1128 - out_1_loss: 0.0652 - out_2_loss: 0.0476 - out_1_acc: 0.9628 - out_2_acc: 0.9712 - val_loss: 0.2818 - val_out_1_loss: 0.1447 - val_out_2_loss: 0.1371 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9526\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1122 - out_1_loss: 0.0646 - out_2_loss: 0.0476 - out_1_acc: 0.9635 - out_2_acc: 0.9716 - val_loss: 0.2816 - val_out_1_loss: 0.1456 - val_out_2_loss: 0.1359 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9537\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1106 - out_1_loss: 0.0643 - out_2_loss: 0.0463 - out_1_acc: 0.9634 - out_2_acc: 0.9725 - val_loss: 0.2870 - val_out_1_loss: 0.1484 - val_out_2_loss: 0.1385 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9531\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1105 - out_1_loss: 0.0640 - out_2_loss: 0.0466 - out_1_acc: 0.9638 - out_2_acc: 0.9726 - val_loss: 0.2882 - val_out_1_loss: 0.1488 - val_out_2_loss: 0.1393 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1102 - out_1_loss: 0.0637 - out_2_loss: 0.0465 - out_1_acc: 0.9641 - out_2_acc: 0.9727 - val_loss: 0.2892 - val_out_1_loss: 0.1507 - val_out_2_loss: 0.1386 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9529\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1085 - out_1_loss: 0.0625 - out_2_loss: 0.0460 - out_1_acc: 0.9651 - out_2_acc: 0.9729 - val_loss: 0.2912 - val_out_1_loss: 0.1513 - val_out_2_loss: 0.1399 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1071 - out_1_loss: 0.0614 - out_2_loss: 0.0457 - out_1_acc: 0.9658 - out_2_acc: 0.9731 - val_loss: 0.2951 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1413 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1069 - out_1_loss: 0.0613 - out_2_loss: 0.0457 - out_1_acc: 0.9657 - out_2_acc: 0.9730 - val_loss: 0.2924 - val_out_1_loss: 0.1528 - val_out_2_loss: 0.1396 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9527\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1054 - out_1_loss: 0.0606 - out_2_loss: 0.0449 - out_1_acc: 0.9661 - out_2_acc: 0.9742 - val_loss: 0.2940 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1411 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9531\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1050 - out_1_loss: 0.0604 - out_2_loss: 0.0445 - out_1_acc: 0.9661 - out_2_acc: 0.9744 - val_loss: 0.2968 - val_out_1_loss: 0.1552 - val_out_2_loss: 0.1416 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9532\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1038 - out_1_loss: 0.0597 - out_2_loss: 0.0442 - out_1_acc: 0.9667 - out_2_acc: 0.9747 - val_loss: 0.2964 - val_out_1_loss: 0.1545 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9527\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1031 - out_1_loss: 0.0590 - out_2_loss: 0.0441 - out_1_acc: 0.9672 - out_2_acc: 0.9749 - val_loss: 0.2995 - val_out_1_loss: 0.1565 - val_out_2_loss: 0.1430 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9537\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1026 - out_1_loss: 0.0592 - out_2_loss: 0.0434 - out_1_acc: 0.9669 - out_2_acc: 0.9755 - val_loss: 0.3028 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1446 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9541\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1018 - out_1_loss: 0.0585 - out_2_loss: 0.0433 - out_1_acc: 0.9677 - out_2_acc: 0.9756 - val_loss: 0.3024 - val_out_1_loss: 0.1567 - val_out_2_loss: 0.1457 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1007 - out_1_loss: 0.0577 - out_2_loss: 0.0430 - out_1_acc: 0.9680 - out_2_acc: 0.9757 - val_loss: 0.3038 - val_out_1_loss: 0.1598 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0991 - out_1_loss: 0.0573 - out_2_loss: 0.0418 - out_1_acc: 0.9683 - out_2_acc: 0.9767 - val_loss: 0.3049 - val_out_1_loss: 0.1589 - val_out_2_loss: 0.1461 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9528\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0973 - out_1_loss: 0.0565 - out_2_loss: 0.0408 - out_1_acc: 0.9690 - out_2_acc: 0.9776 - val_loss: 0.3076 - val_out_1_loss: 0.1598 - val_out_2_loss: 0.1478 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9525\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0959 - out_1_loss: 0.0556 - out_2_loss: 0.0402 - out_1_acc: 0.9699 - out_2_acc: 0.9776 - val_loss: 0.3088 - val_out_1_loss: 0.1608 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9526\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0951 - out_1_loss: 0.0551 - out_2_loss: 0.0400 - out_1_acc: 0.9703 - out_2_acc: 0.9785 - val_loss: 0.3144 - val_out_1_loss: 0.1641 - val_out_2_loss: 0.1503 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9530\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0953 - out_1_loss: 0.0551 - out_2_loss: 0.0402 - out_1_acc: 0.9704 - out_2_acc: 0.9780 - val_loss: 0.3178 - val_out_1_loss: 0.1646 - val_out_2_loss: 0.1533 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9522\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0957 - out_1_loss: 0.0554 - out_2_loss: 0.0403 - out_1_acc: 0.9703 - out_2_acc: 0.9783 - val_loss: 0.3153 - val_out_1_loss: 0.1641 - val_out_2_loss: 0.1512 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0940 - out_1_loss: 0.0544 - out_2_loss: 0.0395 - out_1_acc: 0.9710 - out_2_acc: 0.9788 - val_loss: 0.3203 - val_out_1_loss: 0.1676 - val_out_2_loss: 0.1528 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9529\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0936 - out_1_loss: 0.0541 - out_2_loss: 0.0395 - out_1_acc: 0.9714 - out_2_acc: 0.9788 - val_loss: 0.3193 - val_out_1_loss: 0.1667 - val_out_2_loss: 0.1526 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0933 - out_1_loss: 0.0541 - out_2_loss: 0.0392 - out_1_acc: 0.9716 - out_2_acc: 0.9792 - val_loss: 0.3201 - val_out_1_loss: 0.1682 - val_out_2_loss: 0.1519 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9528\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0948 - out_1_loss: 0.0549 - out_2_loss: 0.0398 - out_1_acc: 0.9709 - out_2_acc: 0.9787 - val_loss: 0.3208 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9529\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0930 - out_1_loss: 0.0546 - out_2_loss: 0.0383 - out_1_acc: 0.9711 - out_2_acc: 0.9798 - val_loss: 0.3271 - val_out_1_loss: 0.1721 - val_out_2_loss: 0.1550 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9516\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0943 - out_1_loss: 0.0556 - out_2_loss: 0.0386 - out_1_acc: 0.9706 - out_2_acc: 0.9797 - val_loss: 0.3271 - val_out_1_loss: 0.1713 - val_out_2_loss: 0.1557 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0911 - out_1_loss: 0.0534 - out_2_loss: 0.0377 - out_1_acc: 0.9729 - out_2_acc: 0.9798 - val_loss: 0.3272 - val_out_1_loss: 0.1698 - val_out_2_loss: 0.1574 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0897 - out_1_loss: 0.0527 - out_2_loss: 0.0370 - out_1_acc: 0.9731 - out_2_acc: 0.9804 - val_loss: 0.3348 - val_out_1_loss: 0.1723 - val_out_2_loss: 0.1625 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0901 - out_1_loss: 0.0525 - out_2_loss: 0.0376 - out_1_acc: 0.9728 - out_2_acc: 0.9805 - val_loss: 0.3339 - val_out_1_loss: 0.1712 - val_out_2_loss: 0.1626 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0881 - out_1_loss: 0.0509 - out_2_loss: 0.0372 - out_1_acc: 0.9740 - out_2_acc: 0.9808 - val_loss: 0.3376 - val_out_1_loss: 0.1745 - val_out_2_loss: 0.1631 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0846 - out_1_loss: 0.0497 - out_2_loss: 0.0349 - out_1_acc: 0.9747 - out_2_acc: 0.9823 - val_loss: 0.3393 - val_out_1_loss: 0.1765 - val_out_2_loss: 0.1629 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9525\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0842 - out_1_loss: 0.0495 - out_2_loss: 0.0347 - out_1_acc: 0.9752 - out_2_acc: 0.9824 - val_loss: 0.3417 - val_out_1_loss: 0.1754 - val_out_2_loss: 0.1662 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9526\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0831 - out_1_loss: 0.0492 - out_2_loss: 0.0339 - out_1_acc: 0.9752 - out_2_acc: 0.9829 - val_loss: 0.3507 - val_out_1_loss: 0.1808 - val_out_2_loss: 0.1700 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9511\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0831 - out_1_loss: 0.0496 - out_2_loss: 0.0335 - out_1_acc: 0.9750 - out_2_acc: 0.9836 - val_loss: 0.3598 - val_out_1_loss: 0.1849 - val_out_2_loss: 0.1749 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0817 - out_1_loss: 0.0487 - out_2_loss: 0.0330 - out_1_acc: 0.9759 - out_2_acc: 0.9837 - val_loss: 0.3679 - val_out_1_loss: 0.1874 - val_out_2_loss: 0.1805 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9516\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0810 - out_1_loss: 0.0485 - out_2_loss: 0.0324 - out_1_acc: 0.9761 - out_2_acc: 0.9838 - val_loss: 0.3620 - val_out_1_loss: 0.1871 - val_out_2_loss: 0.1749 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0814 - out_1_loss: 0.0485 - out_2_loss: 0.0329 - out_1_acc: 0.9761 - out_2_acc: 0.9835 - val_loss: 0.3561 - val_out_1_loss: 0.1834 - val_out_2_loss: 0.1728 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9526\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0795 - out_1_loss: 0.0477 - out_2_loss: 0.0318 - out_1_acc: 0.9763 - out_2_acc: 0.9843 - val_loss: 0.3646 - val_out_1_loss: 0.1866 - val_out_2_loss: 0.1779 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9531\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0784 - out_1_loss: 0.0473 - out_2_loss: 0.0311 - out_1_acc: 0.9766 - out_2_acc: 0.9850 - val_loss: 0.3644 - val_out_1_loss: 0.1870 - val_out_2_loss: 0.1774 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0760 - out_1_loss: 0.0467 - out_2_loss: 0.0293 - out_1_acc: 0.9772 - out_2_acc: 0.9859 - val_loss: 0.3670 - val_out_1_loss: 0.1880 - val_out_2_loss: 0.1790 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9517\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0757 - out_1_loss: 0.0458 - out_2_loss: 0.0299 - out_1_acc: 0.9776 - out_2_acc: 0.9859 - val_loss: 0.3733 - val_out_1_loss: 0.1906 - val_out_2_loss: 0.1827 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0769 - out_1_loss: 0.0458 - out_2_loss: 0.0311 - out_1_acc: 0.9776 - out_2_acc: 0.9850 - val_loss: 0.3729 - val_out_1_loss: 0.1932 - val_out_2_loss: 0.1797 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9518\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0780 - out_1_loss: 0.0462 - out_2_loss: 0.0318 - out_1_acc: 0.9776 - out_2_acc: 0.9845 - val_loss: 0.3785 - val_out_1_loss: 0.1934 - val_out_2_loss: 0.1851 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9526\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0756 - out_1_loss: 0.0451 - out_2_loss: 0.0305 - out_1_acc: 0.9780 - out_2_acc: 0.9854 - val_loss: 0.3800 - val_out_1_loss: 0.1963 - val_out_2_loss: 0.1837 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0745 - out_1_loss: 0.0455 - out_2_loss: 0.0290 - out_1_acc: 0.9779 - out_2_acc: 0.9861 - val_loss: 0.3825 - val_out_1_loss: 0.1993 - val_out_2_loss: 0.1832 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0723 - out_1_loss: 0.0440 - out_2_loss: 0.0283 - out_1_acc: 0.9784 - out_2_acc: 0.9868 - val_loss: 0.3912 - val_out_1_loss: 0.2001 - val_out_2_loss: 0.1911 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9519\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0729 - out_1_loss: 0.0451 - out_2_loss: 0.0278 - out_1_acc: 0.9783 - out_2_acc: 0.9871 - val_loss: 0.3954 - val_out_1_loss: 0.2032 - val_out_2_loss: 0.1921 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0712 - out_1_loss: 0.0447 - out_2_loss: 0.0266 - out_1_acc: 0.9783 - out_2_acc: 0.9881 - val_loss: 0.3939 - val_out_1_loss: 0.2012 - val_out_2_loss: 0.1927 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0694 - out_1_loss: 0.0437 - out_2_loss: 0.0256 - out_1_acc: 0.9792 - out_2_acc: 0.9882 - val_loss: 0.4037 - val_out_1_loss: 0.2055 - val_out_2_loss: 0.1983 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0698 - out_1_loss: 0.0442 - out_2_loss: 0.0256 - out_1_acc: 0.9793 - out_2_acc: 0.9883 - val_loss: 0.3989 - val_out_1_loss: 0.2040 - val_out_2_loss: 0.1949 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0706 - out_1_loss: 0.0456 - out_2_loss: 0.0250 - out_1_acc: 0.9785 - out_2_acc: 0.9889 - val_loss: 0.3949 - val_out_1_loss: 0.2034 - val_out_2_loss: 0.1915 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9536\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0735 - out_1_loss: 0.0490 - out_2_loss: 0.0245 - out_1_acc: 0.9769 - out_2_acc: 0.9891 - val_loss: 0.3953 - val_out_1_loss: 0.1982 - val_out_2_loss: 0.1971 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9516\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0772 - out_1_loss: 0.0525 - out_2_loss: 0.0247 - out_1_acc: 0.9762 - out_2_acc: 0.9890 - val_loss: 0.3982 - val_out_1_loss: 0.1963 - val_out_2_loss: 0.2019 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9517\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0725 - out_1_loss: 0.0472 - out_2_loss: 0.0253 - out_1_acc: 0.9775 - out_2_acc: 0.9888 - val_loss: 0.3991 - val_out_1_loss: 0.1981 - val_out_2_loss: 0.2011 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9535\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0674 - out_1_loss: 0.0436 - out_2_loss: 0.0238 - out_1_acc: 0.9793 - out_2_acc: 0.9896 - val_loss: 0.4110 - val_out_1_loss: 0.2031 - val_out_2_loss: 0.2079 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9531\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0649 - out_1_loss: 0.0411 - out_2_loss: 0.0238 - out_1_acc: 0.9807 - out_2_acc: 0.9896 - val_loss: 0.4132 - val_out_1_loss: 0.2055 - val_out_2_loss: 0.2076 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9538\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0650 - out_1_loss: 0.0409 - out_2_loss: 0.0241 - out_1_acc: 0.9811 - out_2_acc: 0.9895 - val_loss: 0.4059 - val_out_1_loss: 0.2018 - val_out_2_loss: 0.2040 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9534\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0635 - out_1_loss: 0.0393 - out_2_loss: 0.0242 - out_1_acc: 0.9816 - out_2_acc: 0.9892 - val_loss: 0.4261 - val_out_1_loss: 0.2109 - val_out_2_loss: 0.2152 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0655 - out_1_loss: 0.0396 - out_2_loss: 0.0259 - out_1_acc: 0.9816 - out_2_acc: 0.9884 - val_loss: 0.4156 - val_out_1_loss: 0.2101 - val_out_2_loss: 0.2054 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0600 - out_1_loss: 0.0378 - out_2_loss: 0.0222 - out_1_acc: 0.9831 - out_2_acc: 0.9902 - val_loss: 0.4217 - val_out_1_loss: 0.2086 - val_out_2_loss: 0.2131 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0605 - out_1_loss: 0.0374 - out_2_loss: 0.0231 - out_1_acc: 0.9834 - out_2_acc: 0.9901 - val_loss: 0.4170 - val_out_1_loss: 0.2103 - val_out_2_loss: 0.2067 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9540\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0582 - out_1_loss: 0.0361 - out_2_loss: 0.0221 - out_1_acc: 0.9839 - out_2_acc: 0.9902 - val_loss: 0.4142 - val_out_1_loss: 0.2079 - val_out_2_loss: 0.2063 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9538\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0543 - out_1_loss: 0.0351 - out_2_loss: 0.0192 - out_1_acc: 0.9843 - out_2_acc: 0.9918 - val_loss: 0.4240 - val_out_1_loss: 0.2113 - val_out_2_loss: 0.2127 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9527\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0521 - out_1_loss: 0.0339 - out_2_loss: 0.0182 - out_1_acc: 0.9851 - out_2_acc: 0.9923 - val_loss: 0.4272 - val_out_1_loss: 0.2131 - val_out_2_loss: 0.2141 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0489 - out_1_loss: 0.0330 - out_2_loss: 0.0158 - out_1_acc: 0.9855 - out_2_acc: 0.9935 - val_loss: 0.4334 - val_out_1_loss: 0.2159 - val_out_2_loss: 0.2175 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0467 - out_1_loss: 0.0319 - out_2_loss: 0.0148 - out_1_acc: 0.9861 - out_2_acc: 0.9941 - val_loss: 0.4399 - val_out_1_loss: 0.2162 - val_out_2_loss: 0.2237 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9532\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0424 - out_1_loss: 0.0287 - out_2_loss: 0.0137 - out_1_acc: 0.9882 - out_2_acc: 0.9945 - val_loss: 0.4522 - val_out_1_loss: 0.2208 - val_out_2_loss: 0.2314 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9526\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0410 - out_1_loss: 0.0277 - out_2_loss: 0.0133 - out_1_acc: 0.9885 - out_2_acc: 0.9946 - val_loss: 0.4557 - val_out_1_loss: 0.2215 - val_out_2_loss: 0.2342 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9521\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0379 - out_1_loss: 0.0270 - out_2_loss: 0.0109 - out_1_acc: 0.9883 - out_2_acc: 0.9959 - val_loss: 0.4684 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2436 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9519\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0355 - out_1_loss: 0.0254 - out_2_loss: 0.0101 - out_1_acc: 0.9897 - out_2_acc: 0.9963 - val_loss: 0.4672 - val_out_1_loss: 0.2256 - val_out_2_loss: 0.2416 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0333 - out_1_loss: 0.0246 - out_2_loss: 0.0087 - out_1_acc: 0.9897 - out_2_acc: 0.9967 - val_loss: 0.4810 - val_out_1_loss: 0.2298 - val_out_2_loss: 0.2511 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9525\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0317 - out_1_loss: 0.0227 - out_2_loss: 0.0090 - out_1_acc: 0.9912 - out_2_acc: 0.9966 - val_loss: 0.4893 - val_out_1_loss: 0.2286 - val_out_2_loss: 0.2608 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9524\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.0308 - out_1_loss: 0.0212 - out_2_loss: 0.0096 - out_1_acc: 0.9922 - out_2_acc: 0.9963 - val_loss: 0.4840 - val_out_1_loss: 0.2321 - val_out_2_loss: 0.2519 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9529\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0301 - out_1_loss: 0.0214 - out_2_loss: 0.0087 - out_1_acc: 0.9919 - out_2_acc: 0.9969 - val_loss: 0.4882 - val_out_1_loss: 0.2323 - val_out_2_loss: 0.2559 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9524\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0280 - out_1_loss: 0.0202 - out_2_loss: 0.0079 - out_1_acc: 0.9923 - out_2_acc: 0.9969 - val_loss: 0.4946 - val_out_1_loss: 0.2380 - val_out_2_loss: 0.2566 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0277 - out_1_loss: 0.0197 - out_2_loss: 0.0079 - out_1_acc: 0.9928 - out_2_acc: 0.9971 - val_loss: 0.5016 - val_out_1_loss: 0.2406 - val_out_2_loss: 0.2610 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9521\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0274 - out_1_loss: 0.0194 - out_2_loss: 0.0080 - out_1_acc: 0.9929 - out_2_acc: 0.9970 - val_loss: 0.5166 - val_out_1_loss: 0.2517 - val_out_2_loss: 0.2649 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9527\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0276 - out_1_loss: 0.0191 - out_2_loss: 0.0084 - out_1_acc: 0.9930 - out_2_acc: 0.9968 - val_loss: 0.5135 - val_out_1_loss: 0.2493 - val_out_2_loss: 0.2642 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9532\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0259 - out_1_loss: 0.0187 - out_2_loss: 0.0072 - out_1_acc: 0.9931 - out_2_acc: 0.9972 - val_loss: 0.5268 - val_out_1_loss: 0.2572 - val_out_2_loss: 0.2696 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0267 - out_1_loss: 0.0200 - out_2_loss: 0.0067 - out_1_acc: 0.9924 - out_2_acc: 0.9976 - val_loss: 0.5307 - val_out_1_loss: 0.2567 - val_out_2_loss: 0.2740 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9517\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0259 - out_1_loss: 0.0194 - out_2_loss: 0.0065 - out_1_acc: 0.9927 - out_2_acc: 0.9976 - val_loss: 0.5310 - val_out_1_loss: 0.2586 - val_out_2_loss: 0.2724 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0241 - out_1_loss: 0.0178 - out_2_loss: 0.0064 - out_1_acc: 0.9932 - out_2_acc: 0.9977 - val_loss: 0.5383 - val_out_1_loss: 0.2633 - val_out_2_loss: 0.2750 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0249 - out_1_loss: 0.0186 - out_2_loss: 0.0063 - out_1_acc: 0.9926 - out_2_acc: 0.9977 - val_loss: 0.5468 - val_out_1_loss: 0.2685 - val_out_2_loss: 0.2783 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0254 - out_1_loss: 0.0200 - out_2_loss: 0.0054 - out_1_acc: 0.9921 - out_2_acc: 0.9980 - val_loss: 0.5517 - val_out_1_loss: 0.2674 - val_out_2_loss: 0.2844 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0262 - out_1_loss: 0.0205 - out_2_loss: 0.0057 - out_1_acc: 0.9922 - out_2_acc: 0.9979 - val_loss: 0.5401 - val_out_1_loss: 0.2634 - val_out_2_loss: 0.2767 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9529\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0264 - out_1_loss: 0.0199 - out_2_loss: 0.0066 - out_1_acc: 0.9925 - out_2_acc: 0.9975 - val_loss: 0.5446 - val_out_1_loss: 0.2677 - val_out_2_loss: 0.2769 - val_out_1_acc: 0.9429 - val_out_2_acc: 0.9531\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0259 - out_1_loss: 0.0196 - out_2_loss: 0.0062 - out_1_acc: 0.9924 - out_2_acc: 0.9977 - val_loss: 0.5536 - val_out_1_loss: 0.2737 - val_out_2_loss: 0.2798 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9542\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0238 - out_1_loss: 0.0182 - out_2_loss: 0.0056 - out_1_acc: 0.9930 - out_2_acc: 0.9980 - val_loss: 0.5462 - val_out_1_loss: 0.2699 - val_out_2_loss: 0.2763 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9531\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0220 - out_1_loss: 0.0161 - out_2_loss: 0.0058 - out_1_acc: 0.9940 - out_2_acc: 0.9980 - val_loss: 0.5621 - val_out_1_loss: 0.2749 - val_out_2_loss: 0.2872 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9518\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0207 - out_1_loss: 0.0152 - out_2_loss: 0.0056 - out_1_acc: 0.9945 - out_2_acc: 0.9980 - val_loss: 0.5629 - val_out_1_loss: 0.2776 - val_out_2_loss: 0.2853 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0182 - out_1_loss: 0.0140 - out_2_loss: 0.0042 - out_1_acc: 0.9949 - out_2_acc: 0.9986 - val_loss: 0.5714 - val_out_1_loss: 0.2801 - val_out_2_loss: 0.2913 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0166 - out_1_loss: 0.0133 - out_2_loss: 0.0033 - out_1_acc: 0.9953 - out_2_acc: 0.9989 - val_loss: 0.5791 - val_out_1_loss: 0.2819 - val_out_2_loss: 0.2972 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9514\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0152 - out_1_loss: 0.0126 - out_2_loss: 0.0026 - out_1_acc: 0.9956 - out_2_acc: 0.9992 - val_loss: 0.5918 - val_out_1_loss: 0.2910 - val_out_2_loss: 0.3008 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0152 - out_1_loss: 0.0123 - out_2_loss: 0.0029 - out_1_acc: 0.9957 - out_2_acc: 0.9990 - val_loss: 0.5911 - val_out_1_loss: 0.2894 - val_out_2_loss: 0.3017 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0157 - out_1_loss: 0.0118 - out_2_loss: 0.0039 - out_1_acc: 0.9959 - out_2_acc: 0.9986 - val_loss: 0.5987 - val_out_1_loss: 0.2980 - val_out_2_loss: 0.3006 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0161 - out_1_loss: 0.0122 - out_2_loss: 0.0040 - out_1_acc: 0.9957 - out_2_acc: 0.9985 - val_loss: 0.6000 - val_out_1_loss: 0.2964 - val_out_2_loss: 0.3036 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0155 - out_1_loss: 0.0118 - out_2_loss: 0.0037 - out_1_acc: 0.9959 - out_2_acc: 0.9987 - val_loss: 0.5933 - val_out_1_loss: 0.2944 - val_out_2_loss: 0.2989 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9523\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0152 - out_1_loss: 0.0112 - out_2_loss: 0.0040 - out_1_acc: 0.9961 - out_2_acc: 0.9987 - val_loss: 0.6060 - val_out_1_loss: 0.3044 - val_out_2_loss: 0.3015 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9523\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.0134 - out_1_loss: 0.0110 - out_2_loss: 0.0024 - out_1_acc: 0.9965 - out_2_acc: 0.9992 - val_loss: 0.6146 - val_out_1_loss: 0.3067 - val_out_2_loss: 0.3080 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0133 - out_1_loss: 0.0107 - out_2_loss: 0.0027 - out_1_acc: 0.9965 - out_2_acc: 0.9992 - val_loss: 0.6316 - val_out_1_loss: 0.3175 - val_out_2_loss: 0.3141 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0136 - out_1_loss: 0.0108 - out_2_loss: 0.0028 - out_1_acc: 0.9961 - out_2_acc: 0.9991 - val_loss: 0.6288 - val_out_1_loss: 0.3114 - val_out_2_loss: 0.3174 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9519\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0134 - out_1_loss: 0.0102 - out_2_loss: 0.0032 - out_1_acc: 0.9964 - out_2_acc: 0.9989 - val_loss: 0.6288 - val_out_1_loss: 0.3101 - val_out_2_loss: 0.3186 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9527\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0158 - out_1_loss: 0.0115 - out_2_loss: 0.0044 - out_1_acc: 0.9960 - out_2_acc: 0.9986 - val_loss: 0.6427 - val_out_1_loss: 0.3224 - val_out_2_loss: 0.3203 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0183 - out_1_loss: 0.0117 - out_2_loss: 0.0066 - out_1_acc: 0.9958 - out_2_acc: 0.9976 - val_loss: 0.6241 - val_out_1_loss: 0.3186 - val_out_2_loss: 0.3055 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0162 - out_1_loss: 0.0113 - out_2_loss: 0.0048 - out_1_acc: 0.9962 - out_2_acc: 0.9983 - val_loss: 0.6271 - val_out_1_loss: 0.3181 - val_out_2_loss: 0.3090 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9524\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0162 - out_1_loss: 0.0116 - out_2_loss: 0.0046 - out_1_acc: 0.9960 - out_2_acc: 0.9985 - val_loss: 0.6237 - val_out_1_loss: 0.3136 - val_out_2_loss: 0.3102 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0162 - out_1_loss: 0.0117 - out_2_loss: 0.0046 - out_1_acc: 0.9960 - out_2_acc: 0.9984 - val_loss: 0.6261 - val_out_1_loss: 0.3135 - val_out_2_loss: 0.3126 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9522\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0140 - out_1_loss: 0.0096 - out_2_loss: 0.0044 - out_1_acc: 0.9964 - out_2_acc: 0.9985 - val_loss: 0.6412 - val_out_1_loss: 0.3301 - val_out_2_loss: 0.3111 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9528\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0117 - out_1_loss: 0.0088 - out_2_loss: 0.0029 - out_1_acc: 0.9972 - out_2_acc: 0.9990 - val_loss: 0.6537 - val_out_1_loss: 0.3317 - val_out_2_loss: 0.3219 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9537\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0131 - out_1_loss: 0.0099 - out_2_loss: 0.0032 - out_1_acc: 0.9967 - out_2_acc: 0.9990 - val_loss: 0.6409 - val_out_1_loss: 0.3260 - val_out_2_loss: 0.3149 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0129 - out_1_loss: 0.0092 - out_2_loss: 0.0037 - out_1_acc: 0.9967 - out_2_acc: 0.9988 - val_loss: 0.6649 - val_out_1_loss: 0.3402 - val_out_2_loss: 0.3247 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0140 - out_1_loss: 0.0100 - out_2_loss: 0.0040 - out_1_acc: 0.9965 - out_2_acc: 0.9986 - val_loss: 0.6516 - val_out_1_loss: 0.3315 - val_out_2_loss: 0.3201 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0122 - out_1_loss: 0.0087 - out_2_loss: 0.0035 - out_1_acc: 0.9970 - out_2_acc: 0.9988 - val_loss: 0.6620 - val_out_1_loss: 0.3357 - val_out_2_loss: 0.3263 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9516\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0143 - out_1_loss: 0.0101 - out_2_loss: 0.0043 - out_1_acc: 0.9965 - out_2_acc: 0.9985 - val_loss: 0.6583 - val_out_1_loss: 0.3381 - val_out_2_loss: 0.3201 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0175 - out_1_loss: 0.0118 - out_2_loss: 0.0056 - out_1_acc: 0.9959 - out_2_acc: 0.9982 - val_loss: 0.6564 - val_out_1_loss: 0.3329 - val_out_2_loss: 0.3235 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9515\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0154 - out_1_loss: 0.0113 - out_2_loss: 0.0041 - out_1_acc: 0.9962 - out_2_acc: 0.9986 - val_loss: 0.6507 - val_out_1_loss: 0.3326 - val_out_2_loss: 0.3181 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0131 - out_1_loss: 0.0101 - out_2_loss: 0.0031 - out_1_acc: 0.9964 - out_2_acc: 0.9990 - val_loss: 0.6654 - val_out_1_loss: 0.3404 - val_out_2_loss: 0.3250 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0118 - out_1_loss: 0.0094 - out_2_loss: 0.0024 - out_1_acc: 0.9968 - out_2_acc: 0.9992 - val_loss: 0.6712 - val_out_1_loss: 0.3424 - val_out_2_loss: 0.3288 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0121 - out_1_loss: 0.0095 - out_2_loss: 0.0026 - out_1_acc: 0.9967 - out_2_acc: 0.9992 - val_loss: 0.6688 - val_out_1_loss: 0.3329 - val_out_2_loss: 0.3359 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9515\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(3)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6563 - out_1_loss: 0.3373 - out_2_loss: 0.3190 - out_1_acc: 0.9409 - out_2_acc: 0.9519\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 3, 60)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 3, 300), (No 433200      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 3, 300)       433200      input_9[0][0]                    \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,513,480\n",
      "Trainable params: 2,513,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3329 - out_1_loss: 3.6751 - out_2_loss: 3.6578 - out_1_acc: 0.1311 - out_2_acc: 0.2472WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.119653). Check your callbacks.\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 4.4098 - out_1_loss: 2.5362 - out_2_loss: 1.8737 - out_1_acc: 0.6552 - out_2_acc: 0.7633 - val_loss: 1.2383 - val_out_1_loss: 0.8982 - val_out_2_loss: 0.3401 - val_out_1_acc: 0.8179 - val_out_2_acc: 0.9383\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.7709 - out_1_loss: 0.5566 - out_2_loss: 0.2143 - out_1_acc: 0.8985 - out_2_acc: 0.9497 - val_loss: 0.4896 - val_out_1_loss: 0.3374 - val_out_2_loss: 0.1522 - val_out_1_acc: 0.9282 - val_out_2_acc: 0.9496\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.3748 - out_1_loss: 0.2488 - out_2_loss: 0.1261 - out_1_acc: 0.9353 - out_2_acc: 0.9523 - val_loss: 0.3021 - val_out_1_loss: 0.1801 - val_out_2_loss: 0.1220 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9509\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2558 - out_1_loss: 0.1496 - out_2_loss: 0.1061 - out_1_acc: 0.9396 - out_2_acc: 0.9528 - val_loss: 0.2479 - val_out_1_loss: 0.1408 - val_out_2_loss: 0.1071 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9512\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2228 - out_1_loss: 0.1262 - out_2_loss: 0.0966 - out_1_acc: 0.9399 - out_2_acc: 0.9526 - val_loss: 0.2309 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9373 - val_out_2_acc: 0.9507\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2097 - out_1_loss: 0.1184 - out_2_loss: 0.0913 - out_1_acc: 0.9402 - out_2_acc: 0.9527 - val_loss: 0.2224 - val_out_1_loss: 0.1255 - val_out_2_loss: 0.0969 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9505\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.2020 - out_1_loss: 0.1138 - out_2_loss: 0.0881 - out_1_acc: 0.9407 - out_2_acc: 0.9530 - val_loss: 0.2161 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.0943 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9502\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1964 - out_1_loss: 0.1104 - out_2_loss: 0.0859 - out_1_acc: 0.9409 - out_2_acc: 0.9530 - val_loss: 0.2116 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9503\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1924 - out_1_loss: 0.1079 - out_2_loss: 0.0845 - out_1_acc: 0.9413 - out_2_acc: 0.9533 - val_loss: 0.2083 - val_out_1_loss: 0.1165 - val_out_2_loss: 0.0917 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9504\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1893 - out_1_loss: 0.1059 - out_2_loss: 0.0834 - out_1_acc: 0.9416 - out_2_acc: 0.9534 - val_loss: 0.2060 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9507\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1869 - out_1_loss: 0.1044 - out_2_loss: 0.0826 - out_1_acc: 0.9420 - out_2_acc: 0.9538 - val_loss: 0.2044 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9379 - val_out_2_acc: 0.9507\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1849 - out_1_loss: 0.1031 - out_2_loss: 0.0817 - out_1_acc: 0.9422 - out_2_acc: 0.9540 - val_loss: 0.2033 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.0905 - val_out_1_acc: 0.9379 - val_out_2_acc: 0.9505\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1829 - out_1_loss: 0.1021 - out_2_loss: 0.0809 - out_1_acc: 0.9424 - out_2_acc: 0.9545 - val_loss: 0.2025 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.0902 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9515\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1812 - out_1_loss: 0.1012 - out_2_loss: 0.0801 - out_1_acc: 0.9426 - out_2_acc: 0.9548 - val_loss: 0.2023 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.0903 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9517\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1796 - out_1_loss: 0.1004 - out_2_loss: 0.0792 - out_1_acc: 0.9428 - out_2_acc: 0.9553 - val_loss: 0.2024 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0907 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1780 - out_1_loss: 0.0997 - out_2_loss: 0.0783 - out_1_acc: 0.9431 - out_2_acc: 0.9557 - val_loss: 0.2029 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9514\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1763 - out_1_loss: 0.0990 - out_2_loss: 0.0773 - out_1_acc: 0.9434 - out_2_acc: 0.9562 - val_loss: 0.2033 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9517\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1747 - out_1_loss: 0.0984 - out_2_loss: 0.0763 - out_1_acc: 0.9436 - out_2_acc: 0.9566 - val_loss: 0.2039 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9507\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1729 - out_1_loss: 0.0977 - out_2_loss: 0.0752 - out_1_acc: 0.9443 - out_2_acc: 0.9571 - val_loss: 0.2042 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0925 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9517\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1712 - out_1_loss: 0.0972 - out_2_loss: 0.0740 - out_1_acc: 0.9445 - out_2_acc: 0.9578 - val_loss: 0.2052 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.0934 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1694 - out_1_loss: 0.0966 - out_2_loss: 0.0728 - out_1_acc: 0.9448 - out_2_acc: 0.9583 - val_loss: 0.2056 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1676 - out_1_loss: 0.0960 - out_2_loss: 0.0716 - out_1_acc: 0.9449 - out_2_acc: 0.9586 - val_loss: 0.2065 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0945 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1656 - out_1_loss: 0.0954 - out_2_loss: 0.0703 - out_1_acc: 0.9453 - out_2_acc: 0.9595 - val_loss: 0.2074 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1638 - out_1_loss: 0.0947 - out_2_loss: 0.0691 - out_1_acc: 0.9457 - out_2_acc: 0.9598 - val_loss: 0.2086 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1619 - out_1_loss: 0.0941 - out_2_loss: 0.0678 - out_1_acc: 0.9463 - out_2_acc: 0.9606 - val_loss: 0.2106 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9518\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1598 - out_1_loss: 0.0935 - out_2_loss: 0.0663 - out_1_acc: 0.9466 - out_2_acc: 0.9611 - val_loss: 0.2113 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1574 - out_1_loss: 0.0928 - out_2_loss: 0.0647 - out_1_acc: 0.9473 - out_2_acc: 0.9618 - val_loss: 0.2129 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1553 - out_1_loss: 0.0920 - out_2_loss: 0.0634 - out_1_acc: 0.9474 - out_2_acc: 0.9622 - val_loss: 0.2144 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1531 - out_1_loss: 0.0912 - out_2_loss: 0.0619 - out_1_acc: 0.9478 - out_2_acc: 0.9632 - val_loss: 0.2165 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1028 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1511 - out_1_loss: 0.0906 - out_2_loss: 0.0605 - out_1_acc: 0.9482 - out_2_acc: 0.9637 - val_loss: 0.2199 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1048 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1492 - out_1_loss: 0.0899 - out_2_loss: 0.0593 - out_1_acc: 0.9485 - out_2_acc: 0.9641 - val_loss: 0.2216 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1061 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1475 - out_1_loss: 0.0891 - out_2_loss: 0.0584 - out_1_acc: 0.9490 - out_2_acc: 0.9648 - val_loss: 0.2245 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1084 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9523\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1458 - out_1_loss: 0.0883 - out_2_loss: 0.0574 - out_1_acc: 0.9495 - out_2_acc: 0.9649 - val_loss: 0.2266 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.1102 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9524\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1442 - out_1_loss: 0.0874 - out_2_loss: 0.0569 - out_1_acc: 0.9501 - out_2_acc: 0.9653 - val_loss: 0.2292 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1122 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9524\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1435 - out_1_loss: 0.0865 - out_2_loss: 0.0570 - out_1_acc: 0.9507 - out_2_acc: 0.9650 - val_loss: 0.2337 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1154 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9521\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1419 - out_1_loss: 0.0857 - out_2_loss: 0.0562 - out_1_acc: 0.9513 - out_2_acc: 0.9657 - val_loss: 0.2330 - val_out_1_loss: 0.1180 - val_out_2_loss: 0.1149 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9526\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1398 - out_1_loss: 0.0846 - out_2_loss: 0.0552 - out_1_acc: 0.9518 - out_2_acc: 0.9659 - val_loss: 0.2362 - val_out_1_loss: 0.1193 - val_out_2_loss: 0.1169 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1382 - out_1_loss: 0.0838 - out_2_loss: 0.0544 - out_1_acc: 0.9523 - out_2_acc: 0.9661 - val_loss: 0.2398 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.1197 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9529\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1370 - out_1_loss: 0.0829 - out_2_loss: 0.0541 - out_1_acc: 0.9527 - out_2_acc: 0.9662 - val_loss: 0.2393 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.1185 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9530\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1350 - out_1_loss: 0.0819 - out_2_loss: 0.0531 - out_1_acc: 0.9533 - out_2_acc: 0.9667 - val_loss: 0.2420 - val_out_1_loss: 0.1217 - val_out_2_loss: 0.1203 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9523\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1333 - out_1_loss: 0.0809 - out_2_loss: 0.0524 - out_1_acc: 0.9539 - out_2_acc: 0.9674 - val_loss: 0.2438 - val_out_1_loss: 0.1229 - val_out_2_loss: 0.1208 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9523\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1319 - out_1_loss: 0.0799 - out_2_loss: 0.0520 - out_1_acc: 0.9544 - out_2_acc: 0.9670 - val_loss: 0.2480 - val_out_1_loss: 0.1240 - val_out_2_loss: 0.1240 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1299 - out_1_loss: 0.0787 - out_2_loss: 0.0512 - out_1_acc: 0.9550 - out_2_acc: 0.9671 - val_loss: 0.2506 - val_out_1_loss: 0.1249 - val_out_2_loss: 0.1257 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9525\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1286 - out_1_loss: 0.0777 - out_2_loss: 0.0509 - out_1_acc: 0.9557 - out_2_acc: 0.9676 - val_loss: 0.2517 - val_out_1_loss: 0.1262 - val_out_2_loss: 0.1255 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 45/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1275 - out_1_loss: 0.0768 - out_2_loss: 0.0506 - out_1_acc: 0.9562 - out_2_acc: 0.9676 - val_loss: 0.2514 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1242 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9525\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1260 - out_1_loss: 0.0758 - out_2_loss: 0.0502 - out_1_acc: 0.9567 - out_2_acc: 0.9678 - val_loss: 0.2544 - val_out_1_loss: 0.1286 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9526\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1253 - out_1_loss: 0.0752 - out_2_loss: 0.0502 - out_1_acc: 0.9571 - out_2_acc: 0.9680 - val_loss: 0.2563 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1266 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1237 - out_1_loss: 0.0740 - out_2_loss: 0.0497 - out_1_acc: 0.9578 - out_2_acc: 0.9685 - val_loss: 0.2574 - val_out_1_loss: 0.1305 - val_out_2_loss: 0.1269 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9526\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1230 - out_1_loss: 0.0731 - out_2_loss: 0.0499 - out_1_acc: 0.9581 - out_2_acc: 0.9687 - val_loss: 0.2588 - val_out_1_loss: 0.1322 - val_out_2_loss: 0.1266 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9533\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1220 - out_1_loss: 0.0724 - out_2_loss: 0.0495 - out_1_acc: 0.9587 - out_2_acc: 0.9686 - val_loss: 0.2633 - val_out_1_loss: 0.1349 - val_out_2_loss: 0.1284 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9526\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1215 - out_1_loss: 0.0721 - out_2_loss: 0.0494 - out_1_acc: 0.9589 - out_2_acc: 0.9689 - val_loss: 0.2631 - val_out_1_loss: 0.1350 - val_out_2_loss: 0.1281 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9521\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1200 - out_1_loss: 0.0710 - out_2_loss: 0.0490 - out_1_acc: 0.9594 - out_2_acc: 0.9694 - val_loss: 0.2678 - val_out_1_loss: 0.1371 - val_out_2_loss: 0.1307 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9516\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1191 - out_1_loss: 0.0700 - out_2_loss: 0.0491 - out_1_acc: 0.9596 - out_2_acc: 0.9694 - val_loss: 0.2675 - val_out_1_loss: 0.1385 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9527\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1182 - out_1_loss: 0.0695 - out_2_loss: 0.0486 - out_1_acc: 0.9601 - out_2_acc: 0.9694 - val_loss: 0.2702 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1174 - out_1_loss: 0.0689 - out_2_loss: 0.0484 - out_1_acc: 0.9603 - out_2_acc: 0.9700 - val_loss: 0.2718 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1314 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9512\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1163 - out_1_loss: 0.0684 - out_2_loss: 0.0479 - out_1_acc: 0.9610 - out_2_acc: 0.9707 - val_loss: 0.2728 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1323 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9516\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1165 - out_1_loss: 0.0686 - out_2_loss: 0.0479 - out_1_acc: 0.9605 - out_2_acc: 0.9707 - val_loss: 0.2723 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1329 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9527\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1159 - out_1_loss: 0.0681 - out_2_loss: 0.0478 - out_1_acc: 0.9610 - out_2_acc: 0.9711 - val_loss: 0.2732 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1333 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9527\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1147 - out_1_loss: 0.0669 - out_2_loss: 0.0478 - out_1_acc: 0.9618 - out_2_acc: 0.9710 - val_loss: 0.2742 - val_out_1_loss: 0.1400 - val_out_2_loss: 0.1342 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9520\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1137 - out_1_loss: 0.0660 - out_2_loss: 0.0477 - out_1_acc: 0.9622 - out_2_acc: 0.9713 - val_loss: 0.2766 - val_out_1_loss: 0.1422 - val_out_2_loss: 0.1344 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9532\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1135 - out_1_loss: 0.0657 - out_2_loss: 0.0477 - out_1_acc: 0.9627 - out_2_acc: 0.9713 - val_loss: 0.2775 - val_out_1_loss: 0.1432 - val_out_2_loss: 0.1344 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1116 - out_1_loss: 0.0646 - out_2_loss: 0.0470 - out_1_acc: 0.9631 - out_2_acc: 0.9719 - val_loss: 0.2827 - val_out_1_loss: 0.1449 - val_out_2_loss: 0.1378 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1111 - out_1_loss: 0.0640 - out_2_loss: 0.0471 - out_1_acc: 0.9635 - out_2_acc: 0.9718 - val_loss: 0.2839 - val_out_1_loss: 0.1460 - val_out_2_loss: 0.1379 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9525\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1105 - out_1_loss: 0.0635 - out_2_loss: 0.0470 - out_1_acc: 0.9641 - out_2_acc: 0.9721 - val_loss: 0.2875 - val_out_1_loss: 0.1485 - val_out_2_loss: 0.1390 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1099 - out_1_loss: 0.0631 - out_2_loss: 0.0468 - out_1_acc: 0.9643 - out_2_acc: 0.9721 - val_loss: 0.2899 - val_out_1_loss: 0.1507 - val_out_2_loss: 0.1392 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1092 - out_1_loss: 0.0632 - out_2_loss: 0.0460 - out_1_acc: 0.9643 - out_2_acc: 0.9731 - val_loss: 0.2934 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1405 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1095 - out_1_loss: 0.0629 - out_2_loss: 0.0466 - out_1_acc: 0.9643 - out_2_acc: 0.9725 - val_loss: 0.2916 - val_out_1_loss: 0.1511 - val_out_2_loss: 0.1405 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9532\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1084 - out_1_loss: 0.0624 - out_2_loss: 0.0460 - out_1_acc: 0.9652 - out_2_acc: 0.9733 - val_loss: 0.2927 - val_out_1_loss: 0.1514 - val_out_2_loss: 0.1413 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1078 - out_1_loss: 0.0616 - out_2_loss: 0.0462 - out_1_acc: 0.9655 - out_2_acc: 0.9732 - val_loss: 0.2972 - val_out_1_loss: 0.1534 - val_out_2_loss: 0.1437 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1061 - out_1_loss: 0.0607 - out_2_loss: 0.0453 - out_1_acc: 0.9662 - out_2_acc: 0.9736 - val_loss: 0.2970 - val_out_1_loss: 0.1546 - val_out_2_loss: 0.1424 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1045 - out_1_loss: 0.0596 - out_2_loss: 0.0449 - out_1_acc: 0.9663 - out_2_acc: 0.9738 - val_loss: 0.2970 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1428 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9532\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1028 - out_1_loss: 0.0589 - out_2_loss: 0.0439 - out_1_acc: 0.9671 - out_2_acc: 0.9748 - val_loss: 0.2999 - val_out_1_loss: 0.1564 - val_out_2_loss: 0.1435 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1018 - out_1_loss: 0.0583 - out_2_loss: 0.0435 - out_1_acc: 0.9678 - out_2_acc: 0.9751 - val_loss: 0.3034 - val_out_1_loss: 0.1576 - val_out_2_loss: 0.1458 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9534\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1011 - out_1_loss: 0.0580 - out_2_loss: 0.0431 - out_1_acc: 0.9674 - out_2_acc: 0.9755 - val_loss: 0.3028 - val_out_1_loss: 0.1594 - val_out_2_loss: 0.1434 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9529\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1005 - out_1_loss: 0.0575 - out_2_loss: 0.0429 - out_1_acc: 0.9682 - out_2_acc: 0.9759 - val_loss: 0.3029 - val_out_1_loss: 0.1589 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9535\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1000 - out_1_loss: 0.0569 - out_2_loss: 0.0431 - out_1_acc: 0.9684 - out_2_acc: 0.9761 - val_loss: 0.3075 - val_out_1_loss: 0.1621 - val_out_2_loss: 0.1454 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9532\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0998 - out_1_loss: 0.0567 - out_2_loss: 0.0431 - out_1_acc: 0.9688 - out_2_acc: 0.9757 - val_loss: 0.3070 - val_out_1_loss: 0.1612 - val_out_2_loss: 0.1459 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0977 - out_1_loss: 0.0559 - out_2_loss: 0.0418 - out_1_acc: 0.9699 - out_2_acc: 0.9773 - val_loss: 0.3164 - val_out_1_loss: 0.1658 - val_out_2_loss: 0.1506 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9530\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0967 - out_1_loss: 0.0554 - out_2_loss: 0.0413 - out_1_acc: 0.9697 - out_2_acc: 0.9772 - val_loss: 0.3189 - val_out_1_loss: 0.1672 - val_out_2_loss: 0.1517 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9528\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0948 - out_1_loss: 0.0543 - out_2_loss: 0.0405 - out_1_acc: 0.9704 - out_2_acc: 0.9779 - val_loss: 0.3207 - val_out_1_loss: 0.1682 - val_out_2_loss: 0.1525 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0941 - out_1_loss: 0.0541 - out_2_loss: 0.0400 - out_1_acc: 0.9708 - out_2_acc: 0.9782 - val_loss: 0.3242 - val_out_1_loss: 0.1689 - val_out_2_loss: 0.1553 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9523\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0925 - out_1_loss: 0.0530 - out_2_loss: 0.0395 - out_1_acc: 0.9719 - out_2_acc: 0.9788 - val_loss: 0.3251 - val_out_1_loss: 0.1708 - val_out_2_loss: 0.1542 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0911 - out_1_loss: 0.0521 - out_2_loss: 0.0390 - out_1_acc: 0.9725 - out_2_acc: 0.9790 - val_loss: 0.3270 - val_out_1_loss: 0.1734 - val_out_2_loss: 0.1535 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9526\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0912 - out_1_loss: 0.0521 - out_2_loss: 0.0391 - out_1_acc: 0.9725 - out_2_acc: 0.9791 - val_loss: 0.3274 - val_out_1_loss: 0.1724 - val_out_2_loss: 0.1549 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9529\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0901 - out_1_loss: 0.0515 - out_2_loss: 0.0386 - out_1_acc: 0.9726 - out_2_acc: 0.9790 - val_loss: 0.3254 - val_out_1_loss: 0.1727 - val_out_2_loss: 0.1527 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9533\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0888 - out_1_loss: 0.0512 - out_2_loss: 0.0376 - out_1_acc: 0.9729 - out_2_acc: 0.9801 - val_loss: 0.3338 - val_out_1_loss: 0.1748 - val_out_2_loss: 0.1591 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.0882 - out_1_loss: 0.0510 - out_2_loss: 0.0372 - out_1_acc: 0.9735 - out_2_acc: 0.9801 - val_loss: 0.3369 - val_out_1_loss: 0.1777 - val_out_2_loss: 0.1592 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0881 - out_1_loss: 0.0509 - out_2_loss: 0.0372 - out_1_acc: 0.9733 - out_2_acc: 0.9807 - val_loss: 0.3360 - val_out_1_loss: 0.1773 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9537\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0899 - out_1_loss: 0.0522 - out_2_loss: 0.0378 - out_1_acc: 0.9726 - out_2_acc: 0.9801 - val_loss: 0.3391 - val_out_1_loss: 0.1789 - val_out_2_loss: 0.1601 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9533\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0877 - out_1_loss: 0.0507 - out_2_loss: 0.0370 - out_1_acc: 0.9735 - out_2_acc: 0.9806 - val_loss: 0.3440 - val_out_1_loss: 0.1806 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9530\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0882 - out_1_loss: 0.0505 - out_2_loss: 0.0377 - out_1_acc: 0.9737 - out_2_acc: 0.9797 - val_loss: 0.3458 - val_out_1_loss: 0.1829 - val_out_2_loss: 0.1629 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9524\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0898 - out_1_loss: 0.0512 - out_2_loss: 0.0385 - out_1_acc: 0.9733 - out_2_acc: 0.9797 - val_loss: 0.3481 - val_out_1_loss: 0.1847 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0863 - out_1_loss: 0.0505 - out_2_loss: 0.0359 - out_1_acc: 0.9740 - out_2_acc: 0.9811 - val_loss: 0.3537 - val_out_1_loss: 0.1884 - val_out_2_loss: 0.1653 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9530\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0867 - out_1_loss: 0.0504 - out_2_loss: 0.0363 - out_1_acc: 0.9744 - out_2_acc: 0.9813 - val_loss: 0.3605 - val_out_1_loss: 0.1892 - val_out_2_loss: 0.1714 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0856 - out_1_loss: 0.0500 - out_2_loss: 0.0356 - out_1_acc: 0.9746 - out_2_acc: 0.9820 - val_loss: 0.3614 - val_out_1_loss: 0.1950 - val_out_2_loss: 0.1663 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9538\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0850 - out_1_loss: 0.0499 - out_2_loss: 0.0351 - out_1_acc: 0.9747 - out_2_acc: 0.9818 - val_loss: 0.3675 - val_out_1_loss: 0.1941 - val_out_2_loss: 0.1735 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9529\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0839 - out_1_loss: 0.0493 - out_2_loss: 0.0346 - out_1_acc: 0.9753 - out_2_acc: 0.9824 - val_loss: 0.3694 - val_out_1_loss: 0.1972 - val_out_2_loss: 0.1723 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9540\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0821 - out_1_loss: 0.0493 - out_2_loss: 0.0328 - out_1_acc: 0.9749 - out_2_acc: 0.9837 - val_loss: 0.3750 - val_out_1_loss: 0.2001 - val_out_2_loss: 0.1750 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9536\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0816 - out_1_loss: 0.0501 - out_2_loss: 0.0314 - out_1_acc: 0.9746 - out_2_acc: 0.9848 - val_loss: 0.3749 - val_out_1_loss: 0.1978 - val_out_2_loss: 0.1771 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9531\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0865 - out_1_loss: 0.0533 - out_2_loss: 0.0332 - out_1_acc: 0.9732 - out_2_acc: 0.9838 - val_loss: 0.3618 - val_out_1_loss: 0.1907 - val_out_2_loss: 0.1711 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0871 - out_1_loss: 0.0549 - out_2_loss: 0.0322 - out_1_acc: 0.9729 - out_2_acc: 0.9841 - val_loss: 0.3651 - val_out_1_loss: 0.1907 - val_out_2_loss: 0.1744 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0826 - out_1_loss: 0.0509 - out_2_loss: 0.0317 - out_1_acc: 0.9740 - out_2_acc: 0.9848 - val_loss: 0.3663 - val_out_1_loss: 0.1912 - val_out_2_loss: 0.1751 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9531\n",
      "Epoch 103/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0804 - out_1_loss: 0.0480 - out_2_loss: 0.0324 - out_1_acc: 0.9766 - out_2_acc: 0.9843 - val_loss: 0.3651 - val_out_1_loss: 0.1894 - val_out_2_loss: 0.1757 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9529\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0779 - out_1_loss: 0.0474 - out_2_loss: 0.0305 - out_1_acc: 0.9764 - out_2_acc: 0.9850 - val_loss: 0.3759 - val_out_1_loss: 0.1953 - val_out_2_loss: 0.1806 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9526\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0759 - out_1_loss: 0.0461 - out_2_loss: 0.0299 - out_1_acc: 0.9774 - out_2_acc: 0.9857 - val_loss: 0.3755 - val_out_1_loss: 0.1956 - val_out_2_loss: 0.1799 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0771 - out_1_loss: 0.0457 - out_2_loss: 0.0314 - out_1_acc: 0.9774 - out_2_acc: 0.9848 - val_loss: 0.3811 - val_out_1_loss: 0.1982 - val_out_2_loss: 0.1829 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9530\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0760 - out_1_loss: 0.0460 - out_2_loss: 0.0300 - out_1_acc: 0.9778 - out_2_acc: 0.9858 - val_loss: 0.3803 - val_out_1_loss: 0.1988 - val_out_2_loss: 0.1815 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9527\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0725 - out_1_loss: 0.0441 - out_2_loss: 0.0284 - out_1_acc: 0.9792 - out_2_acc: 0.9866 - val_loss: 0.3868 - val_out_1_loss: 0.2007 - val_out_2_loss: 0.1861 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9535\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0714 - out_1_loss: 0.0440 - out_2_loss: 0.0274 - out_1_acc: 0.9790 - out_2_acc: 0.9872 - val_loss: 0.3923 - val_out_1_loss: 0.2071 - val_out_2_loss: 0.1852 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9535\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0723 - out_1_loss: 0.0452 - out_2_loss: 0.0271 - out_1_acc: 0.9784 - out_2_acc: 0.9871 - val_loss: 0.3944 - val_out_1_loss: 0.2053 - val_out_2_loss: 0.1891 - val_out_1_acc: 0.9425 - val_out_2_acc: 0.9531\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0719 - out_1_loss: 0.0437 - out_2_loss: 0.0282 - out_1_acc: 0.9794 - out_2_acc: 0.9869 - val_loss: 0.3976 - val_out_1_loss: 0.2097 - val_out_2_loss: 0.1879 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9538\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0731 - out_1_loss: 0.0453 - out_2_loss: 0.0278 - out_1_acc: 0.9785 - out_2_acc: 0.9868 - val_loss: 0.3861 - val_out_1_loss: 0.2013 - val_out_2_loss: 0.1848 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9532\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0696 - out_1_loss: 0.0430 - out_2_loss: 0.0265 - out_1_acc: 0.9800 - out_2_acc: 0.9878 - val_loss: 0.3935 - val_out_1_loss: 0.2006 - val_out_2_loss: 0.1929 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0675 - out_1_loss: 0.0411 - out_2_loss: 0.0264 - out_1_acc: 0.9809 - out_2_acc: 0.9881 - val_loss: 0.3882 - val_out_1_loss: 0.2016 - val_out_2_loss: 0.1866 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9536\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0674 - out_1_loss: 0.0418 - out_2_loss: 0.0257 - out_1_acc: 0.9810 - out_2_acc: 0.9884 - val_loss: 0.3904 - val_out_1_loss: 0.2018 - val_out_2_loss: 0.1886 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9533\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0643 - out_1_loss: 0.0402 - out_2_loss: 0.0241 - out_1_acc: 0.9816 - out_2_acc: 0.9890 - val_loss: 0.4000 - val_out_1_loss: 0.2018 - val_out_2_loss: 0.1983 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0657 - out_1_loss: 0.0401 - out_2_loss: 0.0256 - out_1_acc: 0.9818 - out_2_acc: 0.9883 - val_loss: 0.4021 - val_out_1_loss: 0.2042 - val_out_2_loss: 0.1978 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9528\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0612 - out_1_loss: 0.0385 - out_2_loss: 0.0226 - out_1_acc: 0.9824 - out_2_acc: 0.9899 - val_loss: 0.4109 - val_out_1_loss: 0.2125 - val_out_2_loss: 0.1984 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9542\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0612 - out_1_loss: 0.0386 - out_2_loss: 0.0226 - out_1_acc: 0.9820 - out_2_acc: 0.9900 - val_loss: 0.4146 - val_out_1_loss: 0.2154 - val_out_2_loss: 0.1992 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9531\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0584 - out_1_loss: 0.0371 - out_2_loss: 0.0213 - out_1_acc: 0.9830 - out_2_acc: 0.9908 - val_loss: 0.4115 - val_out_1_loss: 0.2124 - val_out_2_loss: 0.1991 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9527\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0551 - out_1_loss: 0.0355 - out_2_loss: 0.0197 - out_1_acc: 0.9840 - out_2_acc: 0.9918 - val_loss: 0.4198 - val_out_1_loss: 0.2142 - val_out_2_loss: 0.2057 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0538 - out_1_loss: 0.0340 - out_2_loss: 0.0199 - out_1_acc: 0.9846 - out_2_acc: 0.9915 - val_loss: 0.4230 - val_out_1_loss: 0.2176 - val_out_2_loss: 0.2053 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0505 - out_1_loss: 0.0322 - out_2_loss: 0.0183 - out_1_acc: 0.9856 - out_2_acc: 0.9924 - val_loss: 0.4305 - val_out_1_loss: 0.2226 - val_out_2_loss: 0.2080 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9512\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0494 - out_1_loss: 0.0310 - out_2_loss: 0.0183 - out_1_acc: 0.9862 - out_2_acc: 0.9922 - val_loss: 0.4301 - val_out_1_loss: 0.2219 - val_out_2_loss: 0.2082 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9522\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0471 - out_1_loss: 0.0299 - out_2_loss: 0.0173 - out_1_acc: 0.9870 - out_2_acc: 0.9926 - val_loss: 0.4360 - val_out_1_loss: 0.2247 - val_out_2_loss: 0.2113 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9518\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0437 - out_1_loss: 0.0284 - out_2_loss: 0.0153 - out_1_acc: 0.9879 - out_2_acc: 0.9937 - val_loss: 0.4417 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2169 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0418 - out_1_loss: 0.0277 - out_2_loss: 0.0141 - out_1_acc: 0.9878 - out_2_acc: 0.9942 - val_loss: 0.4568 - val_out_1_loss: 0.2298 - val_out_2_loss: 0.2270 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0407 - out_1_loss: 0.0274 - out_2_loss: 0.0133 - out_1_acc: 0.9883 - out_2_acc: 0.9945 - val_loss: 0.4581 - val_out_1_loss: 0.2330 - val_out_2_loss: 0.2251 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9525\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0413 - out_1_loss: 0.0277 - out_2_loss: 0.0136 - out_1_acc: 0.9877 - out_2_acc: 0.9942 - val_loss: 0.4671 - val_out_1_loss: 0.2382 - val_out_2_loss: 0.2288 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0413 - out_1_loss: 0.0275 - out_2_loss: 0.0138 - out_1_acc: 0.9885 - out_2_acc: 0.9943 - val_loss: 0.4662 - val_out_1_loss: 0.2400 - val_out_2_loss: 0.2262 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9530\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0390 - out_1_loss: 0.0264 - out_2_loss: 0.0126 - out_1_acc: 0.9888 - out_2_acc: 0.9948 - val_loss: 0.4725 - val_out_1_loss: 0.2449 - val_out_2_loss: 0.2276 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9527\n",
      "Epoch 132/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0378 - out_1_loss: 0.0263 - out_2_loss: 0.0114 - out_1_acc: 0.9887 - out_2_acc: 0.9953 - val_loss: 0.4750 - val_out_1_loss: 0.2421 - val_out_2_loss: 0.2328 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9534\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0377 - out_1_loss: 0.0262 - out_2_loss: 0.0115 - out_1_acc: 0.9886 - out_2_acc: 0.9956 - val_loss: 0.4790 - val_out_1_loss: 0.2469 - val_out_2_loss: 0.2320 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9536\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0386 - out_1_loss: 0.0262 - out_2_loss: 0.0124 - out_1_acc: 0.9888 - out_2_acc: 0.9950 - val_loss: 0.4856 - val_out_1_loss: 0.2461 - val_out_2_loss: 0.2395 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9532\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0380 - out_1_loss: 0.0254 - out_2_loss: 0.0126 - out_1_acc: 0.9893 - out_2_acc: 0.9951 - val_loss: 0.4829 - val_out_1_loss: 0.2458 - val_out_2_loss: 0.2371 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9533\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0361 - out_1_loss: 0.0241 - out_2_loss: 0.0119 - out_1_acc: 0.9899 - out_2_acc: 0.9952 - val_loss: 0.4891 - val_out_1_loss: 0.2481 - val_out_2_loss: 0.2410 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0332 - out_1_loss: 0.0230 - out_2_loss: 0.0101 - out_1_acc: 0.9908 - out_2_acc: 0.9961 - val_loss: 0.5077 - val_out_1_loss: 0.2581 - val_out_2_loss: 0.2496 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9524\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0352 - out_1_loss: 0.0253 - out_2_loss: 0.0099 - out_1_acc: 0.9891 - out_2_acc: 0.9961 - val_loss: 0.5108 - val_out_1_loss: 0.2678 - val_out_2_loss: 0.2430 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9531\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0337 - out_1_loss: 0.0251 - out_2_loss: 0.0086 - out_1_acc: 0.9898 - out_2_acc: 0.9967 - val_loss: 0.5122 - val_out_1_loss: 0.2628 - val_out_2_loss: 0.2493 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9532\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0310 - out_1_loss: 0.0234 - out_2_loss: 0.0076 - out_1_acc: 0.9906 - out_2_acc: 0.9972 - val_loss: 0.5171 - val_out_1_loss: 0.2612 - val_out_2_loss: 0.2558 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9534\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0302 - out_1_loss: 0.0222 - out_2_loss: 0.0080 - out_1_acc: 0.9908 - out_2_acc: 0.9968 - val_loss: 0.5121 - val_out_1_loss: 0.2560 - val_out_2_loss: 0.2561 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9526\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0275 - out_1_loss: 0.0204 - out_2_loss: 0.0071 - out_1_acc: 0.9919 - out_2_acc: 0.9973 - val_loss: 0.5155 - val_out_1_loss: 0.2600 - val_out_2_loss: 0.2555 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9535\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0250 - out_1_loss: 0.0183 - out_2_loss: 0.0066 - out_1_acc: 0.9932 - out_2_acc: 0.9974 - val_loss: 0.5209 - val_out_1_loss: 0.2602 - val_out_2_loss: 0.2607 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9532\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0221 - out_1_loss: 0.0166 - out_2_loss: 0.0054 - out_1_acc: 0.9937 - out_2_acc: 0.9982 - val_loss: 0.5292 - val_out_1_loss: 0.2689 - val_out_2_loss: 0.2604 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9532\n",
      "Epoch 145/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0206 - out_1_loss: 0.0157 - out_2_loss: 0.0049 - out_1_acc: 0.9942 - out_2_acc: 0.9984 - val_loss: 0.5413 - val_out_1_loss: 0.2784 - val_out_2_loss: 0.2629 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9533\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0200 - out_1_loss: 0.0157 - out_2_loss: 0.0043 - out_1_acc: 0.9941 - out_2_acc: 0.9986 - val_loss: 0.5469 - val_out_1_loss: 0.2772 - val_out_2_loss: 0.2697 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0191 - out_1_loss: 0.0147 - out_2_loss: 0.0044 - out_1_acc: 0.9946 - out_2_acc: 0.9983 - val_loss: 0.5568 - val_out_1_loss: 0.2794 - val_out_2_loss: 0.2774 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9522\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0194 - out_1_loss: 0.0141 - out_2_loss: 0.0053 - out_1_acc: 0.9948 - out_2_acc: 0.9980 - val_loss: 0.5516 - val_out_1_loss: 0.2843 - val_out_2_loss: 0.2673 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9536\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0201 - out_1_loss: 0.0142 - out_2_loss: 0.0059 - out_1_acc: 0.9948 - out_2_acc: 0.9980 - val_loss: 0.5671 - val_out_1_loss: 0.2950 - val_out_2_loss: 0.2721 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9530\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0193 - out_1_loss: 0.0140 - out_2_loss: 0.0053 - out_1_acc: 0.9950 - out_2_acc: 0.9982 - val_loss: 0.5592 - val_out_1_loss: 0.2891 - val_out_2_loss: 0.2701 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9536\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0176 - out_1_loss: 0.0133 - out_2_loss: 0.0043 - out_1_acc: 0.9952 - out_2_acc: 0.9986 - val_loss: 0.5750 - val_out_1_loss: 0.2999 - val_out_2_loss: 0.2751 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9531\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0169 - out_1_loss: 0.0130 - out_2_loss: 0.0039 - out_1_acc: 0.9951 - out_2_acc: 0.9986 - val_loss: 0.5850 - val_out_1_loss: 0.3031 - val_out_2_loss: 0.2819 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9534\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0177 - out_1_loss: 0.0130 - out_2_loss: 0.0047 - out_1_acc: 0.9953 - out_2_acc: 0.9983 - val_loss: 0.5841 - val_out_1_loss: 0.3059 - val_out_2_loss: 0.2783 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9536\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0172 - out_1_loss: 0.0125 - out_2_loss: 0.0047 - out_1_acc: 0.9953 - out_2_acc: 0.9983 - val_loss: 0.5817 - val_out_1_loss: 0.3056 - val_out_2_loss: 0.2761 - val_out_1_acc: 0.9426 - val_out_2_acc: 0.9535\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0179 - out_1_loss: 0.0125 - out_2_loss: 0.0054 - out_1_acc: 0.9955 - out_2_acc: 0.9981 - val_loss: 0.5871 - val_out_1_loss: 0.3085 - val_out_2_loss: 0.2786 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9536\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0171 - out_1_loss: 0.0124 - out_2_loss: 0.0047 - out_1_acc: 0.9957 - out_2_acc: 0.9984 - val_loss: 0.5831 - val_out_1_loss: 0.3064 - val_out_2_loss: 0.2766 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9532\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0182 - out_1_loss: 0.0130 - out_2_loss: 0.0053 - out_1_acc: 0.9953 - out_2_acc: 0.9984 - val_loss: 0.5896 - val_out_1_loss: 0.3100 - val_out_2_loss: 0.2796 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0168 - out_1_loss: 0.0128 - out_2_loss: 0.0040 - out_1_acc: 0.9954 - out_2_acc: 0.9987 - val_loss: 0.5926 - val_out_1_loss: 0.3131 - val_out_2_loss: 0.2795 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9538\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0159 - out_1_loss: 0.0124 - out_2_loss: 0.0036 - out_1_acc: 0.9956 - out_2_acc: 0.9989 - val_loss: 0.6025 - val_out_1_loss: 0.3198 - val_out_2_loss: 0.2826 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0153 - out_1_loss: 0.0115 - out_2_loss: 0.0038 - out_1_acc: 0.9961 - out_2_acc: 0.9986 - val_loss: 0.6085 - val_out_1_loss: 0.3222 - val_out_2_loss: 0.2862 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9539\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0149 - out_1_loss: 0.0117 - out_2_loss: 0.0032 - out_1_acc: 0.9959 - out_2_acc: 0.9989 - val_loss: 0.6149 - val_out_1_loss: 0.3297 - val_out_2_loss: 0.2851 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9531\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0137 - out_1_loss: 0.0106 - out_2_loss: 0.0031 - out_1_acc: 0.9963 - out_2_acc: 0.9990 - val_loss: 0.6046 - val_out_1_loss: 0.3216 - val_out_2_loss: 0.2830 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9540\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0145 - out_1_loss: 0.0110 - out_2_loss: 0.0035 - out_1_acc: 0.9962 - out_2_acc: 0.9988 - val_loss: 0.6355 - val_out_1_loss: 0.3403 - val_out_2_loss: 0.2952 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9530\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0146 - out_1_loss: 0.0115 - out_2_loss: 0.0031 - out_1_acc: 0.9960 - out_2_acc: 0.9988 - val_loss: 0.6221 - val_out_1_loss: 0.3274 - val_out_2_loss: 0.2947 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0148 - out_1_loss: 0.0112 - out_2_loss: 0.0036 - out_1_acc: 0.9961 - out_2_acc: 0.9987 - val_loss: 0.6274 - val_out_1_loss: 0.3375 - val_out_2_loss: 0.2899 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0136 - out_1_loss: 0.0099 - out_2_loss: 0.0038 - out_1_acc: 0.9967 - out_2_acc: 0.9987 - val_loss: 0.6307 - val_out_1_loss: 0.3380 - val_out_2_loss: 0.2927 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9532\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0131 - out_1_loss: 0.0100 - out_2_loss: 0.0031 - out_1_acc: 0.9965 - out_2_acc: 0.9989 - val_loss: 0.6371 - val_out_1_loss: 0.3401 - val_out_2_loss: 0.2970 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9533\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0119 - out_1_loss: 0.0087 - out_2_loss: 0.0031 - out_1_acc: 0.9972 - out_2_acc: 0.9990 - val_loss: 0.6228 - val_out_1_loss: 0.3303 - val_out_2_loss: 0.2924 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9525\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.0120 - out_1_loss: 0.0090 - out_2_loss: 0.0030 - out_1_acc: 0.9969 - out_2_acc: 0.9989 - val_loss: 0.6424 - val_out_1_loss: 0.3398 - val_out_2_loss: 0.3026 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9538\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0138 - out_1_loss: 0.0101 - out_2_loss: 0.0037 - out_1_acc: 0.9965 - out_2_acc: 0.9987 - val_loss: 0.6403 - val_out_1_loss: 0.3346 - val_out_2_loss: 0.3057 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9532\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0119 - out_1_loss: 0.0086 - out_2_loss: 0.0033 - out_1_acc: 0.9971 - out_2_acc: 0.9989 - val_loss: 0.6535 - val_out_1_loss: 0.3464 - val_out_2_loss: 0.3071 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9534\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0127 - out_1_loss: 0.0092 - out_2_loss: 0.0035 - out_1_acc: 0.9966 - out_2_acc: 0.9988 - val_loss: 0.6666 - val_out_1_loss: 0.3525 - val_out_2_loss: 0.3141 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9533\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0126 - out_1_loss: 0.0088 - out_2_loss: 0.0038 - out_1_acc: 0.9969 - out_2_acc: 0.9988 - val_loss: 0.6582 - val_out_1_loss: 0.3524 - val_out_2_loss: 0.3058 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9536\n",
      "Epoch 174/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0148 - out_1_loss: 0.0107 - out_2_loss: 0.0041 - out_1_acc: 0.9962 - out_2_acc: 0.9986 - val_loss: 0.6541 - val_out_1_loss: 0.3500 - val_out_2_loss: 0.3040 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9531\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0129 - out_1_loss: 0.0092 - out_2_loss: 0.0037 - out_1_acc: 0.9968 - out_2_acc: 0.9987 - val_loss: 0.6480 - val_out_1_loss: 0.3454 - val_out_2_loss: 0.3026 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9538\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0128 - out_1_loss: 0.0093 - out_2_loss: 0.0034 - out_1_acc: 0.9968 - out_2_acc: 0.9987 - val_loss: 0.6685 - val_out_1_loss: 0.3618 - val_out_2_loss: 0.3067 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9535\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0146 - out_1_loss: 0.0106 - out_2_loss: 0.0040 - out_1_acc: 0.9963 - out_2_acc: 0.9986 - val_loss: 0.6696 - val_out_1_loss: 0.3593 - val_out_2_loss: 0.3103 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0135 - out_1_loss: 0.0100 - out_2_loss: 0.0036 - out_1_acc: 0.9964 - out_2_acc: 0.9989 - val_loss: 0.6594 - val_out_1_loss: 0.3523 - val_out_2_loss: 0.3072 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9543\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(3)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6614 - out_1_loss: 0.3375 - out_2_loss: 0.3239 - out_1_acc: 0.9422 - out_2_acc: 0.9524\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 100), (No 52400       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 100)       52400       input_10[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 293,880\n",
      "Trainable params: 293,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3694 - out_1_loss: 3.6917 - out_2_loss: 3.6776 - out_1_acc: 0.0344 - out_2_acc: 0.0690WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117829). Check your callbacks.\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 6.5640 - out_1_loss: 3.3505 - out_2_loss: 3.2135 - out_1_acc: 0.3316 - out_2_acc: 0.3541 - val_loss: 5.1549 - val_out_1_loss: 2.6906 - val_out_2_loss: 2.4644 - val_out_1_acc: 0.3853 - val_out_2_acc: 0.4100\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 4.2038 - out_1_loss: 2.2165 - out_2_loss: 1.9873 - out_1_acc: 0.4792 - out_2_acc: 0.5139 - val_loss: 3.3119 - val_out_1_loss: 1.8265 - val_out_2_loss: 1.4854 - val_out_1_acc: 0.5420 - val_out_2_acc: 0.6345\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 2.4862 - out_1_loss: 1.4396 - out_2_loss: 1.0466 - out_1_acc: 0.6434 - out_2_acc: 0.7511 - val_loss: 1.7189 - val_out_1_loss: 1.0354 - val_out_2_loss: 0.6834 - val_out_1_acc: 0.7573 - val_out_2_acc: 0.8518\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.2808 - out_1_loss: 0.7860 - out_2_loss: 0.4948 - out_1_acc: 0.8200 - out_2_acc: 0.8958 - val_loss: 0.9442 - val_out_1_loss: 0.5760 - val_out_2_loss: 0.3682 - val_out_1_acc: 0.8745 - val_out_2_acc: 0.9194\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.7648 - out_1_loss: 0.4688 - out_2_loss: 0.2960 - out_1_acc: 0.8990 - out_2_acc: 0.9306 - val_loss: 0.6375 - val_out_1_loss: 0.3820 - val_out_2_loss: 0.2556 - val_out_1_acc: 0.9189 - val_out_2_acc: 0.9334\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5397 - out_1_loss: 0.3299 - out_2_loss: 0.2098 - out_1_acc: 0.9245 - out_2_acc: 0.9398 - val_loss: 0.4790 - val_out_1_loss: 0.2867 - val_out_2_loss: 0.1923 - val_out_1_acc: 0.9313 - val_out_2_acc: 0.9410\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.4092 - out_1_loss: 0.2493 - out_2_loss: 0.1599 - out_1_acc: 0.9341 - out_2_acc: 0.9482 - val_loss: 0.3780 - val_out_1_loss: 0.2243 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9492\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3274 - out_1_loss: 0.1966 - out_2_loss: 0.1307 - out_1_acc: 0.9384 - out_2_acc: 0.9518 - val_loss: 0.3155 - val_out_1_loss: 0.1845 - val_out_2_loss: 0.1311 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9500\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2780 - out_1_loss: 0.1643 - out_2_loss: 0.1138 - out_1_acc: 0.9408 - out_2_acc: 0.9525 - val_loss: 0.2783 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1177 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9499\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2479 - out_1_loss: 0.1442 - out_2_loss: 0.1036 - out_1_acc: 0.9413 - out_2_acc: 0.9526 - val_loss: 0.2529 - val_out_1_loss: 0.1444 - val_out_2_loss: 0.1085 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9504\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2286 - out_1_loss: 0.1317 - out_2_loss: 0.0968 - out_1_acc: 0.9417 - out_2_acc: 0.9533 - val_loss: 0.2360 - val_out_1_loss: 0.1329 - val_out_2_loss: 0.1031 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2153 - out_1_loss: 0.1230 - out_2_loss: 0.0924 - out_1_acc: 0.9420 - out_2_acc: 0.9534 - val_loss: 0.2242 - val_out_1_loss: 0.1255 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9512\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2064 - out_1_loss: 0.1169 - out_2_loss: 0.0896 - out_1_acc: 0.9422 - out_2_acc: 0.9537 - val_loss: 0.2176 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2005 - out_1_loss: 0.1129 - out_2_loss: 0.0877 - out_1_acc: 0.9424 - out_2_acc: 0.9540 - val_loss: 0.2130 - val_out_1_loss: 0.1177 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9518\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1962 - out_1_loss: 0.1100 - out_2_loss: 0.0862 - out_1_acc: 0.9428 - out_2_acc: 0.9543 - val_loss: 0.2094 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.0943 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1930 - out_1_loss: 0.1078 - out_2_loss: 0.0852 - out_1_acc: 0.9434 - out_2_acc: 0.9546 - val_loss: 0.2062 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.0931 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1902 - out_1_loss: 0.1060 - out_2_loss: 0.0843 - out_1_acc: 0.9435 - out_2_acc: 0.9547 - val_loss: 0.2035 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0918 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1878 - out_1_loss: 0.1045 - out_2_loss: 0.0834 - out_1_acc: 0.9435 - out_2_acc: 0.9551 - val_loss: 0.2018 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1859 - out_1_loss: 0.1032 - out_2_loss: 0.0826 - out_1_acc: 0.9441 - out_2_acc: 0.9552 - val_loss: 0.2006 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1844 - out_1_loss: 0.1023 - out_2_loss: 0.0821 - out_1_acc: 0.9442 - out_2_acc: 0.9557 - val_loss: 0.2000 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1831 - out_1_loss: 0.1015 - out_2_loss: 0.0816 - out_1_acc: 0.9440 - out_2_acc: 0.9556 - val_loss: 0.1992 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9519\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1818 - out_1_loss: 0.1008 - out_2_loss: 0.0809 - out_1_acc: 0.9440 - out_2_acc: 0.9561 - val_loss: 0.1988 - val_out_1_loss: 0.1077 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1806 - out_1_loss: 0.1002 - out_2_loss: 0.0804 - out_1_acc: 0.9444 - out_2_acc: 0.9562 - val_loss: 0.1986 - val_out_1_loss: 0.1072 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9512\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1796 - out_1_loss: 0.0996 - out_2_loss: 0.0800 - out_1_acc: 0.9444 - out_2_acc: 0.9567 - val_loss: 0.1986 - val_out_1_loss: 0.1070 - val_out_2_loss: 0.0916 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9515\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1788 - out_1_loss: 0.0992 - out_2_loss: 0.0796 - out_1_acc: 0.9448 - out_2_acc: 0.9565 - val_loss: 0.1983 - val_out_1_loss: 0.1068 - val_out_2_loss: 0.0915 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1779 - out_1_loss: 0.0987 - out_2_loss: 0.0791 - out_1_acc: 0.9451 - out_2_acc: 0.9566 - val_loss: 0.1981 - val_out_1_loss: 0.1065 - val_out_2_loss: 0.0915 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1772 - out_1_loss: 0.0984 - out_2_loss: 0.0788 - out_1_acc: 0.9451 - out_2_acc: 0.9565 - val_loss: 0.1977 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1762 - out_1_loss: 0.0979 - out_2_loss: 0.0783 - out_1_acc: 0.9454 - out_2_acc: 0.9568 - val_loss: 0.1975 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1755 - out_1_loss: 0.0976 - out_2_loss: 0.0779 - out_1_acc: 0.9455 - out_2_acc: 0.9574 - val_loss: 0.1975 - val_out_1_loss: 0.1062 - val_out_2_loss: 0.0913 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1746 - out_1_loss: 0.0973 - out_2_loss: 0.0774 - out_1_acc: 0.9454 - out_2_acc: 0.9575 - val_loss: 0.1966 - val_out_1_loss: 0.1061 - val_out_2_loss: 0.0905 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9531\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1739 - out_1_loss: 0.0970 - out_2_loss: 0.0769 - out_1_acc: 0.9456 - out_2_acc: 0.9579 - val_loss: 0.1972 - val_out_1_loss: 0.1061 - val_out_2_loss: 0.0911 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1731 - out_1_loss: 0.0967 - out_2_loss: 0.0764 - out_1_acc: 0.9460 - out_2_acc: 0.9582 - val_loss: 0.1972 - val_out_1_loss: 0.1061 - val_out_2_loss: 0.0912 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1721 - out_1_loss: 0.0964 - out_2_loss: 0.0758 - out_1_acc: 0.9461 - out_2_acc: 0.9590 - val_loss: 0.1975 - val_out_1_loss: 0.1061 - val_out_2_loss: 0.0914 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1717 - out_1_loss: 0.0961 - out_2_loss: 0.0756 - out_1_acc: 0.9461 - out_2_acc: 0.9591 - val_loss: 0.1983 - val_out_1_loss: 0.1062 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1709 - out_1_loss: 0.0958 - out_2_loss: 0.0751 - out_1_acc: 0.9465 - out_2_acc: 0.9590 - val_loss: 0.1983 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9517\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1705 - out_1_loss: 0.0956 - out_2_loss: 0.0748 - out_1_acc: 0.9469 - out_2_acc: 0.9591 - val_loss: 0.1987 - val_out_1_loss: 0.1062 - val_out_2_loss: 0.0925 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1698 - out_1_loss: 0.0954 - out_2_loss: 0.0744 - out_1_acc: 0.9469 - out_2_acc: 0.9593 - val_loss: 0.1992 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0929 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1692 - out_1_loss: 0.0951 - out_2_loss: 0.0741 - out_1_acc: 0.9467 - out_2_acc: 0.9593 - val_loss: 0.1996 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0933 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9516\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1690 - out_1_loss: 0.0949 - out_2_loss: 0.0741 - out_1_acc: 0.9469 - out_2_acc: 0.9588 - val_loss: 0.2000 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0936 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9522\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1682 - out_1_loss: 0.0946 - out_2_loss: 0.0736 - out_1_acc: 0.9473 - out_2_acc: 0.9591 - val_loss: 0.1999 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0936 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9526\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1678 - out_1_loss: 0.0944 - out_2_loss: 0.0733 - out_1_acc: 0.9473 - out_2_acc: 0.9593 - val_loss: 0.1999 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0936 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1671 - out_1_loss: 0.0941 - out_2_loss: 0.0729 - out_1_acc: 0.9475 - out_2_acc: 0.9599 - val_loss: 0.2015 - val_out_1_loss: 0.1065 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1672 - out_1_loss: 0.0940 - out_2_loss: 0.0732 - out_1_acc: 0.9475 - out_2_acc: 0.9596 - val_loss: 0.2007 - val_out_1_loss: 0.1067 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9520\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1667 - out_1_loss: 0.0938 - out_2_loss: 0.0729 - out_1_acc: 0.9475 - out_2_acc: 0.9597 - val_loss: 0.2018 - val_out_1_loss: 0.1065 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9532\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1660 - out_1_loss: 0.0935 - out_2_loss: 0.0725 - out_1_acc: 0.9477 - out_2_acc: 0.9603 - val_loss: 0.2042 - val_out_1_loss: 0.1067 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9528\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1663 - out_1_loss: 0.0936 - out_2_loss: 0.0727 - out_1_acc: 0.9478 - out_2_acc: 0.9602 - val_loss: 0.2021 - val_out_1_loss: 0.1068 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9532\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1654 - out_1_loss: 0.0935 - out_2_loss: 0.0719 - out_1_acc: 0.9476 - out_2_acc: 0.9601 - val_loss: 0.2025 - val_out_1_loss: 0.1073 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1648 - out_1_loss: 0.0932 - out_2_loss: 0.0716 - out_1_acc: 0.9478 - out_2_acc: 0.9602 - val_loss: 0.2049 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0970 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9525\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1646 - out_1_loss: 0.0931 - out_2_loss: 0.0715 - out_1_acc: 0.9478 - out_2_acc: 0.9604 - val_loss: 0.2067 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1648 - out_1_loss: 0.0928 - out_2_loss: 0.0719 - out_1_acc: 0.9479 - out_2_acc: 0.9609 - val_loss: 0.2049 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9509\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1641 - out_1_loss: 0.0926 - out_2_loss: 0.0715 - out_1_acc: 0.9479 - out_2_acc: 0.9606 - val_loss: 0.2068 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0982 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1642 - out_1_loss: 0.0926 - out_2_loss: 0.0717 - out_1_acc: 0.9478 - out_2_acc: 0.9610 - val_loss: 0.2048 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1644 - out_1_loss: 0.0923 - out_2_loss: 0.0721 - out_1_acc: 0.9481 - out_2_acc: 0.9602 - val_loss: 0.2043 - val_out_1_loss: 0.1073 - val_out_2_loss: 0.0970 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9520\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1618 - out_1_loss: 0.0920 - out_2_loss: 0.0698 - out_1_acc: 0.9489 - out_2_acc: 0.9610 - val_loss: 0.2048 - val_out_1_loss: 0.1072 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1602 - out_1_loss: 0.0916 - out_2_loss: 0.0686 - out_1_acc: 0.9485 - out_2_acc: 0.9617 - val_loss: 0.2058 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0977 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9520\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1599 - out_1_loss: 0.0915 - out_2_loss: 0.0684 - out_1_acc: 0.9485 - out_2_acc: 0.9621 - val_loss: 0.2065 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1592 - out_1_loss: 0.0912 - out_2_loss: 0.0680 - out_1_acc: 0.9488 - out_2_acc: 0.9621 - val_loss: 0.2071 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9530\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1591 - out_1_loss: 0.0910 - out_2_loss: 0.0681 - out_1_acc: 0.9489 - out_2_acc: 0.9622 - val_loss: 0.2071 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1605 - out_1_loss: 0.0909 - out_2_loss: 0.0696 - out_1_acc: 0.9488 - out_2_acc: 0.9616 - val_loss: 0.2092 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0997 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9532\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1618 - out_1_loss: 0.0910 - out_2_loss: 0.0707 - out_1_acc: 0.9488 - out_2_acc: 0.9608 - val_loss: 0.2108 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.1007 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9532\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1605 - out_1_loss: 0.0912 - out_2_loss: 0.0693 - out_1_acc: 0.9487 - out_2_acc: 0.9617 - val_loss: 0.2101 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.1004 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9520\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1579 - out_1_loss: 0.0906 - out_2_loss: 0.0672 - out_1_acc: 0.9491 - out_2_acc: 0.9622 - val_loss: 0.2106 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9523\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1566 - out_1_loss: 0.0905 - out_2_loss: 0.0662 - out_1_acc: 0.9491 - out_2_acc: 0.9624 - val_loss: 0.2109 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.1007 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9525\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1555 - out_1_loss: 0.0904 - out_2_loss: 0.0652 - out_1_acc: 0.9488 - out_2_acc: 0.9637 - val_loss: 0.2112 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.1015 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9530\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1553 - out_1_loss: 0.0900 - out_2_loss: 0.0653 - out_1_acc: 0.9495 - out_2_acc: 0.9629 - val_loss: 0.2135 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9533\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1544 - out_1_loss: 0.0897 - out_2_loss: 0.0648 - out_1_acc: 0.9501 - out_2_acc: 0.9636 - val_loss: 0.2151 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9535\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1540 - out_1_loss: 0.0896 - out_2_loss: 0.0644 - out_1_acc: 0.9495 - out_2_acc: 0.9639 - val_loss: 0.2166 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1062 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9538\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1538 - out_1_loss: 0.0896 - out_2_loss: 0.0642 - out_1_acc: 0.9497 - out_2_acc: 0.9638 - val_loss: 0.2198 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9526\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1531 - out_1_loss: 0.0894 - out_2_loss: 0.0637 - out_1_acc: 0.9500 - out_2_acc: 0.9642 - val_loss: 0.2202 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9527\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1524 - out_1_loss: 0.0892 - out_2_loss: 0.0632 - out_1_acc: 0.9496 - out_2_acc: 0.9645 - val_loss: 0.2202 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.1090 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9530\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1517 - out_1_loss: 0.0889 - out_2_loss: 0.0627 - out_1_acc: 0.9505 - out_2_acc: 0.9647 - val_loss: 0.2201 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1095 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1512 - out_1_loss: 0.0887 - out_2_loss: 0.0625 - out_1_acc: 0.9508 - out_2_acc: 0.9649 - val_loss: 0.2233 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.1118 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9512\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1514 - out_1_loss: 0.0887 - out_2_loss: 0.0628 - out_1_acc: 0.9507 - out_2_acc: 0.9648 - val_loss: 0.2241 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1119 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1511 - out_1_loss: 0.0886 - out_2_loss: 0.0626 - out_1_acc: 0.9507 - out_2_acc: 0.9644 - val_loss: 0.2221 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1093 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9518\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1507 - out_1_loss: 0.0885 - out_2_loss: 0.0622 - out_1_acc: 0.9506 - out_2_acc: 0.9647 - val_loss: 0.2215 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1497 - out_1_loss: 0.0880 - out_2_loss: 0.0617 - out_1_acc: 0.9507 - out_2_acc: 0.9655 - val_loss: 0.2213 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1091 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1492 - out_1_loss: 0.0880 - out_2_loss: 0.0612 - out_1_acc: 0.9504 - out_2_acc: 0.9658 - val_loss: 0.2229 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.1099 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9526\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1486 - out_1_loss: 0.0877 - out_2_loss: 0.0609 - out_1_acc: 0.9509 - out_2_acc: 0.9656 - val_loss: 0.2235 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1110 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1481 - out_1_loss: 0.0874 - out_2_loss: 0.0608 - out_1_acc: 0.9512 - out_2_acc: 0.9652 - val_loss: 0.2264 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.1131 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9536\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1475 - out_1_loss: 0.0872 - out_2_loss: 0.0604 - out_1_acc: 0.9513 - out_2_acc: 0.9656 - val_loss: 0.2291 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1154 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1469 - out_1_loss: 0.0871 - out_2_loss: 0.0598 - out_1_acc: 0.9516 - out_2_acc: 0.9669 - val_loss: 0.2288 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.1149 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1465 - out_1_loss: 0.0867 - out_2_loss: 0.0598 - out_1_acc: 0.9518 - out_2_acc: 0.9662 - val_loss: 0.2280 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1143 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1460 - out_1_loss: 0.0866 - out_2_loss: 0.0594 - out_1_acc: 0.9514 - out_2_acc: 0.9665 - val_loss: 0.2279 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1149 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1443 - out_1_loss: 0.0860 - out_2_loss: 0.0583 - out_1_acc: 0.9523 - out_2_acc: 0.9669 - val_loss: 0.2304 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1165 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1443 - out_1_loss: 0.0862 - out_2_loss: 0.0581 - out_1_acc: 0.9522 - out_2_acc: 0.9669 - val_loss: 0.2328 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.1187 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9510\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1441 - out_1_loss: 0.0859 - out_2_loss: 0.0582 - out_1_acc: 0.9525 - out_2_acc: 0.9671 - val_loss: 0.2347 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1201 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1435 - out_1_loss: 0.0857 - out_2_loss: 0.0578 - out_1_acc: 0.9522 - out_2_acc: 0.9674 - val_loss: 0.2369 - val_out_1_loss: 0.1161 - val_out_2_loss: 0.1207 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9525\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1428 - out_1_loss: 0.0854 - out_2_loss: 0.0574 - out_1_acc: 0.9522 - out_2_acc: 0.9675 - val_loss: 0.2380 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1208 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9534\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1427 - out_1_loss: 0.0852 - out_2_loss: 0.0575 - out_1_acc: 0.9526 - out_2_acc: 0.9673 - val_loss: 0.2394 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1218 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9525\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1415 - out_1_loss: 0.0852 - out_2_loss: 0.0563 - out_1_acc: 0.9523 - out_2_acc: 0.9681 - val_loss: 0.2430 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.1248 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9531\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1397 - out_1_loss: 0.0846 - out_2_loss: 0.0550 - out_1_acc: 0.9532 - out_2_acc: 0.9685 - val_loss: 0.2453 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1269 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1388 - out_1_loss: 0.0842 - out_2_loss: 0.0546 - out_1_acc: 0.9531 - out_2_acc: 0.9688 - val_loss: 0.2434 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1253 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1373 - out_1_loss: 0.0836 - out_2_loss: 0.0537 - out_1_acc: 0.9533 - out_2_acc: 0.9695 - val_loss: 0.2457 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1272 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9521\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1362 - out_1_loss: 0.0829 - out_2_loss: 0.0533 - out_1_acc: 0.9540 - out_2_acc: 0.9697 - val_loss: 0.2466 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.1277 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9529\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1360 - out_1_loss: 0.0829 - out_2_loss: 0.0531 - out_1_acc: 0.9539 - out_2_acc: 0.9694 - val_loss: 0.2481 - val_out_1_loss: 0.1197 - val_out_2_loss: 0.1284 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9518\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1349 - out_1_loss: 0.0824 - out_2_loss: 0.0525 - out_1_acc: 0.9542 - out_2_acc: 0.9701 - val_loss: 0.2490 - val_out_1_loss: 0.1205 - val_out_2_loss: 0.1285 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9526\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1346 - out_1_loss: 0.0823 - out_2_loss: 0.0523 - out_1_acc: 0.9538 - out_2_acc: 0.9700 - val_loss: 0.2460 - val_out_1_loss: 0.1193 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9528\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1330 - out_1_loss: 0.0818 - out_2_loss: 0.0512 - out_1_acc: 0.9546 - out_2_acc: 0.9711 - val_loss: 0.2473 - val_out_1_loss: 0.1203 - val_out_2_loss: 0.1270 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9519\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1326 - out_1_loss: 0.0815 - out_2_loss: 0.0511 - out_1_acc: 0.9539 - out_2_acc: 0.9710 - val_loss: 0.2501 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1322 - out_1_loss: 0.0808 - out_2_loss: 0.0514 - out_1_acc: 0.9552 - out_2_acc: 0.9709 - val_loss: 0.2508 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.1300 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1317 - out_1_loss: 0.0809 - out_2_loss: 0.0508 - out_1_acc: 0.9548 - out_2_acc: 0.9713 - val_loss: 0.2532 - val_out_1_loss: 0.1205 - val_out_2_loss: 0.1327 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9530\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1316 - out_1_loss: 0.0806 - out_2_loss: 0.0510 - out_1_acc: 0.9554 - out_2_acc: 0.9710 - val_loss: 0.2536 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1320 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9514\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1302 - out_1_loss: 0.0799 - out_2_loss: 0.0503 - out_1_acc: 0.9559 - out_2_acc: 0.9716 - val_loss: 0.2505 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1296 - out_1_loss: 0.0796 - out_2_loss: 0.0500 - out_1_acc: 0.9556 - out_2_acc: 0.9724 - val_loss: 0.2541 - val_out_1_loss: 0.1221 - val_out_2_loss: 0.1320 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1297 - out_1_loss: 0.0793 - out_2_loss: 0.0504 - out_1_acc: 0.9559 - out_2_acc: 0.9721 - val_loss: 0.2574 - val_out_1_loss: 0.1228 - val_out_2_loss: 0.1346 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9522\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1287 - out_1_loss: 0.0789 - out_2_loss: 0.0498 - out_1_acc: 0.9564 - out_2_acc: 0.9723 - val_loss: 0.2594 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1371 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9513\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1282 - out_1_loss: 0.0784 - out_2_loss: 0.0498 - out_1_acc: 0.9567 - out_2_acc: 0.9722 - val_loss: 0.2605 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1372 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9519\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1279 - out_1_loss: 0.0781 - out_2_loss: 0.0499 - out_1_acc: 0.9569 - out_2_acc: 0.9720 - val_loss: 0.2618 - val_out_1_loss: 0.1244 - val_out_2_loss: 0.1374 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1274 - out_1_loss: 0.0778 - out_2_loss: 0.0496 - out_1_acc: 0.9572 - out_2_acc: 0.9718 - val_loss: 0.2647 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1401 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9524\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1268 - out_1_loss: 0.0782 - out_2_loss: 0.0487 - out_1_acc: 0.9563 - out_2_acc: 0.9727 - val_loss: 0.2608 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1375 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9514\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1260 - out_1_loss: 0.0780 - out_2_loss: 0.0480 - out_1_acc: 0.9575 - out_2_acc: 0.9735 - val_loss: 0.2658 - val_out_1_loss: 0.1250 - val_out_2_loss: 0.1408 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1254 - out_1_loss: 0.0773 - out_2_loss: 0.0481 - out_1_acc: 0.9572 - out_2_acc: 0.9731 - val_loss: 0.2643 - val_out_1_loss: 0.1242 - val_out_2_loss: 0.1401 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1244 - out_1_loss: 0.0768 - out_2_loss: 0.0476 - out_1_acc: 0.9577 - out_2_acc: 0.9736 - val_loss: 0.2655 - val_out_1_loss: 0.1251 - val_out_2_loss: 0.1404 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9508\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1244 - out_1_loss: 0.0767 - out_2_loss: 0.0476 - out_1_acc: 0.9576 - out_2_acc: 0.9735 - val_loss: 0.2676 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1429 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9511\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1235 - out_1_loss: 0.0764 - out_2_loss: 0.0471 - out_1_acc: 0.9581 - out_2_acc: 0.9739 - val_loss: 0.2686 - val_out_1_loss: 0.1239 - val_out_2_loss: 0.1447 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9510\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1235 - out_1_loss: 0.0762 - out_2_loss: 0.0473 - out_1_acc: 0.9582 - out_2_acc: 0.9737 - val_loss: 0.2688 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9513\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1225 - out_1_loss: 0.0757 - out_2_loss: 0.0468 - out_1_acc: 0.9584 - out_2_acc: 0.9738 - val_loss: 0.2717 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1470 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9521\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1220 - out_1_loss: 0.0754 - out_2_loss: 0.0466 - out_1_acc: 0.9588 - out_2_acc: 0.9739 - val_loss: 0.2737 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1483 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1223 - out_1_loss: 0.0753 - out_2_loss: 0.0470 - out_1_acc: 0.9584 - out_2_acc: 0.9741 - val_loss: 0.2740 - val_out_1_loss: 0.1261 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9511\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1209 - out_1_loss: 0.0746 - out_2_loss: 0.0462 - out_1_acc: 0.9591 - out_2_acc: 0.9747 - val_loss: 0.2771 - val_out_1_loss: 0.1273 - val_out_2_loss: 0.1497 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1213 - out_1_loss: 0.0747 - out_2_loss: 0.0466 - out_1_acc: 0.9587 - out_2_acc: 0.9745 - val_loss: 0.2757 - val_out_1_loss: 0.1266 - val_out_2_loss: 0.1491 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1214 - out_1_loss: 0.0744 - out_2_loss: 0.0470 - out_1_acc: 0.9594 - out_2_acc: 0.9742 - val_loss: 0.2764 - val_out_1_loss: 0.1277 - val_out_2_loss: 0.1487 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9517\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1217 - out_1_loss: 0.0746 - out_2_loss: 0.0470 - out_1_acc: 0.9595 - out_2_acc: 0.9742 - val_loss: 0.2787 - val_out_1_loss: 0.1270 - val_out_2_loss: 0.1517 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9517\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1212 - out_1_loss: 0.0742 - out_2_loss: 0.0469 - out_1_acc: 0.9593 - out_2_acc: 0.9739 - val_loss: 0.2797 - val_out_1_loss: 0.1291 - val_out_2_loss: 0.1506 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1200 - out_1_loss: 0.0740 - out_2_loss: 0.0460 - out_1_acc: 0.9592 - out_2_acc: 0.9747 - val_loss: 0.2773 - val_out_1_loss: 0.1276 - val_out_2_loss: 0.1497 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9512\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1196 - out_1_loss: 0.0737 - out_2_loss: 0.0458 - out_1_acc: 0.9595 - out_2_acc: 0.9746 - val_loss: 0.2829 - val_out_1_loss: 0.1288 - val_out_2_loss: 0.1541 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9514\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1191 - out_1_loss: 0.0739 - out_2_loss: 0.0452 - out_1_acc: 0.9594 - out_2_acc: 0.9748 - val_loss: 0.2829 - val_out_1_loss: 0.1302 - val_out_2_loss: 0.1527 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9505\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1176 - out_1_loss: 0.0729 - out_2_loss: 0.0447 - out_1_acc: 0.9604 - out_2_acc: 0.9749 - val_loss: 0.2809 - val_out_1_loss: 0.1309 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1179 - out_1_loss: 0.0736 - out_2_loss: 0.0443 - out_1_acc: 0.9600 - out_2_acc: 0.9757 - val_loss: 0.2821 - val_out_1_loss: 0.1308 - val_out_2_loss: 0.1513 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9519\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1174 - out_1_loss: 0.0731 - out_2_loss: 0.0443 - out_1_acc: 0.9603 - out_2_acc: 0.9758 - val_loss: 0.2846 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1525 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1168 - out_1_loss: 0.0728 - out_2_loss: 0.0440 - out_1_acc: 0.9604 - out_2_acc: 0.9756 - val_loss: 0.2839 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1527 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9519\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1158 - out_1_loss: 0.0724 - out_2_loss: 0.0434 - out_1_acc: 0.9603 - out_2_acc: 0.9762 - val_loss: 0.2870 - val_out_1_loss: 0.1322 - val_out_2_loss: 0.1548 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9517\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1154 - out_1_loss: 0.0727 - out_2_loss: 0.0427 - out_1_acc: 0.9606 - out_2_acc: 0.9763 - val_loss: 0.2897 - val_out_1_loss: 0.1327 - val_out_2_loss: 0.1570 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9521\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1159 - out_1_loss: 0.0727 - out_2_loss: 0.0432 - out_1_acc: 0.9607 - out_2_acc: 0.9763 - val_loss: 0.2899 - val_out_1_loss: 0.1341 - val_out_2_loss: 0.1558 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1149 - out_1_loss: 0.0723 - out_2_loss: 0.0426 - out_1_acc: 0.9606 - out_2_acc: 0.9770 - val_loss: 0.2890 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1560 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1140 - out_1_loss: 0.0718 - out_2_loss: 0.0422 - out_1_acc: 0.9608 - out_2_acc: 0.9772 - val_loss: 0.2911 - val_out_1_loss: 0.1340 - val_out_2_loss: 0.1570 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9515\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1124 - out_1_loss: 0.0707 - out_2_loss: 0.0417 - out_1_acc: 0.9618 - out_2_acc: 0.9778 - val_loss: 0.2950 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1597 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1116 - out_1_loss: 0.0707 - out_2_loss: 0.0409 - out_1_acc: 0.9617 - out_2_acc: 0.9782 - val_loss: 0.2979 - val_out_1_loss: 0.1369 - val_out_2_loss: 0.1610 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9514\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1104 - out_1_loss: 0.0698 - out_2_loss: 0.0406 - out_1_acc: 0.9619 - out_2_acc: 0.9779 - val_loss: 0.2969 - val_out_1_loss: 0.1362 - val_out_2_loss: 0.1606 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9519\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1103 - out_1_loss: 0.0696 - out_2_loss: 0.0407 - out_1_acc: 0.9622 - out_2_acc: 0.9783 - val_loss: 0.3017 - val_out_1_loss: 0.1381 - val_out_2_loss: 0.1635 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9517\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1099 - out_1_loss: 0.0694 - out_2_loss: 0.0405 - out_1_acc: 0.9626 - out_2_acc: 0.9785 - val_loss: 0.3017 - val_out_1_loss: 0.1380 - val_out_2_loss: 0.1637 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9524\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1086 - out_1_loss: 0.0689 - out_2_loss: 0.0397 - out_1_acc: 0.9625 - out_2_acc: 0.9792 - val_loss: 0.3032 - val_out_1_loss: 0.1397 - val_out_2_loss: 0.1635 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9516\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1081 - out_1_loss: 0.0682 - out_2_loss: 0.0399 - out_1_acc: 0.9632 - out_2_acc: 0.9793 - val_loss: 0.3059 - val_out_1_loss: 0.1405 - val_out_2_loss: 0.1655 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9515\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1082 - out_1_loss: 0.0686 - out_2_loss: 0.0396 - out_1_acc: 0.9631 - out_2_acc: 0.9791 - val_loss: 0.3084 - val_out_1_loss: 0.1415 - val_out_2_loss: 0.1669 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9520\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1080 - out_1_loss: 0.0686 - out_2_loss: 0.0394 - out_1_acc: 0.9633 - out_2_acc: 0.9793 - val_loss: 0.3082 - val_out_1_loss: 0.1419 - val_out_2_loss: 0.1663 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1074 - out_1_loss: 0.0680 - out_2_loss: 0.0393 - out_1_acc: 0.9634 - out_2_acc: 0.9793 - val_loss: 0.3133 - val_out_1_loss: 0.1440 - val_out_2_loss: 0.1693 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9515\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1071 - out_1_loss: 0.0676 - out_2_loss: 0.0395 - out_1_acc: 0.9637 - out_2_acc: 0.9794 - val_loss: 0.3113 - val_out_1_loss: 0.1415 - val_out_2_loss: 0.1698 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9518\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1074 - out_1_loss: 0.0675 - out_2_loss: 0.0399 - out_1_acc: 0.9635 - out_2_acc: 0.9789 - val_loss: 0.3115 - val_out_1_loss: 0.1421 - val_out_2_loss: 0.1695 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1070 - out_1_loss: 0.0671 - out_2_loss: 0.0399 - out_1_acc: 0.9645 - out_2_acc: 0.9791 - val_loss: 0.3166 - val_out_1_loss: 0.1446 - val_out_2_loss: 0.1721 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9516\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1065 - out_1_loss: 0.0671 - out_2_loss: 0.0394 - out_1_acc: 0.9640 - out_2_acc: 0.9797 - val_loss: 0.3170 - val_out_1_loss: 0.1451 - val_out_2_loss: 0.1719 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9520\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(6)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2980 - out_1_loss: 0.1384 - out_2_loss: 0.1596 - out_1_acc: 0.9389 - out_2_acc: 0.9523\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 100), (No 52400       input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 100)       52400       input_11[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 293,880\n",
      "Trainable params: 293,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3689 - out_1_loss: 3.6832 - out_2_loss: 3.6857 - out_1_acc: 0.0270 - out_2_acc: 0.0471WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.107926). Check your callbacks.\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 6.5755 - out_1_loss: 3.3138 - out_2_loss: 3.2616 - out_1_acc: 0.3046 - out_2_acc: 0.3485 - val_loss: 5.1501 - val_out_1_loss: 2.6214 - val_out_2_loss: 2.5287 - val_out_1_acc: 0.3497 - val_out_2_acc: 0.4183\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 4.1542 - out_1_loss: 2.2002 - out_2_loss: 1.9540 - out_1_acc: 0.4648 - out_2_acc: 0.5462 - val_loss: 3.1497 - val_out_1_loss: 1.8251 - val_out_2_loss: 1.3246 - val_out_1_acc: 0.5523 - val_out_2_acc: 0.6871\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 2.3180 - out_1_loss: 1.4207 - out_2_loss: 0.8973 - out_1_acc: 0.6556 - out_2_acc: 0.7981 - val_loss: 1.5238 - val_out_1_loss: 0.9422 - val_out_2_loss: 0.5816 - val_out_1_acc: 0.7862 - val_out_2_acc: 0.8684\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 1.1057 - out_1_loss: 0.6805 - out_2_loss: 0.4252 - out_1_acc: 0.8544 - out_2_acc: 0.9076 - val_loss: 0.8240 - val_out_1_loss: 0.5027 - val_out_2_loss: 0.3212 - val_out_1_acc: 0.8979 - val_out_2_acc: 0.9279\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.6754 - out_1_loss: 0.4211 - out_2_loss: 0.2543 - out_1_acc: 0.9112 - out_2_acc: 0.9393 - val_loss: 0.5843 - val_out_1_loss: 0.3608 - val_out_2_loss: 0.2235 - val_out_1_acc: 0.9226 - val_out_2_acc: 0.9416\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.4999 - out_1_loss: 0.3139 - out_2_loss: 0.1859 - out_1_acc: 0.9271 - out_2_acc: 0.9478 - val_loss: 0.4589 - val_out_1_loss: 0.2795 - val_out_2_loss: 0.1794 - val_out_1_acc: 0.9320 - val_out_2_acc: 0.9490\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3972 - out_1_loss: 0.2456 - out_2_loss: 0.1517 - out_1_acc: 0.9337 - out_2_acc: 0.9513 - val_loss: 0.3802 - val_out_1_loss: 0.2253 - val_out_2_loss: 0.1549 - val_out_1_acc: 0.9365 - val_out_2_acc: 0.9507\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3303 - out_1_loss: 0.1994 - out_2_loss: 0.1309 - out_1_acc: 0.9371 - out_2_acc: 0.9523 - val_loss: 0.3280 - val_out_1_loss: 0.1899 - val_out_2_loss: 0.1381 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9510\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2866 - out_1_loss: 0.1695 - out_2_loss: 0.1172 - out_1_acc: 0.9394 - out_2_acc: 0.9525 - val_loss: 0.2928 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9510\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2569 - out_1_loss: 0.1496 - out_2_loss: 0.1073 - out_1_acc: 0.9404 - out_2_acc: 0.9526 - val_loss: 0.2670 - val_out_1_loss: 0.1505 - val_out_2_loss: 0.1166 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9512\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2362 - out_1_loss: 0.1360 - out_2_loss: 0.1002 - out_1_acc: 0.9410 - out_2_acc: 0.9534 - val_loss: 0.2490 - val_out_1_loss: 0.1388 - val_out_2_loss: 0.1102 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9517\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2220 - out_1_loss: 0.1265 - out_2_loss: 0.0955 - out_1_acc: 0.9415 - out_2_acc: 0.9536 - val_loss: 0.2357 - val_out_1_loss: 0.1301 - val_out_2_loss: 0.1055 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2119 - out_1_loss: 0.1199 - out_2_loss: 0.0919 - out_1_acc: 0.9417 - out_2_acc: 0.9542 - val_loss: 0.2268 - val_out_1_loss: 0.1236 - val_out_2_loss: 0.1032 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9505\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2046 - out_1_loss: 0.1152 - out_2_loss: 0.0893 - out_1_acc: 0.9417 - out_2_acc: 0.9543 - val_loss: 0.2202 - val_out_1_loss: 0.1192 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9505\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1993 - out_1_loss: 0.1117 - out_2_loss: 0.0875 - out_1_acc: 0.9422 - out_2_acc: 0.9548 - val_loss: 0.2150 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9503\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1952 - out_1_loss: 0.1090 - out_2_loss: 0.0862 - out_1_acc: 0.9426 - out_2_acc: 0.9551 - val_loss: 0.2115 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9511\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1920 - out_1_loss: 0.1070 - out_2_loss: 0.0850 - out_1_acc: 0.9429 - out_2_acc: 0.9554 - val_loss: 0.2089 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9508\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1892 - out_1_loss: 0.1054 - out_2_loss: 0.0838 - out_1_acc: 0.9431 - out_2_acc: 0.9558 - val_loss: 0.2070 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1871 - out_1_loss: 0.1042 - out_2_loss: 0.0830 - out_1_acc: 0.9434 - out_2_acc: 0.9562 - val_loss: 0.2062 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1856 - out_1_loss: 0.1032 - out_2_loss: 0.0825 - out_1_acc: 0.9436 - out_2_acc: 0.9562 - val_loss: 0.2055 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1843 - out_1_loss: 0.1024 - out_2_loss: 0.0819 - out_1_acc: 0.9440 - out_2_acc: 0.9560 - val_loss: 0.2043 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1831 - out_1_loss: 0.1018 - out_2_loss: 0.0813 - out_1_acc: 0.9441 - out_2_acc: 0.9563 - val_loss: 0.2035 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0946 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1817 - out_1_loss: 0.1012 - out_2_loss: 0.0805 - out_1_acc: 0.9438 - out_2_acc: 0.9565 - val_loss: 0.2036 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1805 - out_1_loss: 0.1006 - out_2_loss: 0.0799 - out_1_acc: 0.9441 - out_2_acc: 0.9570 - val_loss: 0.2028 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.0948 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9514\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1793 - out_1_loss: 0.0999 - out_2_loss: 0.0794 - out_1_acc: 0.9447 - out_2_acc: 0.9572 - val_loss: 0.2017 - val_out_1_loss: 0.1074 - val_out_2_loss: 0.0943 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1781 - out_1_loss: 0.0993 - out_2_loss: 0.0788 - out_1_acc: 0.9449 - out_2_acc: 0.9576 - val_loss: 0.2011 - val_out_1_loss: 0.1070 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1769 - out_1_loss: 0.0988 - out_2_loss: 0.0781 - out_1_acc: 0.9450 - out_2_acc: 0.9577 - val_loss: 0.2009 - val_out_1_loss: 0.1069 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1757 - out_1_loss: 0.0983 - out_2_loss: 0.0774 - out_1_acc: 0.9451 - out_2_acc: 0.9579 - val_loss: 0.2017 - val_out_1_loss: 0.1070 - val_out_2_loss: 0.0946 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1747 - out_1_loss: 0.0979 - out_2_loss: 0.0768 - out_1_acc: 0.9450 - out_2_acc: 0.9588 - val_loss: 0.2022 - val_out_1_loss: 0.1069 - val_out_2_loss: 0.0953 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9514\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1737 - out_1_loss: 0.0975 - out_2_loss: 0.0762 - out_1_acc: 0.9453 - out_2_acc: 0.9587 - val_loss: 0.2024 - val_out_1_loss: 0.1067 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9520\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1729 - out_1_loss: 0.0972 - out_2_loss: 0.0758 - out_1_acc: 0.9452 - out_2_acc: 0.9590 - val_loss: 0.2028 - val_out_1_loss: 0.1066 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9522\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1722 - out_1_loss: 0.0968 - out_2_loss: 0.0754 - out_1_acc: 0.9455 - out_2_acc: 0.9591 - val_loss: 0.2029 - val_out_1_loss: 0.1066 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1715 - out_1_loss: 0.0965 - out_2_loss: 0.0750 - out_1_acc: 0.9457 - out_2_acc: 0.9592 - val_loss: 0.2025 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0961 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1708 - out_1_loss: 0.0962 - out_2_loss: 0.0747 - out_1_acc: 0.9459 - out_2_acc: 0.9598 - val_loss: 0.2025 - val_out_1_loss: 0.1065 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1701 - out_1_loss: 0.0959 - out_2_loss: 0.0742 - out_1_acc: 0.9460 - out_2_acc: 0.9598 - val_loss: 0.2020 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9528\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1695 - out_1_loss: 0.0956 - out_2_loss: 0.0739 - out_1_acc: 0.9462 - out_2_acc: 0.9600 - val_loss: 0.2022 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1688 - out_1_loss: 0.0954 - out_2_loss: 0.0734 - out_1_acc: 0.9463 - out_2_acc: 0.9605 - val_loss: 0.2021 - val_out_1_loss: 0.1064 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1680 - out_1_loss: 0.0951 - out_2_loss: 0.0729 - out_1_acc: 0.9467 - out_2_acc: 0.9605 - val_loss: 0.2028 - val_out_1_loss: 0.1063 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9519\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1676 - out_1_loss: 0.0949 - out_2_loss: 0.0727 - out_1_acc: 0.9469 - out_2_acc: 0.9607 - val_loss: 0.2044 - val_out_1_loss: 0.1066 - val_out_2_loss: 0.0978 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1673 - out_1_loss: 0.0947 - out_2_loss: 0.0727 - out_1_acc: 0.9469 - out_2_acc: 0.9605 - val_loss: 0.2048 - val_out_1_loss: 0.1068 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1669 - out_1_loss: 0.0944 - out_2_loss: 0.0724 - out_1_acc: 0.9473 - out_2_acc: 0.9605 - val_loss: 0.2055 - val_out_1_loss: 0.1070 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1666 - out_1_loss: 0.0943 - out_2_loss: 0.0724 - out_1_acc: 0.9475 - out_2_acc: 0.9607 - val_loss: 0.2063 - val_out_1_loss: 0.1071 - val_out_2_loss: 0.0992 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1661 - out_1_loss: 0.0941 - out_2_loss: 0.0720 - out_1_acc: 0.9478 - out_2_acc: 0.9608 - val_loss: 0.2067 - val_out_1_loss: 0.1067 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1659 - out_1_loss: 0.0939 - out_2_loss: 0.0720 - out_1_acc: 0.9478 - out_2_acc: 0.9605 - val_loss: 0.2070 - val_out_1_loss: 0.1072 - val_out_2_loss: 0.0998 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1654 - out_1_loss: 0.0937 - out_2_loss: 0.0717 - out_1_acc: 0.9477 - out_2_acc: 0.9606 - val_loss: 0.2089 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.1013 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9530\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1646 - out_1_loss: 0.0935 - out_2_loss: 0.0711 - out_1_acc: 0.9471 - out_2_acc: 0.9611 - val_loss: 0.2060 - val_out_1_loss: 0.1072 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9529\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1635 - out_1_loss: 0.0933 - out_2_loss: 0.0702 - out_1_acc: 0.9476 - out_2_acc: 0.9611 - val_loss: 0.2054 - val_out_1_loss: 0.1073 - val_out_2_loss: 0.0981 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9526\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1620 - out_1_loss: 0.0928 - out_2_loss: 0.0692 - out_1_acc: 0.9480 - out_2_acc: 0.9625 - val_loss: 0.2066 - val_out_1_loss: 0.1074 - val_out_2_loss: 0.0992 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9529\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1609 - out_1_loss: 0.0924 - out_2_loss: 0.0685 - out_1_acc: 0.9481 - out_2_acc: 0.9625 - val_loss: 0.2072 - val_out_1_loss: 0.1073 - val_out_2_loss: 0.0999 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9527\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1600 - out_1_loss: 0.0923 - out_2_loss: 0.0677 - out_1_acc: 0.9479 - out_2_acc: 0.9632 - val_loss: 0.2087 - val_out_1_loss: 0.1076 - val_out_2_loss: 0.1011 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1591 - out_1_loss: 0.0920 - out_2_loss: 0.0671 - out_1_acc: 0.9483 - out_2_acc: 0.9629 - val_loss: 0.2118 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1587 - out_1_loss: 0.0918 - out_2_loss: 0.0669 - out_1_acc: 0.9486 - out_2_acc: 0.9634 - val_loss: 0.2129 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.1045 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1578 - out_1_loss: 0.0915 - out_2_loss: 0.0663 - out_1_acc: 0.9484 - out_2_acc: 0.9636 - val_loss: 0.2138 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1571 - out_1_loss: 0.0913 - out_2_loss: 0.0658 - out_1_acc: 0.9487 - out_2_acc: 0.9641 - val_loss: 0.2159 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.1067 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1570 - out_1_loss: 0.0912 - out_2_loss: 0.0659 - out_1_acc: 0.9482 - out_2_acc: 0.9640 - val_loss: 0.2173 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1072 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1568 - out_1_loss: 0.0913 - out_2_loss: 0.0656 - out_1_acc: 0.9482 - out_2_acc: 0.9639 - val_loss: 0.2221 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1112 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1569 - out_1_loss: 0.0909 - out_2_loss: 0.0660 - out_1_acc: 0.9490 - out_2_acc: 0.9641 - val_loss: 0.2191 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1090 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1570 - out_1_loss: 0.0908 - out_2_loss: 0.0662 - out_1_acc: 0.9491 - out_2_acc: 0.9639 - val_loss: 0.2194 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.1085 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9510\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1563 - out_1_loss: 0.0905 - out_2_loss: 0.0658 - out_1_acc: 0.9494 - out_2_acc: 0.9641 - val_loss: 0.2168 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1068 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1551 - out_1_loss: 0.0903 - out_2_loss: 0.0648 - out_1_acc: 0.9493 - out_2_acc: 0.9640 - val_loss: 0.2162 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.1065 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1543 - out_1_loss: 0.0902 - out_2_loss: 0.0642 - out_1_acc: 0.9493 - out_2_acc: 0.9638 - val_loss: 0.2143 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.1047 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1539 - out_1_loss: 0.0898 - out_2_loss: 0.0640 - out_1_acc: 0.9498 - out_2_acc: 0.9641 - val_loss: 0.2127 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.1030 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9527\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1520 - out_1_loss: 0.0895 - out_2_loss: 0.0625 - out_1_acc: 0.9497 - out_2_acc: 0.9647 - val_loss: 0.2158 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1512 - out_1_loss: 0.0894 - out_2_loss: 0.0618 - out_1_acc: 0.9497 - out_2_acc: 0.9653 - val_loss: 0.2156 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1505 - out_1_loss: 0.0892 - out_2_loss: 0.0613 - out_1_acc: 0.9501 - out_2_acc: 0.9662 - val_loss: 0.2181 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.1068 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1505 - out_1_loss: 0.0890 - out_2_loss: 0.0615 - out_1_acc: 0.9500 - out_2_acc: 0.9661 - val_loss: 0.2205 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1081 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9504\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1499 - out_1_loss: 0.0887 - out_2_loss: 0.0612 - out_1_acc: 0.9506 - out_2_acc: 0.9659 - val_loss: 0.2220 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1495 - out_1_loss: 0.0886 - out_2_loss: 0.0608 - out_1_acc: 0.9506 - out_2_acc: 0.9661 - val_loss: 0.2223 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1100 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9505\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1486 - out_1_loss: 0.0882 - out_2_loss: 0.0604 - out_1_acc: 0.9510 - out_2_acc: 0.9668 - val_loss: 0.2244 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.1120 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9511\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1477 - out_1_loss: 0.0877 - out_2_loss: 0.0600 - out_1_acc: 0.9510 - out_2_acc: 0.9667 - val_loss: 0.2253 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.1133 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1472 - out_1_loss: 0.0874 - out_2_loss: 0.0598 - out_1_acc: 0.9513 - out_2_acc: 0.9673 - val_loss: 0.2268 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1140 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9510\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1470 - out_1_loss: 0.0873 - out_2_loss: 0.0597 - out_1_acc: 0.9513 - out_2_acc: 0.9664 - val_loss: 0.2280 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1149 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9512\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1468 - out_1_loss: 0.0872 - out_2_loss: 0.0596 - out_1_acc: 0.9515 - out_2_acc: 0.9668 - val_loss: 0.2292 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1163 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1456 - out_1_loss: 0.0867 - out_2_loss: 0.0589 - out_1_acc: 0.9518 - out_2_acc: 0.9665 - val_loss: 0.2279 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1155 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1449 - out_1_loss: 0.0865 - out_2_loss: 0.0584 - out_1_acc: 0.9519 - out_2_acc: 0.9676 - val_loss: 0.2287 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.1157 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1453 - out_1_loss: 0.0865 - out_2_loss: 0.0588 - out_1_acc: 0.9520 - out_2_acc: 0.9676 - val_loss: 0.2311 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1180 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1452 - out_1_loss: 0.0865 - out_2_loss: 0.0587 - out_1_acc: 0.9520 - out_2_acc: 0.9677 - val_loss: 0.2300 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1166 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1448 - out_1_loss: 0.0864 - out_2_loss: 0.0584 - out_1_acc: 0.9515 - out_2_acc: 0.9678 - val_loss: 0.2282 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1150 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1446 - out_1_loss: 0.0863 - out_2_loss: 0.0583 - out_1_acc: 0.9519 - out_2_acc: 0.9674 - val_loss: 0.2294 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1164 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.1438 - out_1_loss: 0.0858 - out_2_loss: 0.0580 - out_1_acc: 0.9525 - out_2_acc: 0.9678 - val_loss: 0.2301 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.1168 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9517\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1440 - out_1_loss: 0.0858 - out_2_loss: 0.0582 - out_1_acc: 0.9525 - out_2_acc: 0.9675 - val_loss: 0.2310 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1172 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1440 - out_1_loss: 0.0858 - out_2_loss: 0.0581 - out_1_acc: 0.9525 - out_2_acc: 0.9676 - val_loss: 0.2340 - val_out_1_loss: 0.1144 - val_out_2_loss: 0.1195 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9521\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1443 - out_1_loss: 0.0859 - out_2_loss: 0.0584 - out_1_acc: 0.9522 - out_2_acc: 0.9672 - val_loss: 0.2331 - val_out_1_loss: 0.1143 - val_out_2_loss: 0.1188 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1431 - out_1_loss: 0.0856 - out_2_loss: 0.0575 - out_1_acc: 0.9521 - out_2_acc: 0.9675 - val_loss: 0.2319 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.1178 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9514\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1416 - out_1_loss: 0.0852 - out_2_loss: 0.0565 - out_1_acc: 0.9525 - out_2_acc: 0.9678 - val_loss: 0.2343 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1184 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9519\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1412 - out_1_loss: 0.0851 - out_2_loss: 0.0561 - out_1_acc: 0.9526 - out_2_acc: 0.9689 - val_loss: 0.2342 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.1189 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9509\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1404 - out_1_loss: 0.0844 - out_2_loss: 0.0561 - out_1_acc: 0.9529 - out_2_acc: 0.9684 - val_loss: 0.2354 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1201 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9515\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1398 - out_1_loss: 0.0842 - out_2_loss: 0.0556 - out_1_acc: 0.9531 - out_2_acc: 0.9685 - val_loss: 0.2382 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1227 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9504\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1399 - out_1_loss: 0.0842 - out_2_loss: 0.0557 - out_1_acc: 0.9537 - out_2_acc: 0.9684 - val_loss: 0.2410 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.1254 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9501\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1396 - out_1_loss: 0.0837 - out_2_loss: 0.0560 - out_1_acc: 0.9537 - out_2_acc: 0.9683 - val_loss: 0.2411 - val_out_1_loss: 0.1163 - val_out_2_loss: 0.1248 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9516\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1385 - out_1_loss: 0.0835 - out_2_loss: 0.0550 - out_1_acc: 0.9540 - out_2_acc: 0.9692 - val_loss: 0.2434 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1277 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9515\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1373 - out_1_loss: 0.0826 - out_2_loss: 0.0546 - out_1_acc: 0.9540 - out_2_acc: 0.9697 - val_loss: 0.2399 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1239 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1362 - out_1_loss: 0.0822 - out_2_loss: 0.0540 - out_1_acc: 0.9546 - out_2_acc: 0.9695 - val_loss: 0.2384 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.1216 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9524\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1350 - out_1_loss: 0.0819 - out_2_loss: 0.0531 - out_1_acc: 0.9548 - out_2_acc: 0.9701 - val_loss: 0.2413 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1247 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9526\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1345 - out_1_loss: 0.0817 - out_2_loss: 0.0528 - out_1_acc: 0.9551 - out_2_acc: 0.9703 - val_loss: 0.2427 - val_out_1_loss: 0.1173 - val_out_2_loss: 0.1255 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9507\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1343 - out_1_loss: 0.0814 - out_2_loss: 0.0529 - out_1_acc: 0.9549 - out_2_acc: 0.9701 - val_loss: 0.2453 - val_out_1_loss: 0.1186 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1340 - out_1_loss: 0.0813 - out_2_loss: 0.0527 - out_1_acc: 0.9547 - out_2_acc: 0.9700 - val_loss: 0.2433 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1249 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1333 - out_1_loss: 0.0810 - out_2_loss: 0.0523 - out_1_acc: 0.9557 - out_2_acc: 0.9701 - val_loss: 0.2443 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1262 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1324 - out_1_loss: 0.0808 - out_2_loss: 0.0516 - out_1_acc: 0.9547 - out_2_acc: 0.9705 - val_loss: 0.2451 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1266 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9514\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1317 - out_1_loss: 0.0806 - out_2_loss: 0.0510 - out_1_acc: 0.9548 - out_2_acc: 0.9706 - val_loss: 0.2468 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.1280 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9513\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1305 - out_1_loss: 0.0803 - out_2_loss: 0.0503 - out_1_acc: 0.9554 - out_2_acc: 0.9715 - val_loss: 0.2456 - val_out_1_loss: 0.1186 - val_out_2_loss: 0.1270 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9511\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1292 - out_1_loss: 0.0795 - out_2_loss: 0.0497 - out_1_acc: 0.9563 - out_2_acc: 0.9716 - val_loss: 0.2468 - val_out_1_loss: 0.1192 - val_out_2_loss: 0.1277 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9520\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1281 - out_1_loss: 0.0790 - out_2_loss: 0.0491 - out_1_acc: 0.9559 - out_2_acc: 0.9720 - val_loss: 0.2514 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1320 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1275 - out_1_loss: 0.0787 - out_2_loss: 0.0488 - out_1_acc: 0.9559 - out_2_acc: 0.9719 - val_loss: 0.2518 - val_out_1_loss: 0.1203 - val_out_2_loss: 0.1316 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9528\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1262 - out_1_loss: 0.0786 - out_2_loss: 0.0476 - out_1_acc: 0.9564 - out_2_acc: 0.9732 - val_loss: 0.2533 - val_out_1_loss: 0.1206 - val_out_2_loss: 0.1326 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1254 - out_1_loss: 0.0781 - out_2_loss: 0.0473 - out_1_acc: 0.9563 - out_2_acc: 0.9730 - val_loss: 0.2568 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.1358 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1250 - out_1_loss: 0.0776 - out_2_loss: 0.0475 - out_1_acc: 0.9575 - out_2_acc: 0.9736 - val_loss: 0.2576 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1363 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9507\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1245 - out_1_loss: 0.0775 - out_2_loss: 0.0469 - out_1_acc: 0.9576 - out_2_acc: 0.9737 - val_loss: 0.2601 - val_out_1_loss: 0.1224 - val_out_2_loss: 0.1377 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1233 - out_1_loss: 0.0770 - out_2_loss: 0.0463 - out_1_acc: 0.9578 - out_2_acc: 0.9740 - val_loss: 0.2603 - val_out_1_loss: 0.1230 - val_out_2_loss: 0.1374 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9512\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1233 - out_1_loss: 0.0767 - out_2_loss: 0.0466 - out_1_acc: 0.9581 - out_2_acc: 0.9738 - val_loss: 0.2628 - val_out_1_loss: 0.1239 - val_out_2_loss: 0.1389 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9509\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1221 - out_1_loss: 0.0760 - out_2_loss: 0.0461 - out_1_acc: 0.9578 - out_2_acc: 0.9749 - val_loss: 0.2649 - val_out_1_loss: 0.1255 - val_out_2_loss: 0.1394 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9521\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1214 - out_1_loss: 0.0758 - out_2_loss: 0.0456 - out_1_acc: 0.9583 - out_2_acc: 0.9747 - val_loss: 0.2689 - val_out_1_loss: 0.1260 - val_out_2_loss: 0.1429 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1204 - out_1_loss: 0.0751 - out_2_loss: 0.0453 - out_1_acc: 0.9588 - out_2_acc: 0.9754 - val_loss: 0.2714 - val_out_1_loss: 0.1276 - val_out_2_loss: 0.1438 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1201 - out_1_loss: 0.0749 - out_2_loss: 0.0453 - out_1_acc: 0.9592 - out_2_acc: 0.9748 - val_loss: 0.2737 - val_out_1_loss: 0.1271 - val_out_2_loss: 0.1466 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9523\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1199 - out_1_loss: 0.0746 - out_2_loss: 0.0453 - out_1_acc: 0.9594 - out_2_acc: 0.9751 - val_loss: 0.2786 - val_out_1_loss: 0.1289 - val_out_2_loss: 0.1497 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1191 - out_1_loss: 0.0744 - out_2_loss: 0.0448 - out_1_acc: 0.9595 - out_2_acc: 0.9754 - val_loss: 0.2816 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1522 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1183 - out_1_loss: 0.0735 - out_2_loss: 0.0448 - out_1_acc: 0.9599 - out_2_acc: 0.9757 - val_loss: 0.2817 - val_out_1_loss: 0.1294 - val_out_2_loss: 0.1522 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1189 - out_1_loss: 0.0733 - out_2_loss: 0.0457 - out_1_acc: 0.9604 - out_2_acc: 0.9747 - val_loss: 0.2832 - val_out_1_loss: 0.1308 - val_out_2_loss: 0.1525 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9520\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1177 - out_1_loss: 0.0733 - out_2_loss: 0.0444 - out_1_acc: 0.9602 - out_2_acc: 0.9754 - val_loss: 0.2823 - val_out_1_loss: 0.1308 - val_out_2_loss: 0.1516 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1172 - out_1_loss: 0.0731 - out_2_loss: 0.0441 - out_1_acc: 0.9606 - out_2_acc: 0.9760 - val_loss: 0.2853 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1531 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1166 - out_1_loss: 0.0726 - out_2_loss: 0.0441 - out_1_acc: 0.9609 - out_2_acc: 0.9759 - val_loss: 0.2816 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1495 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1168 - out_1_loss: 0.0725 - out_2_loss: 0.0442 - out_1_acc: 0.9611 - out_2_acc: 0.9757 - val_loss: 0.2821 - val_out_1_loss: 0.1317 - val_out_2_loss: 0.1504 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1166 - out_1_loss: 0.0724 - out_2_loss: 0.0442 - out_1_acc: 0.9607 - out_2_acc: 0.9763 - val_loss: 0.2822 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1159 - out_1_loss: 0.0722 - out_2_loss: 0.0437 - out_1_acc: 0.9606 - out_2_acc: 0.9759 - val_loss: 0.2861 - val_out_1_loss: 0.1324 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9517\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1160 - out_1_loss: 0.0723 - out_2_loss: 0.0437 - out_1_acc: 0.9608 - out_2_acc: 0.9760 - val_loss: 0.2854 - val_out_1_loss: 0.1332 - val_out_2_loss: 0.1522 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1160 - out_1_loss: 0.0723 - out_2_loss: 0.0437 - out_1_acc: 0.9609 - out_2_acc: 0.9756 - val_loss: 0.2857 - val_out_1_loss: 0.1325 - val_out_2_loss: 0.1533 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9504\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1156 - out_1_loss: 0.0722 - out_2_loss: 0.0434 - out_1_acc: 0.9606 - out_2_acc: 0.9763 - val_loss: 0.2876 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1534 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1148 - out_1_loss: 0.0722 - out_2_loss: 0.0426 - out_1_acc: 0.9608 - out_2_acc: 0.9764 - val_loss: 0.2895 - val_out_1_loss: 0.1337 - val_out_2_loss: 0.1558 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9514\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1139 - out_1_loss: 0.0715 - out_2_loss: 0.0424 - out_1_acc: 0.9613 - out_2_acc: 0.9770 - val_loss: 0.2910 - val_out_1_loss: 0.1348 - val_out_2_loss: 0.1562 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1135 - out_1_loss: 0.0711 - out_2_loss: 0.0424 - out_1_acc: 0.9618 - out_2_acc: 0.9768 - val_loss: 0.2955 - val_out_1_loss: 0.1363 - val_out_2_loss: 0.1592 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1130 - out_1_loss: 0.0711 - out_2_loss: 0.0418 - out_1_acc: 0.9621 - out_2_acc: 0.9775 - val_loss: 0.2947 - val_out_1_loss: 0.1375 - val_out_2_loss: 0.1572 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1124 - out_1_loss: 0.0706 - out_2_loss: 0.0418 - out_1_acc: 0.9615 - out_2_acc: 0.9773 - val_loss: 0.2952 - val_out_1_loss: 0.1366 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9520\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1114 - out_1_loss: 0.0698 - out_2_loss: 0.0416 - out_1_acc: 0.9621 - out_2_acc: 0.9776 - val_loss: 0.2966 - val_out_1_loss: 0.1380 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1106 - out_1_loss: 0.0694 - out_2_loss: 0.0412 - out_1_acc: 0.9628 - out_2_acc: 0.9776 - val_loss: 0.2954 - val_out_1_loss: 0.1367 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9517\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1097 - out_1_loss: 0.0684 - out_2_loss: 0.0412 - out_1_acc: 0.9633 - out_2_acc: 0.9780 - val_loss: 0.2964 - val_out_1_loss: 0.1382 - val_out_2_loss: 0.1582 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9500\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1091 - out_1_loss: 0.0682 - out_2_loss: 0.0409 - out_1_acc: 0.9634 - out_2_acc: 0.9780 - val_loss: 0.2982 - val_out_1_loss: 0.1379 - val_out_2_loss: 0.1603 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1081 - out_1_loss: 0.0670 - out_2_loss: 0.0411 - out_1_acc: 0.9642 - out_2_acc: 0.9775 - val_loss: 0.2973 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1576 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1072 - out_1_loss: 0.0671 - out_2_loss: 0.0400 - out_1_acc: 0.9636 - out_2_acc: 0.9786 - val_loss: 0.2982 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1590 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9509\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1063 - out_1_loss: 0.0664 - out_2_loss: 0.0398 - out_1_acc: 0.9648 - out_2_acc: 0.9790 - val_loss: 0.2994 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1602 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9524\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1050 - out_1_loss: 0.0659 - out_2_loss: 0.0391 - out_1_acc: 0.9652 - out_2_acc: 0.9794 - val_loss: 0.3001 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1601 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9517\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1045 - out_1_loss: 0.0654 - out_2_loss: 0.0391 - out_1_acc: 0.9654 - out_2_acc: 0.9796 - val_loss: 0.3033 - val_out_1_loss: 0.1410 - val_out_2_loss: 0.1623 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1043 - out_1_loss: 0.0652 - out_2_loss: 0.0391 - out_1_acc: 0.9657 - out_2_acc: 0.9794 - val_loss: 0.3025 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1626 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9514\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1039 - out_1_loss: 0.0648 - out_2_loss: 0.0392 - out_1_acc: 0.9660 - out_2_acc: 0.9797 - val_loss: 0.3056 - val_out_1_loss: 0.1419 - val_out_2_loss: 0.1637 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9515\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1027 - out_1_loss: 0.0639 - out_2_loss: 0.0388 - out_1_acc: 0.9666 - out_2_acc: 0.9800 - val_loss: 0.3064 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1629 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9512\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1023 - out_1_loss: 0.0638 - out_2_loss: 0.0385 - out_1_acc: 0.9673 - out_2_acc: 0.9801 - val_loss: 0.3090 - val_out_1_loss: 0.1445 - val_out_2_loss: 0.1645 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9509\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1025 - out_1_loss: 0.0641 - out_2_loss: 0.0384 - out_1_acc: 0.9664 - out_2_acc: 0.9803 - val_loss: 0.3142 - val_out_1_loss: 0.1464 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9513\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1010 - out_1_loss: 0.0634 - out_2_loss: 0.0376 - out_1_acc: 0.9666 - out_2_acc: 0.9808 - val_loss: 0.3128 - val_out_1_loss: 0.1450 - val_out_2_loss: 0.1677 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9527\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1000 - out_1_loss: 0.0624 - out_2_loss: 0.0376 - out_1_acc: 0.9677 - out_2_acc: 0.9805 - val_loss: 0.3120 - val_out_1_loss: 0.1457 - val_out_2_loss: 0.1664 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0996 - out_1_loss: 0.0623 - out_2_loss: 0.0372 - out_1_acc: 0.9674 - out_2_acc: 0.9809 - val_loss: 0.3175 - val_out_1_loss: 0.1477 - val_out_2_loss: 0.1699 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9523\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0999 - out_1_loss: 0.0619 - out_2_loss: 0.0379 - out_1_acc: 0.9677 - out_2_acc: 0.9806 - val_loss: 0.3182 - val_out_1_loss: 0.1491 - val_out_2_loss: 0.1692 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9516\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1003 - out_1_loss: 0.0619 - out_2_loss: 0.0385 - out_1_acc: 0.9678 - out_2_acc: 0.9801 - val_loss: 0.3183 - val_out_1_loss: 0.1490 - val_out_2_loss: 0.1694 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0990 - out_1_loss: 0.0615 - out_2_loss: 0.0375 - out_1_acc: 0.9683 - out_2_acc: 0.9809 - val_loss: 0.3199 - val_out_1_loss: 0.1480 - val_out_2_loss: 0.1719 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9500\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0979 - out_1_loss: 0.0613 - out_2_loss: 0.0366 - out_1_acc: 0.9682 - out_2_acc: 0.9814 - val_loss: 0.3205 - val_out_1_loss: 0.1489 - val_out_2_loss: 0.1716 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9512\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0964 - out_1_loss: 0.0605 - out_2_loss: 0.0360 - out_1_acc: 0.9690 - out_2_acc: 0.9821 - val_loss: 0.3230 - val_out_1_loss: 0.1499 - val_out_2_loss: 0.1732 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0958 - out_1_loss: 0.0606 - out_2_loss: 0.0352 - out_1_acc: 0.9688 - out_2_acc: 0.9825 - val_loss: 0.3258 - val_out_1_loss: 0.1505 - val_out_2_loss: 0.1753 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0955 - out_1_loss: 0.0602 - out_2_loss: 0.0352 - out_1_acc: 0.9690 - out_2_acc: 0.9822 - val_loss: 0.3225 - val_out_1_loss: 0.1504 - val_out_2_loss: 0.1721 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9515\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0958 - out_1_loss: 0.0606 - out_2_loss: 0.0352 - out_1_acc: 0.9689 - out_2_acc: 0.9826 - val_loss: 0.3260 - val_out_1_loss: 0.1518 - val_out_2_loss: 0.1742 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0963 - out_1_loss: 0.0605 - out_2_loss: 0.0358 - out_1_acc: 0.9690 - out_2_acc: 0.9816 - val_loss: 0.3274 - val_out_1_loss: 0.1517 - val_out_2_loss: 0.1757 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0959 - out_1_loss: 0.0601 - out_2_loss: 0.0357 - out_1_acc: 0.9690 - out_2_acc: 0.9820 - val_loss: 0.3267 - val_out_1_loss: 0.1522 - val_out_2_loss: 0.1745 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0951 - out_1_loss: 0.0598 - out_2_loss: 0.0353 - out_1_acc: 0.9689 - out_2_acc: 0.9822 - val_loss: 0.3263 - val_out_1_loss: 0.1511 - val_out_2_loss: 0.1751 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0943 - out_1_loss: 0.0596 - out_2_loss: 0.0347 - out_1_acc: 0.9689 - out_2_acc: 0.9827 - val_loss: 0.3309 - val_out_1_loss: 0.1527 - val_out_2_loss: 0.1782 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0934 - out_1_loss: 0.0591 - out_2_loss: 0.0343 - out_1_acc: 0.9692 - out_2_acc: 0.9833 - val_loss: 0.3328 - val_out_1_loss: 0.1526 - val_out_2_loss: 0.1802 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0926 - out_1_loss: 0.0587 - out_2_loss: 0.0339 - out_1_acc: 0.9694 - out_2_acc: 0.9833 - val_loss: 0.3332 - val_out_1_loss: 0.1535 - val_out_2_loss: 0.1797 - val_out_1_acc: 0.9425 - val_out_2_acc: 0.9530\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0935 - out_1_loss: 0.0586 - out_2_loss: 0.0349 - out_1_acc: 0.9699 - out_2_acc: 0.9828 - val_loss: 0.3313 - val_out_1_loss: 0.1531 - val_out_2_loss: 0.1782 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9530\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0930 - out_1_loss: 0.0584 - out_2_loss: 0.0346 - out_1_acc: 0.9703 - out_2_acc: 0.9830 - val_loss: 0.3328 - val_out_1_loss: 0.1543 - val_out_2_loss: 0.1786 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0916 - out_1_loss: 0.0577 - out_2_loss: 0.0339 - out_1_acc: 0.9708 - out_2_acc: 0.9833 - val_loss: 0.3351 - val_out_1_loss: 0.1540 - val_out_2_loss: 0.1811 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9511\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0913 - out_1_loss: 0.0577 - out_2_loss: 0.0336 - out_1_acc: 0.9709 - out_2_acc: 0.9838 - val_loss: 0.3383 - val_out_1_loss: 0.1560 - val_out_2_loss: 0.1824 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9507\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0907 - out_1_loss: 0.0575 - out_2_loss: 0.0332 - out_1_acc: 0.9710 - out_2_acc: 0.9836 - val_loss: 0.3401 - val_out_1_loss: 0.1564 - val_out_2_loss: 0.1837 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9515\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0896 - out_1_loss: 0.0571 - out_2_loss: 0.0326 - out_1_acc: 0.9711 - out_2_acc: 0.9838 - val_loss: 0.3399 - val_out_1_loss: 0.1561 - val_out_2_loss: 0.1837 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9530\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0892 - out_1_loss: 0.0570 - out_2_loss: 0.0322 - out_1_acc: 0.9710 - out_2_acc: 0.9843 - val_loss: 0.3423 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1841 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9519\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0889 - out_1_loss: 0.0571 - out_2_loss: 0.0318 - out_1_acc: 0.9712 - out_2_acc: 0.9844 - val_loss: 0.3447 - val_out_1_loss: 0.1583 - val_out_2_loss: 0.1864 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0880 - out_1_loss: 0.0566 - out_2_loss: 0.0314 - out_1_acc: 0.9707 - out_2_acc: 0.9850 - val_loss: 0.3503 - val_out_1_loss: 0.1592 - val_out_2_loss: 0.1911 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9508\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0883 - out_1_loss: 0.0568 - out_2_loss: 0.0315 - out_1_acc: 0.9714 - out_2_acc: 0.9847 - val_loss: 0.3478 - val_out_1_loss: 0.1597 - val_out_2_loss: 0.1881 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0874 - out_1_loss: 0.0559 - out_2_loss: 0.0314 - out_1_acc: 0.9719 - out_2_acc: 0.9851 - val_loss: 0.3505 - val_out_1_loss: 0.1604 - val_out_2_loss: 0.1901 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0876 - out_1_loss: 0.0555 - out_2_loss: 0.0321 - out_1_acc: 0.9723 - out_2_acc: 0.9842 - val_loss: 0.3561 - val_out_1_loss: 0.1620 - val_out_2_loss: 0.1941 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9508\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0873 - out_1_loss: 0.0556 - out_2_loss: 0.0317 - out_1_acc: 0.9714 - out_2_acc: 0.9848 - val_loss: 0.3546 - val_out_1_loss: 0.1634 - val_out_2_loss: 0.1912 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9512\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0849 - out_1_loss: 0.0546 - out_2_loss: 0.0303 - out_1_acc: 0.9725 - out_2_acc: 0.9856 - val_loss: 0.3536 - val_out_1_loss: 0.1628 - val_out_2_loss: 0.1908 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9527\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0848 - out_1_loss: 0.0547 - out_2_loss: 0.0301 - out_1_acc: 0.9721 - out_2_acc: 0.9857 - val_loss: 0.3580 - val_out_1_loss: 0.1638 - val_out_2_loss: 0.1942 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0835 - out_1_loss: 0.0544 - out_2_loss: 0.0291 - out_1_acc: 0.9727 - out_2_acc: 0.9859 - val_loss: 0.3586 - val_out_1_loss: 0.1650 - val_out_2_loss: 0.1936 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9517\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0829 - out_1_loss: 0.0545 - out_2_loss: 0.0285 - out_1_acc: 0.9726 - out_2_acc: 0.9861 - val_loss: 0.3629 - val_out_1_loss: 0.1661 - val_out_2_loss: 0.1968 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0820 - out_1_loss: 0.0540 - out_2_loss: 0.0280 - out_1_acc: 0.9728 - out_2_acc: 0.9869 - val_loss: 0.3643 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1974 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9510\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0826 - out_1_loss: 0.0539 - out_2_loss: 0.0287 - out_1_acc: 0.9728 - out_2_acc: 0.9862 - val_loss: 0.3671 - val_out_1_loss: 0.1683 - val_out_2_loss: 0.1987 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0810 - out_1_loss: 0.0534 - out_2_loss: 0.0276 - out_1_acc: 0.9729 - out_2_acc: 0.9875 - val_loss: 0.3668 - val_out_1_loss: 0.1681 - val_out_2_loss: 0.1986 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0801 - out_1_loss: 0.0529 - out_2_loss: 0.0272 - out_1_acc: 0.9735 - out_2_acc: 0.9875 - val_loss: 0.3669 - val_out_1_loss: 0.1664 - val_out_2_loss: 0.2005 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0800 - out_1_loss: 0.0525 - out_2_loss: 0.0275 - out_1_acc: 0.9737 - out_2_acc: 0.9871 - val_loss: 0.3715 - val_out_1_loss: 0.1690 - val_out_2_loss: 0.2026 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9519\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0807 - out_1_loss: 0.0530 - out_2_loss: 0.0277 - out_1_acc: 0.9735 - out_2_acc: 0.9868 - val_loss: 0.3712 - val_out_1_loss: 0.1675 - val_out_2_loss: 0.2037 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9511\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0803 - out_1_loss: 0.0524 - out_2_loss: 0.0279 - out_1_acc: 0.9738 - out_2_acc: 0.9868 - val_loss: 0.3698 - val_out_1_loss: 0.1687 - val_out_2_loss: 0.2012 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0803 - out_1_loss: 0.0520 - out_2_loss: 0.0283 - out_1_acc: 0.9742 - out_2_acc: 0.9863 - val_loss: 0.3736 - val_out_1_loss: 0.1699 - val_out_2_loss: 0.2037 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9510\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0796 - out_1_loss: 0.0520 - out_2_loss: 0.0276 - out_1_acc: 0.9743 - out_2_acc: 0.9872 - val_loss: 0.3770 - val_out_1_loss: 0.1709 - val_out_2_loss: 0.2062 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0794 - out_1_loss: 0.0516 - out_2_loss: 0.0278 - out_1_acc: 0.9744 - out_2_acc: 0.9872 - val_loss: 0.3799 - val_out_1_loss: 0.1731 - val_out_2_loss: 0.2068 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9517\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0779 - out_1_loss: 0.0511 - out_2_loss: 0.0269 - out_1_acc: 0.9746 - out_2_acc: 0.9880 - val_loss: 0.3781 - val_out_1_loss: 0.1738 - val_out_2_loss: 0.2043 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9502\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0769 - out_1_loss: 0.0503 - out_2_loss: 0.0266 - out_1_acc: 0.9750 - out_2_acc: 0.9877 - val_loss: 0.3857 - val_out_1_loss: 0.1741 - val_out_2_loss: 0.2115 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9518\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0775 - out_1_loss: 0.0503 - out_2_loss: 0.0272 - out_1_acc: 0.9750 - out_2_acc: 0.9873 - val_loss: 0.3843 - val_out_1_loss: 0.1746 - val_out_2_loss: 0.2097 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9506\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0765 - out_1_loss: 0.0500 - out_2_loss: 0.0265 - out_1_acc: 0.9753 - out_2_acc: 0.9875 - val_loss: 0.3891 - val_out_1_loss: 0.1763 - val_out_2_loss: 0.2129 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0774 - out_1_loss: 0.0507 - out_2_loss: 0.0267 - out_1_acc: 0.9751 - out_2_acc: 0.9875 - val_loss: 0.3881 - val_out_1_loss: 0.1769 - val_out_2_loss: 0.2112 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0742 - out_1_loss: 0.0497 - out_2_loss: 0.0245 - out_1_acc: 0.9756 - out_2_acc: 0.9886 - val_loss: 0.3910 - val_out_1_loss: 0.1774 - val_out_2_loss: 0.2136 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0718 - out_1_loss: 0.0490 - out_2_loss: 0.0228 - out_1_acc: 0.9761 - out_2_acc: 0.9898 - val_loss: 0.3947 - val_out_1_loss: 0.1768 - val_out_2_loss: 0.2179 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9504\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0713 - out_1_loss: 0.0494 - out_2_loss: 0.0219 - out_1_acc: 0.9757 - out_2_acc: 0.9900 - val_loss: 0.4011 - val_out_1_loss: 0.1802 - val_out_2_loss: 0.2209 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9508\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0709 - out_1_loss: 0.0492 - out_2_loss: 0.0218 - out_1_acc: 0.9759 - out_2_acc: 0.9902 - val_loss: 0.4008 - val_out_1_loss: 0.1804 - val_out_2_loss: 0.2205 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9503\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0722 - out_1_loss: 0.0485 - out_2_loss: 0.0237 - out_1_acc: 0.9762 - out_2_acc: 0.9891 - val_loss: 0.4035 - val_out_1_loss: 0.1824 - val_out_2_loss: 0.2211 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9501\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(6)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3907 - out_1_loss: 0.1749 - out_2_loss: 0.2158 - out_1_acc: 0.9422 - out_2_acc: 0.9510\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 100), (No 52400       input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 100)       52400       input_12[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 293,880\n",
      "Trainable params: 293,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3622 - out_1_loss: 3.6852 - out_2_loss: 3.6769 - out_1_acc: 0.0349 - out_2_acc: 0.0720WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.115350). Check your callbacks.\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 6.5061 - out_1_loss: 3.3250 - out_2_loss: 3.1811 - out_1_acc: 0.3011 - out_2_acc: 0.3357 - val_loss: 5.0997 - val_out_1_loss: 2.6499 - val_out_2_loss: 2.4498 - val_out_1_acc: 0.3785 - val_out_2_acc: 0.4169\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 4.1225 - out_1_loss: 2.2152 - out_2_loss: 1.9073 - out_1_acc: 0.4841 - out_2_acc: 0.5573 - val_loss: 3.1457 - val_out_1_loss: 1.8257 - val_out_2_loss: 1.3200 - val_out_1_acc: 0.5599 - val_out_2_acc: 0.6922\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 2.3268 - out_1_loss: 1.4093 - out_2_loss: 0.9175 - out_1_acc: 0.6648 - out_2_acc: 0.7927 - val_loss: 1.5815 - val_out_1_loss: 0.9530 - val_out_2_loss: 0.6285 - val_out_1_acc: 0.7825 - val_out_2_acc: 0.8615\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 1.1879 - out_1_loss: 0.7168 - out_2_loss: 0.4712 - out_1_acc: 0.8378 - out_2_acc: 0.8972 - val_loss: 0.9071 - val_out_1_loss: 0.5419 - val_out_2_loss: 0.3652 - val_out_1_acc: 0.8777 - val_out_2_acc: 0.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.7363 - out_1_loss: 0.4495 - out_2_loss: 0.2868 - out_1_acc: 0.8984 - out_2_acc: 0.9354 - val_loss: 0.6303 - val_out_1_loss: 0.3843 - val_out_2_loss: 0.2460 - val_out_1_acc: 0.9122 - val_out_2_acc: 0.9402\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.5287 - out_1_loss: 0.3280 - out_2_loss: 0.2007 - out_1_acc: 0.9222 - out_2_acc: 0.9462 - val_loss: 0.4794 - val_out_1_loss: 0.2922 - val_out_2_loss: 0.1873 - val_out_1_acc: 0.9280 - val_out_2_acc: 0.9492\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.4064 - out_1_loss: 0.2494 - out_2_loss: 0.1570 - out_1_acc: 0.9312 - out_2_acc: 0.9522 - val_loss: 0.3819 - val_out_1_loss: 0.2287 - val_out_2_loss: 0.1532 - val_out_1_acc: 0.9345 - val_out_2_acc: 0.9503\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3306 - out_1_loss: 0.1986 - out_2_loss: 0.1319 - out_1_acc: 0.9363 - out_2_acc: 0.9524 - val_loss: 0.3207 - val_out_1_loss: 0.1895 - val_out_2_loss: 0.1312 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9504\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2837 - out_1_loss: 0.1677 - out_2_loss: 0.1160 - out_1_acc: 0.9390 - out_2_acc: 0.9531 - val_loss: 0.2849 - val_out_1_loss: 0.1660 - val_out_2_loss: 0.1189 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9505\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2542 - out_1_loss: 0.1482 - out_2_loss: 0.1060 - out_1_acc: 0.9403 - out_2_acc: 0.9536 - val_loss: 0.2606 - val_out_1_loss: 0.1497 - val_out_2_loss: 0.1109 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9508\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2341 - out_1_loss: 0.1351 - out_2_loss: 0.0991 - out_1_acc: 0.9410 - out_2_acc: 0.9537 - val_loss: 0.2436 - val_out_1_loss: 0.1382 - val_out_2_loss: 0.1053 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9505\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2204 - out_1_loss: 0.1260 - out_2_loss: 0.0943 - out_1_acc: 0.9416 - out_2_acc: 0.9540 - val_loss: 0.2315 - val_out_1_loss: 0.1303 - val_out_2_loss: 0.1012 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9503\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2110 - out_1_loss: 0.1199 - out_2_loss: 0.0911 - out_1_acc: 0.9421 - out_2_acc: 0.9542 - val_loss: 0.2229 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.0982 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2039 - out_1_loss: 0.1152 - out_2_loss: 0.0887 - out_1_acc: 0.9428 - out_2_acc: 0.9546 - val_loss: 0.2178 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1986 - out_1_loss: 0.1117 - out_2_loss: 0.0869 - out_1_acc: 0.9431 - out_2_acc: 0.9550 - val_loss: 0.2141 - val_out_1_loss: 0.1186 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9505\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1948 - out_1_loss: 0.1093 - out_2_loss: 0.0855 - out_1_acc: 0.9431 - out_2_acc: 0.9552 - val_loss: 0.2108 - val_out_1_loss: 0.1167 - val_out_2_loss: 0.0941 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9511\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1918 - out_1_loss: 0.1074 - out_2_loss: 0.0844 - out_1_acc: 0.9434 - out_2_acc: 0.9553 - val_loss: 0.2084 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.0931 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9508\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1893 - out_1_loss: 0.1058 - out_2_loss: 0.0835 - out_1_acc: 0.9438 - out_2_acc: 0.9559 - val_loss: 0.2066 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.0927 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9515\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1870 - out_1_loss: 0.1044 - out_2_loss: 0.0826 - out_1_acc: 0.9439 - out_2_acc: 0.9560 - val_loss: 0.2051 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.0924 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9508\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1852 - out_1_loss: 0.1033 - out_2_loss: 0.0819 - out_1_acc: 0.9441 - out_2_acc: 0.9564 - val_loss: 0.2040 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0922 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9515\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1836 - out_1_loss: 0.1023 - out_2_loss: 0.0812 - out_1_acc: 0.9443 - out_2_acc: 0.9565 - val_loss: 0.2031 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0919 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1822 - out_1_loss: 0.1016 - out_2_loss: 0.0807 - out_1_acc: 0.9447 - out_2_acc: 0.9572 - val_loss: 0.2026 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1811 - out_1_loss: 0.1009 - out_2_loss: 0.0802 - out_1_acc: 0.9443 - out_2_acc: 0.9572 - val_loss: 0.2019 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0918 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1800 - out_1_loss: 0.1003 - out_2_loss: 0.0797 - out_1_acc: 0.9443 - out_2_acc: 0.9575 - val_loss: 0.2017 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9523\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1790 - out_1_loss: 0.0997 - out_2_loss: 0.0793 - out_1_acc: 0.9442 - out_2_acc: 0.9575 - val_loss: 0.2015 - val_out_1_loss: 0.1096 - val_out_2_loss: 0.0919 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9514\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1778 - out_1_loss: 0.0992 - out_2_loss: 0.0786 - out_1_acc: 0.9446 - out_2_acc: 0.9578 - val_loss: 0.2014 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0920 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1769 - out_1_loss: 0.0988 - out_2_loss: 0.0781 - out_1_acc: 0.9448 - out_2_acc: 0.9583 - val_loss: 0.2014 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0923 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9512\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1760 - out_1_loss: 0.0984 - out_2_loss: 0.0777 - out_1_acc: 0.9451 - out_2_acc: 0.9581 - val_loss: 0.2012 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1751 - out_1_loss: 0.0980 - out_2_loss: 0.0771 - out_1_acc: 0.9450 - out_2_acc: 0.9585 - val_loss: 0.2012 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0924 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9505\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1745 - out_1_loss: 0.0976 - out_2_loss: 0.0769 - out_1_acc: 0.9453 - out_2_acc: 0.9584 - val_loss: 0.2010 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0921 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9518\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1736 - out_1_loss: 0.0972 - out_2_loss: 0.0764 - out_1_acc: 0.9455 - out_2_acc: 0.9589 - val_loss: 0.2014 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1729 - out_1_loss: 0.0968 - out_2_loss: 0.0761 - out_1_acc: 0.9458 - out_2_acc: 0.9585 - val_loss: 0.2015 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0929 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9516\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1723 - out_1_loss: 0.0965 - out_2_loss: 0.0758 - out_1_acc: 0.9462 - out_2_acc: 0.9587 - val_loss: 0.2019 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0935 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1715 - out_1_loss: 0.0963 - out_2_loss: 0.0752 - out_1_acc: 0.9460 - out_2_acc: 0.9589 - val_loss: 0.2029 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0944 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1707 - out_1_loss: 0.0959 - out_2_loss: 0.0748 - out_1_acc: 0.9464 - out_2_acc: 0.9593 - val_loss: 0.2027 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9512\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1699 - out_1_loss: 0.0956 - out_2_loss: 0.0742 - out_1_acc: 0.9463 - out_2_acc: 0.9596 - val_loss: 0.2032 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0946 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1691 - out_1_loss: 0.0953 - out_2_loss: 0.0739 - out_1_acc: 0.9467 - out_2_acc: 0.9600 - val_loss: 0.2031 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9510\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1684 - out_1_loss: 0.0951 - out_2_loss: 0.0733 - out_1_acc: 0.9463 - out_2_acc: 0.9601 - val_loss: 0.2037 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1677 - out_1_loss: 0.0947 - out_2_loss: 0.0730 - out_1_acc: 0.9465 - out_2_acc: 0.9601 - val_loss: 0.2035 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9509\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1669 - out_1_loss: 0.0944 - out_2_loss: 0.0725 - out_1_acc: 0.9464 - out_2_acc: 0.9603 - val_loss: 0.2042 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1664 - out_1_loss: 0.0942 - out_2_loss: 0.0722 - out_1_acc: 0.9468 - out_2_acc: 0.9606 - val_loss: 0.2047 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0961 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9508\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1661 - out_1_loss: 0.0939 - out_2_loss: 0.0722 - out_1_acc: 0.9469 - out_2_acc: 0.9610 - val_loss: 0.2055 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0969 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9510\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1658 - out_1_loss: 0.0936 - out_2_loss: 0.0722 - out_1_acc: 0.9474 - out_2_acc: 0.9606 - val_loss: 0.2053 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1654 - out_1_loss: 0.0933 - out_2_loss: 0.0721 - out_1_acc: 0.9476 - out_2_acc: 0.9609 - val_loss: 0.2057 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1646 - out_1_loss: 0.0930 - out_2_loss: 0.0716 - out_1_acc: 0.9476 - out_2_acc: 0.9614 - val_loss: 0.2053 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9525\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1638 - out_1_loss: 0.0928 - out_2_loss: 0.0710 - out_1_acc: 0.9478 - out_2_acc: 0.9619 - val_loss: 0.2060 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0969 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9533\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1631 - out_1_loss: 0.0928 - out_2_loss: 0.0703 - out_1_acc: 0.9476 - out_2_acc: 0.9618 - val_loss: 0.2066 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0977 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9528\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1625 - out_1_loss: 0.0926 - out_2_loss: 0.0699 - out_1_acc: 0.9477 - out_2_acc: 0.9620 - val_loss: 0.2074 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0982 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1617 - out_1_loss: 0.0923 - out_2_loss: 0.0694 - out_1_acc: 0.9479 - out_2_acc: 0.9619 - val_loss: 0.2075 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0984 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1602 - out_1_loss: 0.0919 - out_2_loss: 0.0683 - out_1_acc: 0.9485 - out_2_acc: 0.9629 - val_loss: 0.2088 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0995 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1594 - out_1_loss: 0.0916 - out_2_loss: 0.0678 - out_1_acc: 0.9485 - out_2_acc: 0.9633 - val_loss: 0.2091 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9530\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1585 - out_1_loss: 0.0913 - out_2_loss: 0.0672 - out_1_acc: 0.9486 - out_2_acc: 0.9635 - val_loss: 0.2105 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.1004 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1579 - out_1_loss: 0.0910 - out_2_loss: 0.0670 - out_1_acc: 0.9489 - out_2_acc: 0.9636 - val_loss: 0.2111 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.1008 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9519\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1571 - out_1_loss: 0.0905 - out_2_loss: 0.0666 - out_1_acc: 0.9492 - out_2_acc: 0.9637 - val_loss: 0.2106 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1572 - out_1_loss: 0.0904 - out_2_loss: 0.0667 - out_1_acc: 0.9494 - out_2_acc: 0.9635 - val_loss: 0.2114 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1566 - out_1_loss: 0.0901 - out_2_loss: 0.0665 - out_1_acc: 0.9490 - out_2_acc: 0.9635 - val_loss: 0.2132 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.1018 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9521\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1571 - out_1_loss: 0.0902 - out_2_loss: 0.0669 - out_1_acc: 0.9492 - out_2_acc: 0.9637 - val_loss: 0.2154 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.1034 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1575 - out_1_loss: 0.0902 - out_2_loss: 0.0674 - out_1_acc: 0.9490 - out_2_acc: 0.9627 - val_loss: 0.2168 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1040 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9514\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1574 - out_1_loss: 0.0900 - out_2_loss: 0.0674 - out_1_acc: 0.9492 - out_2_acc: 0.9626 - val_loss: 0.2165 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.1044 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9510\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1553 - out_1_loss: 0.0896 - out_2_loss: 0.0656 - out_1_acc: 0.9493 - out_2_acc: 0.9639 - val_loss: 0.2165 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1048 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1543 - out_1_loss: 0.0894 - out_2_loss: 0.0649 - out_1_acc: 0.9495 - out_2_acc: 0.9638 - val_loss: 0.2168 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1052 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1530 - out_1_loss: 0.0889 - out_2_loss: 0.0641 - out_1_acc: 0.9499 - out_2_acc: 0.9647 - val_loss: 0.2172 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1048 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9505\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1528 - out_1_loss: 0.0886 - out_2_loss: 0.0642 - out_1_acc: 0.9497 - out_2_acc: 0.9647 - val_loss: 0.2182 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.1060 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1523 - out_1_loss: 0.0885 - out_2_loss: 0.0638 - out_1_acc: 0.9502 - out_2_acc: 0.9647 - val_loss: 0.2196 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.1063 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9512\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1513 - out_1_loss: 0.0881 - out_2_loss: 0.0632 - out_1_acc: 0.9505 - out_2_acc: 0.9653 - val_loss: 0.2208 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1080 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9509\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1510 - out_1_loss: 0.0880 - out_2_loss: 0.0630 - out_1_acc: 0.9501 - out_2_acc: 0.9652 - val_loss: 0.2196 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1069 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1512 - out_1_loss: 0.0882 - out_2_loss: 0.0630 - out_1_acc: 0.9503 - out_2_acc: 0.9653 - val_loss: 0.2210 - val_out_1_loss: 0.1122 - val_out_2_loss: 0.1087 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9510\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1504 - out_1_loss: 0.0875 - out_2_loss: 0.0628 - out_1_acc: 0.9512 - out_2_acc: 0.9650 - val_loss: 0.2243 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.1112 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1504 - out_1_loss: 0.0873 - out_2_loss: 0.0632 - out_1_acc: 0.9510 - out_2_acc: 0.9647 - val_loss: 0.2249 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1112 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9509\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1495 - out_1_loss: 0.0872 - out_2_loss: 0.0624 - out_1_acc: 0.9509 - out_2_acc: 0.9655 - val_loss: 0.2253 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1108 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1488 - out_1_loss: 0.0869 - out_2_loss: 0.0618 - out_1_acc: 0.9507 - out_2_acc: 0.9657 - val_loss: 0.2276 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1122 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9510\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1477 - out_1_loss: 0.0865 - out_2_loss: 0.0611 - out_1_acc: 0.9512 - out_2_acc: 0.9660 - val_loss: 0.2284 - val_out_1_loss: 0.1156 - val_out_2_loss: 0.1128 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1470 - out_1_loss: 0.0863 - out_2_loss: 0.0607 - out_1_acc: 0.9513 - out_2_acc: 0.9664 - val_loss: 0.2278 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1122 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1467 - out_1_loss: 0.0864 - out_2_loss: 0.0603 - out_1_acc: 0.9512 - out_2_acc: 0.9666 - val_loss: 0.2305 - val_out_1_loss: 0.1163 - val_out_2_loss: 0.1142 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9513\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1467 - out_1_loss: 0.0860 - out_2_loss: 0.0607 - out_1_acc: 0.9517 - out_2_acc: 0.9661 - val_loss: 0.2333 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.1165 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1455 - out_1_loss: 0.0859 - out_2_loss: 0.0596 - out_1_acc: 0.9517 - out_2_acc: 0.9669 - val_loss: 0.2365 - val_out_1_loss: 0.1173 - val_out_2_loss: 0.1192 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1460 - out_1_loss: 0.0859 - out_2_loss: 0.0601 - out_1_acc: 0.9516 - out_2_acc: 0.9664 - val_loss: 0.2350 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1168 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1465 - out_1_loss: 0.0856 - out_2_loss: 0.0609 - out_1_acc: 0.9520 - out_2_acc: 0.9664 - val_loss: 0.2337 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1154 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1461 - out_1_loss: 0.0849 - out_2_loss: 0.0612 - out_1_acc: 0.9526 - out_2_acc: 0.9658 - val_loss: 0.2330 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1151 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9527\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1445 - out_1_loss: 0.0851 - out_2_loss: 0.0594 - out_1_acc: 0.9521 - out_2_acc: 0.9666 - val_loss: 0.2319 - val_out_1_loss: 0.1177 - val_out_2_loss: 0.1143 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1435 - out_1_loss: 0.0846 - out_2_loss: 0.0589 - out_1_acc: 0.9522 - out_2_acc: 0.9675 - val_loss: 0.2332 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1153 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9518\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1416 - out_1_loss: 0.0835 - out_2_loss: 0.0581 - out_1_acc: 0.9537 - out_2_acc: 0.9678 - val_loss: 0.2345 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1170 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9515\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1424 - out_1_loss: 0.0838 - out_2_loss: 0.0586 - out_1_acc: 0.9536 - out_2_acc: 0.9671 - val_loss: 0.2366 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1183 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1403 - out_1_loss: 0.0831 - out_2_loss: 0.0572 - out_1_acc: 0.9538 - out_2_acc: 0.9682 - val_loss: 0.2348 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1172 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9510\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1398 - out_1_loss: 0.0829 - out_2_loss: 0.0569 - out_1_acc: 0.9535 - out_2_acc: 0.9681 - val_loss: 0.2371 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1190 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1399 - out_1_loss: 0.0825 - out_2_loss: 0.0573 - out_1_acc: 0.9539 - out_2_acc: 0.9680 - val_loss: 0.2354 - val_out_1_loss: 0.1180 - val_out_2_loss: 0.1174 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1393 - out_1_loss: 0.0828 - out_2_loss: 0.0565 - out_1_acc: 0.9539 - out_2_acc: 0.9683 - val_loss: 0.2360 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1175 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9516\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1384 - out_1_loss: 0.0821 - out_2_loss: 0.0563 - out_1_acc: 0.9538 - out_2_acc: 0.9683 - val_loss: 0.2389 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1209 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9517\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1380 - out_1_loss: 0.0821 - out_2_loss: 0.0559 - out_1_acc: 0.9541 - out_2_acc: 0.9681 - val_loss: 0.2454 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9530\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1373 - out_1_loss: 0.0821 - out_2_loss: 0.0552 - out_1_acc: 0.9547 - out_2_acc: 0.9691 - val_loss: 0.2447 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.1259 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1361 - out_1_loss: 0.0815 - out_2_loss: 0.0546 - out_1_acc: 0.9545 - out_2_acc: 0.9694 - val_loss: 0.2449 - val_out_1_loss: 0.1190 - val_out_2_loss: 0.1259 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9517\n",
      "Epoch 92/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1360 - out_1_loss: 0.0820 - out_2_loss: 0.0540 - out_1_acc: 0.9545 - out_2_acc: 0.9695 - val_loss: 0.2466 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1265 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1352 - out_1_loss: 0.0815 - out_2_loss: 0.0537 - out_1_acc: 0.9546 - out_2_acc: 0.9698 - val_loss: 0.2498 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.1297 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9515\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1342 - out_1_loss: 0.0812 - out_2_loss: 0.0531 - out_1_acc: 0.9546 - out_2_acc: 0.9704 - val_loss: 0.2515 - val_out_1_loss: 0.1205 - val_out_2_loss: 0.1310 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1330 - out_1_loss: 0.0803 - out_2_loss: 0.0528 - out_1_acc: 0.9552 - out_2_acc: 0.9701 - val_loss: 0.2501 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1324 - out_1_loss: 0.0800 - out_2_loss: 0.0524 - out_1_acc: 0.9555 - out_2_acc: 0.9705 - val_loss: 0.2507 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.1292 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1324 - out_1_loss: 0.0796 - out_2_loss: 0.0527 - out_1_acc: 0.9554 - out_2_acc: 0.9702 - val_loss: 0.2531 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.1305 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1313 - out_1_loss: 0.0790 - out_2_loss: 0.0523 - out_1_acc: 0.9561 - out_2_acc: 0.9707 - val_loss: 0.2537 - val_out_1_loss: 0.1236 - val_out_2_loss: 0.1301 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9514\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1295 - out_1_loss: 0.0786 - out_2_loss: 0.0509 - out_1_acc: 0.9563 - out_2_acc: 0.9709 - val_loss: 0.2547 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.1321 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1281 - out_1_loss: 0.0778 - out_2_loss: 0.0503 - out_1_acc: 0.9571 - out_2_acc: 0.9713 - val_loss: 0.2567 - val_out_1_loss: 0.1227 - val_out_2_loss: 0.1341 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1270 - out_1_loss: 0.0773 - out_2_loss: 0.0497 - out_1_acc: 0.9574 - out_2_acc: 0.9723 - val_loss: 0.2584 - val_out_1_loss: 0.1244 - val_out_2_loss: 0.1341 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1264 - out_1_loss: 0.0772 - out_2_loss: 0.0492 - out_1_acc: 0.9573 - out_2_acc: 0.9723 - val_loss: 0.2572 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1326 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1249 - out_1_loss: 0.0767 - out_2_loss: 0.0482 - out_1_acc: 0.9576 - out_2_acc: 0.9733 - val_loss: 0.2583 - val_out_1_loss: 0.1240 - val_out_2_loss: 0.1342 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1257 - out_1_loss: 0.0769 - out_2_loss: 0.0488 - out_1_acc: 0.9575 - out_2_acc: 0.9730 - val_loss: 0.2607 - val_out_1_loss: 0.1260 - val_out_2_loss: 0.1347 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1249 - out_1_loss: 0.0765 - out_2_loss: 0.0484 - out_1_acc: 0.9575 - out_2_acc: 0.9729 - val_loss: 0.2610 - val_out_1_loss: 0.1268 - val_out_2_loss: 0.1342 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9519\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1244 - out_1_loss: 0.0762 - out_2_loss: 0.0482 - out_1_acc: 0.9582 - out_2_acc: 0.9728 - val_loss: 0.2631 - val_out_1_loss: 0.1274 - val_out_2_loss: 0.1357 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9514\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1237 - out_1_loss: 0.0758 - out_2_loss: 0.0479 - out_1_acc: 0.9578 - out_2_acc: 0.9733 - val_loss: 0.2648 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1376 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9520\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1234 - out_1_loss: 0.0754 - out_2_loss: 0.0480 - out_1_acc: 0.9583 - out_2_acc: 0.9730 - val_loss: 0.2699 - val_out_1_loss: 0.1289 - val_out_2_loss: 0.1411 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9515\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1226 - out_1_loss: 0.0748 - out_2_loss: 0.0478 - out_1_acc: 0.9585 - out_2_acc: 0.9732 - val_loss: 0.2712 - val_out_1_loss: 0.1299 - val_out_2_loss: 0.1414 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9514\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1224 - out_1_loss: 0.0750 - out_2_loss: 0.0474 - out_1_acc: 0.9589 - out_2_acc: 0.9735 - val_loss: 0.2683 - val_out_1_loss: 0.1291 - val_out_2_loss: 0.1392 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9515\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1215 - out_1_loss: 0.0746 - out_2_loss: 0.0469 - out_1_acc: 0.9592 - out_2_acc: 0.9742 - val_loss: 0.2704 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1408 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9504\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1212 - out_1_loss: 0.0740 - out_2_loss: 0.0471 - out_1_acc: 0.9591 - out_2_acc: 0.9736 - val_loss: 0.2713 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1401 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9515\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1209 - out_1_loss: 0.0741 - out_2_loss: 0.0468 - out_1_acc: 0.9597 - out_2_acc: 0.9740 - val_loss: 0.2725 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1418 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1206 - out_1_loss: 0.0735 - out_2_loss: 0.0470 - out_1_acc: 0.9598 - out_2_acc: 0.9739 - val_loss: 0.2733 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1425 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9501\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1206 - out_1_loss: 0.0732 - out_2_loss: 0.0474 - out_1_acc: 0.9599 - out_2_acc: 0.9740 - val_loss: 0.2773 - val_out_1_loss: 0.1325 - val_out_2_loss: 0.1448 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9507\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1202 - out_1_loss: 0.0733 - out_2_loss: 0.0468 - out_1_acc: 0.9597 - out_2_acc: 0.9741 - val_loss: 0.2762 - val_out_1_loss: 0.1317 - val_out_2_loss: 0.1445 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9512\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1192 - out_1_loss: 0.0729 - out_2_loss: 0.0462 - out_1_acc: 0.9596 - out_2_acc: 0.9749 - val_loss: 0.2825 - val_out_1_loss: 0.1349 - val_out_2_loss: 0.1477 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9505\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1193 - out_1_loss: 0.0725 - out_2_loss: 0.0468 - out_1_acc: 0.9602 - out_2_acc: 0.9744 - val_loss: 0.2823 - val_out_1_loss: 0.1344 - val_out_2_loss: 0.1479 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9514\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1197 - out_1_loss: 0.0725 - out_2_loss: 0.0472 - out_1_acc: 0.9602 - out_2_acc: 0.9745 - val_loss: 0.2836 - val_out_1_loss: 0.1363 - val_out_2_loss: 0.1474 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9503\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1190 - out_1_loss: 0.0723 - out_2_loss: 0.0467 - out_1_acc: 0.9608 - out_2_acc: 0.9745 - val_loss: 0.2853 - val_out_1_loss: 0.1359 - val_out_2_loss: 0.1494 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9510\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1188 - out_1_loss: 0.0717 - out_2_loss: 0.0471 - out_1_acc: 0.9608 - out_2_acc: 0.9738 - val_loss: 0.2836 - val_out_1_loss: 0.1350 - val_out_2_loss: 0.1486 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1175 - out_1_loss: 0.0712 - out_2_loss: 0.0464 - out_1_acc: 0.9613 - out_2_acc: 0.9741 - val_loss: 0.2860 - val_out_1_loss: 0.1369 - val_out_2_loss: 0.1491 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1180 - out_1_loss: 0.0712 - out_2_loss: 0.0468 - out_1_acc: 0.9611 - out_2_acc: 0.9744 - val_loss: 0.2897 - val_out_1_loss: 0.1379 - val_out_2_loss: 0.1518 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9503\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1176 - out_1_loss: 0.0713 - out_2_loss: 0.0463 - out_1_acc: 0.9612 - out_2_acc: 0.9743 - val_loss: 0.2913 - val_out_1_loss: 0.1375 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9514\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1167 - out_1_loss: 0.0710 - out_2_loss: 0.0458 - out_1_acc: 0.9613 - out_2_acc: 0.9750 - val_loss: 0.2943 - val_out_1_loss: 0.1366 - val_out_2_loss: 0.1577 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1157 - out_1_loss: 0.0702 - out_2_loss: 0.0455 - out_1_acc: 0.9622 - out_2_acc: 0.9750 - val_loss: 0.2949 - val_out_1_loss: 0.1384 - val_out_2_loss: 0.1566 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9516\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1150 - out_1_loss: 0.0700 - out_2_loss: 0.0451 - out_1_acc: 0.9617 - out_2_acc: 0.9753 - val_loss: 0.2952 - val_out_1_loss: 0.1382 - val_out_2_loss: 0.1570 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9519\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1145 - out_1_loss: 0.0696 - out_2_loss: 0.0448 - out_1_acc: 0.9625 - out_2_acc: 0.9754 - val_loss: 0.2983 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1589 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1140 - out_1_loss: 0.0699 - out_2_loss: 0.0441 - out_1_acc: 0.9622 - out_2_acc: 0.9758 - val_loss: 0.2960 - val_out_1_loss: 0.1400 - val_out_2_loss: 0.1560 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9516\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1151 - out_1_loss: 0.0703 - out_2_loss: 0.0447 - out_1_acc: 0.9620 - out_2_acc: 0.9760 - val_loss: 0.2953 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1555 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9514\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1130 - out_1_loss: 0.0696 - out_2_loss: 0.0434 - out_1_acc: 0.9622 - out_2_acc: 0.9763 - val_loss: 0.3006 - val_out_1_loss: 0.1419 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9524\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.1131 - out_1_loss: 0.0703 - out_2_loss: 0.0428 - out_1_acc: 0.9619 - out_2_acc: 0.9768 - val_loss: 0.3009 - val_out_1_loss: 0.1431 - val_out_2_loss: 0.1578 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1118 - out_1_loss: 0.0695 - out_2_loss: 0.0423 - out_1_acc: 0.9621 - out_2_acc: 0.9772 - val_loss: 0.3007 - val_out_1_loss: 0.1417 - val_out_2_loss: 0.1591 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9521\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1115 - out_1_loss: 0.0693 - out_2_loss: 0.0423 - out_1_acc: 0.9624 - out_2_acc: 0.9769 - val_loss: 0.3033 - val_out_1_loss: 0.1460 - val_out_2_loss: 0.1573 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1117 - out_1_loss: 0.0689 - out_2_loss: 0.0428 - out_1_acc: 0.9627 - out_2_acc: 0.9768 - val_loss: 0.3029 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1595 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9511\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1108 - out_1_loss: 0.0688 - out_2_loss: 0.0420 - out_1_acc: 0.9624 - out_2_acc: 0.9777 - val_loss: 0.3059 - val_out_1_loss: 0.1433 - val_out_2_loss: 0.1626 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9509\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1094 - out_1_loss: 0.0678 - out_2_loss: 0.0416 - out_1_acc: 0.9633 - out_2_acc: 0.9778 - val_loss: 0.3082 - val_out_1_loss: 0.1452 - val_out_2_loss: 0.1631 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9511\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1091 - out_1_loss: 0.0675 - out_2_loss: 0.0417 - out_1_acc: 0.9633 - out_2_acc: 0.9778 - val_loss: 0.3096 - val_out_1_loss: 0.1451 - val_out_2_loss: 0.1644 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9512\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1081 - out_1_loss: 0.0666 - out_2_loss: 0.0415 - out_1_acc: 0.9639 - out_2_acc: 0.9779 - val_loss: 0.3106 - val_out_1_loss: 0.1457 - val_out_2_loss: 0.1649 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1065 - out_1_loss: 0.0658 - out_2_loss: 0.0407 - out_1_acc: 0.9641 - out_2_acc: 0.9788 - val_loss: 0.3098 - val_out_1_loss: 0.1464 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9511\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1058 - out_1_loss: 0.0655 - out_2_loss: 0.0404 - out_1_acc: 0.9650 - out_2_acc: 0.9785 - val_loss: 0.3132 - val_out_1_loss: 0.1477 - val_out_2_loss: 0.1656 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1050 - out_1_loss: 0.0649 - out_2_loss: 0.0401 - out_1_acc: 0.9650 - out_2_acc: 0.9785 - val_loss: 0.3135 - val_out_1_loss: 0.1474 - val_out_2_loss: 0.1661 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1056 - out_1_loss: 0.0652 - out_2_loss: 0.0403 - out_1_acc: 0.9649 - out_2_acc: 0.9785 - val_loss: 0.3161 - val_out_1_loss: 0.1484 - val_out_2_loss: 0.1677 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1038 - out_1_loss: 0.0642 - out_2_loss: 0.0396 - out_1_acc: 0.9656 - out_2_acc: 0.9787 - val_loss: 0.3179 - val_out_1_loss: 0.1483 - val_out_2_loss: 0.1696 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 145/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1034 - out_1_loss: 0.0639 - out_2_loss: 0.0395 - out_1_acc: 0.9661 - out_2_acc: 0.9788 - val_loss: 0.3191 - val_out_1_loss: 0.1513 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9503\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1026 - out_1_loss: 0.0635 - out_2_loss: 0.0392 - out_1_acc: 0.9659 - out_2_acc: 0.9788 - val_loss: 0.3212 - val_out_1_loss: 0.1517 - val_out_2_loss: 0.1695 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9505\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1030 - out_1_loss: 0.0634 - out_2_loss: 0.0396 - out_1_acc: 0.9666 - out_2_acc: 0.9786 - val_loss: 0.3266 - val_out_1_loss: 0.1549 - val_out_2_loss: 0.1718 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.1019 - out_1_loss: 0.0634 - out_2_loss: 0.0385 - out_1_acc: 0.9669 - out_2_acc: 0.9800 - val_loss: 0.3247 - val_out_1_loss: 0.1515 - val_out_2_loss: 0.1733 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9521\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1006 - out_1_loss: 0.0625 - out_2_loss: 0.0381 - out_1_acc: 0.9669 - out_2_acc: 0.9800 - val_loss: 0.3245 - val_out_1_loss: 0.1518 - val_out_2_loss: 0.1727 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1002 - out_1_loss: 0.0625 - out_2_loss: 0.0377 - out_1_acc: 0.9669 - out_2_acc: 0.9801 - val_loss: 0.3295 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1766 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1000 - out_1_loss: 0.0618 - out_2_loss: 0.0382 - out_1_acc: 0.9678 - out_2_acc: 0.9797 - val_loss: 0.3296 - val_out_1_loss: 0.1525 - val_out_2_loss: 0.1771 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0992 - out_1_loss: 0.0613 - out_2_loss: 0.0379 - out_1_acc: 0.9681 - out_2_acc: 0.9803 - val_loss: 0.3346 - val_out_1_loss: 0.1556 - val_out_2_loss: 0.1790 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9498\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0992 - out_1_loss: 0.0612 - out_2_loss: 0.0379 - out_1_acc: 0.9679 - out_2_acc: 0.9804 - val_loss: 0.3334 - val_out_1_loss: 0.1540 - val_out_2_loss: 0.1794 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0981 - out_1_loss: 0.0606 - out_2_loss: 0.0375 - out_1_acc: 0.9687 - out_2_acc: 0.9805 - val_loss: 0.3355 - val_out_1_loss: 0.1562 - val_out_2_loss: 0.1793 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9501\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0979 - out_1_loss: 0.0607 - out_2_loss: 0.0372 - out_1_acc: 0.9680 - out_2_acc: 0.9807 - val_loss: 0.3384 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1803 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9509\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0982 - out_1_loss: 0.0605 - out_2_loss: 0.0377 - out_1_acc: 0.9688 - out_2_acc: 0.9804 - val_loss: 0.3396 - val_out_1_loss: 0.1567 - val_out_2_loss: 0.1829 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9509\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0982 - out_1_loss: 0.0604 - out_2_loss: 0.0378 - out_1_acc: 0.9685 - out_2_acc: 0.9801 - val_loss: 0.3447 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1841 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0977 - out_1_loss: 0.0600 - out_2_loss: 0.0377 - out_1_acc: 0.9687 - out_2_acc: 0.9807 - val_loss: 0.3415 - val_out_1_loss: 0.1592 - val_out_2_loss: 0.1823 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9496\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0966 - out_1_loss: 0.0597 - out_2_loss: 0.0368 - out_1_acc: 0.9689 - out_2_acc: 0.9810 - val_loss: 0.3394 - val_out_1_loss: 0.1567 - val_out_2_loss: 0.1827 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0957 - out_1_loss: 0.0592 - out_2_loss: 0.0365 - out_1_acc: 0.9695 - out_2_acc: 0.9810 - val_loss: 0.3478 - val_out_1_loss: 0.1603 - val_out_2_loss: 0.1876 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9509\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0949 - out_1_loss: 0.0589 - out_2_loss: 0.0360 - out_1_acc: 0.9698 - out_2_acc: 0.9815 - val_loss: 0.3499 - val_out_1_loss: 0.1618 - val_out_2_loss: 0.1881 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9504\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0954 - out_1_loss: 0.0590 - out_2_loss: 0.0364 - out_1_acc: 0.9695 - out_2_acc: 0.9810 - val_loss: 0.3512 - val_out_1_loss: 0.1637 - val_out_2_loss: 0.1875 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9500\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0950 - out_1_loss: 0.0587 - out_2_loss: 0.0363 - out_1_acc: 0.9699 - out_2_acc: 0.9814 - val_loss: 0.3508 - val_out_1_loss: 0.1625 - val_out_2_loss: 0.1883 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9505\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0954 - out_1_loss: 0.0590 - out_2_loss: 0.0365 - out_1_acc: 0.9697 - out_2_acc: 0.9811 - val_loss: 0.3512 - val_out_1_loss: 0.1621 - val_out_2_loss: 0.1891 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0942 - out_1_loss: 0.0580 - out_2_loss: 0.0362 - out_1_acc: 0.9700 - out_2_acc: 0.9816 - val_loss: 0.3485 - val_out_1_loss: 0.1630 - val_out_2_loss: 0.1855 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9513\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0947 - out_1_loss: 0.0584 - out_2_loss: 0.0363 - out_1_acc: 0.9697 - out_2_acc: 0.9810 - val_loss: 0.3547 - val_out_1_loss: 0.1655 - val_out_2_loss: 0.1892 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0940 - out_1_loss: 0.0579 - out_2_loss: 0.0361 - out_1_acc: 0.9700 - out_2_acc: 0.9818 - val_loss: 0.3574 - val_out_1_loss: 0.1656 - val_out_2_loss: 0.1918 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0931 - out_1_loss: 0.0576 - out_2_loss: 0.0355 - out_1_acc: 0.9705 - out_2_acc: 0.9815 - val_loss: 0.3604 - val_out_1_loss: 0.1673 - val_out_2_loss: 0.1931 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0939 - out_1_loss: 0.0579 - out_2_loss: 0.0361 - out_1_acc: 0.9701 - out_2_acc: 0.9814 - val_loss: 0.3599 - val_out_1_loss: 0.1693 - val_out_2_loss: 0.1906 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9503\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0940 - out_1_loss: 0.0583 - out_2_loss: 0.0357 - out_1_acc: 0.9696 - out_2_acc: 0.9817 - val_loss: 0.3627 - val_out_1_loss: 0.1675 - val_out_2_loss: 0.1952 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9495\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0944 - out_1_loss: 0.0583 - out_2_loss: 0.0361 - out_1_acc: 0.9697 - out_2_acc: 0.9812 - val_loss: 0.3595 - val_out_1_loss: 0.1687 - val_out_2_loss: 0.1908 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0928 - out_1_loss: 0.0576 - out_2_loss: 0.0352 - out_1_acc: 0.9703 - out_2_acc: 0.9819 - val_loss: 0.3620 - val_out_1_loss: 0.1676 - val_out_2_loss: 0.1944 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9503\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0917 - out_1_loss: 0.0573 - out_2_loss: 0.0344 - out_1_acc: 0.9702 - out_2_acc: 0.9826 - val_loss: 0.3660 - val_out_1_loss: 0.1706 - val_out_2_loss: 0.1954 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9515\n",
      "Epoch 174/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0904 - out_1_loss: 0.0566 - out_2_loss: 0.0337 - out_1_acc: 0.9710 - out_2_acc: 0.9831 - val_loss: 0.3657 - val_out_1_loss: 0.1716 - val_out_2_loss: 0.1941 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9513\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0896 - out_1_loss: 0.0561 - out_2_loss: 0.0335 - out_1_acc: 0.9710 - out_2_acc: 0.9833 - val_loss: 0.3665 - val_out_1_loss: 0.1694 - val_out_2_loss: 0.1971 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9510\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0887 - out_1_loss: 0.0561 - out_2_loss: 0.0326 - out_1_acc: 0.9708 - out_2_acc: 0.9839 - val_loss: 0.3671 - val_out_1_loss: 0.1711 - val_out_2_loss: 0.1960 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9508\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0886 - out_1_loss: 0.0559 - out_2_loss: 0.0327 - out_1_acc: 0.9711 - out_2_acc: 0.9837 - val_loss: 0.3669 - val_out_1_loss: 0.1720 - val_out_2_loss: 0.1949 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0878 - out_1_loss: 0.0559 - out_2_loss: 0.0319 - out_1_acc: 0.9710 - out_2_acc: 0.9837 - val_loss: 0.3714 - val_out_1_loss: 0.1728 - val_out_2_loss: 0.1985 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9516\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0870 - out_1_loss: 0.0552 - out_2_loss: 0.0318 - out_1_acc: 0.9715 - out_2_acc: 0.9841 - val_loss: 0.3725 - val_out_1_loss: 0.1753 - val_out_2_loss: 0.1972 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9519\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0860 - out_1_loss: 0.0549 - out_2_loss: 0.0310 - out_1_acc: 0.9718 - out_2_acc: 0.9845 - val_loss: 0.3706 - val_out_1_loss: 0.1723 - val_out_2_loss: 0.1983 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9518\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0871 - out_1_loss: 0.0555 - out_2_loss: 0.0316 - out_1_acc: 0.9712 - out_2_acc: 0.9842 - val_loss: 0.3744 - val_out_1_loss: 0.1733 - val_out_2_loss: 0.2011 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9507\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0868 - out_1_loss: 0.0549 - out_2_loss: 0.0319 - out_1_acc: 0.9716 - out_2_acc: 0.9843 - val_loss: 0.3727 - val_out_1_loss: 0.1736 - val_out_2_loss: 0.1991 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0865 - out_1_loss: 0.0551 - out_2_loss: 0.0314 - out_1_acc: 0.9716 - out_2_acc: 0.9844 - val_loss: 0.3785 - val_out_1_loss: 0.1763 - val_out_2_loss: 0.2022 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0859 - out_1_loss: 0.0548 - out_2_loss: 0.0311 - out_1_acc: 0.9715 - out_2_acc: 0.9846 - val_loss: 0.3804 - val_out_1_loss: 0.1757 - val_out_2_loss: 0.2047 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9507\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0858 - out_1_loss: 0.0550 - out_2_loss: 0.0308 - out_1_acc: 0.9717 - out_2_acc: 0.9847 - val_loss: 0.3803 - val_out_1_loss: 0.1759 - val_out_2_loss: 0.2044 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0846 - out_1_loss: 0.0541 - out_2_loss: 0.0305 - out_1_acc: 0.9727 - out_2_acc: 0.9851 - val_loss: 0.3822 - val_out_1_loss: 0.1786 - val_out_2_loss: 0.2036 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0834 - out_1_loss: 0.0540 - out_2_loss: 0.0294 - out_1_acc: 0.9720 - out_2_acc: 0.9857 - val_loss: 0.3857 - val_out_1_loss: 0.1790 - val_out_2_loss: 0.2067 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0836 - out_1_loss: 0.0533 - out_2_loss: 0.0302 - out_1_acc: 0.9731 - out_2_acc: 0.9851 - val_loss: 0.3921 - val_out_1_loss: 0.1804 - val_out_2_loss: 0.2117 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0827 - out_1_loss: 0.0528 - out_2_loss: 0.0298 - out_1_acc: 0.9734 - out_2_acc: 0.9856 - val_loss: 0.3875 - val_out_1_loss: 0.1781 - val_out_2_loss: 0.2094 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0835 - out_1_loss: 0.0528 - out_2_loss: 0.0307 - out_1_acc: 0.9733 - out_2_acc: 0.9850 - val_loss: 0.3864 - val_out_1_loss: 0.1794 - val_out_2_loss: 0.2070 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0807 - out_1_loss: 0.0520 - out_2_loss: 0.0286 - out_1_acc: 0.9741 - out_2_acc: 0.9860 - val_loss: 0.3864 - val_out_1_loss: 0.1806 - val_out_2_loss: 0.2059 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0805 - out_1_loss: 0.0524 - out_2_loss: 0.0281 - out_1_acc: 0.9737 - out_2_acc: 0.9865 - val_loss: 0.3907 - val_out_1_loss: 0.1819 - val_out_2_loss: 0.2088 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0782 - out_1_loss: 0.0516 - out_2_loss: 0.0266 - out_1_acc: 0.9741 - out_2_acc: 0.9874 - val_loss: 0.3914 - val_out_1_loss: 0.1797 - val_out_2_loss: 0.2116 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0780 - out_1_loss: 0.0512 - out_2_loss: 0.0268 - out_1_acc: 0.9742 - out_2_acc: 0.9870 - val_loss: 0.3944 - val_out_1_loss: 0.1829 - val_out_2_loss: 0.2115 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9520\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0785 - out_1_loss: 0.0512 - out_2_loss: 0.0273 - out_1_acc: 0.9743 - out_2_acc: 0.9869 - val_loss: 0.3979 - val_out_1_loss: 0.1829 - val_out_2_loss: 0.2150 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0791 - out_1_loss: 0.0509 - out_2_loss: 0.0282 - out_1_acc: 0.9748 - out_2_acc: 0.9864 - val_loss: 0.4005 - val_out_1_loss: 0.1832 - val_out_2_loss: 0.2174 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0769 - out_1_loss: 0.0499 - out_2_loss: 0.0270 - out_1_acc: 0.9750 - out_2_acc: 0.9871 - val_loss: 0.4086 - val_out_1_loss: 0.1881 - val_out_2_loss: 0.2205 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9507\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0765 - out_1_loss: 0.0494 - out_2_loss: 0.0271 - out_1_acc: 0.9756 - out_2_acc: 0.9870 - val_loss: 0.4092 - val_out_1_loss: 0.1891 - val_out_2_loss: 0.2201 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0770 - out_1_loss: 0.0493 - out_2_loss: 0.0278 - out_1_acc: 0.9754 - out_2_acc: 0.9865 - val_loss: 0.4083 - val_out_1_loss: 0.1872 - val_out_2_loss: 0.2211 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0760 - out_1_loss: 0.0490 - out_2_loss: 0.0270 - out_1_acc: 0.9755 - out_2_acc: 0.9873 - val_loss: 0.4042 - val_out_1_loss: 0.1879 - val_out_2_loss: 0.2163 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9519\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0747 - out_1_loss: 0.0489 - out_2_loss: 0.0258 - out_1_acc: 0.9758 - out_2_acc: 0.9881 - val_loss: 0.4141 - val_out_1_loss: 0.1906 - val_out_2_loss: 0.2235 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9507\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0749 - out_1_loss: 0.0494 - out_2_loss: 0.0255 - out_1_acc: 0.9753 - out_2_acc: 0.9879 - val_loss: 0.4171 - val_out_1_loss: 0.1906 - val_out_2_loss: 0.2266 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9500\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0736 - out_1_loss: 0.0486 - out_2_loss: 0.0249 - out_1_acc: 0.9757 - out_2_acc: 0.9887 - val_loss: 0.4300 - val_out_1_loss: 0.1943 - val_out_2_loss: 0.2357 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9505\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0734 - out_1_loss: 0.0473 - out_2_loss: 0.0261 - out_1_acc: 0.9764 - out_2_acc: 0.9876 - val_loss: 0.4253 - val_out_1_loss: 0.1938 - val_out_2_loss: 0.2315 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9505\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0724 - out_1_loss: 0.0476 - out_2_loss: 0.0248 - out_1_acc: 0.9762 - out_2_acc: 0.9886 - val_loss: 0.4269 - val_out_1_loss: 0.1955 - val_out_2_loss: 0.2315 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9498\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0714 - out_1_loss: 0.0476 - out_2_loss: 0.0238 - out_1_acc: 0.9764 - out_2_acc: 0.9893 - val_loss: 0.4305 - val_out_1_loss: 0.1963 - val_out_2_loss: 0.2341 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9505\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0716 - out_1_loss: 0.0474 - out_2_loss: 0.0242 - out_1_acc: 0.9764 - out_2_acc: 0.9887 - val_loss: 0.4275 - val_out_1_loss: 0.1968 - val_out_2_loss: 0.2307 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 35ms/step - loss: 0.0716 - out_1_loss: 0.0475 - out_2_loss: 0.0241 - out_1_acc: 0.9765 - out_2_acc: 0.9889 - val_loss: 0.4291 - val_out_1_loss: 0.1985 - val_out_2_loss: 0.2306 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0709 - out_1_loss: 0.0470 - out_2_loss: 0.0240 - out_1_acc: 0.9771 - out_2_acc: 0.9889 - val_loss: 0.4312 - val_out_1_loss: 0.1973 - val_out_2_loss: 0.2339 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0711 - out_1_loss: 0.0477 - out_2_loss: 0.0234 - out_1_acc: 0.9762 - out_2_acc: 0.9894 - val_loss: 0.4369 - val_out_1_loss: 0.1982 - val_out_2_loss: 0.2387 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9509\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0693 - out_1_loss: 0.0462 - out_2_loss: 0.0231 - out_1_acc: 0.9775 - out_2_acc: 0.9896 - val_loss: 0.4349 - val_out_1_loss: 0.1998 - val_out_2_loss: 0.2351 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9515\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0679 - out_1_loss: 0.0457 - out_2_loss: 0.0222 - out_1_acc: 0.9773 - out_2_acc: 0.9902 - val_loss: 0.4422 - val_out_1_loss: 0.1976 - val_out_2_loss: 0.2446 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9500\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0682 - out_1_loss: 0.0460 - out_2_loss: 0.0222 - out_1_acc: 0.9772 - out_2_acc: 0.9903 - val_loss: 0.4449 - val_out_1_loss: 0.2008 - val_out_2_loss: 0.2442 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9515\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0685 - out_1_loss: 0.0461 - out_2_loss: 0.0224 - out_1_acc: 0.9774 - out_2_acc: 0.9901 - val_loss: 0.4431 - val_out_1_loss: 0.1990 - val_out_2_loss: 0.2441 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9499\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0690 - out_1_loss: 0.0461 - out_2_loss: 0.0230 - out_1_acc: 0.9774 - out_2_acc: 0.9898 - val_loss: 0.4385 - val_out_1_loss: 0.2010 - val_out_2_loss: 0.2376 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0696 - out_1_loss: 0.0459 - out_2_loss: 0.0237 - out_1_acc: 0.9777 - out_2_acc: 0.9894 - val_loss: 0.4448 - val_out_1_loss: 0.2006 - val_out_2_loss: 0.2441 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9514\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0685 - out_1_loss: 0.0450 - out_2_loss: 0.0234 - out_1_acc: 0.9784 - out_2_acc: 0.9891 - val_loss: 0.4451 - val_out_1_loss: 0.2041 - val_out_2_loss: 0.2410 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0656 - out_1_loss: 0.0440 - out_2_loss: 0.0216 - out_1_acc: 0.9786 - out_2_acc: 0.9904 - val_loss: 0.4462 - val_out_1_loss: 0.2045 - val_out_2_loss: 0.2417 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0647 - out_1_loss: 0.0437 - out_2_loss: 0.0210 - out_1_acc: 0.9788 - out_2_acc: 0.9907 - val_loss: 0.4548 - val_out_1_loss: 0.2063 - val_out_2_loss: 0.2485 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9495\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0657 - out_1_loss: 0.0444 - out_2_loss: 0.0213 - out_1_acc: 0.9781 - out_2_acc: 0.9907 - val_loss: 0.4563 - val_out_1_loss: 0.2060 - val_out_2_loss: 0.2503 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9508\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0662 - out_1_loss: 0.0447 - out_2_loss: 0.0216 - out_1_acc: 0.9782 - out_2_acc: 0.9904 - val_loss: 0.4557 - val_out_1_loss: 0.2074 - val_out_2_loss: 0.2483 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9509\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0645 - out_1_loss: 0.0439 - out_2_loss: 0.0206 - out_1_acc: 0.9786 - out_2_acc: 0.9909 - val_loss: 0.4579 - val_out_1_loss: 0.2069 - val_out_2_loss: 0.2510 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9511\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0636 - out_1_loss: 0.0435 - out_2_loss: 0.0201 - out_1_acc: 0.9789 - out_2_acc: 0.9914 - val_loss: 0.4534 - val_out_1_loss: 0.2060 - val_out_2_loss: 0.2473 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0635 - out_1_loss: 0.0430 - out_2_loss: 0.0205 - out_1_acc: 0.9794 - out_2_acc: 0.9913 - val_loss: 0.4609 - val_out_1_loss: 0.2099 - val_out_2_loss: 0.2511 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9513\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0629 - out_1_loss: 0.0426 - out_2_loss: 0.0203 - out_1_acc: 0.9796 - out_2_acc: 0.9909 - val_loss: 0.4657 - val_out_1_loss: 0.2138 - val_out_2_loss: 0.2520 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0625 - out_1_loss: 0.0430 - out_2_loss: 0.0194 - out_1_acc: 0.9792 - out_2_acc: 0.9915 - val_loss: 0.4691 - val_out_1_loss: 0.2132 - val_out_2_loss: 0.2559 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9520\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0621 - out_1_loss: 0.0427 - out_2_loss: 0.0194 - out_1_acc: 0.9795 - out_2_acc: 0.9913 - val_loss: 0.4664 - val_out_1_loss: 0.2112 - val_out_2_loss: 0.2552 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9513\n",
      "Epoch 228/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0608 - out_1_loss: 0.0421 - out_2_loss: 0.0187 - out_1_acc: 0.9801 - out_2_acc: 0.9918 - val_loss: 0.4722 - val_out_1_loss: 0.2125 - val_out_2_loss: 0.2597 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9508\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0589 - out_1_loss: 0.0407 - out_2_loss: 0.0182 - out_1_acc: 0.9807 - out_2_acc: 0.9921 - val_loss: 0.4795 - val_out_1_loss: 0.2140 - val_out_2_loss: 0.2656 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9502\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0590 - out_1_loss: 0.0410 - out_2_loss: 0.0180 - out_1_acc: 0.9805 - out_2_acc: 0.9922 - val_loss: 0.4803 - val_out_1_loss: 0.2174 - val_out_2_loss: 0.2629 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9512\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0574 - out_1_loss: 0.0406 - out_2_loss: 0.0169 - out_1_acc: 0.9810 - out_2_acc: 0.9927 - val_loss: 0.4814 - val_out_1_loss: 0.2150 - val_out_2_loss: 0.2664 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9508\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0586 - out_1_loss: 0.0406 - out_2_loss: 0.0180 - out_1_acc: 0.9807 - out_2_acc: 0.9921 - val_loss: 0.4736 - val_out_1_loss: 0.2137 - val_out_2_loss: 0.2599 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9513\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0573 - out_1_loss: 0.0400 - out_2_loss: 0.0172 - out_1_acc: 0.9816 - out_2_acc: 0.9926 - val_loss: 0.4751 - val_out_1_loss: 0.2152 - val_out_2_loss: 0.2600 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9522\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0595 - out_1_loss: 0.0404 - out_2_loss: 0.0191 - out_1_acc: 0.9806 - out_2_acc: 0.9916 - val_loss: 0.4787 - val_out_1_loss: 0.2168 - val_out_2_loss: 0.2620 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0599 - out_1_loss: 0.0412 - out_2_loss: 0.0187 - out_1_acc: 0.9800 - out_2_acc: 0.9917 - val_loss: 0.4839 - val_out_1_loss: 0.2214 - val_out_2_loss: 0.2625 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9507\n",
      "Epoch 236/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0582 - out_1_loss: 0.0405 - out_2_loss: 0.0177 - out_1_acc: 0.9808 - out_2_acc: 0.9921 - val_loss: 0.4841 - val_out_1_loss: 0.2211 - val_out_2_loss: 0.2630 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9512\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0557 - out_1_loss: 0.0391 - out_2_loss: 0.0167 - out_1_acc: 0.9812 - out_2_acc: 0.9928 - val_loss: 0.4933 - val_out_1_loss: 0.2236 - val_out_2_loss: 0.2697 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9500\n",
      "Epoch 238/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0557 - out_1_loss: 0.0398 - out_2_loss: 0.0159 - out_1_acc: 0.9815 - out_2_acc: 0.9930 - val_loss: 0.4959 - val_out_1_loss: 0.2224 - val_out_2_loss: 0.2734 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 239/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0550 - out_1_loss: 0.0391 - out_2_loss: 0.0159 - out_1_acc: 0.9814 - out_2_acc: 0.9933 - val_loss: 0.4983 - val_out_1_loss: 0.2228 - val_out_2_loss: 0.2755 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9506\n",
      "Epoch 240/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0552 - out_1_loss: 0.0389 - out_2_loss: 0.0163 - out_1_acc: 0.9822 - out_2_acc: 0.9930 - val_loss: 0.5008 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2761 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9507\n",
      "Epoch 241/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0545 - out_1_loss: 0.0389 - out_2_loss: 0.0156 - out_1_acc: 0.9817 - out_2_acc: 0.9936 - val_loss: 0.5068 - val_out_1_loss: 0.2268 - val_out_2_loss: 0.2800 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9498\n",
      "Epoch 242/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0559 - out_1_loss: 0.0398 - out_2_loss: 0.0161 - out_1_acc: 0.9813 - out_2_acc: 0.9933 - val_loss: 0.5028 - val_out_1_loss: 0.2264 - val_out_2_loss: 0.2764 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 243/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0559 - out_1_loss: 0.0402 - out_2_loss: 0.0157 - out_1_acc: 0.9811 - out_2_acc: 0.9933 - val_loss: 0.5098 - val_out_1_loss: 0.2247 - val_out_2_loss: 0.2852 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 244/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0546 - out_1_loss: 0.0391 - out_2_loss: 0.0155 - out_1_acc: 0.9817 - out_2_acc: 0.9938 - val_loss: 0.5143 - val_out_1_loss: 0.2272 - val_out_2_loss: 0.2870 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9496\n",
      "Epoch 245/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0546 - out_1_loss: 0.0389 - out_2_loss: 0.0158 - out_1_acc: 0.9820 - out_2_acc: 0.9935 - val_loss: 0.5153 - val_out_1_loss: 0.2290 - val_out_2_loss: 0.2862 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 246/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0530 - out_1_loss: 0.0382 - out_2_loss: 0.0148 - out_1_acc: 0.9826 - out_2_acc: 0.9938 - val_loss: 0.5118 - val_out_1_loss: 0.2271 - val_out_2_loss: 0.2847 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9503\n",
      "Epoch 247/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0525 - out_1_loss: 0.0383 - out_2_loss: 0.0142 - out_1_acc: 0.9822 - out_2_acc: 0.9943 - val_loss: 0.5121 - val_out_1_loss: 0.2285 - val_out_2_loss: 0.2836 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9507\n",
      "Epoch 248/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0510 - out_1_loss: 0.0372 - out_2_loss: 0.0138 - out_1_acc: 0.9830 - out_2_acc: 0.9943 - val_loss: 0.5120 - val_out_1_loss: 0.2285 - val_out_2_loss: 0.2835 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9508\n",
      "Epoch 249/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0515 - out_1_loss: 0.0367 - out_2_loss: 0.0148 - out_1_acc: 0.9832 - out_2_acc: 0.9939 - val_loss: 0.5197 - val_out_1_loss: 0.2316 - val_out_2_loss: 0.2881 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9510\n",
      "Epoch 250/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0525 - out_1_loss: 0.0375 - out_2_loss: 0.0151 - out_1_acc: 0.9830 - out_2_acc: 0.9936 - val_loss: 0.5287 - val_out_1_loss: 0.2360 - val_out_2_loss: 0.2927 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9510\n",
      "Epoch 251/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0524 - out_1_loss: 0.0374 - out_2_loss: 0.0149 - out_1_acc: 0.9827 - out_2_acc: 0.9937 - val_loss: 0.5302 - val_out_1_loss: 0.2356 - val_out_2_loss: 0.2945 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9509\n",
      "Epoch 252/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0524 - out_1_loss: 0.0382 - out_2_loss: 0.0141 - out_1_acc: 0.9824 - out_2_acc: 0.9940 - val_loss: 0.5231 - val_out_1_loss: 0.2361 - val_out_2_loss: 0.2870 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9509\n",
      "Epoch 253/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0514 - out_1_loss: 0.0375 - out_2_loss: 0.0139 - out_1_acc: 0.9827 - out_2_acc: 0.9942 - val_loss: 0.5268 - val_out_1_loss: 0.2364 - val_out_2_loss: 0.2904 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9524\n",
      "Epoch 254/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0494 - out_1_loss: 0.0366 - out_2_loss: 0.0128 - out_1_acc: 0.9832 - out_2_acc: 0.9948 - val_loss: 0.5253 - val_out_1_loss: 0.2325 - val_out_2_loss: 0.2928 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9512\n",
      "Epoch 255/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0480 - out_1_loss: 0.0356 - out_2_loss: 0.0124 - out_1_acc: 0.9840 - out_2_acc: 0.9949 - val_loss: 0.5338 - val_out_1_loss: 0.2364 - val_out_2_loss: 0.2974 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9507\n",
      "Epoch 256/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0492 - out_1_loss: 0.0355 - out_2_loss: 0.0137 - out_1_acc: 0.9837 - out_2_acc: 0.9944 - val_loss: 0.5302 - val_out_1_loss: 0.2387 - val_out_2_loss: 0.2915 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9513\n",
      "Epoch 257/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0510 - out_1_loss: 0.0370 - out_2_loss: 0.0140 - out_1_acc: 0.9830 - out_2_acc: 0.9946 - val_loss: 0.5326 - val_out_1_loss: 0.2391 - val_out_2_loss: 0.2934 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9510\n",
      "Epoch 258/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0486 - out_1_loss: 0.0354 - out_2_loss: 0.0132 - out_1_acc: 0.9841 - out_2_acc: 0.9945 - val_loss: 0.5399 - val_out_1_loss: 0.2404 - val_out_2_loss: 0.2995 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9500\n",
      "Epoch 259/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0473 - out_1_loss: 0.0346 - out_2_loss: 0.0127 - out_1_acc: 0.9846 - out_2_acc: 0.9952 - val_loss: 0.5312 - val_out_1_loss: 0.2394 - val_out_2_loss: 0.2918 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9511\n",
      "Epoch 260/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0457 - out_1_loss: 0.0339 - out_2_loss: 0.0118 - out_1_acc: 0.9846 - out_2_acc: 0.9950 - val_loss: 0.5447 - val_out_1_loss: 0.2425 - val_out_2_loss: 0.3023 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9500\n",
      "Epoch 261/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0458 - out_1_loss: 0.0341 - out_2_loss: 0.0117 - out_1_acc: 0.9843 - out_2_acc: 0.9953 - val_loss: 0.5493 - val_out_1_loss: 0.2450 - val_out_2_loss: 0.3043 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 262/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0507 - out_1_loss: 0.0358 - out_2_loss: 0.0149 - out_1_acc: 0.9837 - out_2_acc: 0.9942 - val_loss: 0.5502 - val_out_1_loss: 0.2466 - val_out_2_loss: 0.3037 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9501\n",
      "Epoch 263/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0497 - out_1_loss: 0.0357 - out_2_loss: 0.0139 - out_1_acc: 0.9840 - out_2_acc: 0.9948 - val_loss: 0.5431 - val_out_1_loss: 0.2424 - val_out_2_loss: 0.3007 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9501\n",
      "Epoch 264/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0464 - out_1_loss: 0.0338 - out_2_loss: 0.0126 - out_1_acc: 0.9852 - out_2_acc: 0.9949 - val_loss: 0.5472 - val_out_1_loss: 0.2461 - val_out_2_loss: 0.3011 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9497\n",
      "Epoch 265/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0454 - out_1_loss: 0.0330 - out_2_loss: 0.0125 - out_1_acc: 0.9851 - out_2_acc: 0.9951 - val_loss: 0.5491 - val_out_1_loss: 0.2475 - val_out_2_loss: 0.3016 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9503\n",
      "Epoch 266/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0474 - out_1_loss: 0.0340 - out_2_loss: 0.0133 - out_1_acc: 0.9848 - out_2_acc: 0.9946 - val_loss: 0.5451 - val_out_1_loss: 0.2481 - val_out_2_loss: 0.2970 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9506\n",
      "Epoch 267/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0442 - out_1_loss: 0.0328 - out_2_loss: 0.0114 - out_1_acc: 0.9856 - out_2_acc: 0.9956 - val_loss: 0.5513 - val_out_1_loss: 0.2490 - val_out_2_loss: 0.3024 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9508\n",
      "Epoch 268/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0429 - out_1_loss: 0.0321 - out_2_loss: 0.0108 - out_1_acc: 0.9859 - out_2_acc: 0.9958 - val_loss: 0.5519 - val_out_1_loss: 0.2522 - val_out_2_loss: 0.2998 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9510\n",
      "Epoch 269/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0431 - out_1_loss: 0.0317 - out_2_loss: 0.0114 - out_1_acc: 0.9860 - out_2_acc: 0.9956 - val_loss: 0.5578 - val_out_1_loss: 0.2553 - val_out_2_loss: 0.3026 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9511\n",
      "Epoch 270/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0416 - out_1_loss: 0.0310 - out_2_loss: 0.0106 - out_1_acc: 0.9864 - out_2_acc: 0.9959 - val_loss: 0.5578 - val_out_1_loss: 0.2553 - val_out_2_loss: 0.3025 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 271/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0417 - out_1_loss: 0.0310 - out_2_loss: 0.0107 - out_1_acc: 0.9864 - out_2_acc: 0.9956 - val_loss: 0.5589 - val_out_1_loss: 0.2589 - val_out_2_loss: 0.3000 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9503\n",
      "Epoch 272/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0425 - out_1_loss: 0.0318 - out_2_loss: 0.0107 - out_1_acc: 0.9857 - out_2_acc: 0.9958 - val_loss: 0.5624 - val_out_1_loss: 0.2569 - val_out_2_loss: 0.3055 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9504\n",
      "Epoch 273/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0415 - out_1_loss: 0.0306 - out_2_loss: 0.0109 - out_1_acc: 0.9868 - out_2_acc: 0.9957 - val_loss: 0.5714 - val_out_1_loss: 0.2598 - val_out_2_loss: 0.3116 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9512\n",
      "Epoch 274/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0430 - out_1_loss: 0.0312 - out_2_loss: 0.0118 - out_1_acc: 0.9862 - out_2_acc: 0.9955 - val_loss: 0.5699 - val_out_1_loss: 0.2590 - val_out_2_loss: 0.3109 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9503\n",
      "Epoch 275/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0421 - out_1_loss: 0.0314 - out_2_loss: 0.0107 - out_1_acc: 0.9863 - out_2_acc: 0.9958 - val_loss: 0.5646 - val_out_1_loss: 0.2557 - val_out_2_loss: 0.3089 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9498\n",
      "Epoch 276/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0409 - out_1_loss: 0.0312 - out_2_loss: 0.0097 - out_1_acc: 0.9864 - out_2_acc: 0.9963 - val_loss: 0.5656 - val_out_1_loss: 0.2583 - val_out_2_loss: 0.3073 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9504\n",
      "Epoch 277/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0414 - out_1_loss: 0.0309 - out_2_loss: 0.0105 - out_1_acc: 0.9866 - out_2_acc: 0.9959 - val_loss: 0.5720 - val_out_1_loss: 0.2597 - val_out_2_loss: 0.3123 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9503\n",
      "Epoch 278/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0408 - out_1_loss: 0.0301 - out_2_loss: 0.0107 - out_1_acc: 0.9869 - out_2_acc: 0.9959 - val_loss: 0.5742 - val_out_1_loss: 0.2637 - val_out_2_loss: 0.3105 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9514\n",
      "Epoch 279/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0402 - out_1_loss: 0.0301 - out_2_loss: 0.0101 - out_1_acc: 0.9871 - out_2_acc: 0.9962 - val_loss: 0.5798 - val_out_1_loss: 0.2636 - val_out_2_loss: 0.3162 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9513\n",
      "Epoch 280/300\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.0422 - out_1_loss: 0.0313 - out_2_loss: 0.0109 - out_1_acc: 0.9862 - out_2_acc: 0.9957 - val_loss: 0.5767 - val_out_1_loss: 0.2637 - val_out_2_loss: 0.3130 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9513\n",
      "Epoch 281/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0421 - out_1_loss: 0.0312 - out_2_loss: 0.0109 - out_1_acc: 0.9865 - out_2_acc: 0.9956 - val_loss: 0.5792 - val_out_1_loss: 0.2632 - val_out_2_loss: 0.3160 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9505\n",
      "Epoch 282/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0420 - out_1_loss: 0.0311 - out_2_loss: 0.0109 - out_1_acc: 0.9863 - out_2_acc: 0.9960 - val_loss: 0.5860 - val_out_1_loss: 0.2679 - val_out_2_loss: 0.3181 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9507\n",
      "Epoch 283/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0416 - out_1_loss: 0.0303 - out_2_loss: 0.0113 - out_1_acc: 0.9866 - out_2_acc: 0.9959 - val_loss: 0.5851 - val_out_1_loss: 0.2667 - val_out_2_loss: 0.3184 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 284/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0417 - out_1_loss: 0.0299 - out_2_loss: 0.0119 - out_1_acc: 0.9870 - out_2_acc: 0.9957 - val_loss: 0.5883 - val_out_1_loss: 0.2696 - val_out_2_loss: 0.3187 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9512\n",
      "Epoch 285/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0408 - out_1_loss: 0.0305 - out_2_loss: 0.0103 - out_1_acc: 0.9866 - out_2_acc: 0.9959 - val_loss: 0.5797 - val_out_1_loss: 0.2667 - val_out_2_loss: 0.3130 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9517\n",
      "Epoch 286/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0398 - out_1_loss: 0.0296 - out_2_loss: 0.0102 - out_1_acc: 0.9870 - out_2_acc: 0.9960 - val_loss: 0.5888 - val_out_1_loss: 0.2711 - val_out_2_loss: 0.3177 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9510\n",
      "Epoch 287/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0389 - out_1_loss: 0.0291 - out_2_loss: 0.0099 - out_1_acc: 0.9872 - out_2_acc: 0.9963 - val_loss: 0.5868 - val_out_1_loss: 0.2711 - val_out_2_loss: 0.3156 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 288/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0399 - out_1_loss: 0.0297 - out_2_loss: 0.0102 - out_1_acc: 0.9868 - out_2_acc: 0.9959 - val_loss: 0.5901 - val_out_1_loss: 0.2727 - val_out_2_loss: 0.3173 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9515\n",
      "Epoch 289/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0395 - out_1_loss: 0.0299 - out_2_loss: 0.0097 - out_1_acc: 0.9868 - out_2_acc: 0.9962 - val_loss: 0.5966 - val_out_1_loss: 0.2752 - val_out_2_loss: 0.3215 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 290/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0368 - out_1_loss: 0.0283 - out_2_loss: 0.0086 - out_1_acc: 0.9878 - out_2_acc: 0.9967 - val_loss: 0.5972 - val_out_1_loss: 0.2747 - val_out_2_loss: 0.3225 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9505\n",
      "Epoch 291/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0377 - out_1_loss: 0.0288 - out_2_loss: 0.0089 - out_1_acc: 0.9875 - out_2_acc: 0.9966 - val_loss: 0.6123 - val_out_1_loss: 0.2793 - val_out_2_loss: 0.3330 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9510\n",
      "Epoch 292/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0365 - out_1_loss: 0.0281 - out_2_loss: 0.0084 - out_1_acc: 0.9882 - out_2_acc: 0.9967 - val_loss: 0.6094 - val_out_1_loss: 0.2803 - val_out_2_loss: 0.3292 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9507\n",
      "Epoch 293/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0353 - out_1_loss: 0.0279 - out_2_loss: 0.0074 - out_1_acc: 0.9878 - out_2_acc: 0.9973 - val_loss: 0.6071 - val_out_1_loss: 0.2769 - val_out_2_loss: 0.3303 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9503\n",
      "Epoch 294/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0368 - out_1_loss: 0.0287 - out_2_loss: 0.0081 - out_1_acc: 0.9879 - out_2_acc: 0.9970 - val_loss: 0.6122 - val_out_1_loss: 0.2786 - val_out_2_loss: 0.3336 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0357 - out_1_loss: 0.0285 - out_2_loss: 0.0072 - out_1_acc: 0.9875 - out_2_acc: 0.9974 - val_loss: 0.6201 - val_out_1_loss: 0.2810 - val_out_2_loss: 0.3392 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9509\n",
      "Epoch 296/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0353 - out_1_loss: 0.0279 - out_2_loss: 0.0074 - out_1_acc: 0.9884 - out_2_acc: 0.9972 - val_loss: 0.6131 - val_out_1_loss: 0.2807 - val_out_2_loss: 0.3324 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9498\n",
      "Epoch 297/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0333 - out_1_loss: 0.0265 - out_2_loss: 0.0068 - out_1_acc: 0.9885 - out_2_acc: 0.9975 - val_loss: 0.6158 - val_out_1_loss: 0.2824 - val_out_2_loss: 0.3334 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 298/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0331 - out_1_loss: 0.0259 - out_2_loss: 0.0073 - out_1_acc: 0.9889 - out_2_acc: 0.9973 - val_loss: 0.6124 - val_out_1_loss: 0.2811 - val_out_2_loss: 0.3312 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 299/300\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0349 - out_1_loss: 0.0264 - out_2_loss: 0.0085 - out_1_acc: 0.9892 - out_2_acc: 0.9970 - val_loss: 0.6164 - val_out_1_loss: 0.2846 - val_out_2_loss: 0.3318 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9515\n",
      "Epoch 300/300\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.0352 - out_1_loss: 0.0266 - out_2_loss: 0.0086 - out_1_acc: 0.9887 - out_2_acc: 0.9967 - val_loss: 0.6243 - val_out_1_loss: 0.2873 - val_out_2_loss: 0.3369 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9512\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(100)-timesteps(6)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5851 - out_1_loss: 0.2703 - out_2_loss: 0.3148 - out_1_acc: 0.9414 - out_2_acc: 0.9523\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 200), (No 184800      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 200)       184800      input_13[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,107,680\n",
      "Trainable params: 1,107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3432 - out_1_loss: 3.6729 - out_2_loss: 3.6703 - out_1_acc: 0.1320 - out_2_acc: 0.1182WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112017). Check your callbacks.\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 5.7105 - out_1_loss: 2.9308 - out_2_loss: 2.7798 - out_1_acc: 0.3990 - out_2_acc: 0.4040 - val_loss: 4.1194 - val_out_1_loss: 2.1420 - val_out_2_loss: 1.9774 - val_out_1_acc: 0.4951 - val_out_2_acc: 0.5372\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 3.1343 - out_1_loss: 1.7713 - out_2_loss: 1.3630 - out_1_acc: 0.5723 - out_2_acc: 0.6543 - val_loss: 2.0579 - val_out_1_loss: 1.2921 - val_out_2_loss: 0.7659 - val_out_1_acc: 0.6742 - val_out_2_acc: 0.8179\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 1.3828 - out_1_loss: 0.8674 - out_2_loss: 0.5154 - out_1_acc: 0.7869 - out_2_acc: 0.8728 - val_loss: 0.8707 - val_out_1_loss: 0.5316 - val_out_2_loss: 0.3391 - val_out_1_acc: 0.8769 - val_out_2_acc: 0.9172\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.6459 - out_1_loss: 0.3969 - out_2_loss: 0.2489 - out_1_acc: 0.9095 - out_2_acc: 0.9353 - val_loss: 0.5070 - val_out_1_loss: 0.3063 - val_out_2_loss: 0.2007 - val_out_1_acc: 0.9258 - val_out_2_acc: 0.9475\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.4094 - out_1_loss: 0.2490 - out_2_loss: 0.1603 - out_1_acc: 0.9308 - out_2_acc: 0.9517 - val_loss: 0.3662 - val_out_1_loss: 0.2155 - val_out_2_loss: 0.1507 - val_out_1_acc: 0.9334 - val_out_2_acc: 0.9494\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.3090 - out_1_loss: 0.1842 - out_2_loss: 0.1247 - out_1_acc: 0.9372 - out_2_acc: 0.9536 - val_loss: 0.2994 - val_out_1_loss: 0.1728 - val_out_2_loss: 0.1266 - val_out_1_acc: 0.9363 - val_out_2_acc: 0.9496\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.2611 - out_1_loss: 0.1535 - out_2_loss: 0.1076 - out_1_acc: 0.9396 - out_2_acc: 0.9542 - val_loss: 0.2633 - val_out_1_loss: 0.1516 - val_out_2_loss: 0.1117 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9510\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2336 - out_1_loss: 0.1358 - out_2_loss: 0.0978 - out_1_acc: 0.9404 - out_2_acc: 0.9537 - val_loss: 0.2418 - val_out_1_loss: 0.1373 - val_out_2_loss: 0.1045 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9505\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2161 - out_1_loss: 0.1246 - out_2_loss: 0.0916 - out_1_acc: 0.9410 - out_2_acc: 0.9544 - val_loss: 0.2291 - val_out_1_loss: 0.1282 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9509\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.2052 - out_1_loss: 0.1173 - out_2_loss: 0.0879 - out_1_acc: 0.9421 - out_2_acc: 0.9550 - val_loss: 0.2209 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9512\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1980 - out_1_loss: 0.1124 - out_2_loss: 0.0856 - out_1_acc: 0.9423 - out_2_acc: 0.9551 - val_loss: 0.2155 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9516\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1924 - out_1_loss: 0.1088 - out_2_loss: 0.0837 - out_1_acc: 0.9428 - out_2_acc: 0.9558 - val_loss: 0.2118 - val_out_1_loss: 0.1164 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1881 - out_1_loss: 0.1061 - out_2_loss: 0.0820 - out_1_acc: 0.9432 - out_2_acc: 0.9562 - val_loss: 0.2099 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9513\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1847 - out_1_loss: 0.1041 - out_2_loss: 0.0806 - out_1_acc: 0.9436 - out_2_acc: 0.9566 - val_loss: 0.2078 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9505\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1822 - out_1_loss: 0.1025 - out_2_loss: 0.0797 - out_1_acc: 0.9438 - out_2_acc: 0.9568 - val_loss: 0.2069 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9506\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1802 - out_1_loss: 0.1012 - out_2_loss: 0.0791 - out_1_acc: 0.9439 - out_2_acc: 0.9572 - val_loss: 0.2061 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1782 - out_1_loss: 0.1001 - out_2_loss: 0.0781 - out_1_acc: 0.9442 - out_2_acc: 0.9574 - val_loss: 0.2051 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0945 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1762 - out_1_loss: 0.0991 - out_2_loss: 0.0771 - out_1_acc: 0.9448 - out_2_acc: 0.9577 - val_loss: 0.2062 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1744 - out_1_loss: 0.0982 - out_2_loss: 0.0761 - out_1_acc: 0.9448 - out_2_acc: 0.9576 - val_loss: 0.2063 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1730 - out_1_loss: 0.0976 - out_2_loss: 0.0754 - out_1_acc: 0.9449 - out_2_acc: 0.9586 - val_loss: 0.2061 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1714 - out_1_loss: 0.0968 - out_2_loss: 0.0745 - out_1_acc: 0.9456 - out_2_acc: 0.9590 - val_loss: 0.2057 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0948 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1702 - out_1_loss: 0.0961 - out_2_loss: 0.0741 - out_1_acc: 0.9459 - out_2_acc: 0.9593 - val_loss: 0.2050 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1690 - out_1_loss: 0.0956 - out_2_loss: 0.0734 - out_1_acc: 0.9463 - out_2_acc: 0.9595 - val_loss: 0.2061 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1682 - out_1_loss: 0.0950 - out_2_loss: 0.0731 - out_1_acc: 0.9465 - out_2_acc: 0.9597 - val_loss: 0.2064 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1668 - out_1_loss: 0.0945 - out_2_loss: 0.0723 - out_1_acc: 0.9470 - out_2_acc: 0.9597 - val_loss: 0.2065 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0957 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1658 - out_1_loss: 0.0940 - out_2_loss: 0.0718 - out_1_acc: 0.9474 - out_2_acc: 0.9599 - val_loss: 0.2081 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0968 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1649 - out_1_loss: 0.0936 - out_2_loss: 0.0713 - out_1_acc: 0.9473 - out_2_acc: 0.9601 - val_loss: 0.2071 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9523\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1632 - out_1_loss: 0.0930 - out_2_loss: 0.0702 - out_1_acc: 0.9479 - out_2_acc: 0.9611 - val_loss: 0.2066 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9506\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1622 - out_1_loss: 0.0925 - out_2_loss: 0.0696 - out_1_acc: 0.9477 - out_2_acc: 0.9610 - val_loss: 0.2069 - val_out_1_loss: 0.1109 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1608 - out_1_loss: 0.0921 - out_2_loss: 0.0688 - out_1_acc: 0.9477 - out_2_acc: 0.9613 - val_loss: 0.2081 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0970 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1604 - out_1_loss: 0.0916 - out_2_loss: 0.0688 - out_1_acc: 0.9477 - out_2_acc: 0.9615 - val_loss: 0.2081 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0969 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1597 - out_1_loss: 0.0910 - out_2_loss: 0.0687 - out_1_acc: 0.9486 - out_2_acc: 0.9618 - val_loss: 0.2093 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1589 - out_1_loss: 0.0907 - out_2_loss: 0.0682 - out_1_acc: 0.9485 - out_2_acc: 0.9619 - val_loss: 0.2121 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.1005 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9511\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1582 - out_1_loss: 0.0906 - out_2_loss: 0.0676 - out_1_acc: 0.9494 - out_2_acc: 0.9616 - val_loss: 0.2110 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0998 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9501\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1562 - out_1_loss: 0.0899 - out_2_loss: 0.0663 - out_1_acc: 0.9494 - out_2_acc: 0.9628 - val_loss: 0.2110 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0989 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1541 - out_1_loss: 0.0893 - out_2_loss: 0.0648 - out_1_acc: 0.9491 - out_2_acc: 0.9630 - val_loss: 0.2118 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.0989 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1519 - out_1_loss: 0.0887 - out_2_loss: 0.0632 - out_1_acc: 0.9494 - out_2_acc: 0.9637 - val_loss: 0.2136 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1512 - out_1_loss: 0.0885 - out_2_loss: 0.0627 - out_1_acc: 0.9494 - out_2_acc: 0.9642 - val_loss: 0.2160 - val_out_1_loss: 0.1139 - val_out_2_loss: 0.1021 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9519\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1498 - out_1_loss: 0.0878 - out_2_loss: 0.0620 - out_1_acc: 0.9506 - out_2_acc: 0.9648 - val_loss: 0.2182 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1029 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1488 - out_1_loss: 0.0875 - out_2_loss: 0.0613 - out_1_acc: 0.9507 - out_2_acc: 0.9646 - val_loss: 0.2213 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.1051 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1477 - out_1_loss: 0.0868 - out_2_loss: 0.0609 - out_1_acc: 0.9514 - out_2_acc: 0.9648 - val_loss: 0.2202 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1047 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9516\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1466 - out_1_loss: 0.0866 - out_2_loss: 0.0600 - out_1_acc: 0.9517 - out_2_acc: 0.9655 - val_loss: 0.2206 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1056 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1455 - out_1_loss: 0.0861 - out_2_loss: 0.0594 - out_1_acc: 0.9517 - out_2_acc: 0.9659 - val_loss: 0.2238 - val_out_1_loss: 0.1155 - val_out_2_loss: 0.1083 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9516\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1441 - out_1_loss: 0.0856 - out_2_loss: 0.0585 - out_1_acc: 0.9520 - out_2_acc: 0.9664 - val_loss: 0.2244 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.1087 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9511\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1443 - out_1_loss: 0.0855 - out_2_loss: 0.0588 - out_1_acc: 0.9519 - out_2_acc: 0.9661 - val_loss: 0.2276 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.1095 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9514\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1432 - out_1_loss: 0.0849 - out_2_loss: 0.0583 - out_1_acc: 0.9528 - out_2_acc: 0.9661 - val_loss: 0.2273 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1094 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9517\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1427 - out_1_loss: 0.0845 - out_2_loss: 0.0582 - out_1_acc: 0.9529 - out_2_acc: 0.9664 - val_loss: 0.2281 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1115 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1420 - out_1_loss: 0.0839 - out_2_loss: 0.0581 - out_1_acc: 0.9528 - out_2_acc: 0.9660 - val_loss: 0.2332 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1157 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1418 - out_1_loss: 0.0835 - out_2_loss: 0.0583 - out_1_acc: 0.9530 - out_2_acc: 0.9656 - val_loss: 0.2309 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.1131 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1402 - out_1_loss: 0.0829 - out_2_loss: 0.0573 - out_1_acc: 0.9532 - out_2_acc: 0.9659 - val_loss: 0.2309 - val_out_1_loss: 0.1197 - val_out_2_loss: 0.1113 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1389 - out_1_loss: 0.0824 - out_2_loss: 0.0565 - out_1_acc: 0.9530 - out_2_acc: 0.9668 - val_loss: 0.2304 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.1115 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1361 - out_1_loss: 0.0811 - out_2_loss: 0.0550 - out_1_acc: 0.9546 - out_2_acc: 0.9670 - val_loss: 0.2329 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1143 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9530\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1344 - out_1_loss: 0.0806 - out_2_loss: 0.0538 - out_1_acc: 0.9542 - out_2_acc: 0.9677 - val_loss: 0.2333 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1139 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9518\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1332 - out_1_loss: 0.0799 - out_2_loss: 0.0533 - out_1_acc: 0.9548 - out_2_acc: 0.9680 - val_loss: 0.2367 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1160 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9530\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1327 - out_1_loss: 0.0797 - out_2_loss: 0.0529 - out_1_acc: 0.9553 - out_2_acc: 0.9675 - val_loss: 0.2381 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.1172 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1316 - out_1_loss: 0.0792 - out_2_loss: 0.0523 - out_1_acc: 0.9554 - out_2_acc: 0.9684 - val_loss: 0.2398 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.1182 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9535\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1302 - out_1_loss: 0.0786 - out_2_loss: 0.0516 - out_1_acc: 0.9563 - out_2_acc: 0.9689 - val_loss: 0.2400 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1188 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9527\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1294 - out_1_loss: 0.0781 - out_2_loss: 0.0513 - out_1_acc: 0.9569 - out_2_acc: 0.9691 - val_loss: 0.2459 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1235 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1293 - out_1_loss: 0.0778 - out_2_loss: 0.0514 - out_1_acc: 0.9563 - out_2_acc: 0.9689 - val_loss: 0.2449 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1216 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9529\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1280 - out_1_loss: 0.0771 - out_2_loss: 0.0509 - out_1_acc: 0.9574 - out_2_acc: 0.9697 - val_loss: 0.2468 - val_out_1_loss: 0.1245 - val_out_2_loss: 0.1223 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1275 - out_1_loss: 0.0767 - out_2_loss: 0.0508 - out_1_acc: 0.9572 - out_2_acc: 0.9702 - val_loss: 0.2498 - val_out_1_loss: 0.1249 - val_out_2_loss: 0.1249 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1274 - out_1_loss: 0.0769 - out_2_loss: 0.0505 - out_1_acc: 0.9571 - out_2_acc: 0.9703 - val_loss: 0.2522 - val_out_1_loss: 0.1282 - val_out_2_loss: 0.1240 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9532\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1280 - out_1_loss: 0.0769 - out_2_loss: 0.0511 - out_1_acc: 0.9570 - out_2_acc: 0.9696 - val_loss: 0.2520 - val_out_1_loss: 0.1281 - val_out_2_loss: 0.1239 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9528\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1277 - out_1_loss: 0.0766 - out_2_loss: 0.0511 - out_1_acc: 0.9574 - out_2_acc: 0.9699 - val_loss: 0.2519 - val_out_1_loss: 0.1277 - val_out_2_loss: 0.1242 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9534\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1269 - out_1_loss: 0.0761 - out_2_loss: 0.0508 - out_1_acc: 0.9579 - out_2_acc: 0.9702 - val_loss: 0.2539 - val_out_1_loss: 0.1277 - val_out_2_loss: 0.1263 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1277 - out_1_loss: 0.0766 - out_2_loss: 0.0512 - out_1_acc: 0.9569 - out_2_acc: 0.9699 - val_loss: 0.2572 - val_out_1_loss: 0.1305 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1274 - out_1_loss: 0.0761 - out_2_loss: 0.0513 - out_1_acc: 0.9577 - out_2_acc: 0.9700 - val_loss: 0.2603 - val_out_1_loss: 0.1301 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1274 - out_1_loss: 0.0760 - out_2_loss: 0.0514 - out_1_acc: 0.9578 - out_2_acc: 0.9697 - val_loss: 0.2604 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1307 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1283 - out_1_loss: 0.0768 - out_2_loss: 0.0514 - out_1_acc: 0.9564 - out_2_acc: 0.9699 - val_loss: 0.2574 - val_out_1_loss: 0.1286 - val_out_2_loss: 0.1288 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9528\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1266 - out_1_loss: 0.0756 - out_2_loss: 0.0509 - out_1_acc: 0.9572 - out_2_acc: 0.9699 - val_loss: 0.2576 - val_out_1_loss: 0.1281 - val_out_2_loss: 0.1295 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9531\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1250 - out_1_loss: 0.0747 - out_2_loss: 0.0503 - out_1_acc: 0.9569 - out_2_acc: 0.9702 - val_loss: 0.2603 - val_out_1_loss: 0.1294 - val_out_2_loss: 0.1309 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1233 - out_1_loss: 0.0735 - out_2_loss: 0.0498 - out_1_acc: 0.9586 - out_2_acc: 0.9703 - val_loss: 0.2646 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1335 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9535\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1217 - out_1_loss: 0.0725 - out_2_loss: 0.0491 - out_1_acc: 0.9590 - out_2_acc: 0.9707 - val_loss: 0.2637 - val_out_1_loss: 0.1310 - val_out_2_loss: 0.1327 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9537\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1197 - out_1_loss: 0.0711 - out_2_loss: 0.0486 - out_1_acc: 0.9598 - out_2_acc: 0.9711 - val_loss: 0.2660 - val_out_1_loss: 0.1329 - val_out_2_loss: 0.1330 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1197 - out_1_loss: 0.0711 - out_2_loss: 0.0486 - out_1_acc: 0.9597 - out_2_acc: 0.9715 - val_loss: 0.2668 - val_out_1_loss: 0.1340 - val_out_2_loss: 0.1328 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9533\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1187 - out_1_loss: 0.0705 - out_2_loss: 0.0482 - out_1_acc: 0.9601 - out_2_acc: 0.9714 - val_loss: 0.2699 - val_out_1_loss: 0.1378 - val_out_2_loss: 0.1321 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9535\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1177 - out_1_loss: 0.0698 - out_2_loss: 0.0478 - out_1_acc: 0.9610 - out_2_acc: 0.9718 - val_loss: 0.2724 - val_out_1_loss: 0.1389 - val_out_2_loss: 0.1335 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1178 - out_1_loss: 0.0700 - out_2_loss: 0.0478 - out_1_acc: 0.9606 - out_2_acc: 0.9718 - val_loss: 0.2734 - val_out_1_loss: 0.1397 - val_out_2_loss: 0.1337 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9526\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1178 - out_1_loss: 0.0699 - out_2_loss: 0.0479 - out_1_acc: 0.9605 - out_2_acc: 0.9715 - val_loss: 0.2748 - val_out_1_loss: 0.1404 - val_out_2_loss: 0.1344 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1162 - out_1_loss: 0.0692 - out_2_loss: 0.0470 - out_1_acc: 0.9605 - out_2_acc: 0.9728 - val_loss: 0.2774 - val_out_1_loss: 0.1412 - val_out_2_loss: 0.1362 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9529\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.1161 - out_1_loss: 0.0693 - out_2_loss: 0.0468 - out_1_acc: 0.9614 - out_2_acc: 0.9728 - val_loss: 0.2818 - val_out_1_loss: 0.1429 - val_out_2_loss: 0.1389 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1163 - out_1_loss: 0.0691 - out_2_loss: 0.0472 - out_1_acc: 0.9608 - out_2_acc: 0.9723 - val_loss: 0.2824 - val_out_1_loss: 0.1441 - val_out_2_loss: 0.1383 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1170 - out_1_loss: 0.0695 - out_2_loss: 0.0475 - out_1_acc: 0.9608 - out_2_acc: 0.9727 - val_loss: 0.2827 - val_out_1_loss: 0.1459 - val_out_2_loss: 0.1368 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9530\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1161 - out_1_loss: 0.0693 - out_2_loss: 0.0468 - out_1_acc: 0.9611 - out_2_acc: 0.9730 - val_loss: 0.2909 - val_out_1_loss: 0.1475 - val_out_2_loss: 0.1434 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9523\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1172 - out_1_loss: 0.0696 - out_2_loss: 0.0475 - out_1_acc: 0.9605 - out_2_acc: 0.9729 - val_loss: 0.2864 - val_out_1_loss: 0.1448 - val_out_2_loss: 0.1416 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9533\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1164 - out_1_loss: 0.0692 - out_2_loss: 0.0472 - out_1_acc: 0.9609 - out_2_acc: 0.9727 - val_loss: 0.2842 - val_out_1_loss: 0.1441 - val_out_2_loss: 0.1401 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1163 - out_1_loss: 0.0692 - out_2_loss: 0.0471 - out_1_acc: 0.9616 - out_2_acc: 0.9728 - val_loss: 0.2848 - val_out_1_loss: 0.1451 - val_out_2_loss: 0.1397 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1151 - out_1_loss: 0.0687 - out_2_loss: 0.0465 - out_1_acc: 0.9610 - out_2_acc: 0.9730 - val_loss: 0.2824 - val_out_1_loss: 0.1438 - val_out_2_loss: 0.1386 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1149 - out_1_loss: 0.0683 - out_2_loss: 0.0467 - out_1_acc: 0.9612 - out_2_acc: 0.9729 - val_loss: 0.2853 - val_out_1_loss: 0.1448 - val_out_2_loss: 0.1405 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1133 - out_1_loss: 0.0674 - out_2_loss: 0.0459 - out_1_acc: 0.9620 - out_2_acc: 0.9735 - val_loss: 0.2851 - val_out_1_loss: 0.1449 - val_out_2_loss: 0.1402 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9526\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1126 - out_1_loss: 0.0666 - out_2_loss: 0.0460 - out_1_acc: 0.9622 - out_2_acc: 0.9734 - val_loss: 0.2910 - val_out_1_loss: 0.1475 - val_out_2_loss: 0.1435 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1117 - out_1_loss: 0.0660 - out_2_loss: 0.0457 - out_1_acc: 0.9624 - out_2_acc: 0.9736 - val_loss: 0.2910 - val_out_1_loss: 0.1465 - val_out_2_loss: 0.1445 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1116 - out_1_loss: 0.0658 - out_2_loss: 0.0458 - out_1_acc: 0.9626 - out_2_acc: 0.9736 - val_loss: 0.2919 - val_out_1_loss: 0.1477 - val_out_2_loss: 0.1443 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1112 - out_1_loss: 0.0654 - out_2_loss: 0.0458 - out_1_acc: 0.9631 - out_2_acc: 0.9738 - val_loss: 0.2942 - val_out_1_loss: 0.1482 - val_out_2_loss: 0.1460 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9530\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1102 - out_1_loss: 0.0649 - out_2_loss: 0.0454 - out_1_acc: 0.9632 - out_2_acc: 0.9737 - val_loss: 0.2943 - val_out_1_loss: 0.1494 - val_out_2_loss: 0.1449 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9526\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1095 - out_1_loss: 0.0649 - out_2_loss: 0.0446 - out_1_acc: 0.9632 - out_2_acc: 0.9742 - val_loss: 0.2998 - val_out_1_loss: 0.1497 - val_out_2_loss: 0.1500 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9522\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1086 - out_1_loss: 0.0640 - out_2_loss: 0.0446 - out_1_acc: 0.9639 - out_2_acc: 0.9746 - val_loss: 0.2996 - val_out_1_loss: 0.1510 - val_out_2_loss: 0.1486 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9527\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1079 - out_1_loss: 0.0628 - out_2_loss: 0.0451 - out_1_acc: 0.9647 - out_2_acc: 0.9741 - val_loss: 0.3003 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1474 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9526\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1062 - out_1_loss: 0.0620 - out_2_loss: 0.0442 - out_1_acc: 0.9653 - out_2_acc: 0.9747 - val_loss: 0.3002 - val_out_1_loss: 0.1514 - val_out_2_loss: 0.1488 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9530\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1052 - out_1_loss: 0.0613 - out_2_loss: 0.0438 - out_1_acc: 0.9657 - out_2_acc: 0.9749 - val_loss: 0.3063 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1043 - out_1_loss: 0.0609 - out_2_loss: 0.0435 - out_1_acc: 0.9661 - out_2_acc: 0.9753 - val_loss: 0.3053 - val_out_1_loss: 0.1554 - val_out_2_loss: 0.1499 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1054 - out_1_loss: 0.0617 - out_2_loss: 0.0437 - out_1_acc: 0.9657 - out_2_acc: 0.9754 - val_loss: 0.3050 - val_out_1_loss: 0.1549 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1040 - out_1_loss: 0.0615 - out_2_loss: 0.0425 - out_1_acc: 0.9658 - out_2_acc: 0.9761 - val_loss: 0.3071 - val_out_1_loss: 0.1552 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9520\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1034 - out_1_loss: 0.0609 - out_2_loss: 0.0425 - out_1_acc: 0.9664 - out_2_acc: 0.9765 - val_loss: 0.3099 - val_out_1_loss: 0.1557 - val_out_2_loss: 0.1541 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9505\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1036 - out_1_loss: 0.0612 - out_2_loss: 0.0424 - out_1_acc: 0.9661 - out_2_acc: 0.9760 - val_loss: 0.3139 - val_out_1_loss: 0.1587 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1034 - out_1_loss: 0.0605 - out_2_loss: 0.0429 - out_1_acc: 0.9665 - out_2_acc: 0.9765 - val_loss: 0.3148 - val_out_1_loss: 0.1566 - val_out_2_loss: 0.1582 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9523\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1024 - out_1_loss: 0.0600 - out_2_loss: 0.0423 - out_1_acc: 0.9670 - out_2_acc: 0.9769 - val_loss: 0.3150 - val_out_1_loss: 0.1593 - val_out_2_loss: 0.1556 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1016 - out_1_loss: 0.0599 - out_2_loss: 0.0417 - out_1_acc: 0.9670 - out_2_acc: 0.9767 - val_loss: 0.3163 - val_out_1_loss: 0.1584 - val_out_2_loss: 0.1580 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9527\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1008 - out_1_loss: 0.0595 - out_2_loss: 0.0413 - out_1_acc: 0.9675 - out_2_acc: 0.9773 - val_loss: 0.3206 - val_out_1_loss: 0.1610 - val_out_2_loss: 0.1596 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1018 - out_1_loss: 0.0598 - out_2_loss: 0.0420 - out_1_acc: 0.9677 - out_2_acc: 0.9771 - val_loss: 0.3232 - val_out_1_loss: 0.1628 - val_out_2_loss: 0.1604 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1012 - out_1_loss: 0.0595 - out_2_loss: 0.0417 - out_1_acc: 0.9671 - out_2_acc: 0.9769 - val_loss: 0.3211 - val_out_1_loss: 0.1624 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1009 - out_1_loss: 0.0586 - out_2_loss: 0.0422 - out_1_acc: 0.9678 - out_2_acc: 0.9768 - val_loss: 0.3226 - val_out_1_loss: 0.1638 - val_out_2_loss: 0.1589 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9529\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1003 - out_1_loss: 0.0581 - out_2_loss: 0.0422 - out_1_acc: 0.9682 - out_2_acc: 0.9773 - val_loss: 0.3225 - val_out_1_loss: 0.1632 - val_out_2_loss: 0.1593 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0993 - out_1_loss: 0.0577 - out_2_loss: 0.0417 - out_1_acc: 0.9689 - out_2_acc: 0.9775 - val_loss: 0.3273 - val_out_1_loss: 0.1660 - val_out_2_loss: 0.1613 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0969 - out_1_loss: 0.0567 - out_2_loss: 0.0402 - out_1_acc: 0.9689 - out_2_acc: 0.9783 - val_loss: 0.3267 - val_out_1_loss: 0.1652 - val_out_2_loss: 0.1615 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9519\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0966 - out_1_loss: 0.0567 - out_2_loss: 0.0399 - out_1_acc: 0.9695 - out_2_acc: 0.9791 - val_loss: 0.3259 - val_out_1_loss: 0.1672 - val_out_2_loss: 0.1588 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9530\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0964 - out_1_loss: 0.0567 - out_2_loss: 0.0397 - out_1_acc: 0.9697 - out_2_acc: 0.9787 - val_loss: 0.3248 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1578 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9532\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 1s 54ms/step - loss: 0.0966 - out_1_loss: 0.0576 - out_2_loss: 0.0391 - out_1_acc: 0.9689 - out_2_acc: 0.9793 - val_loss: 0.3325 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1637 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0975 - out_1_loss: 0.0576 - out_2_loss: 0.0399 - out_1_acc: 0.9691 - out_2_acc: 0.9783 - val_loss: 0.3364 - val_out_1_loss: 0.1695 - val_out_2_loss: 0.1669 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0978 - out_1_loss: 0.0581 - out_2_loss: 0.0397 - out_1_acc: 0.9692 - out_2_acc: 0.9786 - val_loss: 0.3344 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.1652 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0974 - out_1_loss: 0.0574 - out_2_loss: 0.0400 - out_1_acc: 0.9687 - out_2_acc: 0.9789 - val_loss: 0.3317 - val_out_1_loss: 0.1683 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9534\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0954 - out_1_loss: 0.0560 - out_2_loss: 0.0393 - out_1_acc: 0.9701 - out_2_acc: 0.9797 - val_loss: 0.3389 - val_out_1_loss: 0.1703 - val_out_2_loss: 0.1686 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0956 - out_1_loss: 0.0557 - out_2_loss: 0.0399 - out_1_acc: 0.9704 - out_2_acc: 0.9790 - val_loss: 0.3381 - val_out_1_loss: 0.1723 - val_out_2_loss: 0.1658 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0948 - out_1_loss: 0.0556 - out_2_loss: 0.0392 - out_1_acc: 0.9707 - out_2_acc: 0.9793 - val_loss: 0.3376 - val_out_1_loss: 0.1729 - val_out_2_loss: 0.1647 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0929 - out_1_loss: 0.0548 - out_2_loss: 0.0381 - out_1_acc: 0.9707 - out_2_acc: 0.9805 - val_loss: 0.3404 - val_out_1_loss: 0.1720 - val_out_2_loss: 0.1684 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0920 - out_1_loss: 0.0539 - out_2_loss: 0.0381 - out_1_acc: 0.9715 - out_2_acc: 0.9804 - val_loss: 0.3449 - val_out_1_loss: 0.1755 - val_out_2_loss: 0.1694 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0911 - out_1_loss: 0.0544 - out_2_loss: 0.0367 - out_1_acc: 0.9710 - out_2_acc: 0.9806 - val_loss: 0.3470 - val_out_1_loss: 0.1760 - val_out_2_loss: 0.1710 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9511\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0893 - out_1_loss: 0.0532 - out_2_loss: 0.0362 - out_1_acc: 0.9721 - out_2_acc: 0.9809 - val_loss: 0.3414 - val_out_1_loss: 0.1734 - val_out_2_loss: 0.1679 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9528\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0881 - out_1_loss: 0.0523 - out_2_loss: 0.0358 - out_1_acc: 0.9727 - out_2_acc: 0.9816 - val_loss: 0.3555 - val_out_1_loss: 0.1785 - val_out_2_loss: 0.1770 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0887 - out_1_loss: 0.0529 - out_2_loss: 0.0359 - out_1_acc: 0.9725 - out_2_acc: 0.9813 - val_loss: 0.3542 - val_out_1_loss: 0.1765 - val_out_2_loss: 0.1776 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9515\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0854 - out_1_loss: 0.0513 - out_2_loss: 0.0341 - out_1_acc: 0.9740 - out_2_acc: 0.9827 - val_loss: 0.3601 - val_out_1_loss: 0.1788 - val_out_2_loss: 0.1812 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9522\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0851 - out_1_loss: 0.0511 - out_2_loss: 0.0340 - out_1_acc: 0.9733 - out_2_acc: 0.9826 - val_loss: 0.3680 - val_out_1_loss: 0.1846 - val_out_2_loss: 0.1834 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9530\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0867 - out_1_loss: 0.0523 - out_2_loss: 0.0344 - out_1_acc: 0.9729 - out_2_acc: 0.9825 - val_loss: 0.3666 - val_out_1_loss: 0.1824 - val_out_2_loss: 0.1843 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0861 - out_1_loss: 0.0517 - out_2_loss: 0.0344 - out_1_acc: 0.9732 - out_2_acc: 0.9828 - val_loss: 0.3643 - val_out_1_loss: 0.1818 - val_out_2_loss: 0.1825 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9520\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0853 - out_1_loss: 0.0514 - out_2_loss: 0.0340 - out_1_acc: 0.9737 - out_2_acc: 0.9828 - val_loss: 0.3708 - val_out_1_loss: 0.1859 - val_out_2_loss: 0.1849 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9526\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0839 - out_1_loss: 0.0509 - out_2_loss: 0.0330 - out_1_acc: 0.9743 - out_2_acc: 0.9834 - val_loss: 0.3742 - val_out_1_loss: 0.1857 - val_out_2_loss: 0.1885 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9506\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0826 - out_1_loss: 0.0503 - out_2_loss: 0.0323 - out_1_acc: 0.9747 - out_2_acc: 0.9841 - val_loss: 0.3743 - val_out_1_loss: 0.1852 - val_out_2_loss: 0.1892 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0826 - out_1_loss: 0.0501 - out_2_loss: 0.0325 - out_1_acc: 0.9739 - out_2_acc: 0.9836 - val_loss: 0.3782 - val_out_1_loss: 0.1879 - val_out_2_loss: 0.1902 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0839 - out_1_loss: 0.0502 - out_2_loss: 0.0337 - out_1_acc: 0.9743 - out_2_acc: 0.9828 - val_loss: 0.3741 - val_out_1_loss: 0.1874 - val_out_2_loss: 0.1867 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0835 - out_1_loss: 0.0504 - out_2_loss: 0.0331 - out_1_acc: 0.9740 - out_2_acc: 0.9834 - val_loss: 0.3804 - val_out_1_loss: 0.1877 - val_out_2_loss: 0.1927 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9518\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0813 - out_1_loss: 0.0485 - out_2_loss: 0.0327 - out_1_acc: 0.9757 - out_2_acc: 0.9839 - val_loss: 0.3810 - val_out_1_loss: 0.1907 - val_out_2_loss: 0.1903 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9516\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0815 - out_1_loss: 0.0484 - out_2_loss: 0.0331 - out_1_acc: 0.9760 - out_2_acc: 0.9840 - val_loss: 0.3834 - val_out_1_loss: 0.1898 - val_out_2_loss: 0.1936 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9524\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0805 - out_1_loss: 0.0482 - out_2_loss: 0.0323 - out_1_acc: 0.9758 - out_2_acc: 0.9840 - val_loss: 0.3785 - val_out_1_loss: 0.1901 - val_out_2_loss: 0.1883 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9529\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0812 - out_1_loss: 0.0492 - out_2_loss: 0.0319 - out_1_acc: 0.9755 - out_2_acc: 0.9846 - val_loss: 0.3816 - val_out_1_loss: 0.1914 - val_out_2_loss: 0.1902 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9526\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0772 - out_1_loss: 0.0472 - out_2_loss: 0.0299 - out_1_acc: 0.9766 - out_2_acc: 0.9852 - val_loss: 0.3798 - val_out_1_loss: 0.1903 - val_out_2_loss: 0.1895 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0770 - out_1_loss: 0.0465 - out_2_loss: 0.0305 - out_1_acc: 0.9771 - out_2_acc: 0.9852 - val_loss: 0.3831 - val_out_1_loss: 0.1932 - val_out_2_loss: 0.1899 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9533\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0760 - out_1_loss: 0.0463 - out_2_loss: 0.0297 - out_1_acc: 0.9772 - out_2_acc: 0.9855 - val_loss: 0.3914 - val_out_1_loss: 0.1937 - val_out_2_loss: 0.1977 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0753 - out_1_loss: 0.0459 - out_2_loss: 0.0294 - out_1_acc: 0.9775 - out_2_acc: 0.9861 - val_loss: 0.3985 - val_out_1_loss: 0.1951 - val_out_2_loss: 0.2034 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0744 - out_1_loss: 0.0459 - out_2_loss: 0.0285 - out_1_acc: 0.9776 - out_2_acc: 0.9861 - val_loss: 0.3968 - val_out_1_loss: 0.1961 - val_out_2_loss: 0.2007 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9526\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0765 - out_1_loss: 0.0469 - out_2_loss: 0.0295 - out_1_acc: 0.9770 - out_2_acc: 0.9858 - val_loss: 0.3883 - val_out_1_loss: 0.1943 - val_out_2_loss: 0.1940 - val_out_1_acc: 0.9427 - val_out_2_acc: 0.9513\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(6)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.3573 - out_1_loss: 0.1718 - out_2_loss: 0.1855 - out_1_acc: 0.9431 - out_2_acc: 0.9532\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 200), (No 184800      input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 200)       184800      input_14[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,107,680\n",
      "Trainable params: 1,107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 4s - loss: 7.3433 - out_1_loss: 3.6709 - out_2_loss: 3.6723 - out_1_acc: 0.1069 - out_2_acc: 0.0919WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.131919). Check your callbacks.\n",
      "28/28 [==============================] - 3s 92ms/step - loss: 5.7166 - out_1_loss: 2.9295 - out_2_loss: 2.7871 - out_1_acc: 0.3858 - out_2_acc: 0.4017 - val_loss: 4.1276 - val_out_1_loss: 2.1647 - val_out_2_loss: 1.9629 - val_out_1_acc: 0.4696 - val_out_2_acc: 0.5363\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 3.1337 - out_1_loss: 1.8501 - out_2_loss: 1.2836 - out_1_acc: 0.5278 - out_2_acc: 0.6896 - val_loss: 2.1740 - val_out_1_loss: 1.4502 - val_out_2_loss: 0.7239 - val_out_1_acc: 0.6305 - val_out_2_acc: 0.8260\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 1.4289 - out_1_loss: 0.9444 - out_2_loss: 0.4844 - out_1_acc: 0.7750 - out_2_acc: 0.8824 - val_loss: 0.8508 - val_out_1_loss: 0.5273 - val_out_2_loss: 0.3235 - val_out_1_acc: 0.8889 - val_out_2_acc: 0.9215\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.6291 - out_1_loss: 0.3919 - out_2_loss: 0.2372 - out_1_acc: 0.9109 - out_2_acc: 0.9393 - val_loss: 0.4886 - val_out_1_loss: 0.3039 - val_out_2_loss: 0.1847 - val_out_1_acc: 0.9259 - val_out_2_acc: 0.9449\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.3968 - out_1_loss: 0.2469 - out_2_loss: 0.1500 - out_1_acc: 0.9306 - out_2_acc: 0.9504 - val_loss: 0.3495 - val_out_1_loss: 0.2115 - val_out_2_loss: 0.1380 - val_out_1_acc: 0.9367 - val_out_2_acc: 0.9506\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2978 - out_1_loss: 0.1805 - out_2_loss: 0.1173 - out_1_acc: 0.9381 - out_2_acc: 0.9528 - val_loss: 0.2864 - val_out_1_loss: 0.1690 - val_out_2_loss: 0.1174 - val_out_1_acc: 0.9379 - val_out_2_acc: 0.9511\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2523 - out_1_loss: 0.1498 - out_2_loss: 0.1025 - out_1_acc: 0.9404 - out_2_acc: 0.9532 - val_loss: 0.2536 - val_out_1_loss: 0.1469 - val_out_2_loss: 0.1066 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9515\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2273 - out_1_loss: 0.1326 - out_2_loss: 0.0947 - out_1_acc: 0.9416 - out_2_acc: 0.9542 - val_loss: 0.2355 - val_out_1_loss: 0.1332 - val_out_2_loss: 0.1022 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9519\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.2122 - out_1_loss: 0.1219 - out_2_loss: 0.0902 - out_1_acc: 0.9426 - out_2_acc: 0.9549 - val_loss: 0.2245 - val_out_1_loss: 0.1245 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2029 - out_1_loss: 0.1151 - out_2_loss: 0.0878 - out_1_acc: 0.9429 - out_2_acc: 0.9551 - val_loss: 0.2174 - val_out_1_loss: 0.1195 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1964 - out_1_loss: 0.1106 - out_2_loss: 0.0858 - out_1_acc: 0.9430 - out_2_acc: 0.9550 - val_loss: 0.2135 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1914 - out_1_loss: 0.1073 - out_2_loss: 0.0841 - out_1_acc: 0.9433 - out_2_acc: 0.9555 - val_loss: 0.2100 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9515\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1876 - out_1_loss: 0.1050 - out_2_loss: 0.0826 - out_1_acc: 0.9440 - out_2_acc: 0.9562 - val_loss: 0.2076 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.0948 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1840 - out_1_loss: 0.1031 - out_2_loss: 0.0809 - out_1_acc: 0.9443 - out_2_acc: 0.9566 - val_loss: 0.2057 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.0941 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9527\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1812 - out_1_loss: 0.1015 - out_2_loss: 0.0797 - out_1_acc: 0.9445 - out_2_acc: 0.9572 - val_loss: 0.2036 - val_out_1_loss: 0.1103 - val_out_2_loss: 0.0932 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1792 - out_1_loss: 0.1003 - out_2_loss: 0.0789 - out_1_acc: 0.9448 - out_2_acc: 0.9575 - val_loss: 0.2026 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9526\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1780 - out_1_loss: 0.0994 - out_2_loss: 0.0785 - out_1_acc: 0.9450 - out_2_acc: 0.9574 - val_loss: 0.2024 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0926 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1765 - out_1_loss: 0.0986 - out_2_loss: 0.0779 - out_1_acc: 0.9454 - out_2_acc: 0.9574 - val_loss: 0.2022 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0928 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1752 - out_1_loss: 0.0977 - out_2_loss: 0.0775 - out_1_acc: 0.9460 - out_2_acc: 0.9577 - val_loss: 0.2034 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9518\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1742 - out_1_loss: 0.0970 - out_2_loss: 0.0772 - out_1_acc: 0.9459 - out_2_acc: 0.9574 - val_loss: 0.2040 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1732 - out_1_loss: 0.0964 - out_2_loss: 0.0768 - out_1_acc: 0.9464 - out_2_acc: 0.9573 - val_loss: 0.2012 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0924 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9525\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1721 - out_1_loss: 0.0959 - out_2_loss: 0.0762 - out_1_acc: 0.9463 - out_2_acc: 0.9576 - val_loss: 0.2017 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0929 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9518\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1704 - out_1_loss: 0.0955 - out_2_loss: 0.0749 - out_1_acc: 0.9469 - out_2_acc: 0.9584 - val_loss: 0.2049 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9508\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1691 - out_1_loss: 0.0952 - out_2_loss: 0.0739 - out_1_acc: 0.9470 - out_2_acc: 0.9593 - val_loss: 0.2045 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1681 - out_1_loss: 0.0948 - out_2_loss: 0.0733 - out_1_acc: 0.9468 - out_2_acc: 0.9591 - val_loss: 0.2038 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0945 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1667 - out_1_loss: 0.0941 - out_2_loss: 0.0726 - out_1_acc: 0.9469 - out_2_acc: 0.9597 - val_loss: 0.2029 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0936 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1655 - out_1_loss: 0.0937 - out_2_loss: 0.0718 - out_1_acc: 0.9472 - out_2_acc: 0.9595 - val_loss: 0.2052 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1644 - out_1_loss: 0.0932 - out_2_loss: 0.0712 - out_1_acc: 0.9475 - out_2_acc: 0.9603 - val_loss: 0.2049 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1636 - out_1_loss: 0.0927 - out_2_loss: 0.0709 - out_1_acc: 0.9479 - out_2_acc: 0.9603 - val_loss: 0.2060 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9518\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1615 - out_1_loss: 0.0919 - out_2_loss: 0.0696 - out_1_acc: 0.9481 - out_2_acc: 0.9607 - val_loss: 0.2086 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1601 - out_1_loss: 0.0913 - out_2_loss: 0.0689 - out_1_acc: 0.9489 - out_2_acc: 0.9606 - val_loss: 0.2058 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0966 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1587 - out_1_loss: 0.0909 - out_2_loss: 0.0679 - out_1_acc: 0.9488 - out_2_acc: 0.9614 - val_loss: 0.2072 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9505\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1575 - out_1_loss: 0.0904 - out_2_loss: 0.0671 - out_1_acc: 0.9496 - out_2_acc: 0.9617 - val_loss: 0.2085 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0981 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9510\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1564 - out_1_loss: 0.0901 - out_2_loss: 0.0663 - out_1_acc: 0.9494 - out_2_acc: 0.9622 - val_loss: 0.2127 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9512\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1546 - out_1_loss: 0.0895 - out_2_loss: 0.0651 - out_1_acc: 0.9497 - out_2_acc: 0.9627 - val_loss: 0.2140 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.1019 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9509\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1531 - out_1_loss: 0.0890 - out_2_loss: 0.0641 - out_1_acc: 0.9501 - out_2_acc: 0.9632 - val_loss: 0.2128 - val_out_1_loss: 0.1116 - val_out_2_loss: 0.1013 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9520\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1516 - out_1_loss: 0.0884 - out_2_loss: 0.0632 - out_1_acc: 0.9505 - out_2_acc: 0.9639 - val_loss: 0.2121 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.1012 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9515\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1510 - out_1_loss: 0.0878 - out_2_loss: 0.0632 - out_1_acc: 0.9512 - out_2_acc: 0.9639 - val_loss: 0.2145 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.1026 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1503 - out_1_loss: 0.0876 - out_2_loss: 0.0627 - out_1_acc: 0.9508 - out_2_acc: 0.9639 - val_loss: 0.2179 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1052 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9505\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1481 - out_1_loss: 0.0870 - out_2_loss: 0.0611 - out_1_acc: 0.9511 - out_2_acc: 0.9649 - val_loss: 0.2215 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1075 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9509\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1465 - out_1_loss: 0.0867 - out_2_loss: 0.0598 - out_1_acc: 0.9512 - out_2_acc: 0.9652 - val_loss: 0.2187 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1060 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9513\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1452 - out_1_loss: 0.0862 - out_2_loss: 0.0590 - out_1_acc: 0.9511 - out_2_acc: 0.9655 - val_loss: 0.2199 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9520\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1442 - out_1_loss: 0.0856 - out_2_loss: 0.0586 - out_1_acc: 0.9523 - out_2_acc: 0.9662 - val_loss: 0.2227 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1095 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1447 - out_1_loss: 0.0854 - out_2_loss: 0.0593 - out_1_acc: 0.9518 - out_2_acc: 0.9658 - val_loss: 0.2251 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1102 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9522\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1446 - out_1_loss: 0.0855 - out_2_loss: 0.0591 - out_1_acc: 0.9517 - out_2_acc: 0.9653 - val_loss: 0.2260 - val_out_1_loss: 0.1169 - val_out_2_loss: 0.1091 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1431 - out_1_loss: 0.0850 - out_2_loss: 0.0581 - out_1_acc: 0.9521 - out_2_acc: 0.9657 - val_loss: 0.2282 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1106 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1417 - out_1_loss: 0.0844 - out_2_loss: 0.0572 - out_1_acc: 0.9525 - out_2_acc: 0.9663 - val_loss: 0.2316 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1140 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9515\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1411 - out_1_loss: 0.0847 - out_2_loss: 0.0563 - out_1_acc: 0.9529 - out_2_acc: 0.9668 - val_loss: 0.2303 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1127 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9512\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1405 - out_1_loss: 0.0842 - out_2_loss: 0.0562 - out_1_acc: 0.9529 - out_2_acc: 0.9670 - val_loss: 0.2331 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1148 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9522\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1404 - out_1_loss: 0.0842 - out_2_loss: 0.0562 - out_1_acc: 0.9530 - out_2_acc: 0.9672 - val_loss: 0.2366 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.1168 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9504\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1398 - out_1_loss: 0.0838 - out_2_loss: 0.0560 - out_1_acc: 0.9531 - out_2_acc: 0.9668 - val_loss: 0.2371 - val_out_1_loss: 0.1204 - val_out_2_loss: 0.1167 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9529\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1418 - out_1_loss: 0.0843 - out_2_loss: 0.0576 - out_1_acc: 0.9534 - out_2_acc: 0.9667 - val_loss: 0.2393 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1197 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1426 - out_1_loss: 0.0844 - out_2_loss: 0.0581 - out_1_acc: 0.9524 - out_2_acc: 0.9661 - val_loss: 0.2433 - val_out_1_loss: 0.1204 - val_out_2_loss: 0.1228 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9527\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1424 - out_1_loss: 0.0838 - out_2_loss: 0.0585 - out_1_acc: 0.9525 - out_2_acc: 0.9655 - val_loss: 0.2428 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.1220 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1399 - out_1_loss: 0.0827 - out_2_loss: 0.0573 - out_1_acc: 0.9533 - out_2_acc: 0.9657 - val_loss: 0.2361 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.1183 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1360 - out_1_loss: 0.0811 - out_2_loss: 0.0550 - out_1_acc: 0.9536 - out_2_acc: 0.9670 - val_loss: 0.2350 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1180 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1329 - out_1_loss: 0.0797 - out_2_loss: 0.0532 - out_1_acc: 0.9544 - out_2_acc: 0.9679 - val_loss: 0.2370 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.1188 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9529\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1313 - out_1_loss: 0.0787 - out_2_loss: 0.0526 - out_1_acc: 0.9549 - out_2_acc: 0.9678 - val_loss: 0.2403 - val_out_1_loss: 0.1191 - val_out_2_loss: 0.1212 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9518\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1294 - out_1_loss: 0.0776 - out_2_loss: 0.0518 - out_1_acc: 0.9559 - out_2_acc: 0.9686 - val_loss: 0.2430 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1236 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1282 - out_1_loss: 0.0765 - out_2_loss: 0.0517 - out_1_acc: 0.9567 - out_2_acc: 0.9689 - val_loss: 0.2455 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1242 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1277 - out_1_loss: 0.0764 - out_2_loss: 0.0513 - out_1_acc: 0.9567 - out_2_acc: 0.9694 - val_loss: 0.2469 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1256 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9513\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1269 - out_1_loss: 0.0758 - out_2_loss: 0.0510 - out_1_acc: 0.9570 - out_2_acc: 0.9694 - val_loss: 0.2488 - val_out_1_loss: 0.1213 - val_out_2_loss: 0.1275 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1262 - out_1_loss: 0.0750 - out_2_loss: 0.0512 - out_1_acc: 0.9576 - out_2_acc: 0.9694 - val_loss: 0.2498 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1285 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1247 - out_1_loss: 0.0745 - out_2_loss: 0.0502 - out_1_acc: 0.9579 - out_2_acc: 0.9699 - val_loss: 0.2530 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.1304 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1244 - out_1_loss: 0.0744 - out_2_loss: 0.0500 - out_1_acc: 0.9579 - out_2_acc: 0.9700 - val_loss: 0.2549 - val_out_1_loss: 0.1237 - val_out_2_loss: 0.1311 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1245 - out_1_loss: 0.0742 - out_2_loss: 0.0503 - out_1_acc: 0.9587 - out_2_acc: 0.9699 - val_loss: 0.2550 - val_out_1_loss: 0.1242 - val_out_2_loss: 0.1307 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1239 - out_1_loss: 0.0740 - out_2_loss: 0.0500 - out_1_acc: 0.9583 - out_2_acc: 0.9703 - val_loss: 0.2583 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1329 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1241 - out_1_loss: 0.0735 - out_2_loss: 0.0506 - out_1_acc: 0.9587 - out_2_acc: 0.9699 - val_loss: 0.2583 - val_out_1_loss: 0.1252 - val_out_2_loss: 0.1330 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1244 - out_1_loss: 0.0734 - out_2_loss: 0.0510 - out_1_acc: 0.9587 - out_2_acc: 0.9691 - val_loss: 0.2584 - val_out_1_loss: 0.1266 - val_out_2_loss: 0.1318 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9518\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1233 - out_1_loss: 0.0729 - out_2_loss: 0.0503 - out_1_acc: 0.9587 - out_2_acc: 0.9694 - val_loss: 0.2577 - val_out_1_loss: 0.1264 - val_out_2_loss: 0.1313 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9513\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1229 - out_1_loss: 0.0726 - out_2_loss: 0.0503 - out_1_acc: 0.9589 - out_2_acc: 0.9697 - val_loss: 0.2594 - val_out_1_loss: 0.1286 - val_out_2_loss: 0.1308 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1221 - out_1_loss: 0.0723 - out_2_loss: 0.0498 - out_1_acc: 0.9594 - out_2_acc: 0.9699 - val_loss: 0.2621 - val_out_1_loss: 0.1294 - val_out_2_loss: 0.1327 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1209 - out_1_loss: 0.0711 - out_2_loss: 0.0498 - out_1_acc: 0.9600 - out_2_acc: 0.9697 - val_loss: 0.2639 - val_out_1_loss: 0.1302 - val_out_2_loss: 0.1337 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9524\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1203 - out_1_loss: 0.0708 - out_2_loss: 0.0494 - out_1_acc: 0.9593 - out_2_acc: 0.9699 - val_loss: 0.2665 - val_out_1_loss: 0.1323 - val_out_2_loss: 0.1343 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9528\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1197 - out_1_loss: 0.0706 - out_2_loss: 0.0492 - out_1_acc: 0.9601 - out_2_acc: 0.9703 - val_loss: 0.2685 - val_out_1_loss: 0.1327 - val_out_2_loss: 0.1358 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1194 - out_1_loss: 0.0700 - out_2_loss: 0.0494 - out_1_acc: 0.9605 - out_2_acc: 0.9700 - val_loss: 0.2708 - val_out_1_loss: 0.1327 - val_out_2_loss: 0.1382 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1177 - out_1_loss: 0.0692 - out_2_loss: 0.0484 - out_1_acc: 0.9610 - out_2_acc: 0.9711 - val_loss: 0.2689 - val_out_1_loss: 0.1322 - val_out_2_loss: 0.1367 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1169 - out_1_loss: 0.0683 - out_2_loss: 0.0486 - out_1_acc: 0.9616 - out_2_acc: 0.9710 - val_loss: 0.2695 - val_out_1_loss: 0.1340 - val_out_2_loss: 0.1355 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1155 - out_1_loss: 0.0678 - out_2_loss: 0.0477 - out_1_acc: 0.9615 - out_2_acc: 0.9714 - val_loss: 0.2724 - val_out_1_loss: 0.1349 - val_out_2_loss: 0.1374 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1157 - out_1_loss: 0.0680 - out_2_loss: 0.0478 - out_1_acc: 0.9616 - out_2_acc: 0.9718 - val_loss: 0.2747 - val_out_1_loss: 0.1351 - val_out_2_loss: 0.1396 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1162 - out_1_loss: 0.0680 - out_2_loss: 0.0481 - out_1_acc: 0.9613 - out_2_acc: 0.9712 - val_loss: 0.2744 - val_out_1_loss: 0.1357 - val_out_2_loss: 0.1387 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9515\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1151 - out_1_loss: 0.0674 - out_2_loss: 0.0477 - out_1_acc: 0.9616 - out_2_acc: 0.9715 - val_loss: 0.2765 - val_out_1_loss: 0.1365 - val_out_2_loss: 0.1400 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9531\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1145 - out_1_loss: 0.0667 - out_2_loss: 0.0478 - out_1_acc: 0.9623 - out_2_acc: 0.9719 - val_loss: 0.2763 - val_out_1_loss: 0.1383 - val_out_2_loss: 0.1381 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1131 - out_1_loss: 0.0661 - out_2_loss: 0.0470 - out_1_acc: 0.9627 - out_2_acc: 0.9720 - val_loss: 0.2763 - val_out_1_loss: 0.1374 - val_out_2_loss: 0.1388 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9524\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1125 - out_1_loss: 0.0656 - out_2_loss: 0.0469 - out_1_acc: 0.9630 - out_2_acc: 0.9728 - val_loss: 0.2793 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1393 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1120 - out_1_loss: 0.0653 - out_2_loss: 0.0467 - out_1_acc: 0.9637 - out_2_acc: 0.9728 - val_loss: 0.2799 - val_out_1_loss: 0.1404 - val_out_2_loss: 0.1395 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9532\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1119 - out_1_loss: 0.0656 - out_2_loss: 0.0463 - out_1_acc: 0.9631 - out_2_acc: 0.9730 - val_loss: 0.2778 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1384 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1119 - out_1_loss: 0.0652 - out_2_loss: 0.0467 - out_1_acc: 0.9633 - out_2_acc: 0.9726 - val_loss: 0.2789 - val_out_1_loss: 0.1401 - val_out_2_loss: 0.1388 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1118 - out_1_loss: 0.0655 - out_2_loss: 0.0464 - out_1_acc: 0.9634 - out_2_acc: 0.9736 - val_loss: 0.2803 - val_out_1_loss: 0.1425 - val_out_2_loss: 0.1378 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9536\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1107 - out_1_loss: 0.0651 - out_2_loss: 0.0457 - out_1_acc: 0.9633 - out_2_acc: 0.9736 - val_loss: 0.2858 - val_out_1_loss: 0.1435 - val_out_2_loss: 0.1423 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1102 - out_1_loss: 0.0650 - out_2_loss: 0.0452 - out_1_acc: 0.9633 - out_2_acc: 0.9745 - val_loss: 0.2861 - val_out_1_loss: 0.1433 - val_out_2_loss: 0.1428 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1110 - out_1_loss: 0.0653 - out_2_loss: 0.0457 - out_1_acc: 0.9634 - out_2_acc: 0.9740 - val_loss: 0.2881 - val_out_1_loss: 0.1448 - val_out_2_loss: 0.1433 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1103 - out_1_loss: 0.0646 - out_2_loss: 0.0457 - out_1_acc: 0.9638 - out_2_acc: 0.9735 - val_loss: 0.2899 - val_out_1_loss: 0.1463 - val_out_2_loss: 0.1435 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9515\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1101 - out_1_loss: 0.0647 - out_2_loss: 0.0455 - out_1_acc: 0.9635 - out_2_acc: 0.9742 - val_loss: 0.2926 - val_out_1_loss: 0.1462 - val_out_2_loss: 0.1463 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1098 - out_1_loss: 0.0641 - out_2_loss: 0.0457 - out_1_acc: 0.9643 - out_2_acc: 0.9742 - val_loss: 0.2947 - val_out_1_loss: 0.1481 - val_out_2_loss: 0.1466 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9516\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1093 - out_1_loss: 0.0641 - out_2_loss: 0.0452 - out_1_acc: 0.9645 - out_2_acc: 0.9745 - val_loss: 0.2957 - val_out_1_loss: 0.1491 - val_out_2_loss: 0.1466 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9524\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1103 - out_1_loss: 0.0644 - out_2_loss: 0.0459 - out_1_acc: 0.9641 - out_2_acc: 0.9735 - val_loss: 0.2993 - val_out_1_loss: 0.1497 - val_out_2_loss: 0.1496 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9503\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1073 - out_1_loss: 0.0633 - out_2_loss: 0.0440 - out_1_acc: 0.9646 - out_2_acc: 0.9751 - val_loss: 0.2976 - val_out_1_loss: 0.1493 - val_out_2_loss: 0.1483 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1060 - out_1_loss: 0.0625 - out_2_loss: 0.0436 - out_1_acc: 0.9652 - out_2_acc: 0.9757 - val_loss: 0.3052 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1523 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1062 - out_1_loss: 0.0625 - out_2_loss: 0.0438 - out_1_acc: 0.9650 - out_2_acc: 0.9753 - val_loss: 0.3018 - val_out_1_loss: 0.1531 - val_out_2_loss: 0.1487 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9533\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1046 - out_1_loss: 0.0619 - out_2_loss: 0.0426 - out_1_acc: 0.9657 - out_2_acc: 0.9763 - val_loss: 0.3020 - val_out_1_loss: 0.1533 - val_out_2_loss: 0.1487 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9532\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1043 - out_1_loss: 0.0619 - out_2_loss: 0.0425 - out_1_acc: 0.9661 - out_2_acc: 0.9763 - val_loss: 0.3103 - val_out_1_loss: 0.1577 - val_out_2_loss: 0.1526 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9521\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1038 - out_1_loss: 0.0614 - out_2_loss: 0.0425 - out_1_acc: 0.9663 - out_2_acc: 0.9765 - val_loss: 0.3058 - val_out_1_loss: 0.1542 - val_out_2_loss: 0.1516 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1026 - out_1_loss: 0.0611 - out_2_loss: 0.0416 - out_1_acc: 0.9664 - out_2_acc: 0.9773 - val_loss: 0.3058 - val_out_1_loss: 0.1550 - val_out_2_loss: 0.1508 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1018 - out_1_loss: 0.0604 - out_2_loss: 0.0415 - out_1_acc: 0.9672 - out_2_acc: 0.9775 - val_loss: 0.3088 - val_out_1_loss: 0.1554 - val_out_2_loss: 0.1534 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9520\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1025 - out_1_loss: 0.0610 - out_2_loss: 0.0416 - out_1_acc: 0.9660 - out_2_acc: 0.9772 - val_loss: 0.3125 - val_out_1_loss: 0.1566 - val_out_2_loss: 0.1559 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9517\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1028 - out_1_loss: 0.0611 - out_2_loss: 0.0417 - out_1_acc: 0.9663 - out_2_acc: 0.9770 - val_loss: 0.3114 - val_out_1_loss: 0.1586 - val_out_2_loss: 0.1528 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9519\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1017 - out_1_loss: 0.0599 - out_2_loss: 0.0418 - out_1_acc: 0.9669 - out_2_acc: 0.9771 - val_loss: 0.3120 - val_out_1_loss: 0.1566 - val_out_2_loss: 0.1554 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0998 - out_1_loss: 0.0584 - out_2_loss: 0.0414 - out_1_acc: 0.9682 - out_2_acc: 0.9769 - val_loss: 0.3120 - val_out_1_loss: 0.1568 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9532\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0990 - out_1_loss: 0.0579 - out_2_loss: 0.0411 - out_1_acc: 0.9683 - out_2_acc: 0.9775 - val_loss: 0.3117 - val_out_1_loss: 0.1575 - val_out_2_loss: 0.1542 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0970 - out_1_loss: 0.0575 - out_2_loss: 0.0394 - out_1_acc: 0.9690 - out_2_acc: 0.9790 - val_loss: 0.3181 - val_out_1_loss: 0.1594 - val_out_2_loss: 0.1587 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0963 - out_1_loss: 0.0573 - out_2_loss: 0.0390 - out_1_acc: 0.9691 - out_2_acc: 0.9793 - val_loss: 0.3121 - val_out_1_loss: 0.1584 - val_out_2_loss: 0.1537 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9531\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0952 - out_1_loss: 0.0563 - out_2_loss: 0.0390 - out_1_acc: 0.9700 - out_2_acc: 0.9793 - val_loss: 0.3176 - val_out_1_loss: 0.1594 - val_out_2_loss: 0.1582 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9517\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0932 - out_1_loss: 0.0552 - out_2_loss: 0.0380 - out_1_acc: 0.9706 - out_2_acc: 0.9798 - val_loss: 0.3169 - val_out_1_loss: 0.1583 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9528\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0936 - out_1_loss: 0.0556 - out_2_loss: 0.0380 - out_1_acc: 0.9698 - out_2_acc: 0.9797 - val_loss: 0.3221 - val_out_1_loss: 0.1608 - val_out_2_loss: 0.1613 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0934 - out_1_loss: 0.0553 - out_2_loss: 0.0381 - out_1_acc: 0.9705 - out_2_acc: 0.9802 - val_loss: 0.3319 - val_out_1_loss: 0.1630 - val_out_2_loss: 0.1689 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9526\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0930 - out_1_loss: 0.0549 - out_2_loss: 0.0381 - out_1_acc: 0.9704 - out_2_acc: 0.9799 - val_loss: 0.3243 - val_out_1_loss: 0.1615 - val_out_2_loss: 0.1628 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0929 - out_1_loss: 0.0549 - out_2_loss: 0.0380 - out_1_acc: 0.9709 - out_2_acc: 0.9800 - val_loss: 0.3274 - val_out_1_loss: 0.1632 - val_out_2_loss: 0.1641 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0935 - out_1_loss: 0.0546 - out_2_loss: 0.0389 - out_1_acc: 0.9711 - out_2_acc: 0.9795 - val_loss: 0.3272 - val_out_1_loss: 0.1627 - val_out_2_loss: 0.1645 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9524\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0896 - out_1_loss: 0.0534 - out_2_loss: 0.0362 - out_1_acc: 0.9715 - out_2_acc: 0.9814 - val_loss: 0.3340 - val_out_1_loss: 0.1654 - val_out_2_loss: 0.1686 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0882 - out_1_loss: 0.0529 - out_2_loss: 0.0353 - out_1_acc: 0.9722 - out_2_acc: 0.9818 - val_loss: 0.3359 - val_out_1_loss: 0.1656 - val_out_2_loss: 0.1703 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9519\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0886 - out_1_loss: 0.0526 - out_2_loss: 0.0360 - out_1_acc: 0.9724 - out_2_acc: 0.9813 - val_loss: 0.3330 - val_out_1_loss: 0.1659 - val_out_2_loss: 0.1671 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0875 - out_1_loss: 0.0526 - out_2_loss: 0.0350 - out_1_acc: 0.9720 - out_2_acc: 0.9822 - val_loss: 0.3375 - val_out_1_loss: 0.1657 - val_out_2_loss: 0.1719 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9522\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0857 - out_1_loss: 0.0515 - out_2_loss: 0.0342 - out_1_acc: 0.9734 - out_2_acc: 0.9823 - val_loss: 0.3464 - val_out_1_loss: 0.1698 - val_out_2_loss: 0.1766 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9513\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0841 - out_1_loss: 0.0509 - out_2_loss: 0.0332 - out_1_acc: 0.9739 - out_2_acc: 0.9833 - val_loss: 0.3373 - val_out_1_loss: 0.1661 - val_out_2_loss: 0.1712 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0839 - out_1_loss: 0.0510 - out_2_loss: 0.0329 - out_1_acc: 0.9741 - out_2_acc: 0.9834 - val_loss: 0.3369 - val_out_1_loss: 0.1664 - val_out_2_loss: 0.1706 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9533\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0839 - out_1_loss: 0.0513 - out_2_loss: 0.0326 - out_1_acc: 0.9737 - out_2_acc: 0.9835 - val_loss: 0.3429 - val_out_1_loss: 0.1686 - val_out_2_loss: 0.1743 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0827 - out_1_loss: 0.0503 - out_2_loss: 0.0324 - out_1_acc: 0.9744 - out_2_acc: 0.9836 - val_loss: 0.3477 - val_out_1_loss: 0.1704 - val_out_2_loss: 0.1773 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9526\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0839 - out_1_loss: 0.0507 - out_2_loss: 0.0332 - out_1_acc: 0.9739 - out_2_acc: 0.9831 - val_loss: 0.3419 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1731 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0843 - out_1_loss: 0.0514 - out_2_loss: 0.0329 - out_1_acc: 0.9738 - out_2_acc: 0.9835 - val_loss: 0.3428 - val_out_1_loss: 0.1704 - val_out_2_loss: 0.1725 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9527\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0842 - out_1_loss: 0.0508 - out_2_loss: 0.0333 - out_1_acc: 0.9742 - out_2_acc: 0.9832 - val_loss: 0.3473 - val_out_1_loss: 0.1719 - val_out_2_loss: 0.1754 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9529\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0844 - out_1_loss: 0.0508 - out_2_loss: 0.0336 - out_1_acc: 0.9736 - out_2_acc: 0.9834 - val_loss: 0.3565 - val_out_1_loss: 0.1756 - val_out_2_loss: 0.1810 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0847 - out_1_loss: 0.0509 - out_2_loss: 0.0338 - out_1_acc: 0.9742 - out_2_acc: 0.9831 - val_loss: 0.3582 - val_out_1_loss: 0.1758 - val_out_2_loss: 0.1824 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0831 - out_1_loss: 0.0504 - out_2_loss: 0.0328 - out_1_acc: 0.9746 - out_2_acc: 0.9836 - val_loss: 0.3529 - val_out_1_loss: 0.1744 - val_out_2_loss: 0.1785 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9527\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0815 - out_1_loss: 0.0500 - out_2_loss: 0.0315 - out_1_acc: 0.9746 - out_2_acc: 0.9846 - val_loss: 0.3606 - val_out_1_loss: 0.1794 - val_out_2_loss: 0.1812 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9523\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0806 - out_1_loss: 0.0498 - out_2_loss: 0.0308 - out_1_acc: 0.9750 - out_2_acc: 0.9848 - val_loss: 0.3650 - val_out_1_loss: 0.1784 - val_out_2_loss: 0.1866 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9508\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0802 - out_1_loss: 0.0497 - out_2_loss: 0.0305 - out_1_acc: 0.9748 - out_2_acc: 0.9847 - val_loss: 0.3640 - val_out_1_loss: 0.1772 - val_out_2_loss: 0.1868 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9524\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0805 - out_1_loss: 0.0498 - out_2_loss: 0.0307 - out_1_acc: 0.9752 - out_2_acc: 0.9849 - val_loss: 0.3628 - val_out_1_loss: 0.1772 - val_out_2_loss: 0.1856 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0770 - out_1_loss: 0.0479 - out_2_loss: 0.0290 - out_1_acc: 0.9759 - out_2_acc: 0.9859 - val_loss: 0.3647 - val_out_1_loss: 0.1777 - val_out_2_loss: 0.1870 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9532\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0777 - out_1_loss: 0.0485 - out_2_loss: 0.0292 - out_1_acc: 0.9761 - out_2_acc: 0.9855 - val_loss: 0.3633 - val_out_1_loss: 0.1778 - val_out_2_loss: 0.1855 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9515\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0766 - out_1_loss: 0.0480 - out_2_loss: 0.0286 - out_1_acc: 0.9767 - out_2_acc: 0.9860 - val_loss: 0.3717 - val_out_1_loss: 0.1826 - val_out_2_loss: 0.1891 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9519\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0741 - out_1_loss: 0.0470 - out_2_loss: 0.0271 - out_1_acc: 0.9770 - out_2_acc: 0.9869 - val_loss: 0.3786 - val_out_1_loss: 0.1862 - val_out_2_loss: 0.1924 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0756 - out_1_loss: 0.0477 - out_2_loss: 0.0279 - out_1_acc: 0.9765 - out_2_acc: 0.9866 - val_loss: 0.3772 - val_out_1_loss: 0.1850 - val_out_2_loss: 0.1922 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9518\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0748 - out_1_loss: 0.0471 - out_2_loss: 0.0277 - out_1_acc: 0.9767 - out_2_acc: 0.9869 - val_loss: 0.3791 - val_out_1_loss: 0.1843 - val_out_2_loss: 0.1947 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0748 - out_1_loss: 0.0466 - out_2_loss: 0.0282 - out_1_acc: 0.9769 - out_2_acc: 0.9866 - val_loss: 0.3857 - val_out_1_loss: 0.1862 - val_out_2_loss: 0.1995 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9525\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0747 - out_1_loss: 0.0466 - out_2_loss: 0.0281 - out_1_acc: 0.9774 - out_2_acc: 0.9866 - val_loss: 0.3810 - val_out_1_loss: 0.1833 - val_out_2_loss: 0.1977 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9525\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0721 - out_1_loss: 0.0445 - out_2_loss: 0.0275 - out_1_acc: 0.9782 - out_2_acc: 0.9868 - val_loss: 0.3791 - val_out_1_loss: 0.1830 - val_out_2_loss: 0.1962 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9533\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0722 - out_1_loss: 0.0449 - out_2_loss: 0.0273 - out_1_acc: 0.9780 - out_2_acc: 0.9868 - val_loss: 0.3996 - val_out_1_loss: 0.1902 - val_out_2_loss: 0.2094 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0732 - out_1_loss: 0.0456 - out_2_loss: 0.0276 - out_1_acc: 0.9780 - out_2_acc: 0.9870 - val_loss: 0.4000 - val_out_1_loss: 0.1928 - val_out_2_loss: 0.2072 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0749 - out_1_loss: 0.0461 - out_2_loss: 0.0288 - out_1_acc: 0.9776 - out_2_acc: 0.9862 - val_loss: 0.3926 - val_out_1_loss: 0.1940 - val_out_2_loss: 0.1986 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0715 - out_1_loss: 0.0450 - out_2_loss: 0.0265 - out_1_acc: 0.9782 - out_2_acc: 0.9879 - val_loss: 0.3950 - val_out_1_loss: 0.1922 - val_out_2_loss: 0.2028 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9526\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0716 - out_1_loss: 0.0455 - out_2_loss: 0.0261 - out_1_acc: 0.9782 - out_2_acc: 0.9878 - val_loss: 0.3983 - val_out_1_loss: 0.1946 - val_out_2_loss: 0.2037 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9532\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0703 - out_1_loss: 0.0447 - out_2_loss: 0.0256 - out_1_acc: 0.9782 - out_2_acc: 0.9880 - val_loss: 0.4053 - val_out_1_loss: 0.1943 - val_out_2_loss: 0.2111 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0701 - out_1_loss: 0.0450 - out_2_loss: 0.0251 - out_1_acc: 0.9783 - out_2_acc: 0.9881 - val_loss: 0.3988 - val_out_1_loss: 0.1911 - val_out_2_loss: 0.2078 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0689 - out_1_loss: 0.0447 - out_2_loss: 0.0242 - out_1_acc: 0.9784 - out_2_acc: 0.9885 - val_loss: 0.4050 - val_out_1_loss: 0.1930 - val_out_2_loss: 0.2121 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0678 - out_1_loss: 0.0430 - out_2_loss: 0.0248 - out_1_acc: 0.9791 - out_2_acc: 0.9885 - val_loss: 0.4081 - val_out_1_loss: 0.1956 - val_out_2_loss: 0.2125 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0650 - out_1_loss: 0.0414 - out_2_loss: 0.0236 - out_1_acc: 0.9801 - out_2_acc: 0.9893 - val_loss: 0.4046 - val_out_1_loss: 0.1945 - val_out_2_loss: 0.2101 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0636 - out_1_loss: 0.0402 - out_2_loss: 0.0234 - out_1_acc: 0.9811 - out_2_acc: 0.9887 - val_loss: 0.4108 - val_out_1_loss: 0.1960 - val_out_2_loss: 0.2148 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0613 - out_1_loss: 0.0391 - out_2_loss: 0.0221 - out_1_acc: 0.9816 - out_2_acc: 0.9898 - val_loss: 0.4172 - val_out_1_loss: 0.2016 - val_out_2_loss: 0.2155 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0609 - out_1_loss: 0.0391 - out_2_loss: 0.0218 - out_1_acc: 0.9815 - out_2_acc: 0.9900 - val_loss: 0.4148 - val_out_1_loss: 0.1986 - val_out_2_loss: 0.2163 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9531\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0609 - out_1_loss: 0.0389 - out_2_loss: 0.0220 - out_1_acc: 0.9817 - out_2_acc: 0.9899 - val_loss: 0.4181 - val_out_1_loss: 0.2031 - val_out_2_loss: 0.2151 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9523\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0594 - out_1_loss: 0.0387 - out_2_loss: 0.0207 - out_1_acc: 0.9817 - out_2_acc: 0.9907 - val_loss: 0.4194 - val_out_1_loss: 0.2038 - val_out_2_loss: 0.2156 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0579 - out_1_loss: 0.0376 - out_2_loss: 0.0202 - out_1_acc: 0.9824 - out_2_acc: 0.9909 - val_loss: 0.4316 - val_out_1_loss: 0.2063 - val_out_2_loss: 0.2252 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0582 - out_1_loss: 0.0370 - out_2_loss: 0.0211 - out_1_acc: 0.9829 - out_2_acc: 0.9906 - val_loss: 0.4342 - val_out_1_loss: 0.2094 - val_out_2_loss: 0.2249 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9530\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0579 - out_1_loss: 0.0368 - out_2_loss: 0.0211 - out_1_acc: 0.9829 - out_2_acc: 0.9903 - val_loss: 0.4396 - val_out_1_loss: 0.2131 - val_out_2_loss: 0.2265 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0568 - out_1_loss: 0.0379 - out_2_loss: 0.0189 - out_1_acc: 0.9822 - out_2_acc: 0.9914 - val_loss: 0.4406 - val_out_1_loss: 0.2163 - val_out_2_loss: 0.2243 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9525\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0541 - out_1_loss: 0.0366 - out_2_loss: 0.0174 - out_1_acc: 0.9833 - out_2_acc: 0.9920 - val_loss: 0.4449 - val_out_1_loss: 0.2155 - val_out_2_loss: 0.2293 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9525\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0544 - out_1_loss: 0.0369 - out_2_loss: 0.0175 - out_1_acc: 0.9833 - out_2_acc: 0.9920 - val_loss: 0.4493 - val_out_1_loss: 0.2174 - val_out_2_loss: 0.2319 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0526 - out_1_loss: 0.0353 - out_2_loss: 0.0173 - out_1_acc: 0.9841 - out_2_acc: 0.9923 - val_loss: 0.4608 - val_out_1_loss: 0.2219 - val_out_2_loss: 0.2389 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9534\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0510 - out_1_loss: 0.0344 - out_2_loss: 0.0166 - out_1_acc: 0.9848 - out_2_acc: 0.9924 - val_loss: 0.4597 - val_out_1_loss: 0.2190 - val_out_2_loss: 0.2407 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9515\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0518 - out_1_loss: 0.0354 - out_2_loss: 0.0164 - out_1_acc: 0.9838 - out_2_acc: 0.9926 - val_loss: 0.4658 - val_out_1_loss: 0.2250 - val_out_2_loss: 0.2407 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9513\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0513 - out_1_loss: 0.0352 - out_2_loss: 0.0161 - out_1_acc: 0.9839 - out_2_acc: 0.9928 - val_loss: 0.4611 - val_out_1_loss: 0.2198 - val_out_2_loss: 0.2413 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9515\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0489 - out_1_loss: 0.0334 - out_2_loss: 0.0155 - out_1_acc: 0.9852 - out_2_acc: 0.9931 - val_loss: 0.4747 - val_out_1_loss: 0.2281 - val_out_2_loss: 0.2466 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9514\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0484 - out_1_loss: 0.0334 - out_2_loss: 0.0150 - out_1_acc: 0.9850 - out_2_acc: 0.9933 - val_loss: 0.4755 - val_out_1_loss: 0.2327 - val_out_2_loss: 0.2428 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9526\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0476 - out_1_loss: 0.0330 - out_2_loss: 0.0146 - out_1_acc: 0.9855 - out_2_acc: 0.9936 - val_loss: 0.4741 - val_out_1_loss: 0.2316 - val_out_2_loss: 0.2425 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0479 - out_1_loss: 0.0328 - out_2_loss: 0.0151 - out_1_acc: 0.9858 - out_2_acc: 0.9937 - val_loss: 0.4804 - val_out_1_loss: 0.2344 - val_out_2_loss: 0.2460 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0468 - out_1_loss: 0.0325 - out_2_loss: 0.0143 - out_1_acc: 0.9856 - out_2_acc: 0.9939 - val_loss: 0.4829 - val_out_1_loss: 0.2332 - val_out_2_loss: 0.2497 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9523\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0463 - out_1_loss: 0.0318 - out_2_loss: 0.0146 - out_1_acc: 0.9859 - out_2_acc: 0.9937 - val_loss: 0.4829 - val_out_1_loss: 0.2348 - val_out_2_loss: 0.2481 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0471 - out_1_loss: 0.0328 - out_2_loss: 0.0143 - out_1_acc: 0.9856 - out_2_acc: 0.9937 - val_loss: 0.4972 - val_out_1_loss: 0.2443 - val_out_2_loss: 0.2529 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9526\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0462 - out_1_loss: 0.0322 - out_2_loss: 0.0140 - out_1_acc: 0.9857 - out_2_acc: 0.9938 - val_loss: 0.4973 - val_out_1_loss: 0.2417 - val_out_2_loss: 0.2556 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0469 - out_1_loss: 0.0311 - out_2_loss: 0.0158 - out_1_acc: 0.9862 - out_2_acc: 0.9933 - val_loss: 0.4902 - val_out_1_loss: 0.2372 - val_out_2_loss: 0.2530 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9514\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0450 - out_1_loss: 0.0310 - out_2_loss: 0.0140 - out_1_acc: 0.9864 - out_2_acc: 0.9939 - val_loss: 0.4975 - val_out_1_loss: 0.2424 - val_out_2_loss: 0.2551 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9529\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0430 - out_1_loss: 0.0296 - out_2_loss: 0.0134 - out_1_acc: 0.9873 - out_2_acc: 0.9944 - val_loss: 0.5105 - val_out_1_loss: 0.2427 - val_out_2_loss: 0.2678 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0452 - out_1_loss: 0.0296 - out_2_loss: 0.0156 - out_1_acc: 0.9872 - out_2_acc: 0.9932 - val_loss: 0.5023 - val_out_1_loss: 0.2413 - val_out_2_loss: 0.2610 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0436 - out_1_loss: 0.0294 - out_2_loss: 0.0142 - out_1_acc: 0.9871 - out_2_acc: 0.9937 - val_loss: 0.4955 - val_out_1_loss: 0.2379 - val_out_2_loss: 0.2576 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0407 - out_1_loss: 0.0279 - out_2_loss: 0.0127 - out_1_acc: 0.9878 - out_2_acc: 0.9947 - val_loss: 0.5041 - val_out_1_loss: 0.2439 - val_out_2_loss: 0.2602 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9528\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0397 - out_1_loss: 0.0278 - out_2_loss: 0.0118 - out_1_acc: 0.9879 - out_2_acc: 0.9949 - val_loss: 0.5146 - val_out_1_loss: 0.2513 - val_out_2_loss: 0.2633 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0359 - out_1_loss: 0.0254 - out_2_loss: 0.0106 - out_1_acc: 0.9894 - out_2_acc: 0.9957 - val_loss: 0.5151 - val_out_1_loss: 0.2508 - val_out_2_loss: 0.2643 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9520\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0365 - out_1_loss: 0.0260 - out_2_loss: 0.0104 - out_1_acc: 0.9892 - out_2_acc: 0.9957 - val_loss: 0.5164 - val_out_1_loss: 0.2523 - val_out_2_loss: 0.2642 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0375 - out_1_loss: 0.0262 - out_2_loss: 0.0113 - out_1_acc: 0.9891 - out_2_acc: 0.9952 - val_loss: 0.5191 - val_out_1_loss: 0.2532 - val_out_2_loss: 0.2660 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9521\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0369 - out_1_loss: 0.0261 - out_2_loss: 0.0108 - out_1_acc: 0.9887 - out_2_acc: 0.9956 - val_loss: 0.5218 - val_out_1_loss: 0.2521 - val_out_2_loss: 0.2697 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9526\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0374 - out_1_loss: 0.0259 - out_2_loss: 0.0114 - out_1_acc: 0.9891 - out_2_acc: 0.9953 - val_loss: 0.5232 - val_out_1_loss: 0.2556 - val_out_2_loss: 0.2676 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9520\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0379 - out_1_loss: 0.0259 - out_2_loss: 0.0121 - out_1_acc: 0.9891 - out_2_acc: 0.9951 - val_loss: 0.5281 - val_out_1_loss: 0.2641 - val_out_2_loss: 0.2640 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9534\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0372 - out_1_loss: 0.0259 - out_2_loss: 0.0112 - out_1_acc: 0.9894 - out_2_acc: 0.9954 - val_loss: 0.5313 - val_out_1_loss: 0.2572 - val_out_2_loss: 0.2741 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9529\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0372 - out_1_loss: 0.0260 - out_2_loss: 0.0112 - out_1_acc: 0.9890 - out_2_acc: 0.9958 - val_loss: 0.5299 - val_out_1_loss: 0.2576 - val_out_2_loss: 0.2723 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0372 - out_1_loss: 0.0259 - out_2_loss: 0.0113 - out_1_acc: 0.9896 - out_2_acc: 0.9958 - val_loss: 0.5396 - val_out_1_loss: 0.2630 - val_out_2_loss: 0.2765 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9525\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0374 - out_1_loss: 0.0263 - out_2_loss: 0.0111 - out_1_acc: 0.9893 - out_2_acc: 0.9958 - val_loss: 0.5399 - val_out_1_loss: 0.2636 - val_out_2_loss: 0.2763 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9528\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0357 - out_1_loss: 0.0251 - out_2_loss: 0.0106 - out_1_acc: 0.9899 - out_2_acc: 0.9955 - val_loss: 0.5488 - val_out_1_loss: 0.2672 - val_out_2_loss: 0.2816 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9527\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0345 - out_1_loss: 0.0240 - out_2_loss: 0.0104 - out_1_acc: 0.9901 - out_2_acc: 0.9959 - val_loss: 0.5594 - val_out_1_loss: 0.2771 - val_out_2_loss: 0.2823 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9526\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0356 - out_1_loss: 0.0251 - out_2_loss: 0.0105 - out_1_acc: 0.9899 - out_2_acc: 0.9959 - val_loss: 0.5582 - val_out_1_loss: 0.2741 - val_out_2_loss: 0.2841 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(6)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5616 - out_1_loss: 0.2707 - out_2_loss: 0.2909 - out_1_acc: 0.9415 - out_2_acc: 0.9518\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 200), (No 184800      input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 200)       184800      input_15[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,107,680\n",
      "Trainable params: 1,107,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3509 - out_1_loss: 3.6757 - out_2_loss: 3.6752 - out_1_acc: 0.0952 - out_2_acc: 0.1294WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.113600). Check your callbacks.\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 5.7416 - out_1_loss: 2.9513 - out_2_loss: 2.7902 - out_1_acc: 0.3763 - out_2_acc: 0.4303 - val_loss: 4.1807 - val_out_1_loss: 2.2009 - val_out_2_loss: 1.9799 - val_out_1_acc: 0.4541 - val_out_2_acc: 0.5260\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 3.1537 - out_1_loss: 1.8492 - out_2_loss: 1.3046 - out_1_acc: 0.5329 - out_2_acc: 0.6796 - val_loss: 2.0806 - val_out_1_loss: 1.3749 - val_out_2_loss: 0.7057 - val_out_1_acc: 0.6661 - val_out_2_acc: 0.8277\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 1.3592 - out_1_loss: 0.8947 - out_2_loss: 0.4645 - out_1_acc: 0.7901 - out_2_acc: 0.8906 - val_loss: 0.8339 - val_out_1_loss: 0.5264 - val_out_2_loss: 0.3075 - val_out_1_acc: 0.8824 - val_out_2_acc: 0.9276\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.6207 - out_1_loss: 0.3914 - out_2_loss: 0.2293 - out_1_acc: 0.9093 - out_2_acc: 0.9411 - val_loss: 0.4765 - val_out_1_loss: 0.2949 - val_out_2_loss: 0.1817 - val_out_1_acc: 0.9277 - val_out_2_acc: 0.9470\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.3840 - out_1_loss: 0.2375 - out_2_loss: 0.1465 - out_1_acc: 0.9325 - out_2_acc: 0.9504 - val_loss: 0.3360 - val_out_1_loss: 0.2012 - val_out_2_loss: 0.1348 - val_out_1_acc: 0.9367 - val_out_2_acc: 0.9506\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2855 - out_1_loss: 0.1712 - out_2_loss: 0.1143 - out_1_acc: 0.9384 - out_2_acc: 0.9527 - val_loss: 0.2752 - val_out_1_loss: 0.1601 - val_out_2_loss: 0.1151 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9501\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.2427 - out_1_loss: 0.1422 - out_2_loss: 0.1005 - out_1_acc: 0.9406 - out_2_acc: 0.9538 - val_loss: 0.2457 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1064 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9504\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2207 - out_1_loss: 0.1272 - out_2_loss: 0.0936 - out_1_acc: 0.9417 - out_2_acc: 0.9544 - val_loss: 0.2307 - val_out_1_loss: 0.1283 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9506\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.2076 - out_1_loss: 0.1186 - out_2_loss: 0.0890 - out_1_acc: 0.9422 - out_2_acc: 0.9546 - val_loss: 0.2215 - val_out_1_loss: 0.1220 - val_out_2_loss: 0.0995 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9511\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1986 - out_1_loss: 0.1130 - out_2_loss: 0.0856 - out_1_acc: 0.9428 - out_2_acc: 0.9554 - val_loss: 0.2149 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.0971 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9509\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1924 - out_1_loss: 0.1091 - out_2_loss: 0.0833 - out_1_acc: 0.9429 - out_2_acc: 0.9560 - val_loss: 0.2116 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9519\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1882 - out_1_loss: 0.1063 - out_2_loss: 0.0819 - out_1_acc: 0.9435 - out_2_acc: 0.9564 - val_loss: 0.2103 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1854 - out_1_loss: 0.1043 - out_2_loss: 0.0811 - out_1_acc: 0.9435 - out_2_acc: 0.9561 - val_loss: 0.2076 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9508\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1826 - out_1_loss: 0.1027 - out_2_loss: 0.0799 - out_1_acc: 0.9436 - out_2_acc: 0.9566 - val_loss: 0.2057 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9512\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1805 - out_1_loss: 0.1015 - out_2_loss: 0.0789 - out_1_acc: 0.9439 - out_2_acc: 0.9570 - val_loss: 0.2050 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.1785 - out_1_loss: 0.1005 - out_2_loss: 0.0781 - out_1_acc: 0.9444 - out_2_acc: 0.9571 - val_loss: 0.2064 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9497\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1773 - out_1_loss: 0.0997 - out_2_loss: 0.0776 - out_1_acc: 0.9449 - out_2_acc: 0.9573 - val_loss: 0.2047 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1746 - out_1_loss: 0.0988 - out_2_loss: 0.0758 - out_1_acc: 0.9450 - out_2_acc: 0.9581 - val_loss: 0.2067 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1731 - out_1_loss: 0.0980 - out_2_loss: 0.0750 - out_1_acc: 0.9454 - out_2_acc: 0.9582 - val_loss: 0.2051 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9512\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1712 - out_1_loss: 0.0974 - out_2_loss: 0.0738 - out_1_acc: 0.9457 - out_2_acc: 0.9592 - val_loss: 0.2059 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9515\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1698 - out_1_loss: 0.0969 - out_2_loss: 0.0729 - out_1_acc: 0.9460 - out_2_acc: 0.9594 - val_loss: 0.2056 - val_out_1_loss: 0.1082 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1686 - out_1_loss: 0.0963 - out_2_loss: 0.0723 - out_1_acc: 0.9459 - out_2_acc: 0.9595 - val_loss: 0.2054 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9514\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1674 - out_1_loss: 0.0958 - out_2_loss: 0.0716 - out_1_acc: 0.9463 - out_2_acc: 0.9602 - val_loss: 0.2063 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9514\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1664 - out_1_loss: 0.0953 - out_2_loss: 0.0711 - out_1_acc: 0.9470 - out_2_acc: 0.9604 - val_loss: 0.2059 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0971 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9516\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1656 - out_1_loss: 0.0947 - out_2_loss: 0.0709 - out_1_acc: 0.9475 - out_2_acc: 0.9607 - val_loss: 0.2070 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0981 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1646 - out_1_loss: 0.0943 - out_2_loss: 0.0703 - out_1_acc: 0.9475 - out_2_acc: 0.9606 - val_loss: 0.2095 - val_out_1_loss: 0.1091 - val_out_2_loss: 0.1004 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9504\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1633 - out_1_loss: 0.0937 - out_2_loss: 0.0697 - out_1_acc: 0.9477 - out_2_acc: 0.9606 - val_loss: 0.2082 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0998 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1621 - out_1_loss: 0.0930 - out_2_loss: 0.0690 - out_1_acc: 0.9481 - out_2_acc: 0.9612 - val_loss: 0.2087 - val_out_1_loss: 0.1080 - val_out_2_loss: 0.1007 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1608 - out_1_loss: 0.0925 - out_2_loss: 0.0684 - out_1_acc: 0.9482 - out_2_acc: 0.9616 - val_loss: 0.2097 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.1013 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9526\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1602 - out_1_loss: 0.0922 - out_2_loss: 0.0680 - out_1_acc: 0.9479 - out_2_acc: 0.9613 - val_loss: 0.2114 - val_out_1_loss: 0.1083 - val_out_2_loss: 0.1031 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1592 - out_1_loss: 0.0917 - out_2_loss: 0.0675 - out_1_acc: 0.9487 - out_2_acc: 0.9613 - val_loss: 0.2123 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.1038 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1574 - out_1_loss: 0.0910 - out_2_loss: 0.0663 - out_1_acc: 0.9491 - out_2_acc: 0.9628 - val_loss: 0.2146 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.1054 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9523\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1569 - out_1_loss: 0.0906 - out_2_loss: 0.0662 - out_1_acc: 0.9495 - out_2_acc: 0.9628 - val_loss: 0.2176 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.1074 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9509\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1564 - out_1_loss: 0.0907 - out_2_loss: 0.0657 - out_1_acc: 0.9490 - out_2_acc: 0.9632 - val_loss: 0.2181 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1076 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9511\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1547 - out_1_loss: 0.0901 - out_2_loss: 0.0646 - out_1_acc: 0.9495 - out_2_acc: 0.9631 - val_loss: 0.2166 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.1065 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9516\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1524 - out_1_loss: 0.0893 - out_2_loss: 0.0631 - out_1_acc: 0.9501 - out_2_acc: 0.9636 - val_loss: 0.2177 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1077 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9511\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1503 - out_1_loss: 0.0886 - out_2_loss: 0.0617 - out_1_acc: 0.9504 - out_2_acc: 0.9647 - val_loss: 0.2183 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1077 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1497 - out_1_loss: 0.0882 - out_2_loss: 0.0616 - out_1_acc: 0.9510 - out_2_acc: 0.9645 - val_loss: 0.2223 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.1105 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1492 - out_1_loss: 0.0883 - out_2_loss: 0.0609 - out_1_acc: 0.9507 - out_2_acc: 0.9650 - val_loss: 0.2246 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1112 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9512\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1483 - out_1_loss: 0.0878 - out_2_loss: 0.0605 - out_1_acc: 0.9510 - out_2_acc: 0.9653 - val_loss: 0.2253 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1118 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9509\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1472 - out_1_loss: 0.0874 - out_2_loss: 0.0598 - out_1_acc: 0.9511 - out_2_acc: 0.9656 - val_loss: 0.2266 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1129 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9510\n",
      "Epoch 42/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1459 - out_1_loss: 0.0870 - out_2_loss: 0.0589 - out_1_acc: 0.9517 - out_2_acc: 0.9662 - val_loss: 0.2296 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.1148 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9518\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1455 - out_1_loss: 0.0864 - out_2_loss: 0.0591 - out_1_acc: 0.9523 - out_2_acc: 0.9660 - val_loss: 0.2332 - val_out_1_loss: 0.1143 - val_out_2_loss: 0.1189 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9505\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1448 - out_1_loss: 0.0863 - out_2_loss: 0.0586 - out_1_acc: 0.9518 - out_2_acc: 0.9667 - val_loss: 0.2323 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1173 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9504\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1444 - out_1_loss: 0.0863 - out_2_loss: 0.0581 - out_1_acc: 0.9522 - out_2_acc: 0.9664 - val_loss: 0.2315 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1169 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9510\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1436 - out_1_loss: 0.0856 - out_2_loss: 0.0580 - out_1_acc: 0.9527 - out_2_acc: 0.9665 - val_loss: 0.2337 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1179 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1426 - out_1_loss: 0.0854 - out_2_loss: 0.0572 - out_1_acc: 0.9529 - out_2_acc: 0.9664 - val_loss: 0.2363 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1197 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1415 - out_1_loss: 0.0851 - out_2_loss: 0.0564 - out_1_acc: 0.9527 - out_2_acc: 0.9664 - val_loss: 0.2366 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1200 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1395 - out_1_loss: 0.0842 - out_2_loss: 0.0553 - out_1_acc: 0.9533 - out_2_acc: 0.9675 - val_loss: 0.2406 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1230 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1375 - out_1_loss: 0.0837 - out_2_loss: 0.0539 - out_1_acc: 0.9539 - out_2_acc: 0.9678 - val_loss: 0.2414 - val_out_1_loss: 0.1180 - val_out_2_loss: 0.1233 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9508\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1368 - out_1_loss: 0.0834 - out_2_loss: 0.0534 - out_1_acc: 0.9537 - out_2_acc: 0.9687 - val_loss: 0.2406 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1222 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9509\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1363 - out_1_loss: 0.0832 - out_2_loss: 0.0531 - out_1_acc: 0.9535 - out_2_acc: 0.9691 - val_loss: 0.2416 - val_out_1_loss: 0.1183 - val_out_2_loss: 0.1233 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9497\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1358 - out_1_loss: 0.0829 - out_2_loss: 0.0529 - out_1_acc: 0.9539 - out_2_acc: 0.9693 - val_loss: 0.2428 - val_out_1_loss: 0.1182 - val_out_2_loss: 0.1246 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9504\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1361 - out_1_loss: 0.0830 - out_2_loss: 0.0531 - out_1_acc: 0.9536 - out_2_acc: 0.9690 - val_loss: 0.2457 - val_out_1_loss: 0.1191 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9510\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1355 - out_1_loss: 0.0825 - out_2_loss: 0.0530 - out_1_acc: 0.9541 - out_2_acc: 0.9696 - val_loss: 0.2448 - val_out_1_loss: 0.1192 - val_out_2_loss: 0.1256 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9507\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1345 - out_1_loss: 0.0818 - out_2_loss: 0.0527 - out_1_acc: 0.9541 - out_2_acc: 0.9697 - val_loss: 0.2477 - val_out_1_loss: 0.1205 - val_out_2_loss: 0.1272 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1342 - out_1_loss: 0.0816 - out_2_loss: 0.0527 - out_1_acc: 0.9543 - out_2_acc: 0.9694 - val_loss: 0.2466 - val_out_1_loss: 0.1190 - val_out_2_loss: 0.1276 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9518\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 55ms/step - loss: 0.1338 - out_1_loss: 0.0812 - out_2_loss: 0.0526 - out_1_acc: 0.9547 - out_2_acc: 0.9695 - val_loss: 0.2488 - val_out_1_loss: 0.1193 - val_out_2_loss: 0.1295 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1345 - out_1_loss: 0.0809 - out_2_loss: 0.0536 - out_1_acc: 0.9550 - out_2_acc: 0.9689 - val_loss: 0.2480 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1283 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1337 - out_1_loss: 0.0807 - out_2_loss: 0.0530 - out_1_acc: 0.9553 - out_2_acc: 0.9692 - val_loss: 0.2518 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9521\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1340 - out_1_loss: 0.0806 - out_2_loss: 0.0534 - out_1_acc: 0.9554 - out_2_acc: 0.9686 - val_loss: 0.2509 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.1301 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1332 - out_1_loss: 0.0804 - out_2_loss: 0.0528 - out_1_acc: 0.9551 - out_2_acc: 0.9685 - val_loss: 0.2538 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1322 - out_1_loss: 0.0800 - out_2_loss: 0.0522 - out_1_acc: 0.9557 - out_2_acc: 0.9687 - val_loss: 0.2535 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.1319 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1305 - out_1_loss: 0.0790 - out_2_loss: 0.0515 - out_1_acc: 0.9560 - out_2_acc: 0.9690 - val_loss: 0.2520 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.1297 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9521\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1293 - out_1_loss: 0.0781 - out_2_loss: 0.0513 - out_1_acc: 0.9567 - out_2_acc: 0.9690 - val_loss: 0.2557 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1324 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9499\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1280 - out_1_loss: 0.0774 - out_2_loss: 0.0506 - out_1_acc: 0.9566 - out_2_acc: 0.9693 - val_loss: 0.2570 - val_out_1_loss: 0.1234 - val_out_2_loss: 0.1336 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1268 - out_1_loss: 0.0766 - out_2_loss: 0.0502 - out_1_acc: 0.9576 - out_2_acc: 0.9701 - val_loss: 0.2546 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1323 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1266 - out_1_loss: 0.0765 - out_2_loss: 0.0501 - out_1_acc: 0.9575 - out_2_acc: 0.9699 - val_loss: 0.2550 - val_out_1_loss: 0.1234 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9519\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1262 - out_1_loss: 0.0767 - out_2_loss: 0.0495 - out_1_acc: 0.9569 - out_2_acc: 0.9703 - val_loss: 0.2572 - val_out_1_loss: 0.1238 - val_out_2_loss: 0.1334 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9524\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1258 - out_1_loss: 0.0765 - out_2_loss: 0.0493 - out_1_acc: 0.9569 - out_2_acc: 0.9705 - val_loss: 0.2587 - val_out_1_loss: 0.1249 - val_out_2_loss: 0.1339 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9521\n",
      "Epoch 71/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1264 - out_1_loss: 0.0768 - out_2_loss: 0.0496 - out_1_acc: 0.9570 - out_2_acc: 0.9701 - val_loss: 0.2558 - val_out_1_loss: 0.1242 - val_out_2_loss: 0.1317 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1254 - out_1_loss: 0.0764 - out_2_loss: 0.0491 - out_1_acc: 0.9571 - out_2_acc: 0.9705 - val_loss: 0.2620 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1366 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9510\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1253 - out_1_loss: 0.0759 - out_2_loss: 0.0493 - out_1_acc: 0.9573 - out_2_acc: 0.9707 - val_loss: 0.2648 - val_out_1_loss: 0.1270 - val_out_2_loss: 0.1379 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9519\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1239 - out_1_loss: 0.0750 - out_2_loss: 0.0490 - out_1_acc: 0.9578 - out_2_acc: 0.9709 - val_loss: 0.2627 - val_out_1_loss: 0.1275 - val_out_2_loss: 0.1353 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9511\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1222 - out_1_loss: 0.0734 - out_2_loss: 0.0488 - out_1_acc: 0.9586 - out_2_acc: 0.9710 - val_loss: 0.2642 - val_out_1_loss: 0.1275 - val_out_2_loss: 0.1367 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9519\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1208 - out_1_loss: 0.0724 - out_2_loss: 0.0484 - out_1_acc: 0.9590 - out_2_acc: 0.9715 - val_loss: 0.2664 - val_out_1_loss: 0.1291 - val_out_2_loss: 0.1373 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1195 - out_1_loss: 0.0711 - out_2_loss: 0.0484 - out_1_acc: 0.9598 - out_2_acc: 0.9712 - val_loss: 0.2677 - val_out_1_loss: 0.1287 - val_out_2_loss: 0.1391 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9514\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1180 - out_1_loss: 0.0703 - out_2_loss: 0.0478 - out_1_acc: 0.9602 - out_2_acc: 0.9711 - val_loss: 0.2677 - val_out_1_loss: 0.1310 - val_out_2_loss: 0.1368 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9510\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1170 - out_1_loss: 0.0699 - out_2_loss: 0.0471 - out_1_acc: 0.9606 - out_2_acc: 0.9722 - val_loss: 0.2734 - val_out_1_loss: 0.1325 - val_out_2_loss: 0.1409 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1164 - out_1_loss: 0.0690 - out_2_loss: 0.0474 - out_1_acc: 0.9614 - out_2_acc: 0.9718 - val_loss: 0.2749 - val_out_1_loss: 0.1331 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9514\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1155 - out_1_loss: 0.0689 - out_2_loss: 0.0466 - out_1_acc: 0.9613 - out_2_acc: 0.9724 - val_loss: 0.2743 - val_out_1_loss: 0.1339 - val_out_2_loss: 0.1405 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9511\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1146 - out_1_loss: 0.0680 - out_2_loss: 0.0466 - out_1_acc: 0.9615 - out_2_acc: 0.9724 - val_loss: 0.2755 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1413 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9520\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1131 - out_1_loss: 0.0671 - out_2_loss: 0.0460 - out_1_acc: 0.9621 - out_2_acc: 0.9729 - val_loss: 0.2812 - val_out_1_loss: 0.1353 - val_out_2_loss: 0.1459 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9521\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1121 - out_1_loss: 0.0663 - out_2_loss: 0.0457 - out_1_acc: 0.9630 - out_2_acc: 0.9731 - val_loss: 0.2786 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1444 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9510\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1120 - out_1_loss: 0.0659 - out_2_loss: 0.0460 - out_1_acc: 0.9632 - out_2_acc: 0.9732 - val_loss: 0.2824 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1452 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9504\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.1129 - out_1_loss: 0.0660 - out_2_loss: 0.0469 - out_1_acc: 0.9629 - out_2_acc: 0.9727 - val_loss: 0.2836 - val_out_1_loss: 0.1379 - val_out_2_loss: 0.1457 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9510\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1119 - out_1_loss: 0.0658 - out_2_loss: 0.0461 - out_1_acc: 0.9632 - out_2_acc: 0.9735 - val_loss: 0.2836 - val_out_1_loss: 0.1387 - val_out_2_loss: 0.1449 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9519\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1117 - out_1_loss: 0.0659 - out_2_loss: 0.0458 - out_1_acc: 0.9632 - out_2_acc: 0.9731 - val_loss: 0.2860 - val_out_1_loss: 0.1384 - val_out_2_loss: 0.1476 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1108 - out_1_loss: 0.0650 - out_2_loss: 0.0457 - out_1_acc: 0.9634 - out_2_acc: 0.9736 - val_loss: 0.2868 - val_out_1_loss: 0.1393 - val_out_2_loss: 0.1475 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9505\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1096 - out_1_loss: 0.0643 - out_2_loss: 0.0453 - out_1_acc: 0.9644 - out_2_acc: 0.9739 - val_loss: 0.2897 - val_out_1_loss: 0.1417 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9511\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1093 - out_1_loss: 0.0642 - out_2_loss: 0.0452 - out_1_acc: 0.9643 - out_2_acc: 0.9740 - val_loss: 0.2893 - val_out_1_loss: 0.1414 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1079 - out_1_loss: 0.0637 - out_2_loss: 0.0442 - out_1_acc: 0.9646 - out_2_acc: 0.9748 - val_loss: 0.2944 - val_out_1_loss: 0.1441 - val_out_2_loss: 0.1502 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1082 - out_1_loss: 0.0632 - out_2_loss: 0.0450 - out_1_acc: 0.9648 - out_2_acc: 0.9743 - val_loss: 0.2919 - val_out_1_loss: 0.1426 - val_out_2_loss: 0.1494 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1071 - out_1_loss: 0.0630 - out_2_loss: 0.0442 - out_1_acc: 0.9653 - out_2_acc: 0.9747 - val_loss: 0.2965 - val_out_1_loss: 0.1462 - val_out_2_loss: 0.1503 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9519\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1076 - out_1_loss: 0.0632 - out_2_loss: 0.0444 - out_1_acc: 0.9657 - out_2_acc: 0.9746 - val_loss: 0.3003 - val_out_1_loss: 0.1468 - val_out_2_loss: 0.1535 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9512\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1083 - out_1_loss: 0.0630 - out_2_loss: 0.0452 - out_1_acc: 0.9652 - out_2_acc: 0.9747 - val_loss: 0.2990 - val_out_1_loss: 0.1472 - val_out_2_loss: 0.1518 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9508\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1101 - out_1_loss: 0.0638 - out_2_loss: 0.0464 - out_1_acc: 0.9653 - out_2_acc: 0.9737 - val_loss: 0.2968 - val_out_1_loss: 0.1466 - val_out_2_loss: 0.1503 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9528\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1089 - out_1_loss: 0.0633 - out_2_loss: 0.0456 - out_1_acc: 0.9652 - out_2_acc: 0.9739 - val_loss: 0.3021 - val_out_1_loss: 0.1484 - val_out_2_loss: 0.1536 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9508\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1083 - out_1_loss: 0.0629 - out_2_loss: 0.0454 - out_1_acc: 0.9656 - out_2_acc: 0.9742 - val_loss: 0.3014 - val_out_1_loss: 0.1496 - val_out_2_loss: 0.1518 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 100/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1060 - out_1_loss: 0.0623 - out_2_loss: 0.0437 - out_1_acc: 0.9658 - out_2_acc: 0.9755 - val_loss: 0.3050 - val_out_1_loss: 0.1494 - val_out_2_loss: 0.1555 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9514\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1053 - out_1_loss: 0.0617 - out_2_loss: 0.0436 - out_1_acc: 0.9660 - out_2_acc: 0.9755 - val_loss: 0.3056 - val_out_1_loss: 0.1512 - val_out_2_loss: 0.1544 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1050 - out_1_loss: 0.0617 - out_2_loss: 0.0433 - out_1_acc: 0.9663 - out_2_acc: 0.9760 - val_loss: 0.3101 - val_out_1_loss: 0.1522 - val_out_2_loss: 0.1580 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9514\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1036 - out_1_loss: 0.0608 - out_2_loss: 0.0428 - out_1_acc: 0.9672 - out_2_acc: 0.9763 - val_loss: 0.3099 - val_out_1_loss: 0.1519 - val_out_2_loss: 0.1580 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9513\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.1022 - out_1_loss: 0.0599 - out_2_loss: 0.0423 - out_1_acc: 0.9679 - out_2_acc: 0.9767 - val_loss: 0.3131 - val_out_1_loss: 0.1543 - val_out_2_loss: 0.1588 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.1031 - out_1_loss: 0.0605 - out_2_loss: 0.0426 - out_1_acc: 0.9676 - out_2_acc: 0.9767 - val_loss: 0.3128 - val_out_1_loss: 0.1536 - val_out_2_loss: 0.1592 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9510\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1020 - out_1_loss: 0.0600 - out_2_loss: 0.0420 - out_1_acc: 0.9673 - out_2_acc: 0.9769 - val_loss: 0.3103 - val_out_1_loss: 0.1524 - val_out_2_loss: 0.1579 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9509\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.1000 - out_1_loss: 0.0590 - out_2_loss: 0.0411 - out_1_acc: 0.9684 - out_2_acc: 0.9773 - val_loss: 0.3151 - val_out_1_loss: 0.1546 - val_out_2_loss: 0.1604 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0997 - out_1_loss: 0.0589 - out_2_loss: 0.0408 - out_1_acc: 0.9679 - out_2_acc: 0.9781 - val_loss: 0.3171 - val_out_1_loss: 0.1565 - val_out_2_loss: 0.1606 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0997 - out_1_loss: 0.0589 - out_2_loss: 0.0409 - out_1_acc: 0.9679 - out_2_acc: 0.9776 - val_loss: 0.3198 - val_out_1_loss: 0.1574 - val_out_2_loss: 0.1624 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9519\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.1000 - out_1_loss: 0.0592 - out_2_loss: 0.0409 - out_1_acc: 0.9677 - out_2_acc: 0.9780 - val_loss: 0.3167 - val_out_1_loss: 0.1571 - val_out_2_loss: 0.1597 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9525\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0999 - out_1_loss: 0.0581 - out_2_loss: 0.0419 - out_1_acc: 0.9682 - out_2_acc: 0.9771 - val_loss: 0.3172 - val_out_1_loss: 0.1587 - val_out_2_loss: 0.1585 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9515\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0989 - out_1_loss: 0.0577 - out_2_loss: 0.0412 - out_1_acc: 0.9693 - out_2_acc: 0.9780 - val_loss: 0.3204 - val_out_1_loss: 0.1601 - val_out_2_loss: 0.1603 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0962 - out_1_loss: 0.0561 - out_2_loss: 0.0401 - out_1_acc: 0.9706 - out_2_acc: 0.9783 - val_loss: 0.3229 - val_out_1_loss: 0.1612 - val_out_2_loss: 0.1617 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9528\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0954 - out_1_loss: 0.0559 - out_2_loss: 0.0395 - out_1_acc: 0.9705 - out_2_acc: 0.9786 - val_loss: 0.3253 - val_out_1_loss: 0.1611 - val_out_2_loss: 0.1641 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0939 - out_1_loss: 0.0557 - out_2_loss: 0.0381 - out_1_acc: 0.9708 - out_2_acc: 0.9799 - val_loss: 0.3240 - val_out_1_loss: 0.1606 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0911 - out_1_loss: 0.0546 - out_2_loss: 0.0365 - out_1_acc: 0.9718 - out_2_acc: 0.9809 - val_loss: 0.3285 - val_out_1_loss: 0.1603 - val_out_2_loss: 0.1682 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0915 - out_1_loss: 0.0542 - out_2_loss: 0.0373 - out_1_acc: 0.9716 - out_2_acc: 0.9802 - val_loss: 0.3361 - val_out_1_loss: 0.1649 - val_out_2_loss: 0.1712 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0909 - out_1_loss: 0.0543 - out_2_loss: 0.0365 - out_1_acc: 0.9719 - out_2_acc: 0.9810 - val_loss: 0.3314 - val_out_1_loss: 0.1627 - val_out_2_loss: 0.1687 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9527\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0910 - out_1_loss: 0.0541 - out_2_loss: 0.0369 - out_1_acc: 0.9725 - out_2_acc: 0.9806 - val_loss: 0.3350 - val_out_1_loss: 0.1645 - val_out_2_loss: 0.1705 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0920 - out_1_loss: 0.0548 - out_2_loss: 0.0372 - out_1_acc: 0.9715 - out_2_acc: 0.9808 - val_loss: 0.3396 - val_out_1_loss: 0.1653 - val_out_2_loss: 0.1743 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0911 - out_1_loss: 0.0546 - out_2_loss: 0.0365 - out_1_acc: 0.9718 - out_2_acc: 0.9812 - val_loss: 0.3414 - val_out_1_loss: 0.1658 - val_out_2_loss: 0.1756 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0916 - out_1_loss: 0.0543 - out_2_loss: 0.0374 - out_1_acc: 0.9717 - out_2_acc: 0.9805 - val_loss: 0.3391 - val_out_1_loss: 0.1659 - val_out_2_loss: 0.1732 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9519\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0921 - out_1_loss: 0.0543 - out_2_loss: 0.0378 - out_1_acc: 0.9717 - out_2_acc: 0.9802 - val_loss: 0.3406 - val_out_1_loss: 0.1655 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0901 - out_1_loss: 0.0538 - out_2_loss: 0.0363 - out_1_acc: 0.9718 - out_2_acc: 0.9808 - val_loss: 0.3410 - val_out_1_loss: 0.1671 - val_out_2_loss: 0.1739 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9522\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0888 - out_1_loss: 0.0534 - out_2_loss: 0.0353 - out_1_acc: 0.9723 - out_2_acc: 0.9815 - val_loss: 0.3437 - val_out_1_loss: 0.1659 - val_out_2_loss: 0.1778 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9524\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0889 - out_1_loss: 0.0531 - out_2_loss: 0.0358 - out_1_acc: 0.9722 - out_2_acc: 0.9816 - val_loss: 0.3408 - val_out_1_loss: 0.1669 - val_out_2_loss: 0.1739 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9519\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0872 - out_1_loss: 0.0520 - out_2_loss: 0.0352 - out_1_acc: 0.9731 - out_2_acc: 0.9816 - val_loss: 0.3456 - val_out_1_loss: 0.1679 - val_out_2_loss: 0.1776 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9524\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0859 - out_1_loss: 0.0513 - out_2_loss: 0.0346 - out_1_acc: 0.9737 - out_2_acc: 0.9822 - val_loss: 0.3518 - val_out_1_loss: 0.1717 - val_out_2_loss: 0.1800 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9519\n",
      "Epoch 129/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0861 - out_1_loss: 0.0515 - out_2_loss: 0.0346 - out_1_acc: 0.9738 - out_2_acc: 0.9827 - val_loss: 0.3513 - val_out_1_loss: 0.1692 - val_out_2_loss: 0.1821 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9531\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0847 - out_1_loss: 0.0507 - out_2_loss: 0.0340 - out_1_acc: 0.9746 - out_2_acc: 0.9829 - val_loss: 0.3533 - val_out_1_loss: 0.1731 - val_out_2_loss: 0.1803 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0851 - out_1_loss: 0.0511 - out_2_loss: 0.0339 - out_1_acc: 0.9739 - out_2_acc: 0.9828 - val_loss: 0.3595 - val_out_1_loss: 0.1747 - val_out_2_loss: 0.1848 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9513\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0843 - out_1_loss: 0.0505 - out_2_loss: 0.0339 - out_1_acc: 0.9744 - out_2_acc: 0.9829 - val_loss: 0.3603 - val_out_1_loss: 0.1777 - val_out_2_loss: 0.1826 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9529\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0839 - out_1_loss: 0.0518 - out_2_loss: 0.0320 - out_1_acc: 0.9741 - out_2_acc: 0.9840 - val_loss: 0.3644 - val_out_1_loss: 0.1788 - val_out_2_loss: 0.1856 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9528\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0848 - out_1_loss: 0.0522 - out_2_loss: 0.0327 - out_1_acc: 0.9733 - out_2_acc: 0.9837 - val_loss: 0.3602 - val_out_1_loss: 0.1731 - val_out_2_loss: 0.1871 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9515\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0842 - out_1_loss: 0.0510 - out_2_loss: 0.0331 - out_1_acc: 0.9739 - out_2_acc: 0.9838 - val_loss: 0.3659 - val_out_1_loss: 0.1741 - val_out_2_loss: 0.1918 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0825 - out_1_loss: 0.0498 - out_2_loss: 0.0327 - out_1_acc: 0.9754 - out_2_acc: 0.9841 - val_loss: 0.3584 - val_out_1_loss: 0.1714 - val_out_2_loss: 0.1870 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9516\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0812 - out_1_loss: 0.0493 - out_2_loss: 0.0319 - out_1_acc: 0.9756 - out_2_acc: 0.9845 - val_loss: 0.3607 - val_out_1_loss: 0.1718 - val_out_2_loss: 0.1890 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0788 - out_1_loss: 0.0489 - out_2_loss: 0.0300 - out_1_acc: 0.9756 - out_2_acc: 0.9854 - val_loss: 0.3667 - val_out_1_loss: 0.1729 - val_out_2_loss: 0.1937 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9506\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0764 - out_1_loss: 0.0475 - out_2_loss: 0.0288 - out_1_acc: 0.9766 - out_2_acc: 0.9864 - val_loss: 0.3746 - val_out_1_loss: 0.1764 - val_out_2_loss: 0.1982 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9514\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0788 - out_1_loss: 0.0479 - out_2_loss: 0.0310 - out_1_acc: 0.9765 - out_2_acc: 0.9850 - val_loss: 0.3742 - val_out_1_loss: 0.1796 - val_out_2_loss: 0.1945 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9526\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0763 - out_1_loss: 0.0472 - out_2_loss: 0.0291 - out_1_acc: 0.9770 - out_2_acc: 0.9856 - val_loss: 0.3750 - val_out_1_loss: 0.1789 - val_out_2_loss: 0.1961 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 142/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0729 - out_1_loss: 0.0453 - out_2_loss: 0.0276 - out_1_acc: 0.9783 - out_2_acc: 0.9869 - val_loss: 0.3823 - val_out_1_loss: 0.1820 - val_out_2_loss: 0.2003 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 143/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0708 - out_1_loss: 0.0441 - out_2_loss: 0.0267 - out_1_acc: 0.9789 - out_2_acc: 0.9876 - val_loss: 0.3906 - val_out_1_loss: 0.1850 - val_out_2_loss: 0.2056 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9512\n",
      "Epoch 144/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0711 - out_1_loss: 0.0440 - out_2_loss: 0.0271 - out_1_acc: 0.9786 - out_2_acc: 0.9871 - val_loss: 0.4004 - val_out_1_loss: 0.1898 - val_out_2_loss: 0.2106 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9505\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0710 - out_1_loss: 0.0442 - out_2_loss: 0.0268 - out_1_acc: 0.9786 - out_2_acc: 0.9872 - val_loss: 0.3913 - val_out_1_loss: 0.1882 - val_out_2_loss: 0.2030 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9511\n",
      "Epoch 146/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0677 - out_1_loss: 0.0431 - out_2_loss: 0.0247 - out_1_acc: 0.9792 - out_2_acc: 0.9885 - val_loss: 0.3980 - val_out_1_loss: 0.1912 - val_out_2_loss: 0.2068 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9514\n",
      "Epoch 147/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0657 - out_1_loss: 0.0426 - out_2_loss: 0.0231 - out_1_acc: 0.9792 - out_2_acc: 0.9893 - val_loss: 0.3960 - val_out_1_loss: 0.1885 - val_out_2_loss: 0.2075 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 148/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0631 - out_1_loss: 0.0412 - out_2_loss: 0.0219 - out_1_acc: 0.9806 - out_2_acc: 0.9903 - val_loss: 0.4065 - val_out_1_loss: 0.1916 - val_out_2_loss: 0.2149 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9500\n",
      "Epoch 149/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0648 - out_1_loss: 0.0421 - out_2_loss: 0.0227 - out_1_acc: 0.9797 - out_2_acc: 0.9896 - val_loss: 0.4143 - val_out_1_loss: 0.1956 - val_out_2_loss: 0.2187 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9498\n",
      "Epoch 150/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0652 - out_1_loss: 0.0420 - out_2_loss: 0.0232 - out_1_acc: 0.9803 - out_2_acc: 0.9896 - val_loss: 0.4106 - val_out_1_loss: 0.1921 - val_out_2_loss: 0.2184 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9503\n",
      "Epoch 151/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0636 - out_1_loss: 0.0415 - out_2_loss: 0.0221 - out_1_acc: 0.9803 - out_2_acc: 0.9903 - val_loss: 0.4138 - val_out_1_loss: 0.1958 - val_out_2_loss: 0.2180 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 152/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0631 - out_1_loss: 0.0416 - out_2_loss: 0.0215 - out_1_acc: 0.9804 - out_2_acc: 0.9904 - val_loss: 0.4105 - val_out_1_loss: 0.1947 - val_out_2_loss: 0.2157 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9515\n",
      "Epoch 153/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0609 - out_1_loss: 0.0401 - out_2_loss: 0.0209 - out_1_acc: 0.9813 - out_2_acc: 0.9908 - val_loss: 0.4212 - val_out_1_loss: 0.1959 - val_out_2_loss: 0.2253 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9507\n",
      "Epoch 154/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0610 - out_1_loss: 0.0395 - out_2_loss: 0.0215 - out_1_acc: 0.9819 - out_2_acc: 0.9903 - val_loss: 0.4237 - val_out_1_loss: 0.1955 - val_out_2_loss: 0.2283 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9505\n",
      "Epoch 155/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0623 - out_1_loss: 0.0395 - out_2_loss: 0.0228 - out_1_acc: 0.9812 - out_2_acc: 0.9900 - val_loss: 0.4288 - val_out_1_loss: 0.2003 - val_out_2_loss: 0.2286 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9501\n",
      "Epoch 156/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0594 - out_1_loss: 0.0387 - out_2_loss: 0.0208 - out_1_acc: 0.9820 - out_2_acc: 0.9908 - val_loss: 0.4246 - val_out_1_loss: 0.1982 - val_out_2_loss: 0.2263 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9511\n",
      "Epoch 157/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0594 - out_1_loss: 0.0389 - out_2_loss: 0.0205 - out_1_acc: 0.9821 - out_2_acc: 0.9907 - val_loss: 0.4315 - val_out_1_loss: 0.2022 - val_out_2_loss: 0.2293 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9507\n",
      "Epoch 158/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0587 - out_1_loss: 0.0379 - out_2_loss: 0.0208 - out_1_acc: 0.9825 - out_2_acc: 0.9909 - val_loss: 0.4356 - val_out_1_loss: 0.2040 - val_out_2_loss: 0.2316 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 159/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0591 - out_1_loss: 0.0385 - out_2_loss: 0.0206 - out_1_acc: 0.9820 - out_2_acc: 0.9907 - val_loss: 0.4397 - val_out_1_loss: 0.2045 - val_out_2_loss: 0.2352 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9502\n",
      "Epoch 160/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0578 - out_1_loss: 0.0380 - out_2_loss: 0.0198 - out_1_acc: 0.9824 - out_2_acc: 0.9911 - val_loss: 0.4449 - val_out_1_loss: 0.2086 - val_out_2_loss: 0.2363 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9502\n",
      "Epoch 161/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0589 - out_1_loss: 0.0393 - out_2_loss: 0.0196 - out_1_acc: 0.9813 - out_2_acc: 0.9909 - val_loss: 0.4405 - val_out_1_loss: 0.2035 - val_out_2_loss: 0.2370 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9510\n",
      "Epoch 162/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0568 - out_1_loss: 0.0372 - out_2_loss: 0.0196 - out_1_acc: 0.9827 - out_2_acc: 0.9913 - val_loss: 0.4493 - val_out_1_loss: 0.2079 - val_out_2_loss: 0.2415 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9500\n",
      "Epoch 163/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0540 - out_1_loss: 0.0362 - out_2_loss: 0.0178 - out_1_acc: 0.9836 - out_2_acc: 0.9920 - val_loss: 0.4568 - val_out_1_loss: 0.2106 - val_out_2_loss: 0.2462 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 164/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0538 - out_1_loss: 0.0358 - out_2_loss: 0.0180 - out_1_acc: 0.9835 - out_2_acc: 0.9922 - val_loss: 0.4585 - val_out_1_loss: 0.2121 - val_out_2_loss: 0.2464 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9502\n",
      "Epoch 165/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0527 - out_1_loss: 0.0346 - out_2_loss: 0.0181 - out_1_acc: 0.9843 - out_2_acc: 0.9921 - val_loss: 0.4727 - val_out_1_loss: 0.2154 - val_out_2_loss: 0.2573 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9501\n",
      "Epoch 166/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0540 - out_1_loss: 0.0357 - out_2_loss: 0.0183 - out_1_acc: 0.9837 - out_2_acc: 0.9919 - val_loss: 0.4800 - val_out_1_loss: 0.2148 - val_out_2_loss: 0.2652 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9495\n",
      "Epoch 167/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0539 - out_1_loss: 0.0353 - out_2_loss: 0.0186 - out_1_acc: 0.9841 - out_2_acc: 0.9915 - val_loss: 0.4713 - val_out_1_loss: 0.2155 - val_out_2_loss: 0.2558 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9500\n",
      "Epoch 168/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0509 - out_1_loss: 0.0335 - out_2_loss: 0.0174 - out_1_acc: 0.9848 - out_2_acc: 0.9923 - val_loss: 0.4790 - val_out_1_loss: 0.2198 - val_out_2_loss: 0.2592 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9503\n",
      "Epoch 169/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0508 - out_1_loss: 0.0335 - out_2_loss: 0.0172 - out_1_acc: 0.9848 - out_2_acc: 0.9928 - val_loss: 0.4750 - val_out_1_loss: 0.2219 - val_out_2_loss: 0.2531 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9512\n",
      "Epoch 170/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0485 - out_1_loss: 0.0324 - out_2_loss: 0.0161 - out_1_acc: 0.9859 - out_2_acc: 0.9932 - val_loss: 0.4793 - val_out_1_loss: 0.2229 - val_out_2_loss: 0.2565 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9515\n",
      "Epoch 171/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0503 - out_1_loss: 0.0332 - out_2_loss: 0.0170 - out_1_acc: 0.9850 - out_2_acc: 0.9928 - val_loss: 0.4788 - val_out_1_loss: 0.2230 - val_out_2_loss: 0.2558 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9516\n",
      "Epoch 172/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0507 - out_1_loss: 0.0336 - out_2_loss: 0.0170 - out_1_acc: 0.9847 - out_2_acc: 0.9930 - val_loss: 0.4855 - val_out_1_loss: 0.2252 - val_out_2_loss: 0.2604 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 173/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0489 - out_1_loss: 0.0324 - out_2_loss: 0.0165 - out_1_acc: 0.9858 - out_2_acc: 0.9929 - val_loss: 0.4968 - val_out_1_loss: 0.2285 - val_out_2_loss: 0.2683 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9506\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0481 - out_1_loss: 0.0314 - out_2_loss: 0.0167 - out_1_acc: 0.9868 - out_2_acc: 0.9928 - val_loss: 0.4823 - val_out_1_loss: 0.2270 - val_out_2_loss: 0.2553 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9511\n",
      "Epoch 175/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0485 - out_1_loss: 0.0317 - out_2_loss: 0.0168 - out_1_acc: 0.9858 - out_2_acc: 0.9928 - val_loss: 0.5000 - val_out_1_loss: 0.2334 - val_out_2_loss: 0.2667 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9511\n",
      "Epoch 176/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0480 - out_1_loss: 0.0313 - out_2_loss: 0.0167 - out_1_acc: 0.9861 - out_2_acc: 0.9928 - val_loss: 0.4868 - val_out_1_loss: 0.2302 - val_out_2_loss: 0.2566 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 177/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0469 - out_1_loss: 0.0319 - out_2_loss: 0.0150 - out_1_acc: 0.9859 - out_2_acc: 0.9938 - val_loss: 0.4906 - val_out_1_loss: 0.2299 - val_out_2_loss: 0.2607 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9509\n",
      "Epoch 178/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0438 - out_1_loss: 0.0302 - out_2_loss: 0.0136 - out_1_acc: 0.9871 - out_2_acc: 0.9944 - val_loss: 0.5004 - val_out_1_loss: 0.2344 - val_out_2_loss: 0.2660 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 179/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0451 - out_1_loss: 0.0313 - out_2_loss: 0.0138 - out_1_acc: 0.9868 - out_2_acc: 0.9940 - val_loss: 0.5025 - val_out_1_loss: 0.2372 - val_out_2_loss: 0.2653 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9518\n",
      "Epoch 180/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0442 - out_1_loss: 0.0312 - out_2_loss: 0.0130 - out_1_acc: 0.9863 - out_2_acc: 0.9947 - val_loss: 0.5051 - val_out_1_loss: 0.2394 - val_out_2_loss: 0.2656 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9505\n",
      "Epoch 181/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0443 - out_1_loss: 0.0310 - out_2_loss: 0.0133 - out_1_acc: 0.9867 - out_2_acc: 0.9946 - val_loss: 0.5204 - val_out_1_loss: 0.2410 - val_out_2_loss: 0.2795 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9497\n",
      "Epoch 182/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0436 - out_1_loss: 0.0308 - out_2_loss: 0.0128 - out_1_acc: 0.9864 - out_2_acc: 0.9948 - val_loss: 0.5225 - val_out_1_loss: 0.2432 - val_out_2_loss: 0.2793 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9506\n",
      "Epoch 183/300\n",
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0452 - out_1_loss: 0.0316 - out_2_loss: 0.0136 - out_1_acc: 0.9864 - out_2_acc: 0.9944 - val_loss: 0.5135 - val_out_1_loss: 0.2390 - val_out_2_loss: 0.2745 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 184/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0457 - out_1_loss: 0.0314 - out_2_loss: 0.0143 - out_1_acc: 0.9867 - out_2_acc: 0.9941 - val_loss: 0.5169 - val_out_1_loss: 0.2467 - val_out_2_loss: 0.2702 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9509\n",
      "Epoch 185/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0420 - out_1_loss: 0.0293 - out_2_loss: 0.0126 - out_1_acc: 0.9876 - out_2_acc: 0.9948 - val_loss: 0.5269 - val_out_1_loss: 0.2505 - val_out_2_loss: 0.2764 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9513\n",
      "Epoch 186/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0434 - out_1_loss: 0.0310 - out_2_loss: 0.0124 - out_1_acc: 0.9869 - out_2_acc: 0.9948 - val_loss: 0.5292 - val_out_1_loss: 0.2518 - val_out_2_loss: 0.2774 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9512\n",
      "Epoch 187/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0420 - out_1_loss: 0.0310 - out_2_loss: 0.0110 - out_1_acc: 0.9865 - out_2_acc: 0.9955 - val_loss: 0.5314 - val_out_1_loss: 0.2518 - val_out_2_loss: 0.2797 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9517\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0403 - out_1_loss: 0.0292 - out_2_loss: 0.0111 - out_1_acc: 0.9873 - out_2_acc: 0.9954 - val_loss: 0.5287 - val_out_1_loss: 0.2524 - val_out_2_loss: 0.2763 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0377 - out_1_loss: 0.0283 - out_2_loss: 0.0094 - out_1_acc: 0.9881 - out_2_acc: 0.9964 - val_loss: 0.5353 - val_out_1_loss: 0.2520 - val_out_2_loss: 0.2833 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0376 - out_1_loss: 0.0281 - out_2_loss: 0.0094 - out_1_acc: 0.9879 - out_2_acc: 0.9961 - val_loss: 0.5426 - val_out_1_loss: 0.2525 - val_out_2_loss: 0.2901 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9524\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0380 - out_1_loss: 0.0282 - out_2_loss: 0.0098 - out_1_acc: 0.9882 - out_2_acc: 0.9960 - val_loss: 0.5449 - val_out_1_loss: 0.2521 - val_out_2_loss: 0.2928 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0370 - out_1_loss: 0.0272 - out_2_loss: 0.0098 - out_1_acc: 0.9883 - out_2_acc: 0.9962 - val_loss: 0.5452 - val_out_1_loss: 0.2518 - val_out_2_loss: 0.2934 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0370 - out_1_loss: 0.0275 - out_2_loss: 0.0096 - out_1_acc: 0.9884 - out_2_acc: 0.9961 - val_loss: 0.5392 - val_out_1_loss: 0.2516 - val_out_2_loss: 0.2877 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9520\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0395 - out_1_loss: 0.0276 - out_2_loss: 0.0119 - out_1_acc: 0.9883 - out_2_acc: 0.9953 - val_loss: 0.5427 - val_out_1_loss: 0.2508 - val_out_2_loss: 0.2919 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9522\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0387 - out_1_loss: 0.0271 - out_2_loss: 0.0116 - out_1_acc: 0.9886 - out_2_acc: 0.9954 - val_loss: 0.5451 - val_out_1_loss: 0.2539 - val_out_2_loss: 0.2912 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9504\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 2s 56ms/step - loss: 0.0365 - out_1_loss: 0.0252 - out_2_loss: 0.0113 - out_1_acc: 0.9897 - out_2_acc: 0.9958 - val_loss: 0.5439 - val_out_1_loss: 0.2516 - val_out_2_loss: 0.2923 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0345 - out_1_loss: 0.0239 - out_2_loss: 0.0106 - out_1_acc: 0.9899 - out_2_acc: 0.9959 - val_loss: 0.5541 - val_out_1_loss: 0.2586 - val_out_2_loss: 0.2955 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0325 - out_1_loss: 0.0236 - out_2_loss: 0.0089 - out_1_acc: 0.9899 - out_2_acc: 0.9964 - val_loss: 0.5602 - val_out_1_loss: 0.2622 - val_out_2_loss: 0.2980 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9510\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0326 - out_1_loss: 0.0233 - out_2_loss: 0.0093 - out_1_acc: 0.9904 - out_2_acc: 0.9966 - val_loss: 0.5514 - val_out_1_loss: 0.2568 - val_out_2_loss: 0.2945 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9507\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0311 - out_1_loss: 0.0225 - out_2_loss: 0.0087 - out_1_acc: 0.9907 - out_2_acc: 0.9967 - val_loss: 0.5689 - val_out_1_loss: 0.2655 - val_out_2_loss: 0.3034 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9496\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0295 - out_1_loss: 0.0216 - out_2_loss: 0.0079 - out_1_acc: 0.9912 - out_2_acc: 0.9969 - val_loss: 0.5691 - val_out_1_loss: 0.2639 - val_out_2_loss: 0.3052 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0298 - out_1_loss: 0.0217 - out_2_loss: 0.0081 - out_1_acc: 0.9911 - out_2_acc: 0.9968 - val_loss: 0.5664 - val_out_1_loss: 0.2663 - val_out_2_loss: 0.3001 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9503\n",
      "Epoch 203/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 54ms/step - loss: 0.0279 - out_1_loss: 0.0202 - out_2_loss: 0.0077 - out_1_acc: 0.9921 - out_2_acc: 0.9970 - val_loss: 0.5668 - val_out_1_loss: 0.2684 - val_out_2_loss: 0.2984 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0270 - out_1_loss: 0.0201 - out_2_loss: 0.0070 - out_1_acc: 0.9920 - out_2_acc: 0.9973 - val_loss: 0.5833 - val_out_1_loss: 0.2707 - val_out_2_loss: 0.3126 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0271 - out_1_loss: 0.0197 - out_2_loss: 0.0074 - out_1_acc: 0.9922 - out_2_acc: 0.9973 - val_loss: 0.5700 - val_out_1_loss: 0.2685 - val_out_2_loss: 0.3015 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9522\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 1s 50ms/step - loss: 0.0248 - out_1_loss: 0.0178 - out_2_loss: 0.0070 - out_1_acc: 0.9931 - out_2_acc: 0.9973 - val_loss: 0.5827 - val_out_1_loss: 0.2765 - val_out_2_loss: 0.3062 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0263 - out_1_loss: 0.0192 - out_2_loss: 0.0072 - out_1_acc: 0.9926 - out_2_acc: 0.9974 - val_loss: 0.5875 - val_out_1_loss: 0.2760 - val_out_2_loss: 0.3115 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0251 - out_1_loss: 0.0182 - out_2_loss: 0.0069 - out_1_acc: 0.9931 - out_2_acc: 0.9974 - val_loss: 0.5852 - val_out_1_loss: 0.2778 - val_out_2_loss: 0.3075 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0233 - out_1_loss: 0.0174 - out_2_loss: 0.0059 - out_1_acc: 0.9934 - out_2_acc: 0.9978 - val_loss: 0.5979 - val_out_1_loss: 0.2823 - val_out_2_loss: 0.3157 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0233 - out_1_loss: 0.0170 - out_2_loss: 0.0063 - out_1_acc: 0.9934 - out_2_acc: 0.9977 - val_loss: 0.6050 - val_out_1_loss: 0.2837 - val_out_2_loss: 0.3213 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0225 - out_1_loss: 0.0166 - out_2_loss: 0.0059 - out_1_acc: 0.9936 - out_2_acc: 0.9978 - val_loss: 0.6003 - val_out_1_loss: 0.2854 - val_out_2_loss: 0.3149 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9508\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0226 - out_1_loss: 0.0172 - out_2_loss: 0.0055 - out_1_acc: 0.9936 - out_2_acc: 0.9981 - val_loss: 0.6103 - val_out_1_loss: 0.2888 - val_out_2_loss: 0.3215 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0254 - out_1_loss: 0.0170 - out_2_loss: 0.0084 - out_1_acc: 0.9937 - out_2_acc: 0.9970 - val_loss: 0.6038 - val_out_1_loss: 0.2874 - val_out_2_loss: 0.3164 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9510\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0233 - out_1_loss: 0.0165 - out_2_loss: 0.0068 - out_1_acc: 0.9940 - out_2_acc: 0.9973 - val_loss: 0.6170 - val_out_1_loss: 0.2924 - val_out_2_loss: 0.3246 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9512\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0254 - out_1_loss: 0.0181 - out_2_loss: 0.0074 - out_1_acc: 0.9936 - out_2_acc: 0.9972 - val_loss: 0.6085 - val_out_1_loss: 0.2909 - val_out_2_loss: 0.3176 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9519\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0271 - out_1_loss: 0.0184 - out_2_loss: 0.0087 - out_1_acc: 0.9930 - out_2_acc: 0.9968 - val_loss: 0.6085 - val_out_1_loss: 0.2874 - val_out_2_loss: 0.3211 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9522\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0248 - out_1_loss: 0.0168 - out_2_loss: 0.0080 - out_1_acc: 0.9935 - out_2_acc: 0.9968 - val_loss: 0.6078 - val_out_1_loss: 0.2885 - val_out_2_loss: 0.3193 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9513\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0219 - out_1_loss: 0.0148 - out_2_loss: 0.0071 - out_1_acc: 0.9945 - out_2_acc: 0.9972 - val_loss: 0.6218 - val_out_1_loss: 0.2967 - val_out_2_loss: 0.3251 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0220 - out_1_loss: 0.0149 - out_2_loss: 0.0071 - out_1_acc: 0.9944 - out_2_acc: 0.9974 - val_loss: 0.6206 - val_out_1_loss: 0.2931 - val_out_2_loss: 0.3276 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9512\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0218 - out_1_loss: 0.0145 - out_2_loss: 0.0073 - out_1_acc: 0.9947 - out_2_acc: 0.9973 - val_loss: 0.6168 - val_out_1_loss: 0.2905 - val_out_2_loss: 0.3263 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0209 - out_1_loss: 0.0140 - out_2_loss: 0.0069 - out_1_acc: 0.9947 - out_2_acc: 0.9975 - val_loss: 0.6186 - val_out_1_loss: 0.2935 - val_out_2_loss: 0.3251 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0182 - out_1_loss: 0.0130 - out_2_loss: 0.0052 - out_1_acc: 0.9953 - out_2_acc: 0.9982 - val_loss: 0.6306 - val_out_1_loss: 0.2975 - val_out_2_loss: 0.3331 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0168 - out_1_loss: 0.0120 - out_2_loss: 0.0048 - out_1_acc: 0.9957 - out_2_acc: 0.9984 - val_loss: 0.6199 - val_out_1_loss: 0.2969 - val_out_2_loss: 0.3230 - val_out_1_acc: 0.9421 - val_out_2_acc: 0.9524\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0163 - out_1_loss: 0.0120 - out_2_loss: 0.0043 - out_1_acc: 0.9957 - out_2_acc: 0.9986 - val_loss: 0.6280 - val_out_1_loss: 0.3019 - val_out_2_loss: 0.3261 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0176 - out_1_loss: 0.0125 - out_2_loss: 0.0050 - out_1_acc: 0.9953 - out_2_acc: 0.9984 - val_loss: 0.6328 - val_out_1_loss: 0.3070 - val_out_2_loss: 0.3257 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9530\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0160 - out_1_loss: 0.0120 - out_2_loss: 0.0041 - out_1_acc: 0.9958 - out_2_acc: 0.9985 - val_loss: 0.6493 - val_out_1_loss: 0.3109 - val_out_2_loss: 0.3383 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9525\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0161 - out_1_loss: 0.0120 - out_2_loss: 0.0041 - out_1_acc: 0.9955 - out_2_acc: 0.9986 - val_loss: 0.6502 - val_out_1_loss: 0.3143 - val_out_2_loss: 0.3359 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9525\n",
      "Epoch 228/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0161 - out_1_loss: 0.0121 - out_2_loss: 0.0041 - out_1_acc: 0.9958 - out_2_acc: 0.9986 - val_loss: 0.6630 - val_out_1_loss: 0.3196 - val_out_2_loss: 0.3434 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0161 - out_1_loss: 0.0112 - out_2_loss: 0.0049 - out_1_acc: 0.9959 - out_2_acc: 0.9984 - val_loss: 0.6536 - val_out_1_loss: 0.3153 - val_out_2_loss: 0.3383 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0181 - out_1_loss: 0.0116 - out_2_loss: 0.0066 - out_1_acc: 0.9958 - out_2_acc: 0.9978 - val_loss: 0.6585 - val_out_1_loss: 0.3213 - val_out_2_loss: 0.3372 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0189 - out_1_loss: 0.0128 - out_2_loss: 0.0061 - out_1_acc: 0.9951 - out_2_acc: 0.9979 - val_loss: 0.6488 - val_out_1_loss: 0.3202 - val_out_2_loss: 0.3286 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9519\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0180 - out_1_loss: 0.0124 - out_2_loss: 0.0056 - out_1_acc: 0.9953 - out_2_acc: 0.9981 - val_loss: 0.6410 - val_out_1_loss: 0.3123 - val_out_2_loss: 0.3288 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9520\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0158 - out_1_loss: 0.0112 - out_2_loss: 0.0045 - out_1_acc: 0.9960 - out_2_acc: 0.9985 - val_loss: 0.6542 - val_out_1_loss: 0.3209 - val_out_2_loss: 0.3334 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0160 - out_1_loss: 0.0117 - out_2_loss: 0.0042 - out_1_acc: 0.9956 - out_2_acc: 0.9986 - val_loss: 0.6556 - val_out_1_loss: 0.3222 - val_out_2_loss: 0.3334 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9515\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0179 - out_1_loss: 0.0130 - out_2_loss: 0.0049 - out_1_acc: 0.9955 - out_2_acc: 0.9982 - val_loss: 0.6717 - val_out_1_loss: 0.3310 - val_out_2_loss: 0.3406 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 236/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0194 - out_1_loss: 0.0137 - out_2_loss: 0.0057 - out_1_acc: 0.9949 - out_2_acc: 0.9980 - val_loss: 0.6737 - val_out_1_loss: 0.3339 - val_out_2_loss: 0.3398 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9515\n",
      "Epoch 237/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0180 - out_1_loss: 0.0126 - out_2_loss: 0.0055 - out_1_acc: 0.9954 - out_2_acc: 0.9983 - val_loss: 0.6775 - val_out_1_loss: 0.3348 - val_out_2_loss: 0.3427 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9513\n",
      "Epoch 238/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0188 - out_1_loss: 0.0120 - out_2_loss: 0.0068 - out_1_acc: 0.9957 - out_2_acc: 0.9978 - val_loss: 0.6775 - val_out_1_loss: 0.3380 - val_out_2_loss: 0.3395 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9501\n",
      "Epoch 239/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0157 - out_1_loss: 0.0111 - out_2_loss: 0.0046 - out_1_acc: 0.9961 - out_2_acc: 0.9983 - val_loss: 0.6875 - val_out_1_loss: 0.3403 - val_out_2_loss: 0.3473 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9507\n",
      "Epoch 240/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0152 - out_1_loss: 0.0112 - out_2_loss: 0.0040 - out_1_acc: 0.9957 - out_2_acc: 0.9986 - val_loss: 0.6845 - val_out_1_loss: 0.3372 - val_out_2_loss: 0.3473 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 241/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0151 - out_1_loss: 0.0109 - out_2_loss: 0.0041 - out_1_acc: 0.9961 - out_2_acc: 0.9986 - val_loss: 0.6974 - val_out_1_loss: 0.3455 - val_out_2_loss: 0.3520 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9508\n",
      "Epoch 242/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0152 - out_1_loss: 0.0110 - out_2_loss: 0.0042 - out_1_acc: 0.9961 - out_2_acc: 0.9986 - val_loss: 0.7027 - val_out_1_loss: 0.3445 - val_out_2_loss: 0.3582 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9509\n",
      "Epoch 243/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0179 - out_1_loss: 0.0121 - out_2_loss: 0.0058 - out_1_acc: 0.9957 - out_2_acc: 0.9980 - val_loss: 0.7052 - val_out_1_loss: 0.3514 - val_out_2_loss: 0.3538 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9499\n",
      "Epoch 244/300\n",
      "28/28 [==============================] - 1s 53ms/step - loss: 0.0195 - out_1_loss: 0.0132 - out_2_loss: 0.0062 - out_1_acc: 0.9952 - out_2_acc: 0.9979 - val_loss: 0.6968 - val_out_1_loss: 0.3450 - val_out_2_loss: 0.3518 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9507\n",
      "Epoch 245/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0180 - out_1_loss: 0.0125 - out_2_loss: 0.0055 - out_1_acc: 0.9954 - out_2_acc: 0.9980 - val_loss: 0.6792 - val_out_1_loss: 0.3438 - val_out_2_loss: 0.3353 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9516\n",
      "Epoch 246/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0183 - out_1_loss: 0.0129 - out_2_loss: 0.0053 - out_1_acc: 0.9952 - out_2_acc: 0.9981 - val_loss: 0.6911 - val_out_1_loss: 0.3467 - val_out_2_loss: 0.3445 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9500\n",
      "Epoch 247/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0175 - out_1_loss: 0.0122 - out_2_loss: 0.0053 - out_1_acc: 0.9956 - out_2_acc: 0.9980 - val_loss: 0.6901 - val_out_1_loss: 0.3417 - val_out_2_loss: 0.3484 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9504\n",
      "Epoch 248/300\n",
      "28/28 [==============================] - 1s 51ms/step - loss: 0.0167 - out_1_loss: 0.0120 - out_2_loss: 0.0047 - out_1_acc: 0.9954 - out_2_acc: 0.9983 - val_loss: 0.6871 - val_out_1_loss: 0.3437 - val_out_2_loss: 0.3434 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9515\n",
      "Epoch 249/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0169 - out_1_loss: 0.0118 - out_2_loss: 0.0051 - out_1_acc: 0.9956 - out_2_acc: 0.9982 - val_loss: 0.6871 - val_out_1_loss: 0.3416 - val_out_2_loss: 0.3455 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9506\n",
      "Epoch 250/300\n",
      "28/28 [==============================] - 1s 52ms/step - loss: 0.0151 - out_1_loss: 0.0108 - out_2_loss: 0.0043 - out_1_acc: 0.9957 - out_2_acc: 0.9984 - val_loss: 0.6854 - val_out_1_loss: 0.3400 - val_out_2_loss: 0.3455 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9505\n",
      "Epoch 251/300\n",
      "28/28 [==============================] - 2s 55ms/step - loss: 0.0157 - out_1_loss: 0.0112 - out_2_loss: 0.0045 - out_1_acc: 0.9960 - out_2_acc: 0.9984 - val_loss: 0.7015 - val_out_1_loss: 0.3436 - val_out_2_loss: 0.3579 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9507\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(6)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6814 - out_1_loss: 0.3489 - out_2_loss: 0.3325 - out_1_acc: 0.9409 - out_2_acc: 0.9532\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 300), (No 397200      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 300)       397200      input_16[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,441,480\n",
      "Trainable params: 2,441,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3276 - out_1_loss: 3.6665 - out_2_loss: 3.6611 - out_1_acc: 0.1974 - out_2_acc: 0.1923WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109365). Check your callbacks.\n",
      "28/28 [==============================] - 3s 117ms/step - loss: 5.2928 - out_1_loss: 2.7231 - out_2_loss: 2.5697 - out_1_acc: 0.4283 - out_2_acc: 0.4478 - val_loss: 3.6685 - val_out_1_loss: 1.9764 - val_out_2_loss: 1.6921 - val_out_1_acc: 0.4909 - val_out_2_acc: 0.5652\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 2.4928 - out_1_loss: 1.4925 - out_2_loss: 1.0002 - out_1_acc: 0.6073 - out_2_acc: 0.7415 - val_loss: 1.4301 - val_out_1_loss: 0.9221 - val_out_2_loss: 0.5080 - val_out_1_acc: 0.7688 - val_out_2_acc: 0.8740\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.9260 - out_1_loss: 0.5910 - out_2_loss: 0.3350 - out_1_acc: 0.8594 - out_2_acc: 0.9155 - val_loss: 0.6009 - val_out_1_loss: 0.3771 - val_out_2_loss: 0.2239 - val_out_1_acc: 0.9134 - val_out_2_acc: 0.9392\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.4559 - out_1_loss: 0.2879 - out_2_loss: 0.1680 - out_1_acc: 0.9234 - out_2_acc: 0.9476 - val_loss: 0.3715 - val_out_1_loss: 0.2288 - val_out_2_loss: 0.1427 - val_out_1_acc: 0.9313 - val_out_2_acc: 0.9498\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.3071 - out_1_loss: 0.1882 - out_2_loss: 0.1189 - out_1_acc: 0.9361 - out_2_acc: 0.9525 - val_loss: 0.2926 - val_out_1_loss: 0.1731 - val_out_2_loss: 0.1195 - val_out_1_acc: 0.9370 - val_out_2_acc: 0.9495\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.2509 - out_1_loss: 0.1485 - out_2_loss: 0.1024 - out_1_acc: 0.9400 - out_2_acc: 0.9530 - val_loss: 0.2513 - val_out_1_loss: 0.1444 - val_out_2_loss: 0.1069 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9510\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.2220 - out_1_loss: 0.1283 - out_2_loss: 0.0938 - out_1_acc: 0.9418 - out_2_acc: 0.9540 - val_loss: 0.2322 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1025 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9503\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.2069 - out_1_loss: 0.1175 - out_2_loss: 0.0895 - out_1_acc: 0.9431 - out_2_acc: 0.9542 - val_loss: 0.2226 - val_out_1_loss: 0.1232 - val_out_2_loss: 0.0994 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1978 - out_1_loss: 0.1115 - out_2_loss: 0.0863 - out_1_acc: 0.9435 - out_2_acc: 0.9549 - val_loss: 0.2163 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1916 - out_1_loss: 0.1076 - out_2_loss: 0.0840 - out_1_acc: 0.9441 - out_2_acc: 0.9554 - val_loss: 0.2137 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9504\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1873 - out_1_loss: 0.1049 - out_2_loss: 0.0824 - out_1_acc: 0.9446 - out_2_acc: 0.9558 - val_loss: 0.2093 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.0946 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9506\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1817 - out_1_loss: 0.1027 - out_2_loss: 0.0790 - out_1_acc: 0.9452 - out_2_acc: 0.9570 - val_loss: 0.2082 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.0941 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9522\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1789 - out_1_loss: 0.1011 - out_2_loss: 0.0777 - out_1_acc: 0.9459 - out_2_acc: 0.9572 - val_loss: 0.2075 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1762 - out_1_loss: 0.0996 - out_2_loss: 0.0766 - out_1_acc: 0.9459 - out_2_acc: 0.9580 - val_loss: 0.2068 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1739 - out_1_loss: 0.0985 - out_2_loss: 0.0754 - out_1_acc: 0.9463 - out_2_acc: 0.9583 - val_loss: 0.2062 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.0941 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9516\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1712 - out_1_loss: 0.0973 - out_2_loss: 0.0739 - out_1_acc: 0.9468 - out_2_acc: 0.9589 - val_loss: 0.2081 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1696 - out_1_loss: 0.0963 - out_2_loss: 0.0733 - out_1_acc: 0.9470 - out_2_acc: 0.9589 - val_loss: 0.2074 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1668 - out_1_loss: 0.0952 - out_2_loss: 0.0715 - out_1_acc: 0.9477 - out_2_acc: 0.9598 - val_loss: 0.2080 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1649 - out_1_loss: 0.0948 - out_2_loss: 0.0701 - out_1_acc: 0.9478 - out_2_acc: 0.9602 - val_loss: 0.2079 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1632 - out_1_loss: 0.0939 - out_2_loss: 0.0693 - out_1_acc: 0.9480 - out_2_acc: 0.9606 - val_loss: 0.2088 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9509\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1613 - out_1_loss: 0.0932 - out_2_loss: 0.0681 - out_1_acc: 0.9480 - out_2_acc: 0.9614 - val_loss: 0.2109 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1601 - out_1_loss: 0.0927 - out_2_loss: 0.0673 - out_1_acc: 0.9481 - out_2_acc: 0.9618 - val_loss: 0.2112 - val_out_1_loss: 0.1128 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9514\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1589 - out_1_loss: 0.0918 - out_2_loss: 0.0672 - out_1_acc: 0.9488 - out_2_acc: 0.9620 - val_loss: 0.2129 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1591 - out_1_loss: 0.0912 - out_2_loss: 0.0679 - out_1_acc: 0.9491 - out_2_acc: 0.9615 - val_loss: 0.2151 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1016 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9513\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1590 - out_1_loss: 0.0909 - out_2_loss: 0.0681 - out_1_acc: 0.9496 - out_2_acc: 0.9611 - val_loss: 0.2159 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1035 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9512\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1561 - out_1_loss: 0.0906 - out_2_loss: 0.0655 - out_1_acc: 0.9495 - out_2_acc: 0.9622 - val_loss: 0.2132 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.1007 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1521 - out_1_loss: 0.0897 - out_2_loss: 0.0624 - out_1_acc: 0.9501 - out_2_acc: 0.9642 - val_loss: 0.2166 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9506\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1502 - out_1_loss: 0.0894 - out_2_loss: 0.0608 - out_1_acc: 0.9503 - out_2_acc: 0.9641 - val_loss: 0.2193 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1055 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9507\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1483 - out_1_loss: 0.0886 - out_2_loss: 0.0598 - out_1_acc: 0.9508 - out_2_acc: 0.9647 - val_loss: 0.2212 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.1066 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1458 - out_1_loss: 0.0876 - out_2_loss: 0.0582 - out_1_acc: 0.9511 - out_2_acc: 0.9654 - val_loss: 0.2228 - val_out_1_loss: 0.1145 - val_out_2_loss: 0.1084 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9524\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1439 - out_1_loss: 0.0864 - out_2_loss: 0.0575 - out_1_acc: 0.9517 - out_2_acc: 0.9654 - val_loss: 0.2246 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.1097 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1428 - out_1_loss: 0.0857 - out_2_loss: 0.0571 - out_1_acc: 0.9522 - out_2_acc: 0.9662 - val_loss: 0.2272 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1102 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9519\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1420 - out_1_loss: 0.0853 - out_2_loss: 0.0567 - out_1_acc: 0.9521 - out_2_acc: 0.9660 - val_loss: 0.2286 - val_out_1_loss: 0.1161 - val_out_2_loss: 0.1125 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1406 - out_1_loss: 0.0846 - out_2_loss: 0.0560 - out_1_acc: 0.9525 - out_2_acc: 0.9663 - val_loss: 0.2249 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1100 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1378 - out_1_loss: 0.0836 - out_2_loss: 0.0542 - out_1_acc: 0.9530 - out_2_acc: 0.9672 - val_loss: 0.2263 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1113 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1369 - out_1_loss: 0.0823 - out_2_loss: 0.0545 - out_1_acc: 0.9538 - out_2_acc: 0.9665 - val_loss: 0.2278 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.1113 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1355 - out_1_loss: 0.0815 - out_2_loss: 0.0540 - out_1_acc: 0.9543 - out_2_acc: 0.9675 - val_loss: 0.2311 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1136 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1348 - out_1_loss: 0.0804 - out_2_loss: 0.0544 - out_1_acc: 0.9546 - out_2_acc: 0.9671 - val_loss: 0.2338 - val_out_1_loss: 0.1171 - val_out_2_loss: 0.1166 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1341 - out_1_loss: 0.0796 - out_2_loss: 0.0545 - out_1_acc: 0.9549 - out_2_acc: 0.9670 - val_loss: 0.2355 - val_out_1_loss: 0.1175 - val_out_2_loss: 0.1179 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1336 - out_1_loss: 0.0789 - out_2_loss: 0.0547 - out_1_acc: 0.9557 - out_2_acc: 0.9670 - val_loss: 0.2366 - val_out_1_loss: 0.1194 - val_out_2_loss: 0.1173 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1329 - out_1_loss: 0.0790 - out_2_loss: 0.0539 - out_1_acc: 0.9556 - out_2_acc: 0.9673 - val_loss: 0.2366 - val_out_1_loss: 0.1192 - val_out_2_loss: 0.1174 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1312 - out_1_loss: 0.0778 - out_2_loss: 0.0534 - out_1_acc: 0.9563 - out_2_acc: 0.9673 - val_loss: 0.2403 - val_out_1_loss: 0.1197 - val_out_2_loss: 0.1206 - val_out_1_acc: 0.9426 - val_out_2_acc: 0.9520\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1296 - out_1_loss: 0.0767 - out_2_loss: 0.0529 - out_1_acc: 0.9568 - out_2_acc: 0.9677 - val_loss: 0.2431 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.1223 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9512\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1290 - out_1_loss: 0.0768 - out_2_loss: 0.0522 - out_1_acc: 0.9566 - out_2_acc: 0.9678 - val_loss: 0.2435 - val_out_1_loss: 0.1208 - val_out_2_loss: 0.1227 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9514\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1285 - out_1_loss: 0.0764 - out_2_loss: 0.0521 - out_1_acc: 0.9570 - out_2_acc: 0.9679 - val_loss: 0.2475 - val_out_1_loss: 0.1229 - val_out_2_loss: 0.1246 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9511\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1277 - out_1_loss: 0.0756 - out_2_loss: 0.0521 - out_1_acc: 0.9573 - out_2_acc: 0.9679 - val_loss: 0.2473 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.1251 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9507\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1272 - out_1_loss: 0.0750 - out_2_loss: 0.0522 - out_1_acc: 0.9579 - out_2_acc: 0.9677 - val_loss: 0.2515 - val_out_1_loss: 0.1240 - val_out_2_loss: 0.1275 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9504\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1263 - out_1_loss: 0.0741 - out_2_loss: 0.0522 - out_1_acc: 0.9586 - out_2_acc: 0.9679 - val_loss: 0.2498 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1244 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1254 - out_1_loss: 0.0735 - out_2_loss: 0.0519 - out_1_acc: 0.9585 - out_2_acc: 0.9682 - val_loss: 0.2499 - val_out_1_loss: 0.1264 - val_out_2_loss: 0.1235 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9519\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1236 - out_1_loss: 0.0727 - out_2_loss: 0.0510 - out_1_acc: 0.9590 - out_2_acc: 0.9687 - val_loss: 0.2527 - val_out_1_loss: 0.1278 - val_out_2_loss: 0.1249 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9527\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1230 - out_1_loss: 0.0725 - out_2_loss: 0.0505 - out_1_acc: 0.9591 - out_2_acc: 0.9694 - val_loss: 0.2559 - val_out_1_loss: 0.1295 - val_out_2_loss: 0.1265 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9518\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1237 - out_1_loss: 0.0725 - out_2_loss: 0.0512 - out_1_acc: 0.9584 - out_2_acc: 0.9688 - val_loss: 0.2583 - val_out_1_loss: 0.1305 - val_out_2_loss: 0.1278 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9515\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1235 - out_1_loss: 0.0721 - out_2_loss: 0.0514 - out_1_acc: 0.9594 - out_2_acc: 0.9684 - val_loss: 0.2558 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1228 - out_1_loss: 0.0720 - out_2_loss: 0.0508 - out_1_acc: 0.9594 - out_2_acc: 0.9687 - val_loss: 0.2576 - val_out_1_loss: 0.1284 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9503\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1238 - out_1_loss: 0.0728 - out_2_loss: 0.0510 - out_1_acc: 0.9584 - out_2_acc: 0.9691 - val_loss: 0.2583 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9513\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1227 - out_1_loss: 0.0720 - out_2_loss: 0.0507 - out_1_acc: 0.9588 - out_2_acc: 0.9689 - val_loss: 0.2594 - val_out_1_loss: 0.1306 - val_out_2_loss: 0.1289 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1208 - out_1_loss: 0.0706 - out_2_loss: 0.0503 - out_1_acc: 0.9601 - out_2_acc: 0.9691 - val_loss: 0.2600 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1288 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1192 - out_1_loss: 0.0693 - out_2_loss: 0.0499 - out_1_acc: 0.9604 - out_2_acc: 0.9696 - val_loss: 0.2582 - val_out_1_loss: 0.1303 - val_out_2_loss: 0.1279 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1175 - out_1_loss: 0.0683 - out_2_loss: 0.0492 - out_1_acc: 0.9608 - out_2_acc: 0.9701 - val_loss: 0.2595 - val_out_1_loss: 0.1307 - val_out_2_loss: 0.1288 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9523\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1168 - out_1_loss: 0.0677 - out_2_loss: 0.0490 - out_1_acc: 0.9608 - out_2_acc: 0.9701 - val_loss: 0.2615 - val_out_1_loss: 0.1321 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9509\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1157 - out_1_loss: 0.0669 - out_2_loss: 0.0488 - out_1_acc: 0.9616 - out_2_acc: 0.9703 - val_loss: 0.2631 - val_out_1_loss: 0.1338 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9523\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1151 - out_1_loss: 0.0666 - out_2_loss: 0.0485 - out_1_acc: 0.9621 - out_2_acc: 0.9707 - val_loss: 0.2635 - val_out_1_loss: 0.1338 - val_out_2_loss: 0.1297 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1139 - out_1_loss: 0.0659 - out_2_loss: 0.0480 - out_1_acc: 0.9624 - out_2_acc: 0.9714 - val_loss: 0.2643 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1138 - out_1_loss: 0.0657 - out_2_loss: 0.0482 - out_1_acc: 0.9628 - out_2_acc: 0.9709 - val_loss: 0.2669 - val_out_1_loss: 0.1372 - val_out_2_loss: 0.1298 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9527\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1124 - out_1_loss: 0.0648 - out_2_loss: 0.0477 - out_1_acc: 0.9633 - out_2_acc: 0.9713 - val_loss: 0.2688 - val_out_1_loss: 0.1383 - val_out_2_loss: 0.1305 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1117 - out_1_loss: 0.0646 - out_2_loss: 0.0471 - out_1_acc: 0.9634 - out_2_acc: 0.9719 - val_loss: 0.2701 - val_out_1_loss: 0.1385 - val_out_2_loss: 0.1316 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1108 - out_1_loss: 0.0640 - out_2_loss: 0.0468 - out_1_acc: 0.9637 - out_2_acc: 0.9723 - val_loss: 0.2710 - val_out_1_loss: 0.1404 - val_out_2_loss: 0.1306 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1108 - out_1_loss: 0.0637 - out_2_loss: 0.0471 - out_1_acc: 0.9639 - out_2_acc: 0.9719 - val_loss: 0.2770 - val_out_1_loss: 0.1425 - val_out_2_loss: 0.1345 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1105 - out_1_loss: 0.0639 - out_2_loss: 0.0467 - out_1_acc: 0.9642 - out_2_acc: 0.9726 - val_loss: 0.2793 - val_out_1_loss: 0.1433 - val_out_2_loss: 0.1360 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9521\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1107 - out_1_loss: 0.0639 - out_2_loss: 0.0468 - out_1_acc: 0.9637 - out_2_acc: 0.9729 - val_loss: 0.2794 - val_out_1_loss: 0.1438 - val_out_2_loss: 0.1356 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1105 - out_1_loss: 0.0635 - out_2_loss: 0.0470 - out_1_acc: 0.9641 - out_2_acc: 0.9725 - val_loss: 0.2804 - val_out_1_loss: 0.1446 - val_out_2_loss: 0.1358 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1116 - out_1_loss: 0.0645 - out_2_loss: 0.0471 - out_1_acc: 0.9637 - out_2_acc: 0.9726 - val_loss: 0.2838 - val_out_1_loss: 0.1452 - val_out_2_loss: 0.1386 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1110 - out_1_loss: 0.0636 - out_2_loss: 0.0474 - out_1_acc: 0.9640 - out_2_acc: 0.9721 - val_loss: 0.2860 - val_out_1_loss: 0.1467 - val_out_2_loss: 0.1393 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9518\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1112 - out_1_loss: 0.0641 - out_2_loss: 0.0471 - out_1_acc: 0.9641 - out_2_acc: 0.9723 - val_loss: 0.2910 - val_out_1_loss: 0.1477 - val_out_2_loss: 0.1433 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1113 - out_1_loss: 0.0642 - out_2_loss: 0.0471 - out_1_acc: 0.9633 - out_2_acc: 0.9725 - val_loss: 0.2936 - val_out_1_loss: 0.1498 - val_out_2_loss: 0.1438 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1096 - out_1_loss: 0.0636 - out_2_loss: 0.0460 - out_1_acc: 0.9638 - out_2_acc: 0.9734 - val_loss: 0.2911 - val_out_1_loss: 0.1507 - val_out_2_loss: 0.1404 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1093 - out_1_loss: 0.0627 - out_2_loss: 0.0466 - out_1_acc: 0.9649 - out_2_acc: 0.9733 - val_loss: 0.2986 - val_out_1_loss: 0.1556 - val_out_2_loss: 0.1430 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9511\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1086 - out_1_loss: 0.0631 - out_2_loss: 0.0455 - out_1_acc: 0.9645 - out_2_acc: 0.9735 - val_loss: 0.2982 - val_out_1_loss: 0.1538 - val_out_2_loss: 0.1444 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1086 - out_1_loss: 0.0628 - out_2_loss: 0.0459 - out_1_acc: 0.9648 - out_2_acc: 0.9737 - val_loss: 0.2997 - val_out_1_loss: 0.1536 - val_out_2_loss: 0.1461 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9505\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1073 - out_1_loss: 0.0619 - out_2_loss: 0.0454 - out_1_acc: 0.9650 - out_2_acc: 0.9737 - val_loss: 0.2984 - val_out_1_loss: 0.1531 - val_out_2_loss: 0.1454 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1075 - out_1_loss: 0.0623 - out_2_loss: 0.0452 - out_1_acc: 0.9657 - out_2_acc: 0.9745 - val_loss: 0.3016 - val_out_1_loss: 0.1541 - val_out_2_loss: 0.1476 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1052 - out_1_loss: 0.0611 - out_2_loss: 0.0441 - out_1_acc: 0.9662 - out_2_acc: 0.9753 - val_loss: 0.3053 - val_out_1_loss: 0.1573 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9510\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1051 - out_1_loss: 0.0609 - out_2_loss: 0.0442 - out_1_acc: 0.9664 - out_2_acc: 0.9752 - val_loss: 0.3084 - val_out_1_loss: 0.1548 - val_out_2_loss: 0.1536 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9500\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1075 - out_1_loss: 0.0625 - out_2_loss: 0.0450 - out_1_acc: 0.9653 - out_2_acc: 0.9746 - val_loss: 0.3059 - val_out_1_loss: 0.1550 - val_out_2_loss: 0.1509 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1078 - out_1_loss: 0.0618 - out_2_loss: 0.0460 - out_1_acc: 0.9657 - out_2_acc: 0.9741 - val_loss: 0.3032 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1493 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9507\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1056 - out_1_loss: 0.0613 - out_2_loss: 0.0444 - out_1_acc: 0.9660 - out_2_acc: 0.9750 - val_loss: 0.3042 - val_out_1_loss: 0.1552 - val_out_2_loss: 0.1490 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9503\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1060 - out_1_loss: 0.0613 - out_2_loss: 0.0447 - out_1_acc: 0.9657 - out_2_acc: 0.9748 - val_loss: 0.3032 - val_out_1_loss: 0.1552 - val_out_2_loss: 0.1480 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1049 - out_1_loss: 0.0604 - out_2_loss: 0.0445 - out_1_acc: 0.9664 - out_2_acc: 0.9752 - val_loss: 0.3133 - val_out_1_loss: 0.1580 - val_out_2_loss: 0.1553 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1047 - out_1_loss: 0.0609 - out_2_loss: 0.0438 - out_1_acc: 0.9659 - out_2_acc: 0.9755 - val_loss: 0.3091 - val_out_1_loss: 0.1593 - val_out_2_loss: 0.1498 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1054 - out_1_loss: 0.0607 - out_2_loss: 0.0447 - out_1_acc: 0.9664 - out_2_acc: 0.9750 - val_loss: 0.3140 - val_out_1_loss: 0.1593 - val_out_2_loss: 0.1547 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1047 - out_1_loss: 0.0603 - out_2_loss: 0.0443 - out_1_acc: 0.9672 - out_2_acc: 0.9753 - val_loss: 0.3169 - val_out_1_loss: 0.1590 - val_out_2_loss: 0.1579 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1027 - out_1_loss: 0.0587 - out_2_loss: 0.0440 - out_1_acc: 0.9682 - out_2_acc: 0.9752 - val_loss: 0.3172 - val_out_1_loss: 0.1604 - val_out_2_loss: 0.1569 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9512\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1012 - out_1_loss: 0.0581 - out_2_loss: 0.0431 - out_1_acc: 0.9683 - out_2_acc: 0.9764 - val_loss: 0.3184 - val_out_1_loss: 0.1622 - val_out_2_loss: 0.1562 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9515\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1023 - out_1_loss: 0.0586 - out_2_loss: 0.0438 - out_1_acc: 0.9682 - out_2_acc: 0.9757 - val_loss: 0.3250 - val_out_1_loss: 0.1660 - val_out_2_loss: 0.1590 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9498\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1017 - out_1_loss: 0.0587 - out_2_loss: 0.0430 - out_1_acc: 0.9686 - out_2_acc: 0.9766 - val_loss: 0.3235 - val_out_1_loss: 0.1618 - val_out_2_loss: 0.1617 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9511\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1001 - out_1_loss: 0.0576 - out_2_loss: 0.0425 - out_1_acc: 0.9687 - out_2_acc: 0.9768 - val_loss: 0.3260 - val_out_1_loss: 0.1640 - val_out_2_loss: 0.1620 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9500\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0991 - out_1_loss: 0.0567 - out_2_loss: 0.0425 - out_1_acc: 0.9699 - out_2_acc: 0.9765 - val_loss: 0.3294 - val_out_1_loss: 0.1670 - val_out_2_loss: 0.1623 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9511\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0948 - out_1_loss: 0.0548 - out_2_loss: 0.0400 - out_1_acc: 0.9715 - out_2_acc: 0.9785 - val_loss: 0.3293 - val_out_1_loss: 0.1655 - val_out_2_loss: 0.1638 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9518\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0926 - out_1_loss: 0.0535 - out_2_loss: 0.0390 - out_1_acc: 0.9718 - out_2_acc: 0.9792 - val_loss: 0.3290 - val_out_1_loss: 0.1652 - val_out_2_loss: 0.1638 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0929 - out_1_loss: 0.0541 - out_2_loss: 0.0387 - out_1_acc: 0.9720 - out_2_acc: 0.9797 - val_loss: 0.3386 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1699 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9518\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0916 - out_1_loss: 0.0532 - out_2_loss: 0.0384 - out_1_acc: 0.9724 - out_2_acc: 0.9799 - val_loss: 0.3402 - val_out_1_loss: 0.1703 - val_out_2_loss: 0.1699 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9516\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0898 - out_1_loss: 0.0523 - out_2_loss: 0.0374 - out_1_acc: 0.9724 - out_2_acc: 0.9804 - val_loss: 0.3391 - val_out_1_loss: 0.1705 - val_out_2_loss: 0.1685 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9516\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0904 - out_1_loss: 0.0524 - out_2_loss: 0.0380 - out_1_acc: 0.9726 - out_2_acc: 0.9801 - val_loss: 0.3464 - val_out_1_loss: 0.1730 - val_out_2_loss: 0.1735 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9511\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0912 - out_1_loss: 0.0536 - out_2_loss: 0.0376 - out_1_acc: 0.9719 - out_2_acc: 0.9804 - val_loss: 0.3409 - val_out_1_loss: 0.1731 - val_out_2_loss: 0.1678 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9511\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0885 - out_1_loss: 0.0521 - out_2_loss: 0.0364 - out_1_acc: 0.9728 - out_2_acc: 0.9812 - val_loss: 0.3442 - val_out_1_loss: 0.1721 - val_out_2_loss: 0.1720 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9512\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0864 - out_1_loss: 0.0512 - out_2_loss: 0.0351 - out_1_acc: 0.9740 - out_2_acc: 0.9818 - val_loss: 0.3467 - val_out_1_loss: 0.1752 - val_out_2_loss: 0.1715 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0857 - out_1_loss: 0.0506 - out_2_loss: 0.0351 - out_1_acc: 0.9740 - out_2_acc: 0.9823 - val_loss: 0.3510 - val_out_1_loss: 0.1758 - val_out_2_loss: 0.1752 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0859 - out_1_loss: 0.0506 - out_2_loss: 0.0354 - out_1_acc: 0.9746 - out_2_acc: 0.9821 - val_loss: 0.3575 - val_out_1_loss: 0.1779 - val_out_2_loss: 0.1796 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9521\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0861 - out_1_loss: 0.0505 - out_2_loss: 0.0355 - out_1_acc: 0.9739 - out_2_acc: 0.9817 - val_loss: 0.3621 - val_out_1_loss: 0.1793 - val_out_2_loss: 0.1828 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9507\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0865 - out_1_loss: 0.0515 - out_2_loss: 0.0350 - out_1_acc: 0.9738 - out_2_acc: 0.9823 - val_loss: 0.3650 - val_out_1_loss: 0.1827 - val_out_2_loss: 0.1823 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0883 - out_1_loss: 0.0524 - out_2_loss: 0.0359 - out_1_acc: 0.9729 - out_2_acc: 0.9816 - val_loss: 0.3568 - val_out_1_loss: 0.1767 - val_out_2_loss: 0.1801 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0852 - out_1_loss: 0.0508 - out_2_loss: 0.0344 - out_1_acc: 0.9742 - out_2_acc: 0.9830 - val_loss: 0.3690 - val_out_1_loss: 0.1850 - val_out_2_loss: 0.1841 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9511\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0826 - out_1_loss: 0.0496 - out_2_loss: 0.0330 - out_1_acc: 0.9748 - out_2_acc: 0.9836 - val_loss: 0.3621 - val_out_1_loss: 0.1806 - val_out_2_loss: 0.1814 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0823 - out_1_loss: 0.0497 - out_2_loss: 0.0326 - out_1_acc: 0.9753 - out_2_acc: 0.9838 - val_loss: 0.3714 - val_out_1_loss: 0.1840 - val_out_2_loss: 0.1874 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9510\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0802 - out_1_loss: 0.0477 - out_2_loss: 0.0325 - out_1_acc: 0.9764 - out_2_acc: 0.9839 - val_loss: 0.3721 - val_out_1_loss: 0.1833 - val_out_2_loss: 0.1889 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0807 - out_1_loss: 0.0473 - out_2_loss: 0.0334 - out_1_acc: 0.9770 - out_2_acc: 0.9834 - val_loss: 0.3777 - val_out_1_loss: 0.1880 - val_out_2_loss: 0.1897 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9499\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0822 - out_1_loss: 0.0484 - out_2_loss: 0.0338 - out_1_acc: 0.9756 - out_2_acc: 0.9835 - val_loss: 0.3738 - val_out_1_loss: 0.1845 - val_out_2_loss: 0.1892 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9521\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0796 - out_1_loss: 0.0471 - out_2_loss: 0.0325 - out_1_acc: 0.9763 - out_2_acc: 0.9838 - val_loss: 0.3773 - val_out_1_loss: 0.1845 - val_out_2_loss: 0.1927 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9519\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0805 - out_1_loss: 0.0477 - out_2_loss: 0.0328 - out_1_acc: 0.9768 - out_2_acc: 0.9838 - val_loss: 0.3747 - val_out_1_loss: 0.1822 - val_out_2_loss: 0.1925 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9518\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0781 - out_1_loss: 0.0460 - out_2_loss: 0.0321 - out_1_acc: 0.9777 - out_2_acc: 0.9844 - val_loss: 0.3821 - val_out_1_loss: 0.1875 - val_out_2_loss: 0.1947 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9524\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0746 - out_1_loss: 0.0451 - out_2_loss: 0.0295 - out_1_acc: 0.9782 - out_2_acc: 0.9858 - val_loss: 0.3919 - val_out_1_loss: 0.1917 - val_out_2_loss: 0.2002 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0740 - out_1_loss: 0.0448 - out_2_loss: 0.0292 - out_1_acc: 0.9779 - out_2_acc: 0.9858 - val_loss: 0.3878 - val_out_1_loss: 0.1917 - val_out_2_loss: 0.1962 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9529\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0728 - out_1_loss: 0.0439 - out_2_loss: 0.0289 - out_1_acc: 0.9786 - out_2_acc: 0.9857 - val_loss: 0.3928 - val_out_1_loss: 0.1911 - val_out_2_loss: 0.2018 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9519\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0732 - out_1_loss: 0.0437 - out_2_loss: 0.0295 - out_1_acc: 0.9787 - out_2_acc: 0.9856 - val_loss: 0.3906 - val_out_1_loss: 0.1939 - val_out_2_loss: 0.1967 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9515\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0724 - out_1_loss: 0.0431 - out_2_loss: 0.0293 - out_1_acc: 0.9791 - out_2_acc: 0.9858 - val_loss: 0.3986 - val_out_1_loss: 0.1993 - val_out_2_loss: 0.1993 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9505\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0712 - out_1_loss: 0.0425 - out_2_loss: 0.0287 - out_1_acc: 0.9797 - out_2_acc: 0.9865 - val_loss: 0.4082 - val_out_1_loss: 0.2019 - val_out_2_loss: 0.2063 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9511\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0707 - out_1_loss: 0.0433 - out_2_loss: 0.0275 - out_1_acc: 0.9796 - out_2_acc: 0.9869 - val_loss: 0.4002 - val_out_1_loss: 0.1974 - val_out_2_loss: 0.2028 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9511\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0678 - out_1_loss: 0.0420 - out_2_loss: 0.0258 - out_1_acc: 0.9802 - out_2_acc: 0.9876 - val_loss: 0.4045 - val_out_1_loss: 0.1977 - val_out_2_loss: 0.2068 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9516\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0682 - out_1_loss: 0.0420 - out_2_loss: 0.0262 - out_1_acc: 0.9800 - out_2_acc: 0.9874 - val_loss: 0.4073 - val_out_1_loss: 0.1991 - val_out_2_loss: 0.2082 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0691 - out_1_loss: 0.0420 - out_2_loss: 0.0271 - out_1_acc: 0.9803 - out_2_acc: 0.9872 - val_loss: 0.4120 - val_out_1_loss: 0.2031 - val_out_2_loss: 0.2088 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9512\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0663 - out_1_loss: 0.0405 - out_2_loss: 0.0258 - out_1_acc: 0.9810 - out_2_acc: 0.9880 - val_loss: 0.4147 - val_out_1_loss: 0.2034 - val_out_2_loss: 0.2113 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9510\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0625 - out_1_loss: 0.0389 - out_2_loss: 0.0236 - out_1_acc: 0.9822 - out_2_acc: 0.9891 - val_loss: 0.4252 - val_out_1_loss: 0.2084 - val_out_2_loss: 0.2168 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9507\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0626 - out_1_loss: 0.0393 - out_2_loss: 0.0233 - out_1_acc: 0.9816 - out_2_acc: 0.9892 - val_loss: 0.4249 - val_out_1_loss: 0.2101 - val_out_2_loss: 0.2148 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9513\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0639 - out_1_loss: 0.0397 - out_2_loss: 0.0242 - out_1_acc: 0.9818 - out_2_acc: 0.9892 - val_loss: 0.4250 - val_out_1_loss: 0.2112 - val_out_2_loss: 0.2138 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9509\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0639 - out_1_loss: 0.0395 - out_2_loss: 0.0244 - out_1_acc: 0.9816 - out_2_acc: 0.9890 - val_loss: 0.4304 - val_out_1_loss: 0.2074 - val_out_2_loss: 0.2230 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9507\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0624 - out_1_loss: 0.0395 - out_2_loss: 0.0229 - out_1_acc: 0.9820 - out_2_acc: 0.9894 - val_loss: 0.4245 - val_out_1_loss: 0.2117 - val_out_2_loss: 0.2128 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9519\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0612 - out_1_loss: 0.0397 - out_2_loss: 0.0215 - out_1_acc: 0.9814 - out_2_acc: 0.9902 - val_loss: 0.4344 - val_out_1_loss: 0.2124 - val_out_2_loss: 0.2219 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9524\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0567 - out_1_loss: 0.0361 - out_2_loss: 0.0206 - out_1_acc: 0.9841 - out_2_acc: 0.9907 - val_loss: 0.4357 - val_out_1_loss: 0.2126 - val_out_2_loss: 0.2231 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9518\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0561 - out_1_loss: 0.0364 - out_2_loss: 0.0197 - out_1_acc: 0.9838 - out_2_acc: 0.9911 - val_loss: 0.4434 - val_out_1_loss: 0.2175 - val_out_2_loss: 0.2259 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0552 - out_1_loss: 0.0353 - out_2_loss: 0.0199 - out_1_acc: 0.9842 - out_2_acc: 0.9910 - val_loss: 0.4552 - val_out_1_loss: 0.2231 - val_out_2_loss: 0.2320 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9526\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0516 - out_1_loss: 0.0333 - out_2_loss: 0.0184 - out_1_acc: 0.9852 - out_2_acc: 0.9918 - val_loss: 0.4455 - val_out_1_loss: 0.2204 - val_out_2_loss: 0.2251 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9525\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0504 - out_1_loss: 0.0326 - out_2_loss: 0.0177 - out_1_acc: 0.9854 - out_2_acc: 0.9920 - val_loss: 0.4579 - val_out_1_loss: 0.2244 - val_out_2_loss: 0.2335 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9519\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0495 - out_1_loss: 0.0321 - out_2_loss: 0.0175 - out_1_acc: 0.9855 - out_2_acc: 0.9922 - val_loss: 0.4611 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2362 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9520\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0494 - out_1_loss: 0.0318 - out_2_loss: 0.0176 - out_1_acc: 0.9861 - out_2_acc: 0.9922 - val_loss: 0.4733 - val_out_1_loss: 0.2313 - val_out_2_loss: 0.2419 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9515\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0497 - out_1_loss: 0.0319 - out_2_loss: 0.0178 - out_1_acc: 0.9860 - out_2_acc: 0.9921 - val_loss: 0.4734 - val_out_1_loss: 0.2288 - val_out_2_loss: 0.2446 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0489 - out_1_loss: 0.0314 - out_2_loss: 0.0175 - out_1_acc: 0.9861 - out_2_acc: 0.9925 - val_loss: 0.4831 - val_out_1_loss: 0.2388 - val_out_2_loss: 0.2444 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0462 - out_1_loss: 0.0301 - out_2_loss: 0.0161 - out_1_acc: 0.9869 - out_2_acc: 0.9932 - val_loss: 0.4900 - val_out_1_loss: 0.2362 - val_out_2_loss: 0.2538 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9512\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0457 - out_1_loss: 0.0296 - out_2_loss: 0.0161 - out_1_acc: 0.9869 - out_2_acc: 0.9929 - val_loss: 0.4879 - val_out_1_loss: 0.2338 - val_out_2_loss: 0.2542 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9511\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0439 - out_1_loss: 0.0285 - out_2_loss: 0.0155 - out_1_acc: 0.9881 - out_2_acc: 0.9935 - val_loss: 0.4889 - val_out_1_loss: 0.2353 - val_out_2_loss: 0.2536 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9518\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0424 - out_1_loss: 0.0278 - out_2_loss: 0.0146 - out_1_acc: 0.9879 - out_2_acc: 0.9936 - val_loss: 0.5012 - val_out_1_loss: 0.2419 - val_out_2_loss: 0.2593 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9512\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(6)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4915 - out_1_loss: 0.2321 - out_2_loss: 0.2595 - out_1_acc: 0.9407 - out_2_acc: 0.9509\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 300), (No 397200      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 300)       397200      input_17[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,441,480\n",
      "Trainable params: 2,441,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3314 - out_1_loss: 3.6675 - out_2_loss: 3.6639 - out_1_acc: 0.1753 - out_2_acc: 0.1885WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108809). Check your callbacks.\n",
      "28/28 [==============================] - 3s 118ms/step - loss: 5.3252 - out_1_loss: 2.7500 - out_2_loss: 2.5752 - out_1_acc: 0.4174 - out_2_acc: 0.4460 - val_loss: 3.7535 - val_out_1_loss: 2.0315 - val_out_2_loss: 1.7220 - val_out_1_acc: 0.4967 - val_out_2_acc: 0.5553\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 2.6349 - out_1_loss: 1.6346 - out_2_loss: 1.0003 - out_1_acc: 0.5861 - out_2_acc: 0.7425 - val_loss: 1.5423 - val_out_1_loss: 1.0183 - val_out_2_loss: 0.5240 - val_out_1_acc: 0.7654 - val_out_2_acc: 0.8650\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.9722 - out_1_loss: 0.6140 - out_2_loss: 0.3582 - out_1_acc: 0.8601 - out_2_acc: 0.9093 - val_loss: 0.6174 - val_out_1_loss: 0.3748 - val_out_2_loss: 0.2426 - val_out_1_acc: 0.9141 - val_out_2_acc: 0.9367\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.4637 - out_1_loss: 0.2843 - out_2_loss: 0.1793 - out_1_acc: 0.9238 - out_2_acc: 0.9453 - val_loss: 0.3744 - val_out_1_loss: 0.2213 - val_out_2_loss: 0.1531 - val_out_1_acc: 0.9325 - val_out_2_acc: 0.9468\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.3104 - out_1_loss: 0.1851 - out_2_loss: 0.1253 - out_1_acc: 0.9357 - out_2_acc: 0.9499 - val_loss: 0.2937 - val_out_1_loss: 0.1703 - val_out_2_loss: 0.1234 - val_out_1_acc: 0.9367 - val_out_2_acc: 0.9494\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.2517 - out_1_loss: 0.1480 - out_2_loss: 0.1037 - out_1_acc: 0.9393 - out_2_acc: 0.9521 - val_loss: 0.2516 - val_out_1_loss: 0.1417 - val_out_2_loss: 0.1098 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9508\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.2228 - out_1_loss: 0.1287 - out_2_loss: 0.0940 - out_1_acc: 0.9407 - out_2_acc: 0.9536 - val_loss: 0.2307 - val_out_1_loss: 0.1283 - val_out_2_loss: 0.1023 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9513\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.2070 - out_1_loss: 0.1186 - out_2_loss: 0.0885 - out_1_acc: 0.9416 - out_2_acc: 0.9544 - val_loss: 0.2221 - val_out_1_loss: 0.1220 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9506\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1969 - out_1_loss: 0.1124 - out_2_loss: 0.0845 - out_1_acc: 0.9420 - out_2_acc: 0.9551 - val_loss: 0.2177 - val_out_1_loss: 0.1187 - val_out_2_loss: 0.0989 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9506\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1908 - out_1_loss: 0.1084 - out_2_loss: 0.0824 - out_1_acc: 0.9426 - out_2_acc: 0.9555 - val_loss: 0.2139 - val_out_1_loss: 0.1163 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9506\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1861 - out_1_loss: 0.1056 - out_2_loss: 0.0806 - out_1_acc: 0.9434 - out_2_acc: 0.9561 - val_loss: 0.2118 - val_out_1_loss: 0.1143 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9512\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1821 - out_1_loss: 0.1033 - out_2_loss: 0.0788 - out_1_acc: 0.9442 - out_2_acc: 0.9569 - val_loss: 0.2095 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.0961 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1794 - out_1_loss: 0.1016 - out_2_loss: 0.0779 - out_1_acc: 0.9442 - out_2_acc: 0.9578 - val_loss: 0.2080 - val_out_1_loss: 0.1125 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9518\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1768 - out_1_loss: 0.1005 - out_2_loss: 0.0763 - out_1_acc: 0.9445 - out_2_acc: 0.9579 - val_loss: 0.2055 - val_out_1_loss: 0.1117 - val_out_2_loss: 0.0938 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9527\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1749 - out_1_loss: 0.0992 - out_2_loss: 0.0756 - out_1_acc: 0.9452 - out_2_acc: 0.9586 - val_loss: 0.2058 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.0940 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9530\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1735 - out_1_loss: 0.0981 - out_2_loss: 0.0754 - out_1_acc: 0.9458 - out_2_acc: 0.9588 - val_loss: 0.2072 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9518\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1717 - out_1_loss: 0.0971 - out_2_loss: 0.0746 - out_1_acc: 0.9463 - out_2_acc: 0.9587 - val_loss: 0.2091 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0978 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9508\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1705 - out_1_loss: 0.0963 - out_2_loss: 0.0741 - out_1_acc: 0.9472 - out_2_acc: 0.9584 - val_loss: 0.2092 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.0968 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9507\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1684 - out_1_loss: 0.0956 - out_2_loss: 0.0728 - out_1_acc: 0.9469 - out_2_acc: 0.9593 - val_loss: 0.2131 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.0994 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1662 - out_1_loss: 0.0949 - out_2_loss: 0.0712 - out_1_acc: 0.9469 - out_2_acc: 0.9600 - val_loss: 0.2095 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9522\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1634 - out_1_loss: 0.0939 - out_2_loss: 0.0695 - out_1_acc: 0.9476 - out_2_acc: 0.9604 - val_loss: 0.2080 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9521\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1604 - out_1_loss: 0.0929 - out_2_loss: 0.0676 - out_1_acc: 0.9482 - out_2_acc: 0.9612 - val_loss: 0.2097 - val_out_1_loss: 0.1120 - val_out_2_loss: 0.0977 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1582 - out_1_loss: 0.0918 - out_2_loss: 0.0664 - out_1_acc: 0.9483 - out_2_acc: 0.9623 - val_loss: 0.2115 - val_out_1_loss: 0.1123 - val_out_2_loss: 0.0993 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9518\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1562 - out_1_loss: 0.0907 - out_2_loss: 0.0655 - out_1_acc: 0.9491 - out_2_acc: 0.9621 - val_loss: 0.2150 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1020 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1539 - out_1_loss: 0.0898 - out_2_loss: 0.0641 - out_1_acc: 0.9495 - out_2_acc: 0.9631 - val_loss: 0.2161 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9519\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1528 - out_1_loss: 0.0891 - out_2_loss: 0.0637 - out_1_acc: 0.9502 - out_2_acc: 0.9634 - val_loss: 0.2162 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1013 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9522\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1504 - out_1_loss: 0.0887 - out_2_loss: 0.0617 - out_1_acc: 0.9506 - out_2_acc: 0.9641 - val_loss: 0.2173 - val_out_1_loss: 0.1154 - val_out_2_loss: 0.1019 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1485 - out_1_loss: 0.0879 - out_2_loss: 0.0606 - out_1_acc: 0.9512 - out_2_acc: 0.9646 - val_loss: 0.2200 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.1038 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1469 - out_1_loss: 0.0875 - out_2_loss: 0.0595 - out_1_acc: 0.9515 - out_2_acc: 0.9653 - val_loss: 0.2204 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1046 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1461 - out_1_loss: 0.0868 - out_2_loss: 0.0592 - out_1_acc: 0.9519 - out_2_acc: 0.9657 - val_loss: 0.2219 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.1058 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9512\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1449 - out_1_loss: 0.0861 - out_2_loss: 0.0588 - out_1_acc: 0.9518 - out_2_acc: 0.9654 - val_loss: 0.2223 - val_out_1_loss: 0.1158 - val_out_2_loss: 0.1065 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9510\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1437 - out_1_loss: 0.0851 - out_2_loss: 0.0586 - out_1_acc: 0.9526 - out_2_acc: 0.9656 - val_loss: 0.2268 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1098 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9516\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1424 - out_1_loss: 0.0847 - out_2_loss: 0.0577 - out_1_acc: 0.9528 - out_2_acc: 0.9657 - val_loss: 0.2294 - val_out_1_loss: 0.1185 - val_out_2_loss: 0.1109 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9507\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1417 - out_1_loss: 0.0846 - out_2_loss: 0.0571 - out_1_acc: 0.9532 - out_2_acc: 0.9661 - val_loss: 0.2329 - val_out_1_loss: 0.1187 - val_out_2_loss: 0.1142 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9521\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1420 - out_1_loss: 0.0845 - out_2_loss: 0.0574 - out_1_acc: 0.9529 - out_2_acc: 0.9656 - val_loss: 0.2330 - val_out_1_loss: 0.1200 - val_out_2_loss: 0.1131 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9524\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1422 - out_1_loss: 0.0845 - out_2_loss: 0.0577 - out_1_acc: 0.9529 - out_2_acc: 0.9660 - val_loss: 0.2328 - val_out_1_loss: 0.1195 - val_out_2_loss: 0.1134 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1430 - out_1_loss: 0.0854 - out_2_loss: 0.0575 - out_1_acc: 0.9520 - out_2_acc: 0.9656 - val_loss: 0.2349 - val_out_1_loss: 0.1225 - val_out_2_loss: 0.1124 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9522\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1422 - out_1_loss: 0.0850 - out_2_loss: 0.0572 - out_1_acc: 0.9518 - out_2_acc: 0.9657 - val_loss: 0.2408 - val_out_1_loss: 0.1250 - val_out_2_loss: 0.1158 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9530\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1399 - out_1_loss: 0.0838 - out_2_loss: 0.0562 - out_1_acc: 0.9527 - out_2_acc: 0.9668 - val_loss: 0.2376 - val_out_1_loss: 0.1236 - val_out_2_loss: 0.1140 - val_out_1_acc: 0.9372 - val_out_2_acc: 0.9527\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1368 - out_1_loss: 0.0825 - out_2_loss: 0.0542 - out_1_acc: 0.9527 - out_2_acc: 0.9670 - val_loss: 0.2368 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1157 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9520\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1345 - out_1_loss: 0.0808 - out_2_loss: 0.0538 - out_1_acc: 0.9539 - out_2_acc: 0.9671 - val_loss: 0.2428 - val_out_1_loss: 0.1224 - val_out_2_loss: 0.1203 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9519\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1333 - out_1_loss: 0.0799 - out_2_loss: 0.0534 - out_1_acc: 0.9546 - out_2_acc: 0.9672 - val_loss: 0.2408 - val_out_1_loss: 0.1220 - val_out_2_loss: 0.1188 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1324 - out_1_loss: 0.0793 - out_2_loss: 0.0531 - out_1_acc: 0.9548 - out_2_acc: 0.9678 - val_loss: 0.2434 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1211 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1314 - out_1_loss: 0.0783 - out_2_loss: 0.0531 - out_1_acc: 0.9550 - out_2_acc: 0.9681 - val_loss: 0.2436 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.1226 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1295 - out_1_loss: 0.0766 - out_2_loss: 0.0529 - out_1_acc: 0.9563 - out_2_acc: 0.9681 - val_loss: 0.2426 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1212 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1276 - out_1_loss: 0.0751 - out_2_loss: 0.0525 - out_1_acc: 0.9572 - out_2_acc: 0.9684 - val_loss: 0.2446 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.1228 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9523\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1264 - out_1_loss: 0.0743 - out_2_loss: 0.0521 - out_1_acc: 0.9575 - out_2_acc: 0.9684 - val_loss: 0.2477 - val_out_1_loss: 0.1235 - val_out_2_loss: 0.1242 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9519\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1258 - out_1_loss: 0.0735 - out_2_loss: 0.0522 - out_1_acc: 0.9581 - out_2_acc: 0.9679 - val_loss: 0.2496 - val_out_1_loss: 0.1243 - val_out_2_loss: 0.1253 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9527\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1242 - out_1_loss: 0.0724 - out_2_loss: 0.0518 - out_1_acc: 0.9588 - out_2_acc: 0.9683 - val_loss: 0.2517 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1261 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9529\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1238 - out_1_loss: 0.0721 - out_2_loss: 0.0518 - out_1_acc: 0.9587 - out_2_acc: 0.9686 - val_loss: 0.2523 - val_out_1_loss: 0.1278 - val_out_2_loss: 0.1246 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9534\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1224 - out_1_loss: 0.0714 - out_2_loss: 0.0510 - out_1_acc: 0.9594 - out_2_acc: 0.9687 - val_loss: 0.2547 - val_out_1_loss: 0.1297 - val_out_2_loss: 0.1250 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1213 - out_1_loss: 0.0709 - out_2_loss: 0.0504 - out_1_acc: 0.9598 - out_2_acc: 0.9692 - val_loss: 0.2554 - val_out_1_loss: 0.1291 - val_out_2_loss: 0.1262 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1199 - out_1_loss: 0.0703 - out_2_loss: 0.0496 - out_1_acc: 0.9598 - out_2_acc: 0.9698 - val_loss: 0.2539 - val_out_1_loss: 0.1279 - val_out_2_loss: 0.1260 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9524\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1200 - out_1_loss: 0.0698 - out_2_loss: 0.0502 - out_1_acc: 0.9605 - out_2_acc: 0.9693 - val_loss: 0.2564 - val_out_1_loss: 0.1300 - val_out_2_loss: 0.1264 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1182 - out_1_loss: 0.0687 - out_2_loss: 0.0495 - out_1_acc: 0.9613 - out_2_acc: 0.9699 - val_loss: 0.2597 - val_out_1_loss: 0.1311 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9525\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1178 - out_1_loss: 0.0685 - out_2_loss: 0.0493 - out_1_acc: 0.9611 - out_2_acc: 0.9700 - val_loss: 0.2587 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1275 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9525\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1168 - out_1_loss: 0.0680 - out_2_loss: 0.0489 - out_1_acc: 0.9606 - out_2_acc: 0.9704 - val_loss: 0.2635 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1293 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1171 - out_1_loss: 0.0678 - out_2_loss: 0.0493 - out_1_acc: 0.9611 - out_2_acc: 0.9703 - val_loss: 0.2671 - val_out_1_loss: 0.1362 - val_out_2_loss: 0.1309 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9518\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1152 - out_1_loss: 0.0665 - out_2_loss: 0.0487 - out_1_acc: 0.9621 - out_2_acc: 0.9712 - val_loss: 0.2631 - val_out_1_loss: 0.1354 - val_out_2_loss: 0.1276 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1151 - out_1_loss: 0.0665 - out_2_loss: 0.0486 - out_1_acc: 0.9623 - out_2_acc: 0.9708 - val_loss: 0.2688 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1289 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1145 - out_1_loss: 0.0661 - out_2_loss: 0.0484 - out_1_acc: 0.9626 - out_2_acc: 0.9713 - val_loss: 0.2704 - val_out_1_loss: 0.1401 - val_out_2_loss: 0.1303 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1141 - out_1_loss: 0.0659 - out_2_loss: 0.0483 - out_1_acc: 0.9625 - out_2_acc: 0.9715 - val_loss: 0.2709 - val_out_1_loss: 0.1394 - val_out_2_loss: 0.1315 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1135 - out_1_loss: 0.0654 - out_2_loss: 0.0481 - out_1_acc: 0.9629 - out_2_acc: 0.9721 - val_loss: 0.2748 - val_out_1_loss: 0.1416 - val_out_2_loss: 0.1332 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9526\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1139 - out_1_loss: 0.0656 - out_2_loss: 0.0483 - out_1_acc: 0.9623 - out_2_acc: 0.9713 - val_loss: 0.2742 - val_out_1_loss: 0.1431 - val_out_2_loss: 0.1311 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9535\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1127 - out_1_loss: 0.0648 - out_2_loss: 0.0479 - out_1_acc: 0.9630 - out_2_acc: 0.9720 - val_loss: 0.2783 - val_out_1_loss: 0.1455 - val_out_2_loss: 0.1328 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9533\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1121 - out_1_loss: 0.0642 - out_2_loss: 0.0479 - out_1_acc: 0.9635 - out_2_acc: 0.9713 - val_loss: 0.2792 - val_out_1_loss: 0.1457 - val_out_2_loss: 0.1335 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9528\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1122 - out_1_loss: 0.0643 - out_2_loss: 0.0478 - out_1_acc: 0.9638 - out_2_acc: 0.9719 - val_loss: 0.2821 - val_out_1_loss: 0.1476 - val_out_2_loss: 0.1345 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9531\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1112 - out_1_loss: 0.0641 - out_2_loss: 0.0470 - out_1_acc: 0.9640 - out_2_acc: 0.9721 - val_loss: 0.2844 - val_out_1_loss: 0.1482 - val_out_2_loss: 0.1363 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9524\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1114 - out_1_loss: 0.0642 - out_2_loss: 0.0472 - out_1_acc: 0.9637 - out_2_acc: 0.9725 - val_loss: 0.2872 - val_out_1_loss: 0.1504 - val_out_2_loss: 0.1369 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9525\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1103 - out_1_loss: 0.0636 - out_2_loss: 0.0466 - out_1_acc: 0.9644 - out_2_acc: 0.9729 - val_loss: 0.2854 - val_out_1_loss: 0.1508 - val_out_2_loss: 0.1346 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9536\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1110 - out_1_loss: 0.0643 - out_2_loss: 0.0467 - out_1_acc: 0.9642 - out_2_acc: 0.9730 - val_loss: 0.2897 - val_out_1_loss: 0.1525 - val_out_2_loss: 0.1372 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9528\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1100 - out_1_loss: 0.0640 - out_2_loss: 0.0459 - out_1_acc: 0.9642 - out_2_acc: 0.9736 - val_loss: 0.2940 - val_out_1_loss: 0.1539 - val_out_2_loss: 0.1401 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9531\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1105 - out_1_loss: 0.0642 - out_2_loss: 0.0463 - out_1_acc: 0.9643 - out_2_acc: 0.9732 - val_loss: 0.2987 - val_out_1_loss: 0.1556 - val_out_2_loss: 0.1431 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9528\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1141 - out_1_loss: 0.0651 - out_2_loss: 0.0489 - out_1_acc: 0.9634 - out_2_acc: 0.9720 - val_loss: 0.2980 - val_out_1_loss: 0.1554 - val_out_2_loss: 0.1427 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9530\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1118 - out_1_loss: 0.0640 - out_2_loss: 0.0478 - out_1_acc: 0.9639 - out_2_acc: 0.9726 - val_loss: 0.2993 - val_out_1_loss: 0.1557 - val_out_2_loss: 0.1436 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9530\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1105 - out_1_loss: 0.0631 - out_2_loss: 0.0473 - out_1_acc: 0.9642 - out_2_acc: 0.9726 - val_loss: 0.2997 - val_out_1_loss: 0.1558 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9529\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1081 - out_1_loss: 0.0625 - out_2_loss: 0.0456 - out_1_acc: 0.9647 - out_2_acc: 0.9739 - val_loss: 0.3038 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1456 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1075 - out_1_loss: 0.0625 - out_2_loss: 0.0450 - out_1_acc: 0.9652 - out_2_acc: 0.9743 - val_loss: 0.3062 - val_out_1_loss: 0.1603 - val_out_2_loss: 0.1459 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1071 - out_1_loss: 0.0618 - out_2_loss: 0.0453 - out_1_acc: 0.9657 - out_2_acc: 0.9744 - val_loss: 0.3066 - val_out_1_loss: 0.1613 - val_out_2_loss: 0.1452 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9527\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1061 - out_1_loss: 0.0613 - out_2_loss: 0.0447 - out_1_acc: 0.9663 - out_2_acc: 0.9748 - val_loss: 0.3046 - val_out_1_loss: 0.1594 - val_out_2_loss: 0.1452 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9532\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1058 - out_1_loss: 0.0616 - out_2_loss: 0.0443 - out_1_acc: 0.9660 - out_2_acc: 0.9759 - val_loss: 0.3008 - val_out_1_loss: 0.1577 - val_out_2_loss: 0.1431 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9533\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1053 - out_1_loss: 0.0617 - out_2_loss: 0.0437 - out_1_acc: 0.9658 - out_2_acc: 0.9756 - val_loss: 0.3047 - val_out_1_loss: 0.1596 - val_out_2_loss: 0.1451 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9524\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1052 - out_1_loss: 0.0620 - out_2_loss: 0.0432 - out_1_acc: 0.9657 - out_2_acc: 0.9760 - val_loss: 0.3110 - val_out_1_loss: 0.1625 - val_out_2_loss: 0.1485 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9540\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1054 - out_1_loss: 0.0627 - out_2_loss: 0.0427 - out_1_acc: 0.9660 - out_2_acc: 0.9759 - val_loss: 0.3241 - val_out_1_loss: 0.1702 - val_out_2_loss: 0.1539 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9527\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1063 - out_1_loss: 0.0628 - out_2_loss: 0.0435 - out_1_acc: 0.9655 - out_2_acc: 0.9760 - val_loss: 0.3219 - val_out_1_loss: 0.1653 - val_out_2_loss: 0.1566 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1046 - out_1_loss: 0.0603 - out_2_loss: 0.0443 - out_1_acc: 0.9668 - out_2_acc: 0.9759 - val_loss: 0.3209 - val_out_1_loss: 0.1657 - val_out_2_loss: 0.1553 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9528\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1020 - out_1_loss: 0.0587 - out_2_loss: 0.0433 - out_1_acc: 0.9678 - out_2_acc: 0.9761 - val_loss: 0.3230 - val_out_1_loss: 0.1678 - val_out_2_loss: 0.1552 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9533\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1026 - out_1_loss: 0.0591 - out_2_loss: 0.0435 - out_1_acc: 0.9672 - out_2_acc: 0.9759 - val_loss: 0.3233 - val_out_1_loss: 0.1671 - val_out_2_loss: 0.1562 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9530\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1016 - out_1_loss: 0.0587 - out_2_loss: 0.0429 - out_1_acc: 0.9678 - out_2_acc: 0.9763 - val_loss: 0.3253 - val_out_1_loss: 0.1684 - val_out_2_loss: 0.1569 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9529\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0999 - out_1_loss: 0.0578 - out_2_loss: 0.0421 - out_1_acc: 0.9690 - out_2_acc: 0.9769 - val_loss: 0.3193 - val_out_1_loss: 0.1647 - val_out_2_loss: 0.1546 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0975 - out_1_loss: 0.0563 - out_2_loss: 0.0411 - out_1_acc: 0.9700 - out_2_acc: 0.9772 - val_loss: 0.3243 - val_out_1_loss: 0.1680 - val_out_2_loss: 0.1563 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9519\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0955 - out_1_loss: 0.0558 - out_2_loss: 0.0397 - out_1_acc: 0.9702 - out_2_acc: 0.9786 - val_loss: 0.3238 - val_out_1_loss: 0.1660 - val_out_2_loss: 0.1578 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9525\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0960 - out_1_loss: 0.0562 - out_2_loss: 0.0398 - out_1_acc: 0.9700 - out_2_acc: 0.9784 - val_loss: 0.3267 - val_out_1_loss: 0.1681 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0966 - out_1_loss: 0.0564 - out_2_loss: 0.0402 - out_1_acc: 0.9698 - out_2_acc: 0.9784 - val_loss: 0.3310 - val_out_1_loss: 0.1686 - val_out_2_loss: 0.1623 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9529\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0962 - out_1_loss: 0.0560 - out_2_loss: 0.0402 - out_1_acc: 0.9703 - out_2_acc: 0.9784 - val_loss: 0.3320 - val_out_1_loss: 0.1713 - val_out_2_loss: 0.1608 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0954 - out_1_loss: 0.0560 - out_2_loss: 0.0393 - out_1_acc: 0.9702 - out_2_acc: 0.9789 - val_loss: 0.3343 - val_out_1_loss: 0.1735 - val_out_2_loss: 0.1608 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9528\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0940 - out_1_loss: 0.0551 - out_2_loss: 0.0389 - out_1_acc: 0.9709 - out_2_acc: 0.9794 - val_loss: 0.3348 - val_out_1_loss: 0.1707 - val_out_2_loss: 0.1641 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9512\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0925 - out_1_loss: 0.0546 - out_2_loss: 0.0379 - out_1_acc: 0.9715 - out_2_acc: 0.9804 - val_loss: 0.3459 - val_out_1_loss: 0.1752 - val_out_2_loss: 0.1706 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9531\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0933 - out_1_loss: 0.0549 - out_2_loss: 0.0384 - out_1_acc: 0.9713 - out_2_acc: 0.9798 - val_loss: 0.3448 - val_out_1_loss: 0.1737 - val_out_2_loss: 0.1711 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9505\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0916 - out_1_loss: 0.0531 - out_2_loss: 0.0385 - out_1_acc: 0.9724 - out_2_acc: 0.9795 - val_loss: 0.3373 - val_out_1_loss: 0.1733 - val_out_2_loss: 0.1641 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9526\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0906 - out_1_loss: 0.0529 - out_2_loss: 0.0376 - out_1_acc: 0.9727 - out_2_acc: 0.9803 - val_loss: 0.3494 - val_out_1_loss: 0.1776 - val_out_2_loss: 0.1718 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9532\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0893 - out_1_loss: 0.0517 - out_2_loss: 0.0375 - out_1_acc: 0.9732 - out_2_acc: 0.9807 - val_loss: 0.3488 - val_out_1_loss: 0.1775 - val_out_2_loss: 0.1712 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0898 - out_1_loss: 0.0522 - out_2_loss: 0.0375 - out_1_acc: 0.9733 - out_2_acc: 0.9807 - val_loss: 0.3520 - val_out_1_loss: 0.1782 - val_out_2_loss: 0.1737 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0868 - out_1_loss: 0.0507 - out_2_loss: 0.0361 - out_1_acc: 0.9739 - out_2_acc: 0.9816 - val_loss: 0.3579 - val_out_1_loss: 0.1780 - val_out_2_loss: 0.1800 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9525\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0853 - out_1_loss: 0.0499 - out_2_loss: 0.0354 - out_1_acc: 0.9745 - out_2_acc: 0.9822 - val_loss: 0.3502 - val_out_1_loss: 0.1765 - val_out_2_loss: 0.1738 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9532\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0867 - out_1_loss: 0.0504 - out_2_loss: 0.0362 - out_1_acc: 0.9744 - out_2_acc: 0.9816 - val_loss: 0.3576 - val_out_1_loss: 0.1785 - val_out_2_loss: 0.1791 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0853 - out_1_loss: 0.0499 - out_2_loss: 0.0355 - out_1_acc: 0.9746 - out_2_acc: 0.9822 - val_loss: 0.3626 - val_out_1_loss: 0.1821 - val_out_2_loss: 0.1805 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0839 - out_1_loss: 0.0498 - out_2_loss: 0.0341 - out_1_acc: 0.9748 - out_2_acc: 0.9828 - val_loss: 0.3667 - val_out_1_loss: 0.1838 - val_out_2_loss: 0.1828 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9510\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0828 - out_1_loss: 0.0489 - out_2_loss: 0.0339 - out_1_acc: 0.9753 - out_2_acc: 0.9831 - val_loss: 0.3668 - val_out_1_loss: 0.1847 - val_out_2_loss: 0.1821 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0807 - out_1_loss: 0.0482 - out_2_loss: 0.0325 - out_1_acc: 0.9758 - out_2_acc: 0.9839 - val_loss: 0.3691 - val_out_1_loss: 0.1840 - val_out_2_loss: 0.1851 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0796 - out_1_loss: 0.0477 - out_2_loss: 0.0320 - out_1_acc: 0.9761 - out_2_acc: 0.9843 - val_loss: 0.3711 - val_out_1_loss: 0.1886 - val_out_2_loss: 0.1825 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0790 - out_1_loss: 0.0479 - out_2_loss: 0.0311 - out_1_acc: 0.9760 - out_2_acc: 0.9845 - val_loss: 0.3743 - val_out_1_loss: 0.1882 - val_out_2_loss: 0.1860 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9523\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0809 - out_1_loss: 0.0483 - out_2_loss: 0.0326 - out_1_acc: 0.9760 - out_2_acc: 0.9840 - val_loss: 0.3684 - val_out_1_loss: 0.1858 - val_out_2_loss: 0.1826 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9531\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0801 - out_1_loss: 0.0479 - out_2_loss: 0.0322 - out_1_acc: 0.9763 - out_2_acc: 0.9845 - val_loss: 0.3729 - val_out_1_loss: 0.1862 - val_out_2_loss: 0.1867 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0757 - out_1_loss: 0.0461 - out_2_loss: 0.0296 - out_1_acc: 0.9770 - out_2_acc: 0.9855 - val_loss: 0.3785 - val_out_1_loss: 0.1876 - val_out_2_loss: 0.1909 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9520\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0730 - out_1_loss: 0.0445 - out_2_loss: 0.0285 - out_1_acc: 0.9784 - out_2_acc: 0.9864 - val_loss: 0.3820 - val_out_1_loss: 0.1882 - val_out_2_loss: 0.1938 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9527\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0724 - out_1_loss: 0.0441 - out_2_loss: 0.0283 - out_1_acc: 0.9785 - out_2_acc: 0.9867 - val_loss: 0.3832 - val_out_1_loss: 0.1926 - val_out_2_loss: 0.1906 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9526\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0738 - out_1_loss: 0.0452 - out_2_loss: 0.0286 - out_1_acc: 0.9779 - out_2_acc: 0.9863 - val_loss: 0.3936 - val_out_1_loss: 0.1953 - val_out_2_loss: 0.1983 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9520\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0744 - out_1_loss: 0.0453 - out_2_loss: 0.0291 - out_1_acc: 0.9781 - out_2_acc: 0.9860 - val_loss: 0.3970 - val_out_1_loss: 0.1966 - val_out_2_loss: 0.2004 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9516\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0749 - out_1_loss: 0.0446 - out_2_loss: 0.0303 - out_1_acc: 0.9786 - out_2_acc: 0.9852 - val_loss: 0.3880 - val_out_1_loss: 0.1945 - val_out_2_loss: 0.1935 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9519\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0767 - out_1_loss: 0.0459 - out_2_loss: 0.0308 - out_1_acc: 0.9778 - out_2_acc: 0.9853 - val_loss: 0.4002 - val_out_1_loss: 0.1994 - val_out_2_loss: 0.2007 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9524\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0758 - out_1_loss: 0.0454 - out_2_loss: 0.0305 - out_1_acc: 0.9777 - out_2_acc: 0.9853 - val_loss: 0.3942 - val_out_1_loss: 0.1972 - val_out_2_loss: 0.1969 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9528\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0730 - out_1_loss: 0.0435 - out_2_loss: 0.0295 - out_1_acc: 0.9790 - out_2_acc: 0.9863 - val_loss: 0.3942 - val_out_1_loss: 0.1970 - val_out_2_loss: 0.1972 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0685 - out_1_loss: 0.0419 - out_2_loss: 0.0267 - out_1_acc: 0.9802 - out_2_acc: 0.9875 - val_loss: 0.4082 - val_out_1_loss: 0.2013 - val_out_2_loss: 0.2069 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0706 - out_1_loss: 0.0424 - out_2_loss: 0.0282 - out_1_acc: 0.9796 - out_2_acc: 0.9867 - val_loss: 0.4092 - val_out_1_loss: 0.2014 - val_out_2_loss: 0.2078 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0669 - out_1_loss: 0.0409 - out_2_loss: 0.0260 - out_1_acc: 0.9805 - out_2_acc: 0.9878 - val_loss: 0.4130 - val_out_1_loss: 0.2064 - val_out_2_loss: 0.2066 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9515\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0673 - out_1_loss: 0.0417 - out_2_loss: 0.0255 - out_1_acc: 0.9803 - out_2_acc: 0.9882 - val_loss: 0.4250 - val_out_1_loss: 0.2099 - val_out_2_loss: 0.2151 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9518\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0659 - out_1_loss: 0.0412 - out_2_loss: 0.0247 - out_1_acc: 0.9808 - out_2_acc: 0.9888 - val_loss: 0.4249 - val_out_1_loss: 0.2092 - val_out_2_loss: 0.2157 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0668 - out_1_loss: 0.0417 - out_2_loss: 0.0251 - out_1_acc: 0.9806 - out_2_acc: 0.9885 - val_loss: 0.4250 - val_out_1_loss: 0.2084 - val_out_2_loss: 0.2167 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0656 - out_1_loss: 0.0410 - out_2_loss: 0.0246 - out_1_acc: 0.9807 - out_2_acc: 0.9890 - val_loss: 0.4202 - val_out_1_loss: 0.2075 - val_out_2_loss: 0.2126 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9516\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0633 - out_1_loss: 0.0398 - out_2_loss: 0.0235 - out_1_acc: 0.9810 - out_2_acc: 0.9893 - val_loss: 0.4346 - val_out_1_loss: 0.2134 - val_out_2_loss: 0.2212 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9509\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0658 - out_1_loss: 0.0406 - out_2_loss: 0.0251 - out_1_acc: 0.9812 - out_2_acc: 0.9883 - val_loss: 0.4293 - val_out_1_loss: 0.2137 - val_out_2_loss: 0.2156 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0669 - out_1_loss: 0.0425 - out_2_loss: 0.0244 - out_1_acc: 0.9807 - out_2_acc: 0.9887 - val_loss: 0.4339 - val_out_1_loss: 0.2139 - val_out_2_loss: 0.2199 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0661 - out_1_loss: 0.0408 - out_2_loss: 0.0252 - out_1_acc: 0.9809 - out_2_acc: 0.9883 - val_loss: 0.4398 - val_out_1_loss: 0.2152 - val_out_2_loss: 0.2246 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0610 - out_1_loss: 0.0385 - out_2_loss: 0.0225 - out_1_acc: 0.9822 - out_2_acc: 0.9896 - val_loss: 0.4423 - val_out_1_loss: 0.2199 - val_out_2_loss: 0.2224 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9507\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0582 - out_1_loss: 0.0374 - out_2_loss: 0.0207 - out_1_acc: 0.9830 - out_2_acc: 0.9906 - val_loss: 0.4386 - val_out_1_loss: 0.2163 - val_out_2_loss: 0.2223 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0570 - out_1_loss: 0.0363 - out_2_loss: 0.0207 - out_1_acc: 0.9834 - out_2_acc: 0.9908 - val_loss: 0.4381 - val_out_1_loss: 0.2175 - val_out_2_loss: 0.2206 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0553 - out_1_loss: 0.0352 - out_2_loss: 0.0201 - out_1_acc: 0.9839 - out_2_acc: 0.9909 - val_loss: 0.4492 - val_out_1_loss: 0.2198 - val_out_2_loss: 0.2294 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9524\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0560 - out_1_loss: 0.0355 - out_2_loss: 0.0204 - out_1_acc: 0.9837 - out_2_acc: 0.9906 - val_loss: 0.4565 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2318 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9537\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0562 - out_1_loss: 0.0356 - out_2_loss: 0.0206 - out_1_acc: 0.9837 - out_2_acc: 0.9903 - val_loss: 0.4531 - val_out_1_loss: 0.2239 - val_out_2_loss: 0.2292 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9521\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0536 - out_1_loss: 0.0342 - out_2_loss: 0.0194 - out_1_acc: 0.9845 - out_2_acc: 0.9914 - val_loss: 0.4618 - val_out_1_loss: 0.2294 - val_out_2_loss: 0.2324 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9525\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0545 - out_1_loss: 0.0347 - out_2_loss: 0.0198 - out_1_acc: 0.9842 - out_2_acc: 0.9911 - val_loss: 0.4716 - val_out_1_loss: 0.2346 - val_out_2_loss: 0.2370 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9510\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0513 - out_1_loss: 0.0331 - out_2_loss: 0.0182 - out_1_acc: 0.9854 - out_2_acc: 0.9920 - val_loss: 0.4720 - val_out_1_loss: 0.2310 - val_out_2_loss: 0.2409 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9530\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0518 - out_1_loss: 0.0329 - out_2_loss: 0.0189 - out_1_acc: 0.9851 - out_2_acc: 0.9917 - val_loss: 0.4754 - val_out_1_loss: 0.2328 - val_out_2_loss: 0.2426 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0501 - out_1_loss: 0.0314 - out_2_loss: 0.0188 - out_1_acc: 0.9860 - out_2_acc: 0.9917 - val_loss: 0.4821 - val_out_1_loss: 0.2394 - val_out_2_loss: 0.2427 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0493 - out_1_loss: 0.0314 - out_2_loss: 0.0179 - out_1_acc: 0.9862 - out_2_acc: 0.9921 - val_loss: 0.4754 - val_out_1_loss: 0.2361 - val_out_2_loss: 0.2393 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9528\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0481 - out_1_loss: 0.0312 - out_2_loss: 0.0169 - out_1_acc: 0.9866 - out_2_acc: 0.9928 - val_loss: 0.4865 - val_out_1_loss: 0.2381 - val_out_2_loss: 0.2485 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9516\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0499 - out_1_loss: 0.0311 - out_2_loss: 0.0188 - out_1_acc: 0.9867 - out_2_acc: 0.9918 - val_loss: 0.4971 - val_out_1_loss: 0.2452 - val_out_2_loss: 0.2518 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0501 - out_1_loss: 0.0311 - out_2_loss: 0.0190 - out_1_acc: 0.9862 - out_2_acc: 0.9919 - val_loss: 0.4885 - val_out_1_loss: 0.2414 - val_out_2_loss: 0.2471 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0468 - out_1_loss: 0.0294 - out_2_loss: 0.0174 - out_1_acc: 0.9874 - out_2_acc: 0.9923 - val_loss: 0.4847 - val_out_1_loss: 0.2393 - val_out_2_loss: 0.2454 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9537\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0442 - out_1_loss: 0.0284 - out_2_loss: 0.0159 - out_1_acc: 0.9876 - out_2_acc: 0.9931 - val_loss: 0.4924 - val_out_1_loss: 0.2448 - val_out_2_loss: 0.2476 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0437 - out_1_loss: 0.0286 - out_2_loss: 0.0151 - out_1_acc: 0.9875 - out_2_acc: 0.9939 - val_loss: 0.5060 - val_out_1_loss: 0.2452 - val_out_2_loss: 0.2608 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9527\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0454 - out_1_loss: 0.0288 - out_2_loss: 0.0165 - out_1_acc: 0.9880 - out_2_acc: 0.9926 - val_loss: 0.5085 - val_out_1_loss: 0.2527 - val_out_2_loss: 0.2558 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9528\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0444 - out_1_loss: 0.0281 - out_2_loss: 0.0163 - out_1_acc: 0.9881 - out_2_acc: 0.9932 - val_loss: 0.5050 - val_out_1_loss: 0.2549 - val_out_2_loss: 0.2501 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9532\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0436 - out_1_loss: 0.0293 - out_2_loss: 0.0143 - out_1_acc: 0.9878 - out_2_acc: 0.9941 - val_loss: 0.5145 - val_out_1_loss: 0.2552 - val_out_2_loss: 0.2593 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9532\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0418 - out_1_loss: 0.0282 - out_2_loss: 0.0136 - out_1_acc: 0.9880 - out_2_acc: 0.9945 - val_loss: 0.5157 - val_out_1_loss: 0.2599 - val_out_2_loss: 0.2557 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9532\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0425 - out_1_loss: 0.0289 - out_2_loss: 0.0136 - out_1_acc: 0.9877 - out_2_acc: 0.9944 - val_loss: 0.5164 - val_out_1_loss: 0.2549 - val_out_2_loss: 0.2615 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9536\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0383 - out_1_loss: 0.0259 - out_2_loss: 0.0124 - out_1_acc: 0.9893 - out_2_acc: 0.9953 - val_loss: 0.5243 - val_out_1_loss: 0.2609 - val_out_2_loss: 0.2634 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0384 - out_1_loss: 0.0255 - out_2_loss: 0.0129 - out_1_acc: 0.9892 - out_2_acc: 0.9947 - val_loss: 0.5156 - val_out_1_loss: 0.2579 - val_out_2_loss: 0.2577 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0352 - out_1_loss: 0.0244 - out_2_loss: 0.0107 - out_1_acc: 0.9899 - out_2_acc: 0.9957 - val_loss: 0.5225 - val_out_1_loss: 0.2594 - val_out_2_loss: 0.2631 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9522\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0342 - out_1_loss: 0.0242 - out_2_loss: 0.0100 - out_1_acc: 0.9903 - out_2_acc: 0.9961 - val_loss: 0.5415 - val_out_1_loss: 0.2654 - val_out_2_loss: 0.2761 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9517\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0316 - out_1_loss: 0.0221 - out_2_loss: 0.0095 - out_1_acc: 0.9912 - out_2_acc: 0.9962 - val_loss: 0.5459 - val_out_1_loss: 0.2667 - val_out_2_loss: 0.2792 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9533\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0332 - out_1_loss: 0.0225 - out_2_loss: 0.0107 - out_1_acc: 0.9909 - out_2_acc: 0.9958 - val_loss: 0.5437 - val_out_1_loss: 0.2713 - val_out_2_loss: 0.2724 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9525\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.0321 - out_1_loss: 0.0228 - out_2_loss: 0.0094 - out_1_acc: 0.9910 - out_2_acc: 0.9962 - val_loss: 0.5457 - val_out_1_loss: 0.2703 - val_out_2_loss: 0.2754 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0305 - out_1_loss: 0.0216 - out_2_loss: 0.0090 - out_1_acc: 0.9913 - out_2_acc: 0.9962 - val_loss: 0.5582 - val_out_1_loss: 0.2769 - val_out_2_loss: 0.2813 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9522\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0302 - out_1_loss: 0.0209 - out_2_loss: 0.0093 - out_1_acc: 0.9918 - out_2_acc: 0.9963 - val_loss: 0.5655 - val_out_1_loss: 0.2827 - val_out_2_loss: 0.2828 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9529\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0306 - out_1_loss: 0.0211 - out_2_loss: 0.0095 - out_1_acc: 0.9917 - out_2_acc: 0.9964 - val_loss: 0.5646 - val_out_1_loss: 0.2809 - val_out_2_loss: 0.2837 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0296 - out_1_loss: 0.0212 - out_2_loss: 0.0084 - out_1_acc: 0.9916 - out_2_acc: 0.9967 - val_loss: 0.5606 - val_out_1_loss: 0.2785 - val_out_2_loss: 0.2821 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9539\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0298 - out_1_loss: 0.0207 - out_2_loss: 0.0091 - out_1_acc: 0.9918 - out_2_acc: 0.9964 - val_loss: 0.5678 - val_out_1_loss: 0.2801 - val_out_2_loss: 0.2877 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0295 - out_1_loss: 0.0204 - out_2_loss: 0.0091 - out_1_acc: 0.9919 - out_2_acc: 0.9963 - val_loss: 0.5907 - val_out_1_loss: 0.2913 - val_out_2_loss: 0.2994 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0288 - out_1_loss: 0.0193 - out_2_loss: 0.0095 - out_1_acc: 0.9924 - out_2_acc: 0.9964 - val_loss: 0.5879 - val_out_1_loss: 0.2921 - val_out_2_loss: 0.2958 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9525\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0336 - out_1_loss: 0.0211 - out_2_loss: 0.0124 - out_1_acc: 0.9917 - out_2_acc: 0.9951 - val_loss: 0.5962 - val_out_1_loss: 0.2989 - val_out_2_loss: 0.2972 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9515\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.0323 - out_1_loss: 0.0206 - out_2_loss: 0.0117 - out_1_acc: 0.9913 - out_2_acc: 0.9953 - val_loss: 0.5855 - val_out_1_loss: 0.2955 - val_out_2_loss: 0.2901 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9523\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0309 - out_1_loss: 0.0198 - out_2_loss: 0.0111 - out_1_acc: 0.9922 - out_2_acc: 0.9958 - val_loss: 0.5761 - val_out_1_loss: 0.2924 - val_out_2_loss: 0.2837 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0294 - out_1_loss: 0.0197 - out_2_loss: 0.0097 - out_1_acc: 0.9924 - out_2_acc: 0.9964 - val_loss: 0.5918 - val_out_1_loss: 0.3037 - val_out_2_loss: 0.2881 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0284 - out_1_loss: 0.0192 - out_2_loss: 0.0092 - out_1_acc: 0.9926 - out_2_acc: 0.9965 - val_loss: 0.5879 - val_out_1_loss: 0.2921 - val_out_2_loss: 0.2958 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9514\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0262 - out_1_loss: 0.0184 - out_2_loss: 0.0078 - out_1_acc: 0.9927 - out_2_acc: 0.9970 - val_loss: 0.5928 - val_out_1_loss: 0.3017 - val_out_2_loss: 0.2911 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9532\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.0238 - out_1_loss: 0.0161 - out_2_loss: 0.0077 - out_1_acc: 0.9937 - out_2_acc: 0.9969 - val_loss: 0.5975 - val_out_1_loss: 0.3015 - val_out_2_loss: 0.2960 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9527\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0232 - out_1_loss: 0.0158 - out_2_loss: 0.0074 - out_1_acc: 0.9937 - out_2_acc: 0.9972 - val_loss: 0.6034 - val_out_1_loss: 0.3049 - val_out_2_loss: 0.2985 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9522\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0230 - out_1_loss: 0.0158 - out_2_loss: 0.0072 - out_1_acc: 0.9941 - out_2_acc: 0.9973 - val_loss: 0.6189 - val_out_1_loss: 0.3136 - val_out_2_loss: 0.3053 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0241 - out_1_loss: 0.0170 - out_2_loss: 0.0070 - out_1_acc: 0.9932 - out_2_acc: 0.9975 - val_loss: 0.6214 - val_out_1_loss: 0.3201 - val_out_2_loss: 0.3013 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0202 - out_1_loss: 0.0149 - out_2_loss: 0.0053 - out_1_acc: 0.9943 - out_2_acc: 0.9982 - val_loss: 0.6234 - val_out_1_loss: 0.3148 - val_out_2_loss: 0.3086 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9524\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0228 - out_1_loss: 0.0168 - out_2_loss: 0.0060 - out_1_acc: 0.9934 - out_2_acc: 0.9980 - val_loss: 0.6258 - val_out_1_loss: 0.3111 - val_out_2_loss: 0.3146 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0210 - out_1_loss: 0.0148 - out_2_loss: 0.0062 - out_1_acc: 0.9943 - out_2_acc: 0.9976 - val_loss: 0.6412 - val_out_1_loss: 0.3243 - val_out_2_loss: 0.3170 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0242 - out_1_loss: 0.0169 - out_2_loss: 0.0073 - out_1_acc: 0.9937 - out_2_acc: 0.9972 - val_loss: 0.6321 - val_out_1_loss: 0.3187 - val_out_2_loss: 0.3134 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9529\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0232 - out_1_loss: 0.0158 - out_2_loss: 0.0073 - out_1_acc: 0.9937 - out_2_acc: 0.9975 - val_loss: 0.6423 - val_out_1_loss: 0.3282 - val_out_2_loss: 0.3142 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9524\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0257 - out_1_loss: 0.0178 - out_2_loss: 0.0079 - out_1_acc: 0.9930 - out_2_acc: 0.9971 - val_loss: 0.6299 - val_out_1_loss: 0.3200 - val_out_2_loss: 0.3099 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9509\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0242 - out_1_loss: 0.0167 - out_2_loss: 0.0075 - out_1_acc: 0.9934 - out_2_acc: 0.9971 - val_loss: 0.6344 - val_out_1_loss: 0.3196 - val_out_2_loss: 0.3148 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9516\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0248 - out_1_loss: 0.0166 - out_2_loss: 0.0082 - out_1_acc: 0.9935 - out_2_acc: 0.9971 - val_loss: 0.6329 - val_out_1_loss: 0.3154 - val_out_2_loss: 0.3176 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9520\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0231 - out_1_loss: 0.0158 - out_2_loss: 0.0073 - out_1_acc: 0.9940 - out_2_acc: 0.9973 - val_loss: 0.6409 - val_out_1_loss: 0.3199 - val_out_2_loss: 0.3210 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9512\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0221 - out_1_loss: 0.0158 - out_2_loss: 0.0063 - out_1_acc: 0.9940 - out_2_acc: 0.9977 - val_loss: 0.6428 - val_out_1_loss: 0.3223 - val_out_2_loss: 0.3204 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9519\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0209 - out_1_loss: 0.0146 - out_2_loss: 0.0063 - out_1_acc: 0.9943 - out_2_acc: 0.9978 - val_loss: 0.6327 - val_out_1_loss: 0.3246 - val_out_2_loss: 0.3081 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9535\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(6)-epoch(200)/assets\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6205 - out_1_loss: 0.3186 - out_2_loss: 0.3019 - out_1_acc: 0.9413 - out_2_acc: 0.9514\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 6, 30)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 6, 300), (No 397200      input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 6, 300)       397200      input_18[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,441,480\n",
      "Trainable params: 2,441,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3355 - out_1_loss: 3.6741 - out_2_loss: 3.6614 - out_1_acc: 0.1647 - out_2_acc: 0.1835WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108252). Check your callbacks.\n",
      "28/28 [==============================] - 3s 119ms/step - loss: 5.3352 - out_1_loss: 2.7576 - out_2_loss: 2.5776 - out_1_acc: 0.4162 - out_2_acc: 0.4380 - val_loss: 3.7160 - val_out_1_loss: 2.0131 - val_out_2_loss: 1.7030 - val_out_1_acc: 0.4954 - val_out_2_acc: 0.5724\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 2.6102 - out_1_loss: 1.5796 - out_2_loss: 1.0306 - out_1_acc: 0.5873 - out_2_acc: 0.7324 - val_loss: 1.4764 - val_out_1_loss: 0.9744 - val_out_2_loss: 0.5019 - val_out_1_acc: 0.7629 - val_out_2_acc: 0.8740\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.9404 - out_1_loss: 0.6049 - out_2_loss: 0.3355 - out_1_acc: 0.8628 - out_2_acc: 0.9150 - val_loss: 0.6065 - val_out_1_loss: 0.3774 - val_out_2_loss: 0.2291 - val_out_1_acc: 0.9143 - val_out_2_acc: 0.9373\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.4630 - out_1_loss: 0.2922 - out_2_loss: 0.1708 - out_1_acc: 0.9246 - out_2_acc: 0.9467 - val_loss: 0.3798 - val_out_1_loss: 0.2358 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9326 - val_out_2_acc: 0.9484\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.3159 - out_1_loss: 0.1961 - out_2_loss: 0.1197 - out_1_acc: 0.9349 - out_2_acc: 0.9524 - val_loss: 0.2944 - val_out_1_loss: 0.1778 - val_out_2_loss: 0.1166 - val_out_1_acc: 0.9361 - val_out_2_acc: 0.9513\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.2576 - out_1_loss: 0.1553 - out_2_loss: 0.1022 - out_1_acc: 0.9399 - out_2_acc: 0.9535 - val_loss: 0.2621 - val_out_1_loss: 0.1541 - val_out_2_loss: 0.1080 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9512\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.2286 - out_1_loss: 0.1350 - out_2_loss: 0.0936 - out_1_acc: 0.9410 - out_2_acc: 0.9545 - val_loss: 0.2427 - val_out_1_loss: 0.1403 - val_out_2_loss: 0.1025 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9514\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.2125 - out_1_loss: 0.1235 - out_2_loss: 0.0890 - out_1_acc: 0.9416 - out_2_acc: 0.9549 - val_loss: 0.2305 - val_out_1_loss: 0.1299 - val_out_2_loss: 0.1005 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9509\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.2015 - out_1_loss: 0.1158 - out_2_loss: 0.0857 - out_1_acc: 0.9424 - out_2_acc: 0.9560 - val_loss: 0.2237 - val_out_1_loss: 0.1246 - val_out_2_loss: 0.0991 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9505\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1940 - out_1_loss: 0.1108 - out_2_loss: 0.0832 - out_1_acc: 0.9432 - out_2_acc: 0.9564 - val_loss: 0.2193 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.0981 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9512\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1884 - out_1_loss: 0.1074 - out_2_loss: 0.0810 - out_1_acc: 0.9433 - out_2_acc: 0.9572 - val_loss: 0.2158 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9518\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1841 - out_1_loss: 0.1046 - out_2_loss: 0.0795 - out_1_acc: 0.9442 - out_2_acc: 0.9572 - val_loss: 0.2151 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1809 - out_1_loss: 0.1028 - out_2_loss: 0.0781 - out_1_acc: 0.9445 - out_2_acc: 0.9577 - val_loss: 0.2136 - val_out_1_loss: 0.1171 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9521\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1779 - out_1_loss: 0.1014 - out_2_loss: 0.0765 - out_1_acc: 0.9452 - out_2_acc: 0.9579 - val_loss: 0.2126 - val_out_1_loss: 0.1161 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9525\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1738 - out_1_loss: 0.0994 - out_2_loss: 0.0745 - out_1_acc: 0.9460 - out_2_acc: 0.9583 - val_loss: 0.2133 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1709 - out_1_loss: 0.0980 - out_2_loss: 0.0729 - out_1_acc: 0.9462 - out_2_acc: 0.9592 - val_loss: 0.2121 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9518\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1681 - out_1_loss: 0.0967 - out_2_loss: 0.0713 - out_1_acc: 0.9466 - out_2_acc: 0.9601 - val_loss: 0.2115 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.0979 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9514\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1652 - out_1_loss: 0.0956 - out_2_loss: 0.0696 - out_1_acc: 0.9470 - out_2_acc: 0.9607 - val_loss: 0.2144 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9532\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1648 - out_1_loss: 0.0950 - out_2_loss: 0.0698 - out_1_acc: 0.9476 - out_2_acc: 0.9606 - val_loss: 0.2165 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1025 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9510\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1636 - out_1_loss: 0.0943 - out_2_loss: 0.0693 - out_1_acc: 0.9477 - out_2_acc: 0.9604 - val_loss: 0.2164 - val_out_1_loss: 0.1148 - val_out_2_loss: 0.1016 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9525\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1621 - out_1_loss: 0.0936 - out_2_loss: 0.0685 - out_1_acc: 0.9483 - out_2_acc: 0.9611 - val_loss: 0.2165 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1015 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9525\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1604 - out_1_loss: 0.0929 - out_2_loss: 0.0676 - out_1_acc: 0.9489 - out_2_acc: 0.9615 - val_loss: 0.2172 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1022 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9516\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1585 - out_1_loss: 0.0916 - out_2_loss: 0.0668 - out_1_acc: 0.9493 - out_2_acc: 0.9615 - val_loss: 0.2143 - val_out_1_loss: 0.1138 - val_out_2_loss: 0.1005 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9528\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1562 - out_1_loss: 0.0905 - out_2_loss: 0.0657 - out_1_acc: 0.9497 - out_2_acc: 0.9620 - val_loss: 0.2150 - val_out_1_loss: 0.1133 - val_out_2_loss: 0.1017 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1531 - out_1_loss: 0.0895 - out_2_loss: 0.0636 - out_1_acc: 0.9499 - out_2_acc: 0.9630 - val_loss: 0.2158 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1019 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1496 - out_1_loss: 0.0890 - out_2_loss: 0.0606 - out_1_acc: 0.9505 - out_2_acc: 0.9646 - val_loss: 0.2189 - val_out_1_loss: 0.1149 - val_out_2_loss: 0.1040 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9504\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1468 - out_1_loss: 0.0881 - out_2_loss: 0.0588 - out_1_acc: 0.9510 - out_2_acc: 0.9656 - val_loss: 0.2190 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1041 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9507\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1447 - out_1_loss: 0.0871 - out_2_loss: 0.0576 - out_1_acc: 0.9517 - out_2_acc: 0.9659 - val_loss: 0.2215 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1064 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9514\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1428 - out_1_loss: 0.0862 - out_2_loss: 0.0566 - out_1_acc: 0.9515 - out_2_acc: 0.9663 - val_loss: 0.2224 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.1072 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1411 - out_1_loss: 0.0853 - out_2_loss: 0.0558 - out_1_acc: 0.9524 - out_2_acc: 0.9667 - val_loss: 0.2246 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.1084 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9521\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1399 - out_1_loss: 0.0845 - out_2_loss: 0.0554 - out_1_acc: 0.9525 - out_2_acc: 0.9666 - val_loss: 0.2275 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1103 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9514\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1391 - out_1_loss: 0.0839 - out_2_loss: 0.0551 - out_1_acc: 0.9532 - out_2_acc: 0.9670 - val_loss: 0.2309 - val_out_1_loss: 0.1186 - val_out_2_loss: 0.1123 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9509\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1387 - out_1_loss: 0.0835 - out_2_loss: 0.0552 - out_1_acc: 0.9532 - out_2_acc: 0.9669 - val_loss: 0.2324 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1128 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9516\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1378 - out_1_loss: 0.0828 - out_2_loss: 0.0550 - out_1_acc: 0.9534 - out_2_acc: 0.9670 - val_loss: 0.2359 - val_out_1_loss: 0.1206 - val_out_2_loss: 0.1153 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9522\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1370 - out_1_loss: 0.0818 - out_2_loss: 0.0552 - out_1_acc: 0.9542 - out_2_acc: 0.9667 - val_loss: 0.2407 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1195 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9514\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1371 - out_1_loss: 0.0813 - out_2_loss: 0.0558 - out_1_acc: 0.9543 - out_2_acc: 0.9659 - val_loss: 0.2450 - val_out_1_loss: 0.1237 - val_out_2_loss: 0.1213 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 37/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1357 - out_1_loss: 0.0805 - out_2_loss: 0.0552 - out_1_acc: 0.9546 - out_2_acc: 0.9666 - val_loss: 0.2362 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1148 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9512\n",
      "Epoch 38/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1343 - out_1_loss: 0.0800 - out_2_loss: 0.0543 - out_1_acc: 0.9549 - out_2_acc: 0.9668 - val_loss: 0.2380 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.1161 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 39/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1327 - out_1_loss: 0.0793 - out_2_loss: 0.0534 - out_1_acc: 0.9552 - out_2_acc: 0.9673 - val_loss: 0.2408 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.1185 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9513\n",
      "Epoch 40/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1312 - out_1_loss: 0.0777 - out_2_loss: 0.0535 - out_1_acc: 0.9562 - out_2_acc: 0.9680 - val_loss: 0.2444 - val_out_1_loss: 0.1237 - val_out_2_loss: 0.1207 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9521\n",
      "Epoch 41/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1296 - out_1_loss: 0.0767 - out_2_loss: 0.0529 - out_1_acc: 0.9567 - out_2_acc: 0.9677 - val_loss: 0.2472 - val_out_1_loss: 0.1237 - val_out_2_loss: 0.1235 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9515\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1284 - out_1_loss: 0.0759 - out_2_loss: 0.0525 - out_1_acc: 0.9572 - out_2_acc: 0.9681 - val_loss: 0.2488 - val_out_1_loss: 0.1238 - val_out_2_loss: 0.1249 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9512\n",
      "Epoch 43/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1273 - out_1_loss: 0.0752 - out_2_loss: 0.0521 - out_1_acc: 0.9574 - out_2_acc: 0.9677 - val_loss: 0.2487 - val_out_1_loss: 0.1234 - val_out_2_loss: 0.1253 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 44/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1270 - out_1_loss: 0.0748 - out_2_loss: 0.0521 - out_1_acc: 0.9573 - out_2_acc: 0.9679 - val_loss: 0.2493 - val_out_1_loss: 0.1248 - val_out_2_loss: 0.1246 - val_out_1_acc: 0.9417 - val_out_2_acc: 0.9524\n",
      "Epoch 45/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1253 - out_1_loss: 0.0738 - out_2_loss: 0.0515 - out_1_acc: 0.9584 - out_2_acc: 0.9681 - val_loss: 0.2528 - val_out_1_loss: 0.1275 - val_out_2_loss: 0.1253 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 46/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1249 - out_1_loss: 0.0730 - out_2_loss: 0.0518 - out_1_acc: 0.9586 - out_2_acc: 0.9682 - val_loss: 0.2561 - val_out_1_loss: 0.1304 - val_out_2_loss: 0.1257 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 47/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1239 - out_1_loss: 0.0722 - out_2_loss: 0.0517 - out_1_acc: 0.9590 - out_2_acc: 0.9685 - val_loss: 0.2570 - val_out_1_loss: 0.1312 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9508\n",
      "Epoch 48/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1237 - out_1_loss: 0.0720 - out_2_loss: 0.0517 - out_1_acc: 0.9589 - out_2_acc: 0.9683 - val_loss: 0.2613 - val_out_1_loss: 0.1336 - val_out_2_loss: 0.1277 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9508\n",
      "Epoch 49/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1235 - out_1_loss: 0.0718 - out_2_loss: 0.0517 - out_1_acc: 0.9592 - out_2_acc: 0.9686 - val_loss: 0.2630 - val_out_1_loss: 0.1331 - val_out_2_loss: 0.1299 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 50/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1232 - out_1_loss: 0.0715 - out_2_loss: 0.0517 - out_1_acc: 0.9588 - out_2_acc: 0.9683 - val_loss: 0.2655 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1325 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9516\n",
      "Epoch 51/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1222 - out_1_loss: 0.0705 - out_2_loss: 0.0517 - out_1_acc: 0.9598 - out_2_acc: 0.9680 - val_loss: 0.2640 - val_out_1_loss: 0.1327 - val_out_2_loss: 0.1313 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9521\n",
      "Epoch 52/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1206 - out_1_loss: 0.0696 - out_2_loss: 0.0511 - out_1_acc: 0.9604 - out_2_acc: 0.9690 - val_loss: 0.2685 - val_out_1_loss: 0.1335 - val_out_2_loss: 0.1350 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9518\n",
      "Epoch 53/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1199 - out_1_loss: 0.0692 - out_2_loss: 0.0508 - out_1_acc: 0.9605 - out_2_acc: 0.9689 - val_loss: 0.2695 - val_out_1_loss: 0.1341 - val_out_2_loss: 0.1354 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 54/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1195 - out_1_loss: 0.0691 - out_2_loss: 0.0504 - out_1_acc: 0.9604 - out_2_acc: 0.9692 - val_loss: 0.2743 - val_out_1_loss: 0.1347 - val_out_2_loss: 0.1396 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9506\n",
      "Epoch 55/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1190 - out_1_loss: 0.0685 - out_2_loss: 0.0505 - out_1_acc: 0.9608 - out_2_acc: 0.9694 - val_loss: 0.2719 - val_out_1_loss: 0.1357 - val_out_2_loss: 0.1362 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 56/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1191 - out_1_loss: 0.0683 - out_2_loss: 0.0508 - out_1_acc: 0.9613 - out_2_acc: 0.9687 - val_loss: 0.2759 - val_out_1_loss: 0.1384 - val_out_2_loss: 0.1375 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9503\n",
      "Epoch 57/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1189 - out_1_loss: 0.0684 - out_2_loss: 0.0505 - out_1_acc: 0.9609 - out_2_acc: 0.9690 - val_loss: 0.2769 - val_out_1_loss: 0.1378 - val_out_2_loss: 0.1391 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9521\n",
      "Epoch 58/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1189 - out_1_loss: 0.0684 - out_2_loss: 0.0505 - out_1_acc: 0.9611 - out_2_acc: 0.9693 - val_loss: 0.2764 - val_out_1_loss: 0.1398 - val_out_2_loss: 0.1365 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 59/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1187 - out_1_loss: 0.0684 - out_2_loss: 0.0503 - out_1_acc: 0.9607 - out_2_acc: 0.9694 - val_loss: 0.2790 - val_out_1_loss: 0.1406 - val_out_2_loss: 0.1384 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9520\n",
      "Epoch 60/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1184 - out_1_loss: 0.0681 - out_2_loss: 0.0503 - out_1_acc: 0.9610 - out_2_acc: 0.9695 - val_loss: 0.2810 - val_out_1_loss: 0.1400 - val_out_2_loss: 0.1410 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9507\n",
      "Epoch 61/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1186 - out_1_loss: 0.0679 - out_2_loss: 0.0507 - out_1_acc: 0.9615 - out_2_acc: 0.9690 - val_loss: 0.2819 - val_out_1_loss: 0.1411 - val_out_2_loss: 0.1408 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9529\n",
      "Epoch 62/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1186 - out_1_loss: 0.0679 - out_2_loss: 0.0507 - out_1_acc: 0.9609 - out_2_acc: 0.9692 - val_loss: 0.2815 - val_out_1_loss: 0.1407 - val_out_2_loss: 0.1407 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9525\n",
      "Epoch 63/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1173 - out_1_loss: 0.0674 - out_2_loss: 0.0499 - out_1_acc: 0.9611 - out_2_acc: 0.9694 - val_loss: 0.2820 - val_out_1_loss: 0.1427 - val_out_2_loss: 0.1393 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 64/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1171 - out_1_loss: 0.0674 - out_2_loss: 0.0497 - out_1_acc: 0.9609 - out_2_acc: 0.9695 - val_loss: 0.2829 - val_out_1_loss: 0.1441 - val_out_2_loss: 0.1388 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9513\n",
      "Epoch 65/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1159 - out_1_loss: 0.0663 - out_2_loss: 0.0496 - out_1_acc: 0.9615 - out_2_acc: 0.9700 - val_loss: 0.2855 - val_out_1_loss: 0.1458 - val_out_2_loss: 0.1397 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 66/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1158 - out_1_loss: 0.0663 - out_2_loss: 0.0495 - out_1_acc: 0.9614 - out_2_acc: 0.9697 - val_loss: 0.2882 - val_out_1_loss: 0.1475 - val_out_2_loss: 0.1407 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9510\n",
      "Epoch 67/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1149 - out_1_loss: 0.0654 - out_2_loss: 0.0494 - out_1_acc: 0.9622 - out_2_acc: 0.9703 - val_loss: 0.2878 - val_out_1_loss: 0.1481 - val_out_2_loss: 0.1397 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9510\n",
      "Epoch 68/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1128 - out_1_loss: 0.0640 - out_2_loss: 0.0488 - out_1_acc: 0.9634 - out_2_acc: 0.9707 - val_loss: 0.2894 - val_out_1_loss: 0.1505 - val_out_2_loss: 0.1389 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9528\n",
      "Epoch 69/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1125 - out_1_loss: 0.0639 - out_2_loss: 0.0485 - out_1_acc: 0.9633 - out_2_acc: 0.9708 - val_loss: 0.2934 - val_out_1_loss: 0.1512 - val_out_2_loss: 0.1422 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9524\n",
      "Epoch 70/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1120 - out_1_loss: 0.0634 - out_2_loss: 0.0486 - out_1_acc: 0.9638 - out_2_acc: 0.9710 - val_loss: 0.2952 - val_out_1_loss: 0.1533 - val_out_2_loss: 0.1419 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1110 - out_1_loss: 0.0628 - out_2_loss: 0.0481 - out_1_acc: 0.9643 - out_2_acc: 0.9713 - val_loss: 0.2970 - val_out_1_loss: 0.1546 - val_out_2_loss: 0.1424 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9527\n",
      "Epoch 72/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1099 - out_1_loss: 0.0624 - out_2_loss: 0.0475 - out_1_acc: 0.9648 - out_2_acc: 0.9712 - val_loss: 0.3003 - val_out_1_loss: 0.1563 - val_out_2_loss: 0.1440 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9515\n",
      "Epoch 73/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1098 - out_1_loss: 0.0627 - out_2_loss: 0.0471 - out_1_acc: 0.9650 - out_2_acc: 0.9723 - val_loss: 0.3012 - val_out_1_loss: 0.1570 - val_out_2_loss: 0.1442 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 74/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1100 - out_1_loss: 0.0624 - out_2_loss: 0.0476 - out_1_acc: 0.9646 - out_2_acc: 0.9720 - val_loss: 0.3009 - val_out_1_loss: 0.1579 - val_out_2_loss: 0.1429 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9522\n",
      "Epoch 75/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1092 - out_1_loss: 0.0620 - out_2_loss: 0.0472 - out_1_acc: 0.9649 - out_2_acc: 0.9725 - val_loss: 0.3000 - val_out_1_loss: 0.1564 - val_out_2_loss: 0.1436 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9532\n",
      "Epoch 76/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1090 - out_1_loss: 0.0625 - out_2_loss: 0.0466 - out_1_acc: 0.9651 - out_2_acc: 0.9723 - val_loss: 0.3022 - val_out_1_loss: 0.1564 - val_out_2_loss: 0.1458 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9523\n",
      "Epoch 77/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1081 - out_1_loss: 0.0620 - out_2_loss: 0.0462 - out_1_acc: 0.9650 - out_2_acc: 0.9731 - val_loss: 0.3027 - val_out_1_loss: 0.1573 - val_out_2_loss: 0.1454 - val_out_1_acc: 0.9418 - val_out_2_acc: 0.9523\n",
      "Epoch 78/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1072 - out_1_loss: 0.0614 - out_2_loss: 0.0458 - out_1_acc: 0.9663 - out_2_acc: 0.9736 - val_loss: 0.3010 - val_out_1_loss: 0.1569 - val_out_2_loss: 0.1441 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9517\n",
      "Epoch 79/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1058 - out_1_loss: 0.0606 - out_2_loss: 0.0452 - out_1_acc: 0.9665 - out_2_acc: 0.9742 - val_loss: 0.3064 - val_out_1_loss: 0.1583 - val_out_2_loss: 0.1481 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 80/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1078 - out_1_loss: 0.0619 - out_2_loss: 0.0459 - out_1_acc: 0.9653 - out_2_acc: 0.9734 - val_loss: 0.3062 - val_out_1_loss: 0.1573 - val_out_2_loss: 0.1489 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9514\n",
      "Epoch 81/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1066 - out_1_loss: 0.0608 - out_2_loss: 0.0459 - out_1_acc: 0.9661 - out_2_acc: 0.9734 - val_loss: 0.3038 - val_out_1_loss: 0.1554 - val_out_2_loss: 0.1484 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 82/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1061 - out_1_loss: 0.0609 - out_2_loss: 0.0452 - out_1_acc: 0.9663 - out_2_acc: 0.9741 - val_loss: 0.3047 - val_out_1_loss: 0.1550 - val_out_2_loss: 0.1496 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 83/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1071 - out_1_loss: 0.0616 - out_2_loss: 0.0455 - out_1_acc: 0.9659 - out_2_acc: 0.9739 - val_loss: 0.3051 - val_out_1_loss: 0.1556 - val_out_2_loss: 0.1495 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9525\n",
      "Epoch 84/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1077 - out_1_loss: 0.0619 - out_2_loss: 0.0458 - out_1_acc: 0.9652 - out_2_acc: 0.9735 - val_loss: 0.3072 - val_out_1_loss: 0.1566 - val_out_2_loss: 0.1506 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9528\n",
      "Epoch 85/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1056 - out_1_loss: 0.0605 - out_2_loss: 0.0451 - out_1_acc: 0.9662 - out_2_acc: 0.9744 - val_loss: 0.3107 - val_out_1_loss: 0.1569 - val_out_2_loss: 0.1538 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9517\n",
      "Epoch 86/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1057 - out_1_loss: 0.0603 - out_2_loss: 0.0454 - out_1_acc: 0.9664 - out_2_acc: 0.9741 - val_loss: 0.3113 - val_out_1_loss: 0.1582 - val_out_2_loss: 0.1531 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 87/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1058 - out_1_loss: 0.0608 - out_2_loss: 0.0451 - out_1_acc: 0.9664 - out_2_acc: 0.9744 - val_loss: 0.3154 - val_out_1_loss: 0.1603 - val_out_2_loss: 0.1551 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9527\n",
      "Epoch 88/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1050 - out_1_loss: 0.0603 - out_2_loss: 0.0447 - out_1_acc: 0.9668 - out_2_acc: 0.9752 - val_loss: 0.3165 - val_out_1_loss: 0.1615 - val_out_2_loss: 0.1550 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9522\n",
      "Epoch 89/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1039 - out_1_loss: 0.0590 - out_2_loss: 0.0449 - out_1_acc: 0.9681 - out_2_acc: 0.9748 - val_loss: 0.3146 - val_out_1_loss: 0.1618 - val_out_2_loss: 0.1528 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9517\n",
      "Epoch 90/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.1031 - out_1_loss: 0.0591 - out_2_loss: 0.0440 - out_1_acc: 0.9675 - out_2_acc: 0.9755 - val_loss: 0.3207 - val_out_1_loss: 0.1634 - val_out_2_loss: 0.1572 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 91/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.1027 - out_1_loss: 0.0588 - out_2_loss: 0.0439 - out_1_acc: 0.9678 - out_2_acc: 0.9759 - val_loss: 0.3208 - val_out_1_loss: 0.1625 - val_out_2_loss: 0.1583 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9513\n",
      "Epoch 92/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.1006 - out_1_loss: 0.0573 - out_2_loss: 0.0433 - out_1_acc: 0.9684 - out_2_acc: 0.9757 - val_loss: 0.3202 - val_out_1_loss: 0.1621 - val_out_2_loss: 0.1581 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9516\n",
      "Epoch 93/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0985 - out_1_loss: 0.0564 - out_2_loss: 0.0421 - out_1_acc: 0.9697 - out_2_acc: 0.9763 - val_loss: 0.3251 - val_out_1_loss: 0.1665 - val_out_2_loss: 0.1586 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 94/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0979 - out_1_loss: 0.0562 - out_2_loss: 0.0417 - out_1_acc: 0.9696 - out_2_acc: 0.9772 - val_loss: 0.3303 - val_out_1_loss: 0.1677 - val_out_2_loss: 0.1625 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 95/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0975 - out_1_loss: 0.0557 - out_2_loss: 0.0418 - out_1_acc: 0.9699 - out_2_acc: 0.9775 - val_loss: 0.3260 - val_out_1_loss: 0.1651 - val_out_2_loss: 0.1609 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9525\n",
      "Epoch 96/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0959 - out_1_loss: 0.0543 - out_2_loss: 0.0416 - out_1_acc: 0.9709 - out_2_acc: 0.9775 - val_loss: 0.3316 - val_out_1_loss: 0.1677 - val_out_2_loss: 0.1639 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 97/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0958 - out_1_loss: 0.0547 - out_2_loss: 0.0411 - out_1_acc: 0.9711 - out_2_acc: 0.9780 - val_loss: 0.3319 - val_out_1_loss: 0.1682 - val_out_2_loss: 0.1637 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9527\n",
      "Epoch 98/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0960 - out_1_loss: 0.0545 - out_2_loss: 0.0416 - out_1_acc: 0.9712 - out_2_acc: 0.9780 - val_loss: 0.3370 - val_out_1_loss: 0.1688 - val_out_2_loss: 0.1683 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 99/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0962 - out_1_loss: 0.0541 - out_2_loss: 0.0421 - out_1_acc: 0.9718 - out_2_acc: 0.9776 - val_loss: 0.3336 - val_out_1_loss: 0.1686 - val_out_2_loss: 0.1650 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9531\n",
      "Epoch 100/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0946 - out_1_loss: 0.0533 - out_2_loss: 0.0413 - out_1_acc: 0.9718 - out_2_acc: 0.9780 - val_loss: 0.3399 - val_out_1_loss: 0.1714 - val_out_2_loss: 0.1684 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9515\n",
      "Epoch 101/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0928 - out_1_loss: 0.0531 - out_2_loss: 0.0397 - out_1_acc: 0.9720 - out_2_acc: 0.9790 - val_loss: 0.3449 - val_out_1_loss: 0.1729 - val_out_2_loss: 0.1719 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9517\n",
      "Epoch 102/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0930 - out_1_loss: 0.0532 - out_2_loss: 0.0398 - out_1_acc: 0.9715 - out_2_acc: 0.9788 - val_loss: 0.3526 - val_out_1_loss: 0.1755 - val_out_2_loss: 0.1770 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 103/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0932 - out_1_loss: 0.0539 - out_2_loss: 0.0393 - out_1_acc: 0.9713 - out_2_acc: 0.9792 - val_loss: 0.3408 - val_out_1_loss: 0.1719 - val_out_2_loss: 0.1689 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 104/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0935 - out_1_loss: 0.0543 - out_2_loss: 0.0392 - out_1_acc: 0.9711 - out_2_acc: 0.9795 - val_loss: 0.3451 - val_out_1_loss: 0.1726 - val_out_2_loss: 0.1725 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9518\n",
      "Epoch 105/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0920 - out_1_loss: 0.0523 - out_2_loss: 0.0396 - out_1_acc: 0.9728 - out_2_acc: 0.9789 - val_loss: 0.3480 - val_out_1_loss: 0.1748 - val_out_2_loss: 0.1732 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9522\n",
      "Epoch 106/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0904 - out_1_loss: 0.0519 - out_2_loss: 0.0385 - out_1_acc: 0.9731 - out_2_acc: 0.9803 - val_loss: 0.3512 - val_out_1_loss: 0.1759 - val_out_2_loss: 0.1754 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9508\n",
      "Epoch 107/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0892 - out_1_loss: 0.0511 - out_2_loss: 0.0381 - out_1_acc: 0.9735 - out_2_acc: 0.9805 - val_loss: 0.3498 - val_out_1_loss: 0.1766 - val_out_2_loss: 0.1732 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9527\n",
      "Epoch 108/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0875 - out_1_loss: 0.0503 - out_2_loss: 0.0372 - out_1_acc: 0.9744 - out_2_acc: 0.9805 - val_loss: 0.3593 - val_out_1_loss: 0.1796 - val_out_2_loss: 0.1797 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 109/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0862 - out_1_loss: 0.0493 - out_2_loss: 0.0369 - out_1_acc: 0.9754 - out_2_acc: 0.9811 - val_loss: 0.3604 - val_out_1_loss: 0.1802 - val_out_2_loss: 0.1802 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 110/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0843 - out_1_loss: 0.0483 - out_2_loss: 0.0360 - out_1_acc: 0.9755 - out_2_acc: 0.9815 - val_loss: 0.3696 - val_out_1_loss: 0.1842 - val_out_2_loss: 0.1854 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9520\n",
      "Epoch 111/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0854 - out_1_loss: 0.0489 - out_2_loss: 0.0365 - out_1_acc: 0.9754 - out_2_acc: 0.9812 - val_loss: 0.3679 - val_out_1_loss: 0.1860 - val_out_2_loss: 0.1819 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 112/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0844 - out_1_loss: 0.0487 - out_2_loss: 0.0357 - out_1_acc: 0.9753 - out_2_acc: 0.9817 - val_loss: 0.3723 - val_out_1_loss: 0.1844 - val_out_2_loss: 0.1879 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 113/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0840 - out_1_loss: 0.0487 - out_2_loss: 0.0353 - out_1_acc: 0.9755 - out_2_acc: 0.9826 - val_loss: 0.3706 - val_out_1_loss: 0.1853 - val_out_2_loss: 0.1853 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 114/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0821 - out_1_loss: 0.0469 - out_2_loss: 0.0352 - out_1_acc: 0.9769 - out_2_acc: 0.9822 - val_loss: 0.3731 - val_out_1_loss: 0.1868 - val_out_2_loss: 0.1863 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9526\n",
      "Epoch 115/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0774 - out_1_loss: 0.0453 - out_2_loss: 0.0321 - out_1_acc: 0.9777 - out_2_acc: 0.9844 - val_loss: 0.3844 - val_out_1_loss: 0.1901 - val_out_2_loss: 0.1943 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9523\n",
      "Epoch 116/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0769 - out_1_loss: 0.0452 - out_2_loss: 0.0317 - out_1_acc: 0.9780 - out_2_acc: 0.9849 - val_loss: 0.3900 - val_out_1_loss: 0.1920 - val_out_2_loss: 0.1981 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9514\n",
      "Epoch 117/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0763 - out_1_loss: 0.0445 - out_2_loss: 0.0318 - out_1_acc: 0.9786 - out_2_acc: 0.9843 - val_loss: 0.3890 - val_out_1_loss: 0.1885 - val_out_2_loss: 0.2005 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9513\n",
      "Epoch 118/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0777 - out_1_loss: 0.0453 - out_2_loss: 0.0325 - out_1_acc: 0.9781 - out_2_acc: 0.9843 - val_loss: 0.3861 - val_out_1_loss: 0.1921 - val_out_2_loss: 0.1940 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9506\n",
      "Epoch 119/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0783 - out_1_loss: 0.0454 - out_2_loss: 0.0330 - out_1_acc: 0.9780 - out_2_acc: 0.9842 - val_loss: 0.3977 - val_out_1_loss: 0.1944 - val_out_2_loss: 0.2033 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9509\n",
      "Epoch 120/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0785 - out_1_loss: 0.0451 - out_2_loss: 0.0334 - out_1_acc: 0.9784 - out_2_acc: 0.9837 - val_loss: 0.3995 - val_out_1_loss: 0.1981 - val_out_2_loss: 0.2014 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9515\n",
      "Epoch 121/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0756 - out_1_loss: 0.0450 - out_2_loss: 0.0306 - out_1_acc: 0.9781 - out_2_acc: 0.9853 - val_loss: 0.4057 - val_out_1_loss: 0.2019 - val_out_2_loss: 0.2038 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9501\n",
      "Epoch 122/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0757 - out_1_loss: 0.0454 - out_2_loss: 0.0303 - out_1_acc: 0.9785 - out_2_acc: 0.9855 - val_loss: 0.4031 - val_out_1_loss: 0.2020 - val_out_2_loss: 0.2011 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9513\n",
      "Epoch 123/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0740 - out_1_loss: 0.0444 - out_2_loss: 0.0296 - out_1_acc: 0.9785 - out_2_acc: 0.9859 - val_loss: 0.4111 - val_out_1_loss: 0.2031 - val_out_2_loss: 0.2080 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 124/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0749 - out_1_loss: 0.0439 - out_2_loss: 0.0310 - out_1_acc: 0.9788 - out_2_acc: 0.9851 - val_loss: 0.4138 - val_out_1_loss: 0.2058 - val_out_2_loss: 0.2081 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9510\n",
      "Epoch 125/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0757 - out_1_loss: 0.0445 - out_2_loss: 0.0312 - out_1_acc: 0.9783 - out_2_acc: 0.9850 - val_loss: 0.4115 - val_out_1_loss: 0.2062 - val_out_2_loss: 0.2054 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9509\n",
      "Epoch 126/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0746 - out_1_loss: 0.0442 - out_2_loss: 0.0304 - out_1_acc: 0.9787 - out_2_acc: 0.9857 - val_loss: 0.4081 - val_out_1_loss: 0.2031 - val_out_2_loss: 0.2050 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9516\n",
      "Epoch 127/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0705 - out_1_loss: 0.0422 - out_2_loss: 0.0282 - out_1_acc: 0.9801 - out_2_acc: 0.9866 - val_loss: 0.4172 - val_out_1_loss: 0.2048 - val_out_2_loss: 0.2124 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9496\n",
      "Epoch 128/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0715 - out_1_loss: 0.0433 - out_2_loss: 0.0283 - out_1_acc: 0.9796 - out_2_acc: 0.9870 - val_loss: 0.4221 - val_out_1_loss: 0.2065 - val_out_2_loss: 0.2156 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9506\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0682 - out_1_loss: 0.0411 - out_2_loss: 0.0271 - out_1_acc: 0.9807 - out_2_acc: 0.9871 - val_loss: 0.4257 - val_out_1_loss: 0.2081 - val_out_2_loss: 0.2177 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9511\n",
      "Epoch 130/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0705 - out_1_loss: 0.0421 - out_2_loss: 0.0284 - out_1_acc: 0.9803 - out_2_acc: 0.9865 - val_loss: 0.4250 - val_out_1_loss: 0.2105 - val_out_2_loss: 0.2145 - val_out_1_acc: 0.9409 - val_out_2_acc: 0.9518\n",
      "Epoch 131/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0706 - out_1_loss: 0.0429 - out_2_loss: 0.0277 - out_1_acc: 0.9800 - out_2_acc: 0.9869 - val_loss: 0.4272 - val_out_1_loss: 0.2122 - val_out_2_loss: 0.2150 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9515\n",
      "Epoch 132/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0665 - out_1_loss: 0.0410 - out_2_loss: 0.0255 - out_1_acc: 0.9807 - out_2_acc: 0.9880 - val_loss: 0.4342 - val_out_1_loss: 0.2164 - val_out_2_loss: 0.2178 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9517\n",
      "Epoch 133/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0660 - out_1_loss: 0.0398 - out_2_loss: 0.0262 - out_1_acc: 0.9818 - out_2_acc: 0.9876 - val_loss: 0.4259 - val_out_1_loss: 0.2102 - val_out_2_loss: 0.2157 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9505\n",
      "Epoch 134/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0629 - out_1_loss: 0.0382 - out_2_loss: 0.0247 - out_1_acc: 0.9825 - out_2_acc: 0.9885 - val_loss: 0.4437 - val_out_1_loss: 0.2201 - val_out_2_loss: 0.2236 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9514\n",
      "Epoch 135/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0632 - out_1_loss: 0.0387 - out_2_loss: 0.0245 - out_1_acc: 0.9823 - out_2_acc: 0.9890 - val_loss: 0.4507 - val_out_1_loss: 0.2248 - val_out_2_loss: 0.2260 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9519\n",
      "Epoch 136/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0617 - out_1_loss: 0.0376 - out_2_loss: 0.0241 - out_1_acc: 0.9829 - out_2_acc: 0.9889 - val_loss: 0.4415 - val_out_1_loss: 0.2193 - val_out_2_loss: 0.2223 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9520\n",
      "Epoch 137/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0597 - out_1_loss: 0.0357 - out_2_loss: 0.0240 - out_1_acc: 0.9841 - out_2_acc: 0.9893 - val_loss: 0.4447 - val_out_1_loss: 0.2172 - val_out_2_loss: 0.2275 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 138/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0618 - out_1_loss: 0.0364 - out_2_loss: 0.0254 - out_1_acc: 0.9837 - out_2_acc: 0.9885 - val_loss: 0.4469 - val_out_1_loss: 0.2231 - val_out_2_loss: 0.2238 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 139/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0583 - out_1_loss: 0.0348 - out_2_loss: 0.0234 - out_1_acc: 0.9846 - out_2_acc: 0.9893 - val_loss: 0.4497 - val_out_1_loss: 0.2218 - val_out_2_loss: 0.2280 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9521\n",
      "Epoch 140/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0551 - out_1_loss: 0.0336 - out_2_loss: 0.0215 - out_1_acc: 0.9851 - out_2_acc: 0.9904 - val_loss: 0.4627 - val_out_1_loss: 0.2257 - val_out_2_loss: 0.2370 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9505\n",
      "Epoch 141/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0537 - out_1_loss: 0.0330 - out_2_loss: 0.0207 - out_1_acc: 0.9855 - out_2_acc: 0.9906 - val_loss: 0.4636 - val_out_1_loss: 0.2240 - val_out_2_loss: 0.2396 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9507\n",
      "Epoch 142/300\n",
      " 2/28 [=>............................] - ETA: 0s - loss: 0.0520 - out_1_loss: 0.0317 - out_2_loss: 0.0202 - out_1_acc: 0.9861 - out_2_acc: 0.9916Epoch 187/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0242 - out_1_loss: 0.0167 - out_2_loss: 0.0076 - out_1_acc: 0.9936 - out_2_acc: 0.9974 - val_loss: 0.6511 - val_out_1_loss: 0.3402 - val_out_2_loss: 0.3109 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 188/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0239 - out_1_loss: 0.0163 - out_2_loss: 0.0076 - out_1_acc: 0.9935 - out_2_acc: 0.9973 - val_loss: 0.6445 - val_out_1_loss: 0.3340 - val_out_2_loss: 0.3106 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 189/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0201 - out_1_loss: 0.0143 - out_2_loss: 0.0058 - out_1_acc: 0.9949 - out_2_acc: 0.9980 - val_loss: 0.6485 - val_out_1_loss: 0.3329 - val_out_2_loss: 0.3157 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 190/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0187 - out_1_loss: 0.0135 - out_2_loss: 0.0052 - out_1_acc: 0.9951 - out_2_acc: 0.9980 - val_loss: 0.6605 - val_out_1_loss: 0.3429 - val_out_2_loss: 0.3176 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9532\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0195 - out_1_loss: 0.0142 - out_2_loss: 0.0054 - out_1_acc: 0.9947 - out_2_acc: 0.9980 - val_loss: 0.6505 - val_out_1_loss: 0.3376 - val_out_2_loss: 0.3129 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9516\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0187 - out_1_loss: 0.0144 - out_2_loss: 0.0042 - out_1_acc: 0.9948 - out_2_acc: 0.9985 - val_loss: 0.6767 - val_out_1_loss: 0.3501 - val_out_2_loss: 0.3265 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9521\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0211 - out_1_loss: 0.0152 - out_2_loss: 0.0059 - out_1_acc: 0.9941 - out_2_acc: 0.9980 - val_loss: 0.6798 - val_out_1_loss: 0.3441 - val_out_2_loss: 0.3357 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0205 - out_1_loss: 0.0150 - out_2_loss: 0.0056 - out_1_acc: 0.9942 - out_2_acc: 0.9980 - val_loss: 0.6782 - val_out_1_loss: 0.3477 - val_out_2_loss: 0.3305 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9520\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0188 - out_1_loss: 0.0133 - out_2_loss: 0.0055 - out_1_acc: 0.9951 - out_2_acc: 0.9980 - val_loss: 0.6878 - val_out_1_loss: 0.3554 - val_out_2_loss: 0.3324 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9534\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0190 - out_1_loss: 0.0137 - out_2_loss: 0.0052 - out_1_acc: 0.9949 - out_2_acc: 0.9981 - val_loss: 0.6778 - val_out_1_loss: 0.3422 - val_out_2_loss: 0.3356 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9525\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0205 - out_1_loss: 0.0135 - out_2_loss: 0.0070 - out_1_acc: 0.9951 - out_2_acc: 0.9975 - val_loss: 0.6849 - val_out_1_loss: 0.3492 - val_out_2_loss: 0.3357 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9514\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0198 - out_1_loss: 0.0132 - out_2_loss: 0.0066 - out_1_acc: 0.9952 - out_2_acc: 0.9977 - val_loss: 0.6797 - val_out_1_loss: 0.3534 - val_out_2_loss: 0.3263 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9517\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0184 - out_1_loss: 0.0122 - out_2_loss: 0.0062 - out_1_acc: 0.9956 - out_2_acc: 0.9979 - val_loss: 0.6850 - val_out_1_loss: 0.3493 - val_out_2_loss: 0.3358 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0158 - out_1_loss: 0.0107 - out_2_loss: 0.0052 - out_1_acc: 0.9962 - out_2_acc: 0.9982 - val_loss: 0.6852 - val_out_1_loss: 0.3547 - val_out_2_loss: 0.3305 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9513\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0125 - out_1_loss: 0.0088 - out_2_loss: 0.0037 - out_1_acc: 0.9967 - out_2_acc: 0.9987 - val_loss: 0.6895 - val_out_1_loss: 0.3571 - val_out_2_loss: 0.3324 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9523\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0138 - out_1_loss: 0.0090 - out_2_loss: 0.0048 - out_1_acc: 0.9968 - out_2_acc: 0.9984 - val_loss: 0.6871 - val_out_1_loss: 0.3524 - val_out_2_loss: 0.3347 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0134 - out_1_loss: 0.0089 - out_2_loss: 0.0045 - out_1_acc: 0.9969 - out_2_acc: 0.9984 - val_loss: 0.7126 - val_out_1_loss: 0.3622 - val_out_2_loss: 0.3505 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9517\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0148 - out_1_loss: 0.0098 - out_2_loss: 0.0051 - out_1_acc: 0.9965 - out_2_acc: 0.9983 - val_loss: 0.7062 - val_out_1_loss: 0.3613 - val_out_2_loss: 0.3448 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9512\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0129 - out_1_loss: 0.0086 - out_2_loss: 0.0043 - out_1_acc: 0.9969 - out_2_acc: 0.9985 - val_loss: 0.7191 - val_out_1_loss: 0.3691 - val_out_2_loss: 0.3500 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0120 - out_1_loss: 0.0074 - out_2_loss: 0.0046 - out_1_acc: 0.9974 - out_2_acc: 0.9985 - val_loss: 0.7096 - val_out_1_loss: 0.3714 - val_out_2_loss: 0.3382 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9520\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0131 - out_1_loss: 0.0078 - out_2_loss: 0.0052 - out_1_acc: 0.9972 - out_2_acc: 0.9981 - val_loss: 0.7023 - val_out_1_loss: 0.3637 - val_out_2_loss: 0.3386 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9518\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.0112 - out_1_loss: 0.0071 - out_2_loss: 0.0041 - out_1_acc: 0.9975 - out_2_acc: 0.9985 - val_loss: 0.7188 - val_out_1_loss: 0.3756 - val_out_2_loss: 0.3431 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9512\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0113 - out_1_loss: 0.0074 - out_2_loss: 0.0039 - out_1_acc: 0.9972 - out_2_acc: 0.9986 - val_loss: 0.7295 - val_out_1_loss: 0.3785 - val_out_2_loss: 0.3511 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9511\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0122 - out_1_loss: 0.0079 - out_2_loss: 0.0044 - out_1_acc: 0.9973 - out_2_acc: 0.9984 - val_loss: 0.7109 - val_out_1_loss: 0.3709 - val_out_2_loss: 0.3399 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9512\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0109 - out_1_loss: 0.0069 - out_2_loss: 0.0040 - out_1_acc: 0.9977 - out_2_acc: 0.9986 - val_loss: 0.7105 - val_out_1_loss: 0.3711 - val_out_2_loss: 0.3394 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9518\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0093 - out_1_loss: 0.0062 - out_2_loss: 0.0031 - out_1_acc: 0.9979 - out_2_acc: 0.9989 - val_loss: 0.7235 - val_out_1_loss: 0.3763 - val_out_2_loss: 0.3471 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0076 - out_1_loss: 0.0053 - out_2_loss: 0.0023 - out_1_acc: 0.9983 - out_2_acc: 0.9993 - val_loss: 0.7352 - val_out_1_loss: 0.3787 - val_out_2_loss: 0.3565 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9514\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0066 - out_1_loss: 0.0039 - out_2_loss: 0.0027 - out_1_acc: 0.9987 - out_2_acc: 0.9991 - val_loss: 0.7344 - val_out_1_loss: 0.3786 - val_out_2_loss: 0.3558 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0064 - out_1_loss: 0.0040 - out_2_loss: 0.0023 - out_1_acc: 0.9988 - out_2_acc: 0.9993 - val_loss: 0.7268 - val_out_1_loss: 0.3745 - val_out_2_loss: 0.3524 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9526\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0072 - out_1_loss: 0.0044 - out_2_loss: 0.0028 - out_1_acc: 0.9985 - out_2_acc: 0.9991 - val_loss: 0.7373 - val_out_1_loss: 0.3853 - val_out_2_loss: 0.3520 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0066 - out_1_loss: 0.0045 - out_2_loss: 0.0021 - out_1_acc: 0.9985 - out_2_acc: 0.9992 - val_loss: 0.7351 - val_out_1_loss: 0.3874 - val_out_2_loss: 0.3477 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9522\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0064 - out_1_loss: 0.0040 - out_2_loss: 0.0024 - out_1_acc: 0.9986 - out_2_acc: 0.9992 - val_loss: 0.7364 - val_out_1_loss: 0.3876 - val_out_2_loss: 0.3488 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9520\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0050 - out_1_loss: 0.0032 - out_2_loss: 0.0018 - out_1_acc: 0.9990 - out_2_acc: 0.9994 - val_loss: 0.7398 - val_out_1_loss: 0.3830 - val_out_2_loss: 0.3568 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9525\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0052 - out_1_loss: 0.0034 - out_2_loss: 0.0019 - out_1_acc: 0.9988 - out_2_acc: 0.9993 - val_loss: 0.7392 - val_out_1_loss: 0.3855 - val_out_2_loss: 0.3538 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9522\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0048 - out_1_loss: 0.0030 - out_2_loss: 0.0018 - out_1_acc: 0.9992 - out_2_acc: 0.9993 - val_loss: 0.7488 - val_out_1_loss: 0.3880 - val_out_2_loss: 0.3608 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.0043 - out_1_loss: 0.0028 - out_2_loss: 0.0016 - out_1_acc: 0.9991 - out_2_acc: 0.9995 - val_loss: 0.7538 - val_out_1_loss: 0.3908 - val_out_2_loss: 0.3630 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9523\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0074 - out_1_loss: 0.0039 - out_2_loss: 0.0035 - out_1_acc: 0.9986 - out_2_acc: 0.9988 - val_loss: 0.7619 - val_out_1_loss: 0.3903 - val_out_2_loss: 0.3716 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9511\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0099 - out_1_loss: 0.0053 - out_2_loss: 0.0045 - out_1_acc: 0.9983 - out_2_acc: 0.9985 - val_loss: 0.7441 - val_out_1_loss: 0.3904 - val_out_2_loss: 0.3537 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9514\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0087 - out_1_loss: 0.0049 - out_2_loss: 0.0038 - out_1_acc: 0.9983 - out_2_acc: 0.9986 - val_loss: 0.7418 - val_out_1_loss: 0.3933 - val_out_2_loss: 0.3485 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9511\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0081 - out_1_loss: 0.0047 - out_2_loss: 0.0034 - out_1_acc: 0.9985 - out_2_acc: 0.9989 - val_loss: 0.7509 - val_out_1_loss: 0.3934 - val_out_2_loss: 0.3575 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9506\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.0069 - out_1_loss: 0.0038 - out_2_loss: 0.0030 - out_1_acc: 0.9986 - out_2_acc: 0.9990 - val_loss: 0.7504 - val_out_1_loss: 0.3921 - val_out_2_loss: 0.3583 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9522\n",
      "Epoch 228/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0071 - out_1_loss: 0.0042 - out_2_loss: 0.0029 - out_1_acc: 0.9987 - out_2_acc: 0.9991 - val_loss: 0.7526 - val_out_1_loss: 0.3942 - val_out_2_loss: 0.3583 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9522\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0074 - out_1_loss: 0.0044 - out_2_loss: 0.0030 - out_1_acc: 0.9985 - out_2_acc: 0.9990 - val_loss: 0.7601 - val_out_1_loss: 0.3973 - val_out_2_loss: 0.3628 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9512\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0066 - out_1_loss: 0.0042 - out_2_loss: 0.0023 - out_1_acc: 0.9986 - out_2_acc: 0.9993 - val_loss: 0.7602 - val_out_1_loss: 0.4030 - val_out_2_loss: 0.3572 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0047 - out_1_loss: 0.0034 - out_2_loss: 0.0013 - out_1_acc: 0.9989 - out_2_acc: 0.9996 - val_loss: 0.7739 - val_out_1_loss: 0.4017 - val_out_2_loss: 0.3722 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9513\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 2s 82ms/step - loss: 0.0045 - out_1_loss: 0.0032 - out_2_loss: 0.0013 - out_1_acc: 0.9988 - out_2_acc: 0.9996 - val_loss: 0.7703 - val_out_1_loss: 0.3982 - val_out_2_loss: 0.3721 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9517\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(6)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7539 - out_1_loss: 0.3902 - out_2_loss: 0.3636 - out_1_acc: 0.9395 - out_2_acc: 0.9522\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 9, 20)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 9, 100), (No 48400       input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 100), (None, 80400       vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 9, 100)       48400       input_19[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 100)          80400       vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 100)          10100       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 100)          10100       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           4040        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           4040        dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 285,880\n",
      "Trainable params: 285,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3616 - out_1_loss: 3.6790 - out_2_loss: 3.6825 - out_1_acc: 0.0551 - out_2_acc: 0.0592WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109756). Check your callbacks.\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 6.6110 - out_1_loss: 3.3329 - out_2_loss: 3.2782 - out_1_acc: 0.2553 - out_2_acc: 0.2804 - val_loss: 5.4839 - val_out_1_loss: 2.8128 - val_out_2_loss: 2.6711 - val_out_1_acc: 0.2858 - val_out_2_acc: 0.3323\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 4.5837 - out_1_loss: 2.4453 - out_2_loss: 2.1384 - out_1_acc: 0.3642 - out_2_acc: 0.4485 - val_loss: 3.5524 - val_out_1_loss: 2.0196 - val_out_2_loss: 1.5328 - val_out_1_acc: 0.4460 - val_out_2_acc: 0.6042\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 2.7512 - out_1_loss: 1.6212 - out_2_loss: 1.1299 - out_1_acc: 0.5463 - out_2_acc: 0.7060 - val_loss: 2.0976 - val_out_1_loss: 1.2743 - val_out_2_loss: 0.8232 - val_out_1_acc: 0.6355 - val_out_2_acc: 0.7864\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 1.6610 - out_1_loss: 1.0353 - out_2_loss: 0.6257 - out_1_acc: 0.6927 - out_2_acc: 0.8376 - val_loss: 1.3414 - val_out_1_loss: 0.8426 - val_out_2_loss: 0.4988 - val_out_1_acc: 0.7500 - val_out_2_acc: 0.8738\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 1.1141 - out_1_loss: 0.7178 - out_2_loss: 0.3962 - out_1_acc: 0.7881 - out_2_acc: 0.8985 - val_loss: 0.9507 - val_out_1_loss: 0.6078 - val_out_2_loss: 0.3429 - val_out_1_acc: 0.8298 - val_out_2_acc: 0.9105\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.8073 - out_1_loss: 0.5282 - out_2_loss: 0.2792 - out_1_acc: 0.8508 - out_2_acc: 0.9274 - val_loss: 0.7124 - val_out_1_loss: 0.4552 - val_out_2_loss: 0.2572 - val_out_1_acc: 0.8758 - val_out_2_acc: 0.9295\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.6108 - out_1_loss: 0.3959 - out_2_loss: 0.2150 - out_1_acc: 0.8877 - out_2_acc: 0.9407 - val_loss: 0.5570 - val_out_1_loss: 0.3502 - val_out_2_loss: 0.2068 - val_out_1_acc: 0.9023 - val_out_2_acc: 0.9405\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.4797 - out_1_loss: 0.3052 - out_2_loss: 0.1745 - out_1_acc: 0.9110 - out_2_acc: 0.9472 - val_loss: 0.4505 - val_out_1_loss: 0.2774 - val_out_2_loss: 0.1730 - val_out_1_acc: 0.9183 - val_out_2_acc: 0.9445\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3895 - out_1_loss: 0.2430 - out_2_loss: 0.1465 - out_1_acc: 0.9239 - out_2_acc: 0.9506 - val_loss: 0.3775 - val_out_1_loss: 0.2263 - val_out_2_loss: 0.1512 - val_out_1_acc: 0.9280 - val_out_2_acc: 0.9478\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.3292 - out_1_loss: 0.2010 - out_2_loss: 0.1282 - out_1_acc: 0.9301 - out_2_acc: 0.9525 - val_loss: 0.3219 - val_out_1_loss: 0.1905 - val_out_2_loss: 0.1314 - val_out_1_acc: 0.9321 - val_out_2_acc: 0.9486\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2872 - out_1_loss: 0.1725 - out_2_loss: 0.1147 - out_1_acc: 0.9335 - out_2_acc: 0.9536 - val_loss: 0.2887 - val_out_1_loss: 0.1675 - val_out_2_loss: 0.1212 - val_out_1_acc: 0.9358 - val_out_2_acc: 0.9493\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.2595 - out_1_loss: 0.1532 - out_2_loss: 0.1063 - out_1_acc: 0.9368 - out_2_acc: 0.9542 - val_loss: 0.2661 - val_out_1_loss: 0.1529 - val_out_2_loss: 0.1132 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9500\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.2407 - out_1_loss: 0.1404 - out_2_loss: 0.1002 - out_1_acc: 0.9386 - out_2_acc: 0.9548 - val_loss: 0.2506 - val_out_1_loss: 0.1422 - val_out_2_loss: 0.1083 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9493\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2281 - out_1_loss: 0.1316 - out_2_loss: 0.0965 - out_1_acc: 0.9396 - out_2_acc: 0.9549 - val_loss: 0.2407 - val_out_1_loss: 0.1357 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9504\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2190 - out_1_loss: 0.1251 - out_2_loss: 0.0939 - out_1_acc: 0.9400 - out_2_acc: 0.9550 - val_loss: 0.2319 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1026 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2122 - out_1_loss: 0.1204 - out_2_loss: 0.0919 - out_1_acc: 0.9403 - out_2_acc: 0.9555 - val_loss: 0.2268 - val_out_1_loss: 0.1252 - val_out_2_loss: 0.1016 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.2066 - out_1_loss: 0.1164 - out_2_loss: 0.0901 - out_1_acc: 0.9412 - out_2_acc: 0.9557 - val_loss: 0.2232 - val_out_1_loss: 0.1219 - val_out_2_loss: 0.1013 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9501\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.2017 - out_1_loss: 0.1132 - out_2_loss: 0.0885 - out_1_acc: 0.9415 - out_2_acc: 0.9557 - val_loss: 0.2189 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.0991 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9507\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1974 - out_1_loss: 0.1105 - out_2_loss: 0.0869 - out_1_acc: 0.9419 - out_2_acc: 0.9556 - val_loss: 0.2160 - val_out_1_loss: 0.1181 - val_out_2_loss: 0.0980 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9507\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1942 - out_1_loss: 0.1086 - out_2_loss: 0.0856 - out_1_acc: 0.9419 - out_2_acc: 0.9563 - val_loss: 0.2127 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9511\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1914 - out_1_loss: 0.1070 - out_2_loss: 0.0844 - out_1_acc: 0.9424 - out_2_acc: 0.9562 - val_loss: 0.2113 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9505\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1893 - out_1_loss: 0.1057 - out_2_loss: 0.0836 - out_1_acc: 0.9423 - out_2_acc: 0.9562 - val_loss: 0.2105 - val_out_1_loss: 0.1142 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9496\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1875 - out_1_loss: 0.1047 - out_2_loss: 0.0828 - out_1_acc: 0.9429 - out_2_acc: 0.9567 - val_loss: 0.2088 - val_out_1_loss: 0.1131 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1860 - out_1_loss: 0.1040 - out_2_loss: 0.0821 - out_1_acc: 0.9430 - out_2_acc: 0.9567 - val_loss: 0.2076 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0956 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9504\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1850 - out_1_loss: 0.1034 - out_2_loss: 0.0816 - out_1_acc: 0.9430 - out_2_acc: 0.9569 - val_loss: 0.2073 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9505\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1845 - out_1_loss: 0.1031 - out_2_loss: 0.0814 - out_1_acc: 0.9430 - out_2_acc: 0.9567 - val_loss: 0.2070 - val_out_1_loss: 0.1115 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9506\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1829 - out_1_loss: 0.1021 - out_2_loss: 0.0808 - out_1_acc: 0.9432 - out_2_acc: 0.9572 - val_loss: 0.2070 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9496\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1817 - out_1_loss: 0.1010 - out_2_loss: 0.0807 - out_1_acc: 0.9435 - out_2_acc: 0.9572 - val_loss: 0.2058 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9507\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1814 - out_1_loss: 0.1009 - out_2_loss: 0.0805 - out_1_acc: 0.9434 - out_2_acc: 0.9569 - val_loss: 0.2061 - val_out_1_loss: 0.1102 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9506\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1819 - out_1_loss: 0.1018 - out_2_loss: 0.0801 - out_1_acc: 0.9428 - out_2_acc: 0.9570 - val_loss: 0.2056 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9516\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1790 - out_1_loss: 0.0996 - out_2_loss: 0.0794 - out_1_acc: 0.9437 - out_2_acc: 0.9577 - val_loss: 0.2060 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.0960 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9511\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1787 - out_1_loss: 0.0993 - out_2_loss: 0.0794 - out_1_acc: 0.9436 - out_2_acc: 0.9575 - val_loss: 0.2061 - val_out_1_loss: 0.1107 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9518\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1785 - out_1_loss: 0.0992 - out_2_loss: 0.0793 - out_1_acc: 0.9438 - out_2_acc: 0.9574 - val_loss: 0.2051 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9511\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1776 - out_1_loss: 0.0983 - out_2_loss: 0.0793 - out_1_acc: 0.9441 - out_2_acc: 0.9576 - val_loss: 0.2084 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0979 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9515\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1783 - out_1_loss: 0.0982 - out_2_loss: 0.0801 - out_1_acc: 0.9443 - out_2_acc: 0.9570 - val_loss: 0.2041 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9517\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1767 - out_1_loss: 0.0978 - out_2_loss: 0.0789 - out_1_acc: 0.9445 - out_2_acc: 0.9575 - val_loss: 0.2056 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0966 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1762 - out_1_loss: 0.0977 - out_2_loss: 0.0785 - out_1_acc: 0.9440 - out_2_acc: 0.9571 - val_loss: 0.2041 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1754 - out_1_loss: 0.0971 - out_2_loss: 0.0783 - out_1_acc: 0.9447 - out_2_acc: 0.9577 - val_loss: 0.2050 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9508\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1754 - out_1_loss: 0.0970 - out_2_loss: 0.0784 - out_1_acc: 0.9448 - out_2_acc: 0.9573 - val_loss: 0.2049 - val_out_1_loss: 0.1086 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9517\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1749 - out_1_loss: 0.0969 - out_2_loss: 0.0780 - out_1_acc: 0.9449 - out_2_acc: 0.9579 - val_loss: 0.2058 - val_out_1_loss: 0.1092 - val_out_2_loss: 0.0966 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9512\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1741 - out_1_loss: 0.0970 - out_2_loss: 0.0771 - out_1_acc: 0.9449 - out_2_acc: 0.9584 - val_loss: 0.2036 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0942 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.1733 - out_1_loss: 0.0968 - out_2_loss: 0.0764 - out_1_acc: 0.9450 - out_2_acc: 0.9587 - val_loss: 0.2033 - val_out_1_loss: 0.1088 - val_out_2_loss: 0.0945 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9518\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1725 - out_1_loss: 0.0966 - out_2_loss: 0.0759 - out_1_acc: 0.9451 - out_2_acc: 0.9582 - val_loss: 0.2038 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9512\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1719 - out_1_loss: 0.0963 - out_2_loss: 0.0756 - out_1_acc: 0.9448 - out_2_acc: 0.9589 - val_loss: 0.2033 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0950 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9517\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1711 - out_1_loss: 0.0962 - out_2_loss: 0.0749 - out_1_acc: 0.9450 - out_2_acc: 0.9592 - val_loss: 0.2037 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9517\n",
      "Epoch 46/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1709 - out_1_loss: 0.0960 - out_2_loss: 0.0749 - out_1_acc: 0.9451 - out_2_acc: 0.9594 - val_loss: 0.2054 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9523\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.1706 - out_1_loss: 0.0960 - out_2_loss: 0.0746 - out_1_acc: 0.9455 - out_2_acc: 0.9597 - val_loss: 0.2057 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.0952 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9519\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1708 - out_1_loss: 0.0964 - out_2_loss: 0.0744 - out_1_acc: 0.9453 - out_2_acc: 0.9600 - val_loss: 0.2040 - val_out_1_loss: 0.1089 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1711 - out_1_loss: 0.0968 - out_2_loss: 0.0742 - out_1_acc: 0.9452 - out_2_acc: 0.9598 - val_loss: 0.2060 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9520\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1699 - out_1_loss: 0.0958 - out_2_loss: 0.0741 - out_1_acc: 0.9453 - out_2_acc: 0.9604 - val_loss: 0.2028 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.0949 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9518\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1690 - out_1_loss: 0.0953 - out_2_loss: 0.0737 - out_1_acc: 0.9457 - out_2_acc: 0.9600 - val_loss: 0.2035 - val_out_1_loss: 0.1081 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9513\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1688 - out_1_loss: 0.0953 - out_2_loss: 0.0736 - out_1_acc: 0.9452 - out_2_acc: 0.9602 - val_loss: 0.2049 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0951 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9523\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1687 - out_1_loss: 0.0954 - out_2_loss: 0.0732 - out_1_acc: 0.9456 - out_2_acc: 0.9603 - val_loss: 0.2041 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.0947 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.1696 - out_1_loss: 0.0953 - out_2_loss: 0.0742 - out_1_acc: 0.9456 - out_2_acc: 0.9596 - val_loss: 0.2076 - val_out_1_loss: 0.1097 - val_out_2_loss: 0.0979 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9520\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1689 - out_1_loss: 0.0953 - out_2_loss: 0.0736 - out_1_acc: 0.9459 - out_2_acc: 0.9601 - val_loss: 0.2074 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9513\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1675 - out_1_loss: 0.0950 - out_2_loss: 0.0725 - out_1_acc: 0.9458 - out_2_acc: 0.9605 - val_loss: 0.2056 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0961 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9520\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1675 - out_1_loss: 0.0950 - out_2_loss: 0.0725 - out_1_acc: 0.9457 - out_2_acc: 0.9606 - val_loss: 0.2071 - val_out_1_loss: 0.1112 - val_out_2_loss: 0.0959 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9515\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1670 - out_1_loss: 0.0949 - out_2_loss: 0.0721 - out_1_acc: 0.9457 - out_2_acc: 0.9609 - val_loss: 0.2067 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0954 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9517\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1657 - out_1_loss: 0.0944 - out_2_loss: 0.0713 - out_1_acc: 0.9459 - out_2_acc: 0.9610 - val_loss: 0.2072 - val_out_1_loss: 0.1098 - val_out_2_loss: 0.0974 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9506\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1662 - out_1_loss: 0.0943 - out_2_loss: 0.0719 - out_1_acc: 0.9464 - out_2_acc: 0.9611 - val_loss: 0.2077 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0976 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9513\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.1659 - out_1_loss: 0.0943 - out_2_loss: 0.0716 - out_1_acc: 0.9465 - out_2_acc: 0.9615 - val_loss: 0.2081 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.0985 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9513\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1663 - out_1_loss: 0.0943 - out_2_loss: 0.0720 - out_1_acc: 0.9466 - out_2_acc: 0.9604 - val_loss: 0.2100 - val_out_1_loss: 0.1113 - val_out_2_loss: 0.0987 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9507\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1662 - out_1_loss: 0.0941 - out_2_loss: 0.0721 - out_1_acc: 0.9467 - out_2_acc: 0.9605 - val_loss: 0.2091 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.0986 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9515\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1665 - out_1_loss: 0.0943 - out_2_loss: 0.0722 - out_1_acc: 0.9467 - out_2_acc: 0.9608 - val_loss: 0.2088 - val_out_1_loss: 0.1101 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1660 - out_1_loss: 0.0937 - out_2_loss: 0.0723 - out_1_acc: 0.9468 - out_2_acc: 0.9607 - val_loss: 0.2081 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.0982 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1661 - out_1_loss: 0.0940 - out_2_loss: 0.0721 - out_1_acc: 0.9471 - out_2_acc: 0.9603 - val_loss: 0.2113 - val_out_1_loss: 0.1114 - val_out_2_loss: 0.0999 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1663 - out_1_loss: 0.0949 - out_2_loss: 0.0713 - out_1_acc: 0.9462 - out_2_acc: 0.9603 - val_loss: 0.2134 - val_out_1_loss: 0.1137 - val_out_2_loss: 0.0997 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9510\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1663 - out_1_loss: 0.0946 - out_2_loss: 0.0717 - out_1_acc: 0.9465 - out_2_acc: 0.9608 - val_loss: 0.2112 - val_out_1_loss: 0.1111 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9516\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1645 - out_1_loss: 0.0938 - out_2_loss: 0.0707 - out_1_acc: 0.9466 - out_2_acc: 0.9615 - val_loss: 0.2090 - val_out_1_loss: 0.1087 - val_out_2_loss: 0.1004 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9511\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1634 - out_1_loss: 0.0936 - out_2_loss: 0.0699 - out_1_acc: 0.9473 - out_2_acc: 0.9614 - val_loss: 0.2088 - val_out_1_loss: 0.1085 - val_out_2_loss: 0.1003 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9509\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1631 - out_1_loss: 0.0934 - out_2_loss: 0.0698 - out_1_acc: 0.9469 - out_2_acc: 0.9619 - val_loss: 0.2104 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1623 - out_1_loss: 0.0926 - out_2_loss: 0.0698 - out_1_acc: 0.9472 - out_2_acc: 0.9614 - val_loss: 0.2099 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9513\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1617 - out_1_loss: 0.0926 - out_2_loss: 0.0692 - out_1_acc: 0.9473 - out_2_acc: 0.9620 - val_loss: 0.2133 - val_out_1_loss: 0.1105 - val_out_2_loss: 0.1028 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9505\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1609 - out_1_loss: 0.0924 - out_2_loss: 0.0685 - out_1_acc: 0.9473 - out_2_acc: 0.9617 - val_loss: 0.2084 - val_out_1_loss: 0.1084 - val_out_2_loss: 0.0999 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9523\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1592 - out_1_loss: 0.0919 - out_2_loss: 0.0673 - out_1_acc: 0.9477 - out_2_acc: 0.9633 - val_loss: 0.2095 - val_out_1_loss: 0.1079 - val_out_2_loss: 0.1016 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9519\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1588 - out_1_loss: 0.0916 - out_2_loss: 0.0672 - out_1_acc: 0.9479 - out_2_acc: 0.9634 - val_loss: 0.2122 - val_out_1_loss: 0.1090 - val_out_2_loss: 0.1032 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9513\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1583 - out_1_loss: 0.0915 - out_2_loss: 0.0669 - out_1_acc: 0.9480 - out_2_acc: 0.9628 - val_loss: 0.2113 - val_out_1_loss: 0.1093 - val_out_2_loss: 0.1020 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9515\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1586 - out_1_loss: 0.0916 - out_2_loss: 0.0671 - out_1_acc: 0.9472 - out_2_acc: 0.9632 - val_loss: 0.2106 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.1012 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9513\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1581 - out_1_loss: 0.0912 - out_2_loss: 0.0669 - out_1_acc: 0.9482 - out_2_acc: 0.9629 - val_loss: 0.2128 - val_out_1_loss: 0.1094 - val_out_2_loss: 0.1034 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9516\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1572 - out_1_loss: 0.0911 - out_2_loss: 0.0661 - out_1_acc: 0.9482 - out_2_acc: 0.9640 - val_loss: 0.2126 - val_out_1_loss: 0.1095 - val_out_2_loss: 0.1031 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1569 - out_1_loss: 0.0909 - out_2_loss: 0.0660 - out_1_acc: 0.9485 - out_2_acc: 0.9640 - val_loss: 0.2132 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1032 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9521\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1569 - out_1_loss: 0.0908 - out_2_loss: 0.0661 - out_1_acc: 0.9483 - out_2_acc: 0.9639 - val_loss: 0.2129 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9516\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1599 - out_1_loss: 0.0908 - out_2_loss: 0.0690 - out_1_acc: 0.9482 - out_2_acc: 0.9623 - val_loss: 0.2131 - val_out_1_loss: 0.1104 - val_out_2_loss: 0.1027 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9508\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1569 - out_1_loss: 0.0906 - out_2_loss: 0.0663 - out_1_acc: 0.9484 - out_2_acc: 0.9633 - val_loss: 0.2121 - val_out_1_loss: 0.1100 - val_out_2_loss: 0.1021 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9509\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1569 - out_1_loss: 0.0908 - out_2_loss: 0.0661 - out_1_acc: 0.9485 - out_2_acc: 0.9635 - val_loss: 0.2158 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.1059 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9509\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1558 - out_1_loss: 0.0904 - out_2_loss: 0.0654 - out_1_acc: 0.9485 - out_2_acc: 0.9643 - val_loss: 0.2181 - val_out_1_loss: 0.1106 - val_out_2_loss: 0.1074 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9509\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 1s 42ms/step - loss: 0.1565 - out_1_loss: 0.0905 - out_2_loss: 0.0660 - out_1_acc: 0.9491 - out_2_acc: 0.9638 - val_loss: 0.2149 - val_out_1_loss: 0.1099 - val_out_2_loss: 0.1050 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9523\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1558 - out_1_loss: 0.0899 - out_2_loss: 0.0658 - out_1_acc: 0.9491 - out_2_acc: 0.9639 - val_loss: 0.2185 - val_out_1_loss: 0.1108 - val_out_2_loss: 0.1078 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9516\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1577 - out_1_loss: 0.0906 - out_2_loss: 0.0672 - out_1_acc: 0.9485 - out_2_acc: 0.9635 - val_loss: 0.2168 - val_out_1_loss: 0.1110 - val_out_2_loss: 0.1058 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9515\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1566 - out_1_loss: 0.0903 - out_2_loss: 0.0663 - out_1_acc: 0.9492 - out_2_acc: 0.9637 - val_loss: 0.2192 - val_out_1_loss: 0.1126 - val_out_2_loss: 0.1066 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9507\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1573 - out_1_loss: 0.0905 - out_2_loss: 0.0668 - out_1_acc: 0.9489 - out_2_acc: 0.9631 - val_loss: 0.2188 - val_out_1_loss: 0.1118 - val_out_2_loss: 0.1070 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9515\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1558 - out_1_loss: 0.0901 - out_2_loss: 0.0657 - out_1_acc: 0.9488 - out_2_acc: 0.9638 - val_loss: 0.2201 - val_out_1_loss: 0.1119 - val_out_2_loss: 0.1082 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9517\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1563 - out_1_loss: 0.0906 - out_2_loss: 0.0657 - out_1_acc: 0.9489 - out_2_acc: 0.9638 - val_loss: 0.2200 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.1079 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9512\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1551 - out_1_loss: 0.0904 - out_2_loss: 0.0647 - out_1_acc: 0.9485 - out_2_acc: 0.9645 - val_loss: 0.2187 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1060 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9517\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1527 - out_1_loss: 0.0897 - out_2_loss: 0.0629 - out_1_acc: 0.9494 - out_2_acc: 0.9652 - val_loss: 0.2203 - val_out_1_loss: 0.1127 - val_out_2_loss: 0.1076 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9519\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1525 - out_1_loss: 0.0896 - out_2_loss: 0.0630 - out_1_acc: 0.9487 - out_2_acc: 0.9652 - val_loss: 0.2181 - val_out_1_loss: 0.1121 - val_out_2_loss: 0.1060 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9522\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1535 - out_1_loss: 0.0901 - out_2_loss: 0.0634 - out_1_acc: 0.9488 - out_2_acc: 0.9654 - val_loss: 0.2215 - val_out_1_loss: 0.1130 - val_out_2_loss: 0.1086 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9515\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1519 - out_1_loss: 0.0893 - out_2_loss: 0.0626 - out_1_acc: 0.9492 - out_2_acc: 0.9648 - val_loss: 0.2207 - val_out_1_loss: 0.1124 - val_out_2_loss: 0.1082 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1511 - out_1_loss: 0.0893 - out_2_loss: 0.0617 - out_1_acc: 0.9498 - out_2_acc: 0.9658 - val_loss: 0.2228 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9512\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1502 - out_1_loss: 0.0888 - out_2_loss: 0.0614 - out_1_acc: 0.9493 - out_2_acc: 0.9661 - val_loss: 0.2239 - val_out_1_loss: 0.1147 - val_out_2_loss: 0.1092 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9515\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1504 - out_1_loss: 0.0891 - out_2_loss: 0.0613 - out_1_acc: 0.9494 - out_2_acc: 0.9661 - val_loss: 0.2228 - val_out_1_loss: 0.1151 - val_out_2_loss: 0.1076 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9521\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1503 - out_1_loss: 0.0895 - out_2_loss: 0.0609 - out_1_acc: 0.9486 - out_2_acc: 0.9666 - val_loss: 0.2233 - val_out_1_loss: 0.1150 - val_out_2_loss: 0.1082 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9517\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1485 - out_1_loss: 0.0885 - out_2_loss: 0.0599 - out_1_acc: 0.9492 - out_2_acc: 0.9667 - val_loss: 0.2213 - val_out_1_loss: 0.1144 - val_out_2_loss: 0.1069 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9514\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1482 - out_1_loss: 0.0883 - out_2_loss: 0.0599 - out_1_acc: 0.9493 - out_2_acc: 0.9669 - val_loss: 0.2233 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1087 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9513\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1480 - out_1_loss: 0.0882 - out_2_loss: 0.0597 - out_1_acc: 0.9499 - out_2_acc: 0.9667 - val_loss: 0.2226 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1094 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9520\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1471 - out_1_loss: 0.0879 - out_2_loss: 0.0593 - out_1_acc: 0.9501 - out_2_acc: 0.9672 - val_loss: 0.2248 - val_out_1_loss: 0.1140 - val_out_2_loss: 0.1108 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9508\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1472 - out_1_loss: 0.0885 - out_2_loss: 0.0587 - out_1_acc: 0.9498 - out_2_acc: 0.9677 - val_loss: 0.2242 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1107 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1463 - out_1_loss: 0.0881 - out_2_loss: 0.0582 - out_1_acc: 0.9505 - out_2_acc: 0.9684 - val_loss: 0.2256 - val_out_1_loss: 0.1135 - val_out_2_loss: 0.1121 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9515\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1459 - out_1_loss: 0.0877 - out_2_loss: 0.0582 - out_1_acc: 0.9500 - out_2_acc: 0.9678 - val_loss: 0.2266 - val_out_1_loss: 0.1129 - val_out_2_loss: 0.1137 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9517\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1454 - out_1_loss: 0.0876 - out_2_loss: 0.0578 - out_1_acc: 0.9504 - out_2_acc: 0.9677 - val_loss: 0.2257 - val_out_1_loss: 0.1136 - val_out_2_loss: 0.1121 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9518\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1449 - out_1_loss: 0.0874 - out_2_loss: 0.0575 - out_1_acc: 0.9506 - out_2_acc: 0.9677 - val_loss: 0.2281 - val_out_1_loss: 0.1141 - val_out_2_loss: 0.1139 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 1s 38ms/step - loss: 0.1444 - out_1_loss: 0.0871 - out_2_loss: 0.0573 - out_1_acc: 0.9511 - out_2_acc: 0.9679 - val_loss: 0.2271 - val_out_1_loss: 0.1134 - val_out_2_loss: 0.1138 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9515\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.1440 - out_1_loss: 0.0872 - out_2_loss: 0.0568 - out_1_acc: 0.9508 - out_2_acc: 0.9686 - val_loss: 0.2282 - val_out_1_loss: 0.1132 - val_out_2_loss: 0.1150 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9525\n",
      "Epoch 114/150\n",
      " 1/28 [>.............................] - ETA: 0s - loss: 0.1446 - out_1_loss: 0.0857 - out_2_loss: 0.0589 - out_1_acc: 0.9534 - out_2_acc: 0.9685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1316 - out_1_loss: 0.0800 - out_2_loss: 0.0516 - out_1_acc: 0.9556 - out_2_acc: 0.9689 - val_loss: 0.2499 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1276 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9516\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1301 - out_1_loss: 0.0795 - out_2_loss: 0.0506 - out_1_acc: 0.9556 - out_2_acc: 0.9695 - val_loss: 0.2506 - val_out_1_loss: 0.1231 - val_out_2_loss: 0.1275 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9524\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1294 - out_1_loss: 0.0791 - out_2_loss: 0.0503 - out_1_acc: 0.9566 - out_2_acc: 0.9698 - val_loss: 0.2556 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1300 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9523\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1296 - out_1_loss: 0.0792 - out_2_loss: 0.0504 - out_1_acc: 0.9559 - out_2_acc: 0.9700 - val_loss: 0.2562 - val_out_1_loss: 0.1260 - val_out_2_loss: 0.1302 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9523\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1295 - out_1_loss: 0.0792 - out_2_loss: 0.0504 - out_1_acc: 0.9562 - out_2_acc: 0.9696 - val_loss: 0.2575 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1318 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9520\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1289 - out_1_loss: 0.0785 - out_2_loss: 0.0504 - out_1_acc: 0.9560 - out_2_acc: 0.9696 - val_loss: 0.2558 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1304 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9511\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1289 - out_1_loss: 0.0788 - out_2_loss: 0.0501 - out_1_acc: 0.9565 - out_2_acc: 0.9705 - val_loss: 0.2579 - val_out_1_loss: 0.1253 - val_out_2_loss: 0.1326 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9513\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1281 - out_1_loss: 0.0784 - out_2_loss: 0.0497 - out_1_acc: 0.9563 - out_2_acc: 0.9702 - val_loss: 0.2600 - val_out_1_loss: 0.1260 - val_out_2_loss: 0.1340 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9519\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1271 - out_1_loss: 0.0775 - out_2_loss: 0.0496 - out_1_acc: 0.9567 - out_2_acc: 0.9700 - val_loss: 0.2604 - val_out_1_loss: 0.1265 - val_out_2_loss: 0.1340 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9518\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1265 - out_1_loss: 0.0770 - out_2_loss: 0.0494 - out_1_acc: 0.9572 - out_2_acc: 0.9708 - val_loss: 0.2641 - val_out_1_loss: 0.1274 - val_out_2_loss: 0.1367 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9513\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1272 - out_1_loss: 0.0775 - out_2_loss: 0.0497 - out_1_acc: 0.9568 - out_2_acc: 0.9704 - val_loss: 0.2669 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.1402 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9523\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1262 - out_1_loss: 0.0770 - out_2_loss: 0.0493 - out_1_acc: 0.9574 - out_2_acc: 0.9708 - val_loss: 0.2678 - val_out_1_loss: 0.1271 - val_out_2_loss: 0.1406 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1249 - out_1_loss: 0.0757 - out_2_loss: 0.0492 - out_1_acc: 0.9584 - out_2_acc: 0.9707 - val_loss: 0.2661 - val_out_1_loss: 0.1296 - val_out_2_loss: 0.1365 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9520\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1251 - out_1_loss: 0.0762 - out_2_loss: 0.0489 - out_1_acc: 0.9578 - out_2_acc: 0.9709 - val_loss: 0.2682 - val_out_1_loss: 0.1290 - val_out_2_loss: 0.1392 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9521\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1244 - out_1_loss: 0.0758 - out_2_loss: 0.0486 - out_1_acc: 0.9578 - out_2_acc: 0.9711 - val_loss: 0.2685 - val_out_1_loss: 0.1293 - val_out_2_loss: 0.1392 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9516\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1225 - out_1_loss: 0.0743 - out_2_loss: 0.0481 - out_1_acc: 0.9588 - out_2_acc: 0.9715 - val_loss: 0.2771 - val_out_1_loss: 0.1336 - val_out_2_loss: 0.1435 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9513\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1233 - out_1_loss: 0.0740 - out_2_loss: 0.0493 - out_1_acc: 0.9592 - out_2_acc: 0.9713 - val_loss: 0.2742 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1412 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1220 - out_1_loss: 0.0737 - out_2_loss: 0.0483 - out_1_acc: 0.9590 - out_2_acc: 0.9712 - val_loss: 0.2777 - val_out_1_loss: 0.1343 - val_out_2_loss: 0.1434 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9519\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1219 - out_1_loss: 0.0736 - out_2_loss: 0.0483 - out_1_acc: 0.9588 - out_2_acc: 0.9717 - val_loss: 0.2800 - val_out_1_loss: 0.1351 - val_out_2_loss: 0.1448 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9519\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1228 - out_1_loss: 0.0740 - out_2_loss: 0.0488 - out_1_acc: 0.9591 - out_2_acc: 0.9711 - val_loss: 0.2850 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1495 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9518\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.1230 - out_1_loss: 0.0744 - out_2_loss: 0.0486 - out_1_acc: 0.9585 - out_2_acc: 0.9718 - val_loss: 0.2798 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1456 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9526\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1229 - out_1_loss: 0.0746 - out_2_loss: 0.0482 - out_1_acc: 0.9587 - out_2_acc: 0.9716 - val_loss: 0.2832 - val_out_1_loss: 0.1367 - val_out_2_loss: 0.1465 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9511\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1221 - out_1_loss: 0.0738 - out_2_loss: 0.0483 - out_1_acc: 0.9588 - out_2_acc: 0.9716 - val_loss: 0.2812 - val_out_1_loss: 0.1357 - val_out_2_loss: 0.1455 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9520\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1214 - out_1_loss: 0.0736 - out_2_loss: 0.0478 - out_1_acc: 0.9590 - out_2_acc: 0.9719 - val_loss: 0.2821 - val_out_1_loss: 0.1352 - val_out_2_loss: 0.1469 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9512\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1209 - out_1_loss: 0.0730 - out_2_loss: 0.0479 - out_1_acc: 0.9599 - out_2_acc: 0.9721 - val_loss: 0.2830 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1475 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9511\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.1202 - out_1_loss: 0.0727 - out_2_loss: 0.0475 - out_1_acc: 0.9601 - out_2_acc: 0.9724 - val_loss: 0.2815 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1460 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9522\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1194 - out_1_loss: 0.0717 - out_2_loss: 0.0478 - out_1_acc: 0.9598 - out_2_acc: 0.9721 - val_loss: 0.2782 - val_out_1_loss: 0.1342 - val_out_2_loss: 0.1439 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9515\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1201 - out_1_loss: 0.0720 - out_2_loss: 0.0481 - out_1_acc: 0.9598 - out_2_acc: 0.9726 - val_loss: 0.2780 - val_out_1_loss: 0.1355 - val_out_2_loss: 0.1425 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9519\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1191 - out_1_loss: 0.0719 - out_2_loss: 0.0472 - out_1_acc: 0.9601 - out_2_acc: 0.9728 - val_loss: 0.2861 - val_out_1_loss: 0.1386 - val_out_2_loss: 0.1474 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9505\n",
      "Epoch 105/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1188 - out_1_loss: 0.0717 - out_2_loss: 0.0470 - out_1_acc: 0.9599 - out_2_acc: 0.9728 - val_loss: 0.2950 - val_out_1_loss: 0.1415 - val_out_2_loss: 0.1535 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9515\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1191 - out_1_loss: 0.0718 - out_2_loss: 0.0473 - out_1_acc: 0.9599 - out_2_acc: 0.9723 - val_loss: 0.2899 - val_out_1_loss: 0.1412 - val_out_2_loss: 0.1487 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9509\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1186 - out_1_loss: 0.0716 - out_2_loss: 0.0471 - out_1_acc: 0.9599 - out_2_acc: 0.9731 - val_loss: 0.2955 - val_out_1_loss: 0.1425 - val_out_2_loss: 0.1530 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9512\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1182 - out_1_loss: 0.0714 - out_2_loss: 0.0468 - out_1_acc: 0.9601 - out_2_acc: 0.9735 - val_loss: 0.2968 - val_out_1_loss: 0.1451 - val_out_2_loss: 0.1518 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9512\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1172 - out_1_loss: 0.0708 - out_2_loss: 0.0465 - out_1_acc: 0.9605 - out_2_acc: 0.9738 - val_loss: 0.2962 - val_out_1_loss: 0.1443 - val_out_2_loss: 0.1520 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9518\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1189 - out_1_loss: 0.0716 - out_2_loss: 0.0473 - out_1_acc: 0.9600 - out_2_acc: 0.9725 - val_loss: 0.2948 - val_out_1_loss: 0.1399 - val_out_2_loss: 0.1549 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9509\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1175 - out_1_loss: 0.0708 - out_2_loss: 0.0467 - out_1_acc: 0.9604 - out_2_acc: 0.9731 - val_loss: 0.2987 - val_out_1_loss: 0.1431 - val_out_2_loss: 0.1556 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9518\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1166 - out_1_loss: 0.0707 - out_2_loss: 0.0460 - out_1_acc: 0.9600 - out_2_acc: 0.9737 - val_loss: 0.2977 - val_out_1_loss: 0.1452 - val_out_2_loss: 0.1526 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9516\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1172 - out_1_loss: 0.0706 - out_2_loss: 0.0466 - out_1_acc: 0.9607 - out_2_acc: 0.9735 - val_loss: 0.2969 - val_out_1_loss: 0.1468 - val_out_2_loss: 0.1501 - val_out_1_acc: 0.9377 - val_out_2_acc: 0.9523\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1179 - out_1_loss: 0.0715 - out_2_loss: 0.0465 - out_1_acc: 0.9601 - out_2_acc: 0.9736 - val_loss: 0.3077 - val_out_1_loss: 0.1487 - val_out_2_loss: 0.1590 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9526\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1180 - out_1_loss: 0.0713 - out_2_loss: 0.0467 - out_1_acc: 0.9606 - out_2_acc: 0.9739 - val_loss: 0.3032 - val_out_1_loss: 0.1489 - val_out_2_loss: 0.1543 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9515\n",
      "Epoch 116/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1164 - out_1_loss: 0.0702 - out_2_loss: 0.0462 - out_1_acc: 0.9615 - out_2_acc: 0.9737 - val_loss: 0.3042 - val_out_1_loss: 0.1494 - val_out_2_loss: 0.1548 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9517\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1155 - out_1_loss: 0.0698 - out_2_loss: 0.0457 - out_1_acc: 0.9609 - out_2_acc: 0.9748 - val_loss: 0.3049 - val_out_1_loss: 0.1502 - val_out_2_loss: 0.1547 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9510\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1183 - out_1_loss: 0.0714 - out_2_loss: 0.0469 - out_1_acc: 0.9604 - out_2_acc: 0.9739 - val_loss: 0.3062 - val_out_1_loss: 0.1483 - val_out_2_loss: 0.1579 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9518\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1183 - out_1_loss: 0.0707 - out_2_loss: 0.0476 - out_1_acc: 0.9610 - out_2_acc: 0.9733 - val_loss: 0.2992 - val_out_1_loss: 0.1449 - val_out_2_loss: 0.1543 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9508\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1178 - out_1_loss: 0.0715 - out_2_loss: 0.0464 - out_1_acc: 0.9605 - out_2_acc: 0.9742 - val_loss: 0.3048 - val_out_1_loss: 0.1459 - val_out_2_loss: 0.1589 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9510\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1164 - out_1_loss: 0.0705 - out_2_loss: 0.0459 - out_1_acc: 0.9609 - out_2_acc: 0.9746 - val_loss: 0.3008 - val_out_1_loss: 0.1467 - val_out_2_loss: 0.1541 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9509\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1170 - out_1_loss: 0.0711 - out_2_loss: 0.0459 - out_1_acc: 0.9608 - out_2_acc: 0.9741 - val_loss: 0.2964 - val_out_1_loss: 0.1467 - val_out_2_loss: 0.1498 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9524\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1175 - out_1_loss: 0.0711 - out_2_loss: 0.0465 - out_1_acc: 0.9606 - out_2_acc: 0.9743 - val_loss: 0.3044 - val_out_1_loss: 0.1465 - val_out_2_loss: 0.1579 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9520\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1177 - out_1_loss: 0.0716 - out_2_loss: 0.0461 - out_1_acc: 0.9602 - out_2_acc: 0.9742 - val_loss: 0.3067 - val_out_1_loss: 0.1509 - val_out_2_loss: 0.1559 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9520\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1205 - out_1_loss: 0.0726 - out_2_loss: 0.0479 - out_1_acc: 0.9596 - out_2_acc: 0.9733 - val_loss: 0.3082 - val_out_1_loss: 0.1510 - val_out_2_loss: 0.1572 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9509\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1198 - out_1_loss: 0.0727 - out_2_loss: 0.0471 - out_1_acc: 0.9601 - out_2_acc: 0.9735 - val_loss: 0.3140 - val_out_1_loss: 0.1505 - val_out_2_loss: 0.1634 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9521\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1183 - out_1_loss: 0.0719 - out_2_loss: 0.0464 - out_1_acc: 0.9596 - out_2_acc: 0.9740 - val_loss: 0.3094 - val_out_1_loss: 0.1510 - val_out_2_loss: 0.1584 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9517\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(9)-epoch(150)/assets\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2956 - out_1_loss: 0.1436 - out_2_loss: 0.1520 - out_1_acc: 0.9405 - out_2_acc: 0.9526\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 9, 20)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 9, 200), (No 176800      input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 200), (None, 320800      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 9, 200)       176800      input_23[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 200)          320800      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 200)          40200       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 200)          40200       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           8040        dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           8040        dense_45[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,091,680\n",
      "Trainable params: 1,091,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 2/28 [=>............................] - ETA: 3s - loss: 7.3388 - out_1_loss: 3.6676 - out_2_loss: 3.6713 - out_1_acc: 0.1597 - out_2_acc: 0.1194WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109419). Check your callbacks.\n",
      "28/28 [==============================] - 3s 103ms/step - loss: 5.9831 - out_1_loss: 3.0405 - out_2_loss: 2.9426 - out_1_acc: 0.2762 - out_2_acc: 0.2996 - val_loss: 4.7133 - val_out_1_loss: 2.4827 - val_out_2_loss: 2.2306 - val_out_1_acc: 0.3494 - val_out_2_acc: 0.3890\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 3.6130 - out_1_loss: 1.9852 - out_2_loss: 1.6278 - out_1_acc: 0.4508 - out_2_acc: 0.5315 - val_loss: 2.5254 - val_out_1_loss: 1.4861 - val_out_2_loss: 1.0394 - val_out_1_acc: 0.5677 - val_out_2_acc: 0.6881\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 1.8409 - out_1_loss: 1.1325 - out_2_loss: 0.7084 - out_1_acc: 0.6655 - out_2_acc: 0.7934 - val_loss: 1.3150 - val_out_1_loss: 0.8260 - val_out_2_loss: 0.4890 - val_out_1_acc: 0.7598 - val_out_2_acc: 0.8603\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.9942 - out_1_loss: 0.6413 - out_2_loss: 0.3529 - out_1_acc: 0.8131 - out_2_acc: 0.9057 - val_loss: 0.7770 - val_out_1_loss: 0.5008 - val_out_2_loss: 0.2762 - val_out_1_acc: 0.8584 - val_out_2_acc: 0.9275\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.6196 - out_1_loss: 0.4040 - out_2_loss: 0.2157 - out_1_acc: 0.8831 - out_2_acc: 0.9390 - val_loss: 0.5390 - val_out_1_loss: 0.3483 - val_out_2_loss: 0.1907 - val_out_1_acc: 0.8975 - val_out_2_acc: 0.9413\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 0.4434 - out_1_loss: 0.2876 - out_2_loss: 0.1558 - out_1_acc: 0.9111 - out_2_acc: 0.9492 - val_loss: 0.4000 - val_out_1_loss: 0.2547 - val_out_2_loss: 0.1452 - val_out_1_acc: 0.9183 - val_out_2_acc: 0.9466\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.3470 - out_1_loss: 0.2206 - out_2_loss: 0.1265 - out_1_acc: 0.9251 - out_2_acc: 0.9514 - val_loss: 0.3398 - val_out_1_loss: 0.2125 - val_out_2_loss: 0.1274 - val_out_1_acc: 0.9245 - val_out_2_acc: 0.9499\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2968 - out_1_loss: 0.1848 - out_2_loss: 0.1120 - out_1_acc: 0.9306 - out_2_acc: 0.9530 - val_loss: 0.3035 - val_out_1_loss: 0.1834 - val_out_2_loss: 0.1201 - val_out_1_acc: 0.9293 - val_out_2_acc: 0.9484\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2657 - out_1_loss: 0.1617 - out_2_loss: 0.1040 - out_1_acc: 0.9349 - out_2_acc: 0.9533 - val_loss: 0.2790 - val_out_1_loss: 0.1681 - val_out_2_loss: 0.1109 - val_out_1_acc: 0.9309 - val_out_2_acc: 0.9507\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2440 - out_1_loss: 0.1478 - out_2_loss: 0.0962 - out_1_acc: 0.9364 - out_2_acc: 0.9543 - val_loss: 0.2569 - val_out_1_loss: 0.1508 - val_out_2_loss: 0.1061 - val_out_1_acc: 0.9338 - val_out_2_acc: 0.9501\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2286 - out_1_loss: 0.1372 - out_2_loss: 0.0914 - out_1_acc: 0.9382 - out_2_acc: 0.9546 - val_loss: 0.2424 - val_out_1_loss: 0.1400 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9367 - val_out_2_acc: 0.9519\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2170 - out_1_loss: 0.1281 - out_2_loss: 0.0889 - out_1_acc: 0.9404 - out_2_acc: 0.9557 - val_loss: 0.2338 - val_out_1_loss: 0.1330 - val_out_2_loss: 0.1008 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9505\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2097 - out_1_loss: 0.1232 - out_2_loss: 0.0866 - out_1_acc: 0.9411 - out_2_acc: 0.9562 - val_loss: 0.2309 - val_out_1_loss: 0.1308 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9375 - val_out_2_acc: 0.9504\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.2040 - out_1_loss: 0.1185 - out_2_loss: 0.0854 - out_1_acc: 0.9418 - out_2_acc: 0.9561 - val_loss: 0.2266 - val_out_1_loss: 0.1267 - val_out_2_loss: 0.0999 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9503\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 2s 65ms/step - loss: 0.1994 - out_1_loss: 0.1158 - out_2_loss: 0.0836 - out_1_acc: 0.9419 - out_2_acc: 0.9565 - val_loss: 0.2258 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9503\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1928 - out_1_loss: 0.1105 - out_2_loss: 0.0823 - out_1_acc: 0.9438 - out_2_acc: 0.9571 - val_loss: 0.2193 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9509\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1899 - out_1_loss: 0.1093 - out_2_loss: 0.0806 - out_1_acc: 0.9434 - out_2_acc: 0.9576 - val_loss: 0.2203 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9372 - val_out_2_acc: 0.9498\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1879 - out_1_loss: 0.1080 - out_2_loss: 0.0799 - out_1_acc: 0.9432 - out_2_acc: 0.9579 - val_loss: 0.2198 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.0988 - val_out_1_acc: 0.9374 - val_out_2_acc: 0.9510\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1862 - out_1_loss: 0.1064 - out_2_loss: 0.0798 - out_1_acc: 0.9438 - out_2_acc: 0.9580 - val_loss: 0.2220 - val_out_1_loss: 0.1226 - val_out_2_loss: 0.0995 - val_out_1_acc: 0.9375 - val_out_2_acc: 0.9503\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1851 - out_1_loss: 0.1052 - out_2_loss: 0.0798 - out_1_acc: 0.9440 - out_2_acc: 0.9575 - val_loss: 0.2173 - val_out_1_loss: 0.1172 - val_out_2_loss: 0.1001 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9505\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1833 - out_1_loss: 0.1038 - out_2_loss: 0.0794 - out_1_acc: 0.9446 - out_2_acc: 0.9577 - val_loss: 0.2171 - val_out_1_loss: 0.1180 - val_out_2_loss: 0.0991 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9501\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1836 - out_1_loss: 0.1040 - out_2_loss: 0.0796 - out_1_acc: 0.9448 - out_2_acc: 0.9576 - val_loss: 0.2162 - val_out_1_loss: 0.1189 - val_out_2_loss: 0.0973 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9499\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1791 - out_1_loss: 0.1030 - out_2_loss: 0.0760 - out_1_acc: 0.9442 - out_2_acc: 0.9592 - val_loss: 0.2132 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.0979 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9500\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1765 - out_1_loss: 0.1009 - out_2_loss: 0.0757 - out_1_acc: 0.9451 - out_2_acc: 0.9591 - val_loss: 0.2122 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.0963 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9507\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1745 - out_1_loss: 0.0996 - out_2_loss: 0.0749 - out_1_acc: 0.9455 - out_2_acc: 0.9592 - val_loss: 0.2131 - val_out_1_loss: 0.1167 - val_out_2_loss: 0.0964 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9514\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1729 - out_1_loss: 0.0991 - out_2_loss: 0.0738 - out_1_acc: 0.9460 - out_2_acc: 0.9601 - val_loss: 0.2161 - val_out_1_loss: 0.1162 - val_out_2_loss: 0.0999 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9507\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1713 - out_1_loss: 0.0984 - out_2_loss: 0.0729 - out_1_acc: 0.9459 - out_2_acc: 0.9603 - val_loss: 0.2143 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.0975 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9506\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1703 - out_1_loss: 0.0980 - out_2_loss: 0.0723 - out_1_acc: 0.9464 - out_2_acc: 0.9606 - val_loss: 0.2134 - val_out_1_loss: 0.1157 - val_out_2_loss: 0.0977 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9506\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1686 - out_1_loss: 0.0973 - out_2_loss: 0.0713 - out_1_acc: 0.9464 - out_2_acc: 0.9608 - val_loss: 0.2153 - val_out_1_loss: 0.1168 - val_out_2_loss: 0.0984 - val_out_1_acc: 0.9382 - val_out_2_acc: 0.9508\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1672 - out_1_loss: 0.0965 - out_2_loss: 0.0707 - out_1_acc: 0.9467 - out_2_acc: 0.9614 - val_loss: 0.2158 - val_out_1_loss: 0.1166 - val_out_2_loss: 0.0992 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9515\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1664 - out_1_loss: 0.0964 - out_2_loss: 0.0700 - out_1_acc: 0.9469 - out_2_acc: 0.9615 - val_loss: 0.2171 - val_out_1_loss: 0.1169 - val_out_2_loss: 0.1002 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9513\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1661 - out_1_loss: 0.0962 - out_2_loss: 0.0698 - out_1_acc: 0.9474 - out_2_acc: 0.9620 - val_loss: 0.2198 - val_out_1_loss: 0.1176 - val_out_2_loss: 0.1022 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9505\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1664 - out_1_loss: 0.0965 - out_2_loss: 0.0699 - out_1_acc: 0.9472 - out_2_acc: 0.9617 - val_loss: 0.2215 - val_out_1_loss: 0.1190 - val_out_2_loss: 0.1025 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9511\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1661 - out_1_loss: 0.0963 - out_2_loss: 0.0698 - out_1_acc: 0.9473 - out_2_acc: 0.9616 - val_loss: 0.2221 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1009 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9513\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1658 - out_1_loss: 0.0963 - out_2_loss: 0.0695 - out_1_acc: 0.9475 - out_2_acc: 0.9615 - val_loss: 0.2235 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9376 - val_out_2_acc: 0.9499\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1655 - out_1_loss: 0.0959 - out_2_loss: 0.0696 - out_1_acc: 0.9475 - out_2_acc: 0.9617 - val_loss: 0.2181 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1028 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9503\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1653 - out_1_loss: 0.0958 - out_2_loss: 0.0695 - out_1_acc: 0.9469 - out_2_acc: 0.9612 - val_loss: 0.2207 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1033 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9511\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1648 - out_1_loss: 0.0958 - out_2_loss: 0.0690 - out_1_acc: 0.9476 - out_2_acc: 0.9618 - val_loss: 0.2155 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1008 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9528\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1656 - out_1_loss: 0.0959 - out_2_loss: 0.0697 - out_1_acc: 0.9476 - out_2_acc: 0.9614 - val_loss: 0.2175 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1017 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9511\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1649 - out_1_loss: 0.0958 - out_2_loss: 0.0691 - out_1_acc: 0.9479 - out_2_acc: 0.9617 - val_loss: 0.2189 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9507\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1623 - out_1_loss: 0.0953 - out_2_loss: 0.0669 - out_1_acc: 0.9474 - out_2_acc: 0.9626 - val_loss: 0.2188 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1028 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9503\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1580 - out_1_loss: 0.0938 - out_2_loss: 0.0642 - out_1_acc: 0.9479 - out_2_acc: 0.9637 - val_loss: 0.2191 - val_out_1_loss: 0.1153 - val_out_2_loss: 0.1038 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9523\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1567 - out_1_loss: 0.0926 - out_2_loss: 0.0641 - out_1_acc: 0.9491 - out_2_acc: 0.9636 - val_loss: 0.2176 - val_out_1_loss: 0.1152 - val_out_2_loss: 0.1024 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9520\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1560 - out_1_loss: 0.0926 - out_2_loss: 0.0635 - out_1_acc: 0.9488 - out_2_acc: 0.9638 - val_loss: 0.2193 - val_out_1_loss: 0.1146 - val_out_2_loss: 0.1048 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9518\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1560 - out_1_loss: 0.0922 - out_2_loss: 0.0637 - out_1_acc: 0.9489 - out_2_acc: 0.9641 - val_loss: 0.2239 - val_out_1_loss: 0.1159 - val_out_2_loss: 0.1080 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9509\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1549 - out_1_loss: 0.0926 - out_2_loss: 0.0623 - out_1_acc: 0.9490 - out_2_acc: 0.9649 - val_loss: 0.2229 - val_out_1_loss: 0.1170 - val_out_2_loss: 0.1059 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9513\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1530 - out_1_loss: 0.0917 - out_2_loss: 0.0613 - out_1_acc: 0.9489 - out_2_acc: 0.9655 - val_loss: 0.2259 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1085 - val_out_1_acc: 0.9378 - val_out_2_acc: 0.9506\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1507 - out_1_loss: 0.0906 - out_2_loss: 0.0601 - out_1_acc: 0.9494 - out_2_acc: 0.9659 - val_loss: 0.2229 - val_out_1_loss: 0.1160 - val_out_2_loss: 0.1069 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9525\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1496 - out_1_loss: 0.0901 - out_2_loss: 0.0595 - out_1_acc: 0.9500 - out_2_acc: 0.9665 - val_loss: 0.2274 - val_out_1_loss: 0.1174 - val_out_2_loss: 0.1100 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9506\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1500 - out_1_loss: 0.0904 - out_2_loss: 0.0597 - out_1_acc: 0.9500 - out_2_acc: 0.9664 - val_loss: 0.2382 - val_out_1_loss: 0.1241 - val_out_2_loss: 0.1140 - val_out_1_acc: 0.9373 - val_out_2_acc: 0.9502\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1502 - out_1_loss: 0.0906 - out_2_loss: 0.0597 - out_1_acc: 0.9498 - out_2_acc: 0.9660 - val_loss: 0.2304 - val_out_1_loss: 0.1177 - val_out_2_loss: 0.1127 - val_out_1_acc: 0.9373 - val_out_2_acc: 0.9513\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1511 - out_1_loss: 0.0910 - out_2_loss: 0.0601 - out_1_acc: 0.9498 - out_2_acc: 0.9656 - val_loss: 0.2315 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.1137 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9514\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1516 - out_1_loss: 0.0915 - out_2_loss: 0.0601 - out_1_acc: 0.9494 - out_2_acc: 0.9657 - val_loss: 0.2298 - val_out_1_loss: 0.1169 - val_out_2_loss: 0.1129 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9507\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1496 - out_1_loss: 0.0901 - out_2_loss: 0.0596 - out_1_acc: 0.9500 - out_2_acc: 0.9660 - val_loss: 0.2320 - val_out_1_loss: 0.1178 - val_out_2_loss: 0.1142 - val_out_1_acc: 0.9375 - val_out_2_acc: 0.9522\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1473 - out_1_loss: 0.0887 - out_2_loss: 0.0586 - out_1_acc: 0.9511 - out_2_acc: 0.9663 - val_loss: 0.2361 - val_out_1_loss: 0.1198 - val_out_2_loss: 0.1163 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9521\n",
      "Epoch 56/200\n",
      " 6/28 [=====>........................] - ETA: 1s - loss: 0.1542 - out_1_loss: 0.0927 - out_2_loss: 0.0615 - out_1_acc: 0.9504 - out_2_acc: 0.9650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0801 - out_1_loss: 0.0498 - out_2_loss: 0.0303 - out_1_acc: 0.9746 - out_2_acc: 0.9857 - val_loss: 0.3776 - val_out_1_loss: 0.1796 - val_out_2_loss: 0.1980 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9529\n",
      "Epoch 191/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0790 - out_1_loss: 0.0496 - out_2_loss: 0.0295 - out_1_acc: 0.9751 - out_2_acc: 0.9860 - val_loss: 0.3832 - val_out_1_loss: 0.1801 - val_out_2_loss: 0.2031 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9528\n",
      "Epoch 192/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0795 - out_1_loss: 0.0511 - out_2_loss: 0.0284 - out_1_acc: 0.9744 - out_2_acc: 0.9865 - val_loss: 0.3798 - val_out_1_loss: 0.1832 - val_out_2_loss: 0.1966 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9540\n",
      "Epoch 193/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0795 - out_1_loss: 0.0514 - out_2_loss: 0.0280 - out_1_acc: 0.9740 - out_2_acc: 0.9869 - val_loss: 0.3939 - val_out_1_loss: 0.1872 - val_out_2_loss: 0.2067 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9528\n",
      "Epoch 194/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0779 - out_1_loss: 0.0500 - out_2_loss: 0.0279 - out_1_acc: 0.9747 - out_2_acc: 0.9869 - val_loss: 0.3952 - val_out_1_loss: 0.1868 - val_out_2_loss: 0.2084 - val_out_1_acc: 0.9422 - val_out_2_acc: 0.9513\n",
      "Epoch 195/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0762 - out_1_loss: 0.0495 - out_2_loss: 0.0268 - out_1_acc: 0.9751 - out_2_acc: 0.9873 - val_loss: 0.4028 - val_out_1_loss: 0.1893 - val_out_2_loss: 0.2135 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9521\n",
      "Epoch 196/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0774 - out_1_loss: 0.0501 - out_2_loss: 0.0273 - out_1_acc: 0.9746 - out_2_acc: 0.9869 - val_loss: 0.4002 - val_out_1_loss: 0.1905 - val_out_2_loss: 0.2096 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9528\n",
      "Epoch 197/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0755 - out_1_loss: 0.0497 - out_2_loss: 0.0258 - out_1_acc: 0.9749 - out_2_acc: 0.9879 - val_loss: 0.4006 - val_out_1_loss: 0.1906 - val_out_2_loss: 0.2100 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 198/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0731 - out_1_loss: 0.0483 - out_2_loss: 0.0248 - out_1_acc: 0.9755 - out_2_acc: 0.9883 - val_loss: 0.4067 - val_out_1_loss: 0.1948 - val_out_2_loss: 0.2119 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9517\n",
      "Epoch 199/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0710 - out_1_loss: 0.0467 - out_2_loss: 0.0242 - out_1_acc: 0.9764 - out_2_acc: 0.9885 - val_loss: 0.4080 - val_out_1_loss: 0.1947 - val_out_2_loss: 0.2133 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9535\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0701 - out_1_loss: 0.0465 - out_2_loss: 0.0236 - out_1_acc: 0.9775 - out_2_acc: 0.9886 - val_loss: 0.4144 - val_out_1_loss: 0.1949 - val_out_2_loss: 0.2194 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9522\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0725 - out_1_loss: 0.0483 - out_2_loss: 0.0242 - out_1_acc: 0.9762 - out_2_acc: 0.9888 - val_loss: 0.4182 - val_out_1_loss: 0.1981 - val_out_2_loss: 0.2200 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9534\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0718 - out_1_loss: 0.0477 - out_2_loss: 0.0241 - out_1_acc: 0.9765 - out_2_acc: 0.9888 - val_loss: 0.4158 - val_out_1_loss: 0.1987 - val_out_2_loss: 0.2171 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9523\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.0721 - out_1_loss: 0.0487 - out_2_loss: 0.0235 - out_1_acc: 0.9759 - out_2_acc: 0.9891 - val_loss: 0.4283 - val_out_1_loss: 0.2010 - val_out_2_loss: 0.2273 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9526\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0707 - out_1_loss: 0.0480 - out_2_loss: 0.0227 - out_1_acc: 0.9760 - out_2_acc: 0.9898 - val_loss: 0.4299 - val_out_1_loss: 0.1994 - val_out_2_loss: 0.2304 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0731 - out_1_loss: 0.0489 - out_2_loss: 0.0242 - out_1_acc: 0.9761 - out_2_acc: 0.9887 - val_loss: 0.4273 - val_out_1_loss: 0.2029 - val_out_2_loss: 0.2244 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9516\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0730 - out_1_loss: 0.0495 - out_2_loss: 0.0236 - out_1_acc: 0.9750 - out_2_acc: 0.9893 - val_loss: 0.4382 - val_out_1_loss: 0.2066 - val_out_2_loss: 0.2316 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0736 - out_1_loss: 0.0490 - out_2_loss: 0.0246 - out_1_acc: 0.9758 - out_2_acc: 0.9886 - val_loss: 0.4350 - val_out_1_loss: 0.2039 - val_out_2_loss: 0.2311 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0706 - out_1_loss: 0.0480 - out_2_loss: 0.0226 - out_1_acc: 0.9762 - out_2_acc: 0.9894 - val_loss: 0.4293 - val_out_1_loss: 0.1938 - val_out_2_loss: 0.2355 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9513\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0702 - out_1_loss: 0.0484 - out_2_loss: 0.0218 - out_1_acc: 0.9761 - out_2_acc: 0.9896 - val_loss: 0.4350 - val_out_1_loss: 0.1971 - val_out_2_loss: 0.2379 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9519\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0683 - out_1_loss: 0.0466 - out_2_loss: 0.0217 - out_1_acc: 0.9773 - out_2_acc: 0.9900 - val_loss: 0.4383 - val_out_1_loss: 0.2004 - val_out_2_loss: 0.2379 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9506\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0648 - out_1_loss: 0.0448 - out_2_loss: 0.0199 - out_1_acc: 0.9779 - out_2_acc: 0.9910 - val_loss: 0.4420 - val_out_1_loss: 0.2042 - val_out_2_loss: 0.2378 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9520\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0634 - out_1_loss: 0.0449 - out_2_loss: 0.0185 - out_1_acc: 0.9780 - out_2_acc: 0.9917 - val_loss: 0.4445 - val_out_1_loss: 0.2065 - val_out_2_loss: 0.2380 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9514\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0642 - out_1_loss: 0.0454 - out_2_loss: 0.0188 - out_1_acc: 0.9774 - out_2_acc: 0.9914 - val_loss: 0.4433 - val_out_1_loss: 0.2061 - val_out_2_loss: 0.2372 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9530\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0644 - out_1_loss: 0.0445 - out_2_loss: 0.0200 - out_1_acc: 0.9779 - out_2_acc: 0.9908 - val_loss: 0.4468 - val_out_1_loss: 0.2100 - val_out_2_loss: 0.2368 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9530\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0642 - out_1_loss: 0.0440 - out_2_loss: 0.0201 - out_1_acc: 0.9783 - out_2_acc: 0.9910 - val_loss: 0.4494 - val_out_1_loss: 0.2095 - val_out_2_loss: 0.2399 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0635 - out_1_loss: 0.0443 - out_2_loss: 0.0191 - out_1_acc: 0.9785 - out_2_acc: 0.9915 - val_loss: 0.4536 - val_out_1_loss: 0.2138 - val_out_2_loss: 0.2398 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0626 - out_1_loss: 0.0431 - out_2_loss: 0.0195 - out_1_acc: 0.9788 - out_2_acc: 0.9913 - val_loss: 0.4481 - val_out_1_loss: 0.2086 - val_out_2_loss: 0.2395 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9519\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0630 - out_1_loss: 0.0431 - out_2_loss: 0.0199 - out_1_acc: 0.9791 - out_2_acc: 0.9908 - val_loss: 0.4549 - val_out_1_loss: 0.2126 - val_out_2_loss: 0.2424 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9519\n",
      "Epoch 219/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0587 - out_1_loss: 0.0421 - out_2_loss: 0.0167 - out_1_acc: 0.9797 - out_2_acc: 0.9926 - val_loss: 0.4705 - val_out_1_loss: 0.2160 - val_out_2_loss: 0.2545 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0587 - out_1_loss: 0.0415 - out_2_loss: 0.0172 - out_1_acc: 0.9801 - out_2_acc: 0.9922 - val_loss: 0.4614 - val_out_1_loss: 0.2167 - val_out_2_loss: 0.2447 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9517\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0589 - out_1_loss: 0.0427 - out_2_loss: 0.0162 - out_1_acc: 0.9793 - out_2_acc: 0.9929 - val_loss: 0.4712 - val_out_1_loss: 0.2158 - val_out_2_loss: 0.2554 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9524\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0596 - out_1_loss: 0.0424 - out_2_loss: 0.0172 - out_1_acc: 0.9796 - out_2_acc: 0.9925 - val_loss: 0.4747 - val_out_1_loss: 0.2205 - val_out_2_loss: 0.2542 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9529\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0596 - out_1_loss: 0.0425 - out_2_loss: 0.0171 - out_1_acc: 0.9797 - out_2_acc: 0.9924 - val_loss: 0.4809 - val_out_1_loss: 0.2174 - val_out_2_loss: 0.2634 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9521\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0590 - out_1_loss: 0.0417 - out_2_loss: 0.0173 - out_1_acc: 0.9800 - out_2_acc: 0.9922 - val_loss: 0.4793 - val_out_1_loss: 0.2240 - val_out_2_loss: 0.2553 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9527\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0579 - out_1_loss: 0.0420 - out_2_loss: 0.0159 - out_1_acc: 0.9796 - out_2_acc: 0.9930 - val_loss: 0.4849 - val_out_1_loss: 0.2256 - val_out_2_loss: 0.2592 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9516\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0603 - out_1_loss: 0.0431 - out_2_loss: 0.0172 - out_1_acc: 0.9793 - out_2_acc: 0.9927 - val_loss: 0.4840 - val_out_1_loss: 0.2288 - val_out_2_loss: 0.2553 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9517\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0607 - out_1_loss: 0.0429 - out_2_loss: 0.0178 - out_1_acc: 0.9796 - out_2_acc: 0.9921 - val_loss: 0.4836 - val_out_1_loss: 0.2220 - val_out_2_loss: 0.2616 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9530\n",
      "Epoch 228/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0592 - out_1_loss: 0.0426 - out_2_loss: 0.0166 - out_1_acc: 0.9794 - out_2_acc: 0.9924 - val_loss: 0.4928 - val_out_1_loss: 0.2258 - val_out_2_loss: 0.2670 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9509\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0586 - out_1_loss: 0.0426 - out_2_loss: 0.0160 - out_1_acc: 0.9796 - out_2_acc: 0.9932 - val_loss: 0.4985 - val_out_1_loss: 0.2328 - val_out_2_loss: 0.2657 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0592 - out_1_loss: 0.0430 - out_2_loss: 0.0162 - out_1_acc: 0.9796 - out_2_acc: 0.9931 - val_loss: 0.4874 - val_out_1_loss: 0.2268 - val_out_2_loss: 0.2606 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9520\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.0593 - out_1_loss: 0.0430 - out_2_loss: 0.0163 - out_1_acc: 0.9795 - out_2_acc: 0.9929 - val_loss: 0.4854 - val_out_1_loss: 0.2264 - val_out_2_loss: 0.2590 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9520\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0610 - out_1_loss: 0.0444 - out_2_loss: 0.0166 - out_1_acc: 0.9787 - out_2_acc: 0.9930 - val_loss: 0.4987 - val_out_1_loss: 0.2312 - val_out_2_loss: 0.2674 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9530\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0601 - out_1_loss: 0.0437 - out_2_loss: 0.0164 - out_1_acc: 0.9797 - out_2_acc: 0.9928 - val_loss: 0.4910 - val_out_1_loss: 0.2270 - val_out_2_loss: 0.2640 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9506\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0589 - out_1_loss: 0.0430 - out_2_loss: 0.0159 - out_1_acc: 0.9796 - out_2_acc: 0.9933 - val_loss: 0.4881 - val_out_1_loss: 0.2224 - val_out_2_loss: 0.2657 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9523\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0585 - out_1_loss: 0.0422 - out_2_loss: 0.0163 - out_1_acc: 0.9797 - out_2_acc: 0.9932 - val_loss: 0.4953 - val_out_1_loss: 0.2231 - val_out_2_loss: 0.2721 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9517\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(200)-timesteps(9)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.4607 - out_1_loss: 0.2109 - out_2_loss: 0.2498 - out_1_acc: 0.9405 - out_2_acc: 0.9520\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 9, 20)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_1 (LSTM)                  [(None, 9, 300), (No 385200      input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "vfc_1_2 (LSTM)                  [(None, 300), (None, 721200      vfc_1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_1 (LSTM)                  (None, 9, 300)       385200      input_25[0][0]                   \n",
      "                                                                 vfc_1_1[0][1]                    \n",
      "                                                                 vfc_1_1[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "vfc_2_2 (LSTM)                  (None, 300)          721200      vfc_2_1[0][0]                    \n",
      "                                                                 vfc_1_2[0][1]                    \n",
      "                                                                 vfc_1_2[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 300)          90300       vfc_1_2[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 300)          90300       vfc_2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out_1 (Dense)                   (None, 40)           12040       dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out_2 (Dense)                   (None, 40)           12040       dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,417,480\n",
      "Trainable params: 2,417,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      " 2/28 [=>............................] - ETA: 4s - loss: 7.3363 - out_1_loss: 3.6630 - out_2_loss: 3.6734 - out_1_acc: 0.1677 - out_2_acc: 0.1486WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.114114). Check your callbacks.\n",
      "28/28 [==============================] - 4s 145ms/step - loss: 5.6726 - out_1_loss: 2.9029 - out_2_loss: 2.7697 - out_1_acc: 0.2981 - out_2_acc: 0.3295 - val_loss: 4.3907 - val_out_1_loss: 2.3981 - val_out_2_loss: 1.9927 - val_out_1_acc: 0.3377 - val_out_2_acc: 0.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 3.1798 - out_1_loss: 1.8204 - out_2_loss: 1.3593 - out_1_acc: 0.4933 - out_2_acc: 0.5985 - val_loss: 2.1067 - val_out_1_loss: 1.1898 - val_out_2_loss: 0.9169 - val_out_1_acc: 0.6574 - val_out_2_acc: 0.7308\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 1.4847 - out_1_loss: 0.8775 - out_2_loss: 0.6072 - out_1_acc: 0.7361 - out_2_acc: 0.8222 - val_loss: 1.0985 - val_out_1_loss: 0.6630 - val_out_2_loss: 0.4356 - val_out_1_acc: 0.7994 - val_out_2_acc: 0.8676\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.8351 - out_1_loss: 0.5225 - out_2_loss: 0.3126 - out_1_acc: 0.8428 - out_2_acc: 0.9079 - val_loss: 0.6517 - val_out_1_loss: 0.4048 - val_out_2_loss: 0.2470 - val_out_1_acc: 0.8808 - val_out_2_acc: 0.9280\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.5208 - out_1_loss: 0.3320 - out_2_loss: 0.1889 - out_1_acc: 0.8990 - out_2_acc: 0.9414 - val_loss: 0.4464 - val_out_1_loss: 0.2871 - val_out_2_loss: 0.1593 - val_out_1_acc: 0.9118 - val_out_2_acc: 0.9443\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.3709 - out_1_loss: 0.2380 - out_2_loss: 0.1329 - out_1_acc: 0.9205 - out_2_acc: 0.9500 - val_loss: 0.3522 - val_out_1_loss: 0.2231 - val_out_2_loss: 0.1291 - val_out_1_acc: 0.9225 - val_out_2_acc: 0.9481\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.3012 - out_1_loss: 0.1897 - out_2_loss: 0.1116 - out_1_acc: 0.9297 - out_2_acc: 0.9522 - val_loss: 0.3039 - val_out_1_loss: 0.1859 - val_out_2_loss: 0.1179 - val_out_1_acc: 0.9296 - val_out_2_acc: 0.9479\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.2593 - out_1_loss: 0.1587 - out_2_loss: 0.1006 - out_1_acc: 0.9355 - out_2_acc: 0.9536 - val_loss: 0.2694 - val_out_1_loss: 0.1584 - val_out_2_loss: 0.1110 - val_out_1_acc: 0.9336 - val_out_2_acc: 0.9488\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.2361 - out_1_loss: 0.1415 - out_2_loss: 0.0946 - out_1_acc: 0.9383 - out_2_acc: 0.9540 - val_loss: 0.2528 - val_out_1_loss: 0.1489 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9357 - val_out_2_acc: 0.9496\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.2194 - out_1_loss: 0.1286 - out_2_loss: 0.0907 - out_1_acc: 0.9404 - out_2_acc: 0.9545 - val_loss: 0.2351 - val_out_1_loss: 0.1341 - val_out_2_loss: 0.1010 - val_out_1_acc: 0.9376 - val_out_2_acc: 0.9503\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.2088 - out_1_loss: 0.1211 - out_2_loss: 0.0877 - out_1_acc: 0.9415 - out_2_acc: 0.9547 - val_loss: 0.2299 - val_out_1_loss: 0.1313 - val_out_2_loss: 0.0987 - val_out_1_acc: 0.9375 - val_out_2_acc: 0.9503\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.2015 - out_1_loss: 0.1168 - out_2_loss: 0.0848 - out_1_acc: 0.9424 - out_2_acc: 0.9556 - val_loss: 0.2262 - val_out_1_loss: 0.1280 - val_out_2_loss: 0.0983 - val_out_1_acc: 0.9370 - val_out_2_acc: 0.9506\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1957 - out_1_loss: 0.1137 - out_2_loss: 0.0819 - out_1_acc: 0.9422 - out_2_acc: 0.9563 - val_loss: 0.2219 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.0965 - val_out_1_acc: 0.9381 - val_out_2_acc: 0.9517\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1958 - out_1_loss: 0.1154 - out_2_loss: 0.0804 - out_1_acc: 0.9426 - out_2_acc: 0.9570 - val_loss: 0.2225 - val_out_1_loss: 0.1262 - val_out_2_loss: 0.0962 - val_out_1_acc: 0.9376 - val_out_2_acc: 0.9516\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1859 - out_1_loss: 0.1074 - out_2_loss: 0.0785 - out_1_acc: 0.9435 - out_2_acc: 0.9573 - val_loss: 0.2183 - val_out_1_loss: 0.1216 - val_out_2_loss: 0.0967 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9510\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1828 - out_1_loss: 0.1062 - out_2_loss: 0.0766 - out_1_acc: 0.9444 - out_2_acc: 0.9578 - val_loss: 0.2164 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.0958 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9512\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1791 - out_1_loss: 0.1038 - out_2_loss: 0.0753 - out_1_acc: 0.9449 - out_2_acc: 0.9585 - val_loss: 0.2143 - val_out_1_loss: 0.1188 - val_out_2_loss: 0.0955 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1758 - out_1_loss: 0.1016 - out_2_loss: 0.0742 - out_1_acc: 0.9454 - out_2_acc: 0.9592 - val_loss: 0.2148 - val_out_1_loss: 0.1177 - val_out_2_loss: 0.0972 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9511\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1735 - out_1_loss: 0.1005 - out_2_loss: 0.0729 - out_1_acc: 0.9464 - out_2_acc: 0.9596 - val_loss: 0.2205 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.0997 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9514\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1730 - out_1_loss: 0.0999 - out_2_loss: 0.0731 - out_1_acc: 0.9464 - out_2_acc: 0.9595 - val_loss: 0.2230 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1015 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9510\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1724 - out_1_loss: 0.1002 - out_2_loss: 0.0722 - out_1_acc: 0.9463 - out_2_acc: 0.9605 - val_loss: 0.2218 - val_out_1_loss: 0.1212 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9505\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1708 - out_1_loss: 0.0994 - out_2_loss: 0.0714 - out_1_acc: 0.9467 - out_2_acc: 0.9604 - val_loss: 0.2184 - val_out_1_loss: 0.1184 - val_out_2_loss: 0.1000 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9506\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1677 - out_1_loss: 0.0974 - out_2_loss: 0.0704 - out_1_acc: 0.9471 - out_2_acc: 0.9610 - val_loss: 0.2220 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1006 - val_out_1_acc: 0.9383 - val_out_2_acc: 0.9503\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1651 - out_1_loss: 0.0959 - out_2_loss: 0.0692 - out_1_acc: 0.9474 - out_2_acc: 0.9614 - val_loss: 0.2216 - val_out_1_loss: 0.1196 - val_out_2_loss: 0.1020 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9501\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1643 - out_1_loss: 0.0957 - out_2_loss: 0.0686 - out_1_acc: 0.9473 - out_2_acc: 0.9617 - val_loss: 0.2246 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 3s 114ms/step - loss: 0.1630 - out_1_loss: 0.0955 - out_2_loss: 0.0675 - out_1_acc: 0.9474 - out_2_acc: 0.9628 - val_loss: 0.2240 - val_out_1_loss: 0.1201 - val_out_2_loss: 0.1039 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9511\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1614 - out_1_loss: 0.0948 - out_2_loss: 0.0666 - out_1_acc: 0.9480 - out_2_acc: 0.9625 - val_loss: 0.2216 - val_out_1_loss: 0.1179 - val_out_2_loss: 0.1037 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9502\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1615 - out_1_loss: 0.0961 - out_2_loss: 0.0654 - out_1_acc: 0.9480 - out_2_acc: 0.9631 - val_loss: 0.2233 - val_out_1_loss: 0.1197 - val_out_2_loss: 0.1036 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9503\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1597 - out_1_loss: 0.0948 - out_2_loss: 0.0650 - out_1_acc: 0.9481 - out_2_acc: 0.9633 - val_loss: 0.2262 - val_out_1_loss: 0.1206 - val_out_2_loss: 0.1055 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9508\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1588 - out_1_loss: 0.0931 - out_2_loss: 0.0656 - out_1_acc: 0.9488 - out_2_acc: 0.9627 - val_loss: 0.2305 - val_out_1_loss: 0.1223 - val_out_2_loss: 0.1082 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9509\n",
      "Epoch 31/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1570 - out_1_loss: 0.0927 - out_2_loss: 0.0643 - out_1_acc: 0.9490 - out_2_acc: 0.9632 - val_loss: 0.2297 - val_out_1_loss: 0.1215 - val_out_2_loss: 0.1081 - val_out_1_acc: 0.9392 - val_out_2_acc: 0.9519\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1570 - out_1_loss: 0.0922 - out_2_loss: 0.0648 - out_1_acc: 0.9493 - out_2_acc: 0.9628 - val_loss: 0.2298 - val_out_1_loss: 0.1222 - val_out_2_loss: 0.1076 - val_out_1_acc: 0.9391 - val_out_2_acc: 0.9505\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1570 - out_1_loss: 0.0928 - out_2_loss: 0.0643 - out_1_acc: 0.9490 - out_2_acc: 0.9627 - val_loss: 0.2283 - val_out_1_loss: 0.1205 - val_out_2_loss: 0.1077 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1563 - out_1_loss: 0.0912 - out_2_loss: 0.0651 - out_1_acc: 0.9494 - out_2_acc: 0.9631 - val_loss: 0.2357 - val_out_1_loss: 0.1209 - val_out_2_loss: 0.1148 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9492\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1562 - out_1_loss: 0.0916 - out_2_loss: 0.0646 - out_1_acc: 0.9498 - out_2_acc: 0.9627 - val_loss: 0.2350 - val_out_1_loss: 0.1202 - val_out_2_loss: 0.1148 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9506\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1535 - out_1_loss: 0.0902 - out_2_loss: 0.0633 - out_1_acc: 0.9499 - out_2_acc: 0.9633 - val_loss: 0.2360 - val_out_1_loss: 0.1254 - val_out_2_loss: 0.1106 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9492\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1519 - out_1_loss: 0.0904 - out_2_loss: 0.0616 - out_1_acc: 0.9503 - out_2_acc: 0.9644 - val_loss: 0.2348 - val_out_1_loss: 0.1258 - val_out_2_loss: 0.1090 - val_out_1_acc: 0.9371 - val_out_2_acc: 0.9507\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1519 - out_1_loss: 0.0908 - out_2_loss: 0.0611 - out_1_acc: 0.9503 - out_2_acc: 0.9642 - val_loss: 0.2394 - val_out_1_loss: 0.1256 - val_out_2_loss: 0.1138 - val_out_1_acc: 0.9373 - val_out_2_acc: 0.9492\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1503 - out_1_loss: 0.0900 - out_2_loss: 0.0603 - out_1_acc: 0.9497 - out_2_acc: 0.9646 - val_loss: 0.2343 - val_out_1_loss: 0.1220 - val_out_2_loss: 0.1124 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9510\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1489 - out_1_loss: 0.0887 - out_2_loss: 0.0602 - out_1_acc: 0.9506 - out_2_acc: 0.9641 - val_loss: 0.2386 - val_out_1_loss: 0.1249 - val_out_2_loss: 0.1136 - val_out_1_acc: 0.9385 - val_out_2_acc: 0.9511\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1478 - out_1_loss: 0.0884 - out_2_loss: 0.0594 - out_1_acc: 0.9507 - out_2_acc: 0.9646 - val_loss: 0.2435 - val_out_1_loss: 0.1247 - val_out_2_loss: 0.1188 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9507\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1471 - out_1_loss: 0.0879 - out_2_loss: 0.0592 - out_1_acc: 0.9511 - out_2_acc: 0.9648 - val_loss: 0.2429 - val_out_1_loss: 0.1243 - val_out_2_loss: 0.1186 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9513\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1465 - out_1_loss: 0.0872 - out_2_loss: 0.0593 - out_1_acc: 0.9513 - out_2_acc: 0.9651 - val_loss: 0.2383 - val_out_1_loss: 0.1207 - val_out_2_loss: 0.1176 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9514\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1446 - out_1_loss: 0.0863 - out_2_loss: 0.0583 - out_1_acc: 0.9520 - out_2_acc: 0.9656 - val_loss: 0.2370 - val_out_1_loss: 0.1210 - val_out_2_loss: 0.1159 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9496\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1410 - out_1_loss: 0.0849 - out_2_loss: 0.0561 - out_1_acc: 0.9526 - out_2_acc: 0.9667 - val_loss: 0.2364 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1150 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9506\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1387 - out_1_loss: 0.0837 - out_2_loss: 0.0550 - out_1_acc: 0.9534 - out_2_acc: 0.9669 - val_loss: 0.2417 - val_out_1_loss: 0.1214 - val_out_2_loss: 0.1203 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9508\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1365 - out_1_loss: 0.0825 - out_2_loss: 0.0540 - out_1_acc: 0.9541 - out_2_acc: 0.9673 - val_loss: 0.2439 - val_out_1_loss: 0.1218 - val_out_2_loss: 0.1221 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9495\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1358 - out_1_loss: 0.0818 - out_2_loss: 0.0540 - out_1_acc: 0.9545 - out_2_acc: 0.9665 - val_loss: 0.2470 - val_out_1_loss: 0.1235 - val_out_2_loss: 0.1235 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9504\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1351 - out_1_loss: 0.0815 - out_2_loss: 0.0536 - out_1_acc: 0.9543 - out_2_acc: 0.9673 - val_loss: 0.2466 - val_out_1_loss: 0.1233 - val_out_2_loss: 0.1233 - val_out_1_acc: 0.9380 - val_out_2_acc: 0.9505\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1343 - out_1_loss: 0.0812 - out_2_loss: 0.0531 - out_1_acc: 0.9548 - out_2_acc: 0.9674 - val_loss: 0.2498 - val_out_1_loss: 0.1257 - val_out_2_loss: 0.1242 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9508\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1336 - out_1_loss: 0.0805 - out_2_loss: 0.0531 - out_1_acc: 0.9549 - out_2_acc: 0.9676 - val_loss: 0.2535 - val_out_1_loss: 0.1268 - val_out_2_loss: 0.1267 - val_out_1_acc: 0.9386 - val_out_2_acc: 0.9510\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1340 - out_1_loss: 0.0805 - out_2_loss: 0.0535 - out_1_acc: 0.9553 - out_2_acc: 0.9677 - val_loss: 0.2524 - val_out_1_loss: 0.1259 - val_out_2_loss: 0.1265 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9514\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1334 - out_1_loss: 0.0800 - out_2_loss: 0.0534 - out_1_acc: 0.9554 - out_2_acc: 0.9678 - val_loss: 0.2530 - val_out_1_loss: 0.1272 - val_out_2_loss: 0.1258 - val_out_1_acc: 0.9384 - val_out_2_acc: 0.9511\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.1338 - out_1_loss: 0.0806 - out_2_loss: 0.0532 - out_1_acc: 0.9546 - out_2_acc: 0.9676 - val_loss: 0.2578 - val_out_1_loss: 0.1292 - val_out_2_loss: 0.1286 - val_out_1_acc: 0.9393 - val_out_2_acc: 0.9512\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1321 - out_1_loss: 0.0796 - out_2_loss: 0.0525 - out_1_acc: 0.9555 - out_2_acc: 0.9683 - val_loss: 0.2581 - val_out_1_loss: 0.1270 - val_out_2_loss: 0.1311 - val_out_1_acc: 0.9395 - val_out_2_acc: 0.9515\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1325 - out_1_loss: 0.0794 - out_2_loss: 0.0531 - out_1_acc: 0.9559 - out_2_acc: 0.9679 - val_loss: 0.2648 - val_out_1_loss: 0.1318 - val_out_2_loss: 0.1331 - val_out_1_acc: 0.9394 - val_out_2_acc: 0.9506\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1318 - out_1_loss: 0.0792 - out_2_loss: 0.0526 - out_1_acc: 0.9556 - out_2_acc: 0.9681 - val_loss: 0.2606 - val_out_1_loss: 0.1298 - val_out_2_loss: 0.1307 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9505\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1310 - out_1_loss: 0.0785 - out_2_loss: 0.0526 - out_1_acc: 0.9563 - out_2_acc: 0.9679 - val_loss: 0.2611 - val_out_1_loss: 0.1317 - val_out_2_loss: 0.1294 - val_out_1_acc: 0.9390 - val_out_2_acc: 0.9507\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.1293 - out_1_loss: 0.0775 - out_2_loss: 0.0519 - out_1_acc: 0.9569 - out_2_acc: 0.9683 - val_loss: 0.2628 - val_out_1_loss: 0.1317 - val_out_2_loss: 0.1312 - val_out_1_acc: 0.9388 - val_out_2_acc: 0.9500\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 111ms/step - loss: 0.1288 - out_1_loss: 0.0770 - out_2_loss: 0.0518 - out_1_acc: 0.9567 - out_2_acc: 0.9685 - val_loss: 0.2647 - val_out_1_loss: 0.1313 - val_out_2_loss: 0.1334 - val_out_1_acc: 0.9387 - val_out_2_acc: 0.9507\n",
      "Epoch 61/150\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.1297 - out_1_loss: 0.0771 - out_2_loss: 0.0526 - out_1_acc: 0.9563 - out_2_acc: 0.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0547 - out_1_loss: 0.0379 - out_2_loss: 0.0168 - out_1_acc: 0.9823 - out_2_acc: 0.9925 - val_loss: 0.5209 - val_out_1_loss: 0.2402 - val_out_2_loss: 0.2807 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 200/300\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0534 - out_1_loss: 0.0368 - out_2_loss: 0.0166 - out_1_acc: 0.9825 - out_2_acc: 0.9926 - val_loss: 0.5181 - val_out_1_loss: 0.2373 - val_out_2_loss: 0.2808 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 201/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0532 - out_1_loss: 0.0361 - out_2_loss: 0.0171 - out_1_acc: 0.9833 - out_2_acc: 0.9920 - val_loss: 0.5167 - val_out_1_loss: 0.2396 - val_out_2_loss: 0.2771 - val_out_1_acc: 0.9396 - val_out_2_acc: 0.9518\n",
      "Epoch 202/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0521 - out_1_loss: 0.0364 - out_2_loss: 0.0157 - out_1_acc: 0.9832 - out_2_acc: 0.9929 - val_loss: 0.5289 - val_out_1_loss: 0.2459 - val_out_2_loss: 0.2830 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 203/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0540 - out_1_loss: 0.0381 - out_2_loss: 0.0160 - out_1_acc: 0.9825 - out_2_acc: 0.9928 - val_loss: 0.5336 - val_out_1_loss: 0.2481 - val_out_2_loss: 0.2855 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9521\n",
      "Epoch 204/300\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.0545 - out_1_loss: 0.0383 - out_2_loss: 0.0162 - out_1_acc: 0.9824 - out_2_acc: 0.9930 - val_loss: 0.5309 - val_out_1_loss: 0.2465 - val_out_2_loss: 0.2844 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9517\n",
      "Epoch 205/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0570 - out_1_loss: 0.0391 - out_2_loss: 0.0179 - out_1_acc: 0.9822 - out_2_acc: 0.9923 - val_loss: 0.5272 - val_out_1_loss: 0.2401 - val_out_2_loss: 0.2871 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9516\n",
      "Epoch 206/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0541 - out_1_loss: 0.0366 - out_2_loss: 0.0176 - out_1_acc: 0.9833 - out_2_acc: 0.9925 - val_loss: 0.5239 - val_out_1_loss: 0.2408 - val_out_2_loss: 0.2831 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9524\n",
      "Epoch 207/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0500 - out_1_loss: 0.0344 - out_2_loss: 0.0156 - out_1_acc: 0.9837 - out_2_acc: 0.9934 - val_loss: 0.5322 - val_out_1_loss: 0.2456 - val_out_2_loss: 0.2866 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9517\n",
      "Epoch 208/300\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0507 - out_1_loss: 0.0354 - out_2_loss: 0.0153 - out_1_acc: 0.9837 - out_2_acc: 0.9932 - val_loss: 0.5414 - val_out_1_loss: 0.2519 - val_out_2_loss: 0.2895 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9526\n",
      "Epoch 209/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0505 - out_1_loss: 0.0351 - out_2_loss: 0.0153 - out_1_acc: 0.9838 - out_2_acc: 0.9936 - val_loss: 0.5404 - val_out_1_loss: 0.2520 - val_out_2_loss: 0.2884 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9525\n",
      "Epoch 210/300\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0494 - out_1_loss: 0.0345 - out_2_loss: 0.0149 - out_1_acc: 0.9844 - out_2_acc: 0.9939 - val_loss: 0.5355 - val_out_1_loss: 0.2439 - val_out_2_loss: 0.2916 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9529\n",
      "Epoch 211/300\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.0527 - out_1_loss: 0.0362 - out_2_loss: 0.0165 - out_1_acc: 0.9839 - out_2_acc: 0.9930 - val_loss: 0.5222 - val_out_1_loss: 0.2448 - val_out_2_loss: 0.2774 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9527\n",
      "Epoch 212/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0497 - out_1_loss: 0.0346 - out_2_loss: 0.0151 - out_1_acc: 0.9847 - out_2_acc: 0.9938 - val_loss: 0.5329 - val_out_1_loss: 0.2489 - val_out_2_loss: 0.2840 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9523\n",
      "Epoch 213/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0479 - out_1_loss: 0.0322 - out_2_loss: 0.0157 - out_1_acc: 0.9855 - out_2_acc: 0.9932 - val_loss: 0.5278 - val_out_1_loss: 0.2435 - val_out_2_loss: 0.2844 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9523\n",
      "Epoch 214/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0467 - out_1_loss: 0.0314 - out_2_loss: 0.0153 - out_1_acc: 0.9858 - out_2_acc: 0.9935 - val_loss: 0.5251 - val_out_1_loss: 0.2459 - val_out_2_loss: 0.2792 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9525\n",
      "Epoch 215/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0444 - out_1_loss: 0.0299 - out_2_loss: 0.0145 - out_1_acc: 0.9866 - out_2_acc: 0.9941 - val_loss: 0.5291 - val_out_1_loss: 0.2480 - val_out_2_loss: 0.2811 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9512\n",
      "Epoch 216/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0440 - out_1_loss: 0.0297 - out_2_loss: 0.0143 - out_1_acc: 0.9868 - out_2_acc: 0.9939 - val_loss: 0.5468 - val_out_1_loss: 0.2526 - val_out_2_loss: 0.2942 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9509\n",
      "Epoch 217/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0450 - out_1_loss: 0.0294 - out_2_loss: 0.0155 - out_1_acc: 0.9871 - out_2_acc: 0.9932 - val_loss: 0.5544 - val_out_1_loss: 0.2596 - val_out_2_loss: 0.2948 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9513\n",
      "Epoch 218/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0438 - out_1_loss: 0.0285 - out_2_loss: 0.0153 - out_1_acc: 0.9874 - out_2_acc: 0.9937 - val_loss: 0.5384 - val_out_1_loss: 0.2548 - val_out_2_loss: 0.2836 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9524\n",
      "Epoch 219/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0380 - out_1_loss: 0.0261 - out_2_loss: 0.0119 - out_1_acc: 0.9890 - out_2_acc: 0.9950 - val_loss: 0.5639 - val_out_1_loss: 0.2679 - val_out_2_loss: 0.2960 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9522\n",
      "Epoch 220/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0390 - out_1_loss: 0.0260 - out_2_loss: 0.0130 - out_1_acc: 0.9887 - out_2_acc: 0.9945 - val_loss: 0.5636 - val_out_1_loss: 0.2628 - val_out_2_loss: 0.3009 - val_out_1_acc: 0.9420 - val_out_2_acc: 0.9507\n",
      "Epoch 221/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0370 - out_1_loss: 0.0251 - out_2_loss: 0.0119 - out_1_acc: 0.9896 - out_2_acc: 0.9949 - val_loss: 0.5705 - val_out_1_loss: 0.2697 - val_out_2_loss: 0.3008 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9507\n",
      "Epoch 222/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0366 - out_1_loss: 0.0250 - out_2_loss: 0.0116 - out_1_acc: 0.9894 - out_2_acc: 0.9952 - val_loss: 0.5669 - val_out_1_loss: 0.2687 - val_out_2_loss: 0.2983 - val_out_1_acc: 0.9389 - val_out_2_acc: 0.9515\n",
      "Epoch 223/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0349 - out_1_loss: 0.0243 - out_2_loss: 0.0106 - out_1_acc: 0.9896 - out_2_acc: 0.9958 - val_loss: 0.5812 - val_out_1_loss: 0.2715 - val_out_2_loss: 0.3097 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9520\n",
      "Epoch 224/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0346 - out_1_loss: 0.0237 - out_2_loss: 0.0109 - out_1_acc: 0.9900 - out_2_acc: 0.9957 - val_loss: 0.5861 - val_out_1_loss: 0.2755 - val_out_2_loss: 0.3106 - val_out_1_acc: 0.9397 - val_out_2_acc: 0.9511\n",
      "Epoch 225/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0351 - out_1_loss: 0.0240 - out_2_loss: 0.0111 - out_1_acc: 0.9898 - out_2_acc: 0.9953 - val_loss: 0.5897 - val_out_1_loss: 0.2865 - val_out_2_loss: 0.3032 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9521\n",
      "Epoch 226/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0334 - out_1_loss: 0.0230 - out_2_loss: 0.0104 - out_1_acc: 0.9904 - out_2_acc: 0.9956 - val_loss: 0.5903 - val_out_1_loss: 0.2883 - val_out_2_loss: 0.3020 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9508\n",
      "Epoch 227/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0331 - out_1_loss: 0.0227 - out_2_loss: 0.0104 - out_1_acc: 0.9905 - out_2_acc: 0.9959 - val_loss: 0.5935 - val_out_1_loss: 0.2857 - val_out_2_loss: 0.3078 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0304 - out_1_loss: 0.0216 - out_2_loss: 0.0088 - out_1_acc: 0.9909 - out_2_acc: 0.9964 - val_loss: 0.5970 - val_out_1_loss: 0.2867 - val_out_2_loss: 0.3103 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9517\n",
      "Epoch 229/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0296 - out_1_loss: 0.0214 - out_2_loss: 0.0082 - out_1_acc: 0.9910 - out_2_acc: 0.9967 - val_loss: 0.5891 - val_out_1_loss: 0.2836 - val_out_2_loss: 0.3054 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9515\n",
      "Epoch 230/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0291 - out_1_loss: 0.0206 - out_2_loss: 0.0085 - out_1_acc: 0.9915 - out_2_acc: 0.9968 - val_loss: 0.5989 - val_out_1_loss: 0.2857 - val_out_2_loss: 0.3133 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9518\n",
      "Epoch 231/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0291 - out_1_loss: 0.0198 - out_2_loss: 0.0094 - out_1_acc: 0.9919 - out_2_acc: 0.9962 - val_loss: 0.5999 - val_out_1_loss: 0.2891 - val_out_2_loss: 0.3108 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9517\n",
      "Epoch 232/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0298 - out_1_loss: 0.0205 - out_2_loss: 0.0093 - out_1_acc: 0.9915 - out_2_acc: 0.9963 - val_loss: 0.6107 - val_out_1_loss: 0.2937 - val_out_2_loss: 0.3170 - val_out_1_acc: 0.9398 - val_out_2_acc: 0.9522\n",
      "Epoch 233/300\n",
      "28/28 [==============================] - 3s 114ms/step - loss: 0.0294 - out_1_loss: 0.0198 - out_2_loss: 0.0096 - out_1_acc: 0.9917 - out_2_acc: 0.9961 - val_loss: 0.6062 - val_out_1_loss: 0.2910 - val_out_2_loss: 0.3152 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9521\n",
      "Epoch 234/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0273 - out_1_loss: 0.0186 - out_2_loss: 0.0086 - out_1_acc: 0.9923 - out_2_acc: 0.9966 - val_loss: 0.6130 - val_out_1_loss: 0.2945 - val_out_2_loss: 0.3185 - val_out_1_acc: 0.9414 - val_out_2_acc: 0.9520\n",
      "Epoch 235/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0263 - out_1_loss: 0.0184 - out_2_loss: 0.0079 - out_1_acc: 0.9926 - out_2_acc: 0.9970 - val_loss: 0.6311 - val_out_1_loss: 0.3003 - val_out_2_loss: 0.3307 - val_out_1_acc: 0.9407 - val_out_2_acc: 0.9527\n",
      "Epoch 236/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0258 - out_1_loss: 0.0175 - out_2_loss: 0.0083 - out_1_acc: 0.9928 - out_2_acc: 0.9968 - val_loss: 0.6299 - val_out_1_loss: 0.3013 - val_out_2_loss: 0.3286 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9512\n",
      "Epoch 237/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0284 - out_1_loss: 0.0199 - out_2_loss: 0.0085 - out_1_acc: 0.9919 - out_2_acc: 0.9968 - val_loss: 0.6257 - val_out_1_loss: 0.3000 - val_out_2_loss: 0.3257 - val_out_1_acc: 0.9406 - val_out_2_acc: 0.9525\n",
      "Epoch 238/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0298 - out_1_loss: 0.0200 - out_2_loss: 0.0097 - out_1_acc: 0.9919 - out_2_acc: 0.9963 - val_loss: 0.6307 - val_out_1_loss: 0.3031 - val_out_2_loss: 0.3276 - val_out_1_acc: 0.9415 - val_out_2_acc: 0.9520\n",
      "Epoch 239/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0263 - out_1_loss: 0.0183 - out_2_loss: 0.0080 - out_1_acc: 0.9928 - out_2_acc: 0.9969 - val_loss: 0.6301 - val_out_1_loss: 0.3007 - val_out_2_loss: 0.3294 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9521\n",
      "Epoch 240/300\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0232 - out_1_loss: 0.0161 - out_2_loss: 0.0071 - out_1_acc: 0.9938 - out_2_acc: 0.9974 - val_loss: 0.6447 - val_out_1_loss: 0.3092 - val_out_2_loss: 0.3354 - val_out_1_acc: 0.9412 - val_out_2_acc: 0.9516\n",
      "Epoch 241/300\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.0239 - out_1_loss: 0.0168 - out_2_loss: 0.0071 - out_1_acc: 0.9935 - out_2_acc: 0.9974 - val_loss: 0.6574 - val_out_1_loss: 0.3104 - val_out_2_loss: 0.3470 - val_out_1_acc: 0.9403 - val_out_2_acc: 0.9505\n",
      "Epoch 242/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0256 - out_1_loss: 0.0172 - out_2_loss: 0.0084 - out_1_acc: 0.9932 - out_2_acc: 0.9968 - val_loss: 0.6417 - val_out_1_loss: 0.3089 - val_out_2_loss: 0.3328 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9519\n",
      "Epoch 243/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0271 - out_1_loss: 0.0169 - out_2_loss: 0.0102 - out_1_acc: 0.9934 - out_2_acc: 0.9963 - val_loss: 0.6598 - val_out_1_loss: 0.3169 - val_out_2_loss: 0.3429 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9510\n",
      "Epoch 244/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0256 - out_1_loss: 0.0162 - out_2_loss: 0.0094 - out_1_acc: 0.9935 - out_2_acc: 0.9967 - val_loss: 0.6635 - val_out_1_loss: 0.3214 - val_out_2_loss: 0.3421 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9518\n",
      "Epoch 245/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0234 - out_1_loss: 0.0152 - out_2_loss: 0.0082 - out_1_acc: 0.9939 - out_2_acc: 0.9970 - val_loss: 0.6590 - val_out_1_loss: 0.3193 - val_out_2_loss: 0.3397 - val_out_1_acc: 0.9399 - val_out_2_acc: 0.9513\n",
      "Epoch 246/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0206 - out_1_loss: 0.0138 - out_2_loss: 0.0069 - out_1_acc: 0.9948 - out_2_acc: 0.9975 - val_loss: 0.6569 - val_out_1_loss: 0.3252 - val_out_2_loss: 0.3317 - val_out_1_acc: 0.9408 - val_out_2_acc: 0.9515\n",
      "Epoch 247/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0200 - out_1_loss: 0.0144 - out_2_loss: 0.0056 - out_1_acc: 0.9944 - out_2_acc: 0.9978 - val_loss: 0.6738 - val_out_1_loss: 0.3290 - val_out_2_loss: 0.3448 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9506\n",
      "Epoch 248/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0205 - out_1_loss: 0.0146 - out_2_loss: 0.0058 - out_1_acc: 0.9942 - out_2_acc: 0.9978 - val_loss: 0.6814 - val_out_1_loss: 0.3367 - val_out_2_loss: 0.3447 - val_out_1_acc: 0.9400 - val_out_2_acc: 0.9516\n",
      "Epoch 249/300\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.0192 - out_1_loss: 0.0138 - out_2_loss: 0.0055 - out_1_acc: 0.9949 - out_2_acc: 0.9982 - val_loss: 0.6866 - val_out_1_loss: 0.3351 - val_out_2_loss: 0.3515 - val_out_1_acc: 0.9401 - val_out_2_acc: 0.9510\n",
      "Epoch 250/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0193 - out_1_loss: 0.0128 - out_2_loss: 0.0066 - out_1_acc: 0.9949 - out_2_acc: 0.9975 - val_loss: 0.6978 - val_out_1_loss: 0.3473 - val_out_2_loss: 0.3506 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9518\n",
      "Epoch 251/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0185 - out_1_loss: 0.0129 - out_2_loss: 0.0056 - out_1_acc: 0.9950 - out_2_acc: 0.9979 - val_loss: 0.7053 - val_out_1_loss: 0.3534 - val_out_2_loss: 0.3518 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9524\n",
      "Epoch 252/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0188 - out_1_loss: 0.0137 - out_2_loss: 0.0051 - out_1_acc: 0.9944 - out_2_acc: 0.9980 - val_loss: 0.6969 - val_out_1_loss: 0.3471 - val_out_2_loss: 0.3498 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9528\n",
      "Epoch 253/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0174 - out_1_loss: 0.0125 - out_2_loss: 0.0049 - out_1_acc: 0.9953 - out_2_acc: 0.9982 - val_loss: 0.7021 - val_out_1_loss: 0.3457 - val_out_2_loss: 0.3564 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9518\n",
      "Epoch 254/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0171 - out_1_loss: 0.0126 - out_2_loss: 0.0045 - out_1_acc: 0.9952 - out_2_acc: 0.9983 - val_loss: 0.7122 - val_out_1_loss: 0.3525 - val_out_2_loss: 0.3598 - val_out_1_acc: 0.9416 - val_out_2_acc: 0.9521\n",
      "Epoch 255/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0147 - out_1_loss: 0.0106 - out_2_loss: 0.0041 - out_1_acc: 0.9959 - out_2_acc: 0.9985 - val_loss: 0.7103 - val_out_1_loss: 0.3539 - val_out_2_loss: 0.3564 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9520\n",
      "Epoch 256/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0179 - out_1_loss: 0.0132 - out_2_loss: 0.0048 - out_1_acc: 0.9949 - out_2_acc: 0.9983 - val_loss: 0.7229 - val_out_1_loss: 0.3579 - val_out_2_loss: 0.3650 - val_out_1_acc: 0.9404 - val_out_2_acc: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0182 - out_1_loss: 0.0121 - out_2_loss: 0.0062 - out_1_acc: 0.9954 - out_2_acc: 0.9978 - val_loss: 0.7185 - val_out_1_loss: 0.3588 - val_out_2_loss: 0.3597 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9514\n",
      "Epoch 258/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0175 - out_1_loss: 0.0116 - out_2_loss: 0.0059 - out_1_acc: 0.9955 - out_2_acc: 0.9978 - val_loss: 0.7241 - val_out_1_loss: 0.3649 - val_out_2_loss: 0.3593 - val_out_1_acc: 0.9413 - val_out_2_acc: 0.9531\n",
      "Epoch 259/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0186 - out_1_loss: 0.0129 - out_2_loss: 0.0056 - out_1_acc: 0.9952 - out_2_acc: 0.9979 - val_loss: 0.7220 - val_out_1_loss: 0.3623 - val_out_2_loss: 0.3597 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9514\n",
      "Epoch 260/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0215 - out_1_loss: 0.0146 - out_2_loss: 0.0068 - out_1_acc: 0.9945 - out_2_acc: 0.9975 - val_loss: 0.7183 - val_out_1_loss: 0.3568 - val_out_2_loss: 0.3615 - val_out_1_acc: 0.9402 - val_out_2_acc: 0.9520\n",
      "Epoch 261/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0209 - out_1_loss: 0.0141 - out_2_loss: 0.0069 - out_1_acc: 0.9946 - out_2_acc: 0.9974 - val_loss: 0.7147 - val_out_1_loss: 0.3509 - val_out_2_loss: 0.3638 - val_out_1_acc: 0.9427 - val_out_2_acc: 0.9523\n",
      "Epoch 262/300\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.0189 - out_1_loss: 0.0127 - out_2_loss: 0.0062 - out_1_acc: 0.9952 - out_2_acc: 0.9981 - val_loss: 0.7071 - val_out_1_loss: 0.3542 - val_out_2_loss: 0.3529 - val_out_1_acc: 0.9419 - val_out_2_acc: 0.9518\n",
      "Epoch 263/300\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.0181 - out_1_loss: 0.0129 - out_2_loss: 0.0052 - out_1_acc: 0.9951 - out_2_acc: 0.9982 - val_loss: 0.7175 - val_out_1_loss: 0.3629 - val_out_2_loss: 0.3545 - val_out_1_acc: 0.9411 - val_out_2_acc: 0.9520\n",
      "Epoch 264/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0191 - out_1_loss: 0.0126 - out_2_loss: 0.0065 - out_1_acc: 0.9953 - out_2_acc: 0.9977 - val_loss: 0.7157 - val_out_1_loss: 0.3563 - val_out_2_loss: 0.3594 - val_out_1_acc: 0.9410 - val_out_2_acc: 0.9515\n",
      "Epoch 265/300\n",
      "28/28 [==============================] - 3s 110ms/step - loss: 0.0212 - out_1_loss: 0.0129 - out_2_loss: 0.0083 - out_1_acc: 0.9951 - out_2_acc: 0.9970 - val_loss: 0.7015 - val_out_1_loss: 0.3580 - val_out_2_loss: 0.3436 - val_out_1_acc: 0.9405 - val_out_2_acc: 0.9522\n",
      "INFO:tensorflow:Assets written to: saved_model/lstm-rnn-unit(300)-timesteps(9)-epoch(300)/assets\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.6644 - out_1_loss: 0.3471 - out_2_loss: 0.3173 - out_1_acc: 0.9424 - out_2_acc: 0.9527\n"
     ]
    }
   ],
   "source": [
    "try_timesteps=[3,6,9]#list(range(3,18,3))\n",
    "try_units=[100,200, 300]#[50,100,200,300,180]#list(range(10,200,20))\n",
    "try_epochs=[150, 200,300]\n",
    "\n",
    "\"\"\"\n",
    "try_timesteps=[3]\n",
    "try_units=[180]#list(range(10,200,20))\n",
    "try_epochs=[150]\n",
    "\"\"\"\n",
    "df_all = pd.DataFrame([], columns=[[\"loss\", \"out_1_loss\", \"out_2_loss\", \"out_1_acc\", \"out_2_acc\", \"timesteps\", \"units\", \"epoch\"]])\n",
    "for timesteps in try_timesteps:\n",
    "    for units in try_units:\n",
    "        for epoch in try_epochs:\n",
    "            X = tf.reshape(X_raw, [y.shape[0],timesteps,180//timesteps])\n",
    "            train_dataset, val_dataset, test_dataset = split_dataset(X, y)\n",
    "            \n",
    "            model = construct_model(timesteps=timesteps, data_dim = 180//timesteps, units=units)\n",
    "            model, history = compile_fit_model(model,epochs=epoch,train_dataset=train_dataset,val_dataset=val_dataset)\n",
    "            model.save(\"saved_model/lstm-rnn-unit(\"+str(units)+\")-timesteps(\"+str(timesteps)+\")-epoch(\"+str(epoch)+\")\")\n",
    "            results = model.evaluate(test_dataset)\n",
    "            results.extend([timesteps, units, epoch])\n",
    "            df = pd.DataFrame([results], columns=[[\"loss\", \"out_1_loss\", \"out_2_loss\", \"out_1_acc\", \"out_2_acc\", \"timesteps\", \"units\", \"epoch\"]])\n",
    "            df_all = df_all.append(df)\n",
    "df_all.to_csv(\"save/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863bdbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>out_1_loss</th>\n",
       "      <th>out_2_loss</th>\n",
       "      <th>out_1_acc</th>\n",
       "      <th>out_2_acc</th>\n",
       "      <th>timesteps</th>\n",
       "      <th>units</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355148</td>\n",
       "      <td>0.157957</td>\n",
       "      <td>0.197190</td>\n",
       "      <td>0.943708</td>\n",
       "      <td>0.953292</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.478453</td>\n",
       "      <td>0.214341</td>\n",
       "      <td>0.264112</td>\n",
       "      <td>0.940667</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.460420</td>\n",
       "      <td>0.209530</td>\n",
       "      <td>0.250890</td>\n",
       "      <td>0.942583</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448695</td>\n",
       "      <td>0.212640</td>\n",
       "      <td>0.236055</td>\n",
       "      <td>0.942375</td>\n",
       "      <td>0.954833</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.653737</td>\n",
       "      <td>0.328468</td>\n",
       "      <td>0.325268</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.953167</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374218</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.190718</td>\n",
       "      <td>0.940583</td>\n",
       "      <td>0.953167</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556743</td>\n",
       "      <td>0.278242</td>\n",
       "      <td>0.278501</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.952292</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656323</td>\n",
       "      <td>0.337308</td>\n",
       "      <td>0.319015</td>\n",
       "      <td>0.940917</td>\n",
       "      <td>0.951917</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661425</td>\n",
       "      <td>0.337478</td>\n",
       "      <td>0.323947</td>\n",
       "      <td>0.942208</td>\n",
       "      <td>0.952417</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.297995</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.159590</td>\n",
       "      <td>0.938875</td>\n",
       "      <td>0.952292</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390668</td>\n",
       "      <td>0.174902</td>\n",
       "      <td>0.215766</td>\n",
       "      <td>0.942208</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585113</td>\n",
       "      <td>0.270266</td>\n",
       "      <td>0.314847</td>\n",
       "      <td>0.941417</td>\n",
       "      <td>0.952292</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.357307</td>\n",
       "      <td>0.171839</td>\n",
       "      <td>0.185468</td>\n",
       "      <td>0.943125</td>\n",
       "      <td>0.953208</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.561592</td>\n",
       "      <td>0.270678</td>\n",
       "      <td>0.290914</td>\n",
       "      <td>0.941542</td>\n",
       "      <td>0.951792</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.681402</td>\n",
       "      <td>0.348892</td>\n",
       "      <td>0.332510</td>\n",
       "      <td>0.940917</td>\n",
       "      <td>0.953208</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.232074</td>\n",
       "      <td>0.259451</td>\n",
       "      <td>0.940708</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620464</td>\n",
       "      <td>0.318552</td>\n",
       "      <td>0.301912</td>\n",
       "      <td>0.941292</td>\n",
       "      <td>0.951375</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.753881</td>\n",
       "      <td>0.390239</td>\n",
       "      <td>0.363642</td>\n",
       "      <td>0.939542</td>\n",
       "      <td>0.952208</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.242722</td>\n",
       "      <td>0.114636</td>\n",
       "      <td>0.128086</td>\n",
       "      <td>0.942458</td>\n",
       "      <td>0.952458</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286849</td>\n",
       "      <td>0.132964</td>\n",
       "      <td>0.153885</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.952833</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.308398</td>\n",
       "      <td>0.137252</td>\n",
       "      <td>0.171146</td>\n",
       "      <td>0.942125</td>\n",
       "      <td>0.951375</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295579</td>\n",
       "      <td>0.143579</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>0.952625</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.186218</td>\n",
       "      <td>0.217774</td>\n",
       "      <td>0.939708</td>\n",
       "      <td>0.952125</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.460705</td>\n",
       "      <td>0.210880</td>\n",
       "      <td>0.249825</td>\n",
       "      <td>0.940500</td>\n",
       "      <td>0.951958</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289232</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.144984</td>\n",
       "      <td>0.939750</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282457</td>\n",
       "      <td>0.146414</td>\n",
       "      <td>0.136043</td>\n",
       "      <td>0.940917</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.664441</td>\n",
       "      <td>0.347118</td>\n",
       "      <td>0.317323</td>\n",
       "      <td>0.942375</td>\n",
       "      <td>0.952708</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss out_1_loss out_2_loss out_1_acc out_2_acc timesteps units epoch\n",
       "0  0.355148   0.157957   0.197190  0.943708  0.953292         3   100   150\n",
       "0  0.478453   0.214341   0.264112  0.940667  0.952542         3   100   200\n",
       "0  0.460420   0.209530   0.250890  0.942583  0.953500         3   100   300\n",
       "0  0.448695   0.212640   0.236055  0.942375  0.954833         3   200   150\n",
       "0  0.653737   0.328468   0.325268  0.942000  0.953167         3   200   200\n",
       "0  0.374218   0.183500   0.190718  0.940583  0.953167         3   200   300\n",
       "0  0.556743   0.278242   0.278501  0.941000  0.952292         3   300   150\n",
       "0  0.656323   0.337308   0.319015  0.940917  0.951917         3   300   200\n",
       "0  0.661425   0.337478   0.323947  0.942208  0.952417         3   300   300\n",
       "0  0.297995   0.138405   0.159590  0.938875  0.952292         6   100   150\n",
       "0  0.390668   0.174902   0.215766  0.942208  0.951000         6   100   200\n",
       "0  0.585113   0.270266   0.314847  0.941417  0.952292         6   100   300\n",
       "0  0.357307   0.171839   0.185468  0.943125  0.953208         6   200   150\n",
       "0  0.561592   0.270678   0.290914  0.941542  0.951792         6   200   200\n",
       "0  0.681402   0.348892   0.332510  0.940917  0.953208         6   200   300\n",
       "0  0.491525   0.232074   0.259451  0.940708  0.950917         6   300   150\n",
       "0  0.620464   0.318552   0.301912  0.941292  0.951375         6   300   200\n",
       "0  0.753881   0.390239   0.363642  0.939542  0.952208         6   300   300\n",
       "0  0.242722   0.114636   0.128086  0.942458  0.952458         9   100   150\n",
       "0  0.286849   0.132964   0.153885  0.938583  0.952833         9   100   200\n",
       "0  0.308398   0.137252   0.171146  0.942125  0.951375         9   100   300\n",
       "0  0.295579   0.143579   0.152000  0.940500  0.952625         9   200   150\n",
       "0  0.403993   0.186218   0.217774  0.939708  0.952125         9   200   200\n",
       "0  0.460705   0.210880   0.249825  0.940500  0.951958         9   200   300\n",
       "0  0.289232   0.144248   0.144984  0.939750  0.951333         9   300   150\n",
       "0  0.282457   0.146414   0.136043  0.940917  0.951333         9   300   200\n",
       "0  0.664441   0.347118   0.317323  0.942375  0.952708         9   300   300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa253a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e8265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707f7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_all = pd.read_csv(\"save/result.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c026239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opened-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loss out_1_loss out_2_loss out_1_acc out_2_acc timesteps units epoch\n",
      "3  0.448695    0.21264   0.236055  0.942375  0.954833         3   200   150\n",
      "112000 24000 24000\n",
      "train: 112000\n",
      "val: 24000\n",
      "test: 24000\n",
      "new train 112000\n"
     ]
    }
   ],
   "source": [
    "d = df_all.copy().reset_index(drop=True)\n",
    "_max =  d[[\"out_1_acc\",\"out_2_acc\"]].sum(axis=1).max()\n",
    "best_result = d[ d[[\"out_1_acc\",\"out_2_acc\"]].sum(axis=1)==_max]\n",
    "print(best_result)\n",
    "best_unit = int(best_result.iloc[0]['units'])\n",
    "best_timesteps = int(best_result.iloc[0]['timesteps'])\n",
    "best_epoch = int(best_result.iloc[0]['epoch'])\n",
    "\n",
    "X = tf.reshape(X_raw, [y.shape[0],best_timesteps,180//best_timesteps])\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(X, y)\n",
    "\n",
    "best_model = tf.keras.models.load_model(\"saved_model/lstm-rnn-unit(\"+str(best_unit)+\")-timesteps(\"+str(best_timesteps)+\")-epoch(\"+str(best_epoch)+\")\")\n",
    "#y_pred = best_model.predict(test_dataset)\n",
    "#best_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a5f3ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort([[2,1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f57a385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of freq combination (1600, 2)\n",
      "(288000,)01392\n",
      "(288000,) (1600, 2, 40)\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_dataset(repeat=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "322d9c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 60)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a42627d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(820, 2)\n",
      "100.0 0.018120527267456055701690673828\r"
     ]
    }
   ],
   "source": [
    "# 最新測試\n",
    "sampling_rate = 30\n",
    "y_true = np.argmax( y, axis=2 )\n",
    "y_true = np.unique(y_true, axis=0)\n",
    "print(y_true.shape)\n",
    "y_preds = np.zeros((y_true.shape[0], 2))\n",
    "result_matrix = np.zeros( (40,40,3) )\n",
    "\n",
    "i=0\n",
    "for f1, f2 in y_true:\n",
    "    #print(f1, f2)\n",
    "    start = time.time()\n",
    "    X_test = np_generate_signal([f1,f2],sampling_rate)\n",
    "    X_test = X_test.reshape([1,best_timesteps,180//best_timesteps])\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    y_pred = list(np.argmax(y_pred, axis = 2))\n",
    "    result_matrix[f1][f2] += [abs(f1-int(y_pred[0])), abs(f2-int(y_pred[1])), abs((f1+f2)-(int(y_pred[0])+int(y_pred[1])))]\n",
    "    y_preds[i] = y_pred\n",
    "    \n",
    "    print(100-round((y_true.shape[0]-i)/y_true.shape[0],2)*100,time.time()-start, end=\"\\r\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4c1341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fc3a7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAOJCAYAAAD1AwiSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABRHElEQVR4nO39f5yld1kf/r+uzSaRJLBBfgRckChC1ZY2MVu0VSOKCiiCtuIP+jWpUtbaj6DVFtPqA6T9QKEIlo/VyvoDsSIVQQER+RBpAgolZMUAwVAQDBBggSgSE2jCZq7PH3O232F75twzc58zc87u85nHeeyZ+577OteceefMXPN+v69T3R0AAAB2Zt9eJwAAALDKFFUAAAAjKKoAAABGUFQBAACMoKgCAAAYQVEFAAAwgqIKAAA47VTV51XVW6vq7VX1rqp6+uT451fVlVX13sm/dx+M5X2qAACA001VVZJzu/vWqjozyR8n+ZEk/yjJX3X3s6rqiiR37+6fmBXLTBUAAHDa6XW3Tj48c3LrJI9N8qLJ8Rcl+fahWIoqAADgtFRVZ1TVdUk+nuTK7r4myQXd/dEkmfx776E4+xeaZZL9Zx1cmvWFF5x7/lzifOy2v55LnHn5mnt/2Vzi/PHHb5hLnO+670PnEuelH33r6Bg/9gWXziGT5HkfeeNc4szLr97r6+cS5wc+cdVc4rzu7l89lzh3O/OO0THOvcv4GEnykA+8fS5xPvwPHzSXOAff/N65xPnLfzKf14t7vHg+rxef+rfj/x+t8+82h0ySuz3l1XOJw+J9+j2vnEucOu/z5xJnXu7yBV87lzif+cgfzSXOvPI5Fc3rOT7znl9ccwm0iz578/uX5nf7rTjrXg/8wSSHNxw60t1HTnzQ3Xcmuaiqzk/yu1X1d3byOAsvqgAAAPbCpIA6soXP++uqujrJI5N8rKru290frar7Zn0WaybL/wAAgNNOVd1rMkOVqrpLkm9M8u4kr0py+eTTLk8yOD1upgoAADgd3TfJi6rqjKxPNr20u19dVf8jyUur6glJPpjkcUOBFFUAAMDWrN251xnMTXe/I8nFU47/ZZKHbyeW5X8AAAAjKKoAAABGsPwPAADYml7b6wyW0mBRVVVfmvV3FT6Y9XcY/kiSV3X3fN6kBAAAYIXNXP5XVT+R5L8lqSRvTXLt5P5LquqKxacHAACw3IZmqp6Q5G9392c3Hqyq5yV5V5JnLSoxAACAVTBUVK0l+YIkHzjp+H0n56aqqsNJDidJnXEg+/adOyZHAABgGazZUzXNUFH1o0leX1XvTfKhybEvTPIlSX54s4u6+0iSI0my/6yDPT5NAACA5TSzqOru11bVg5M8NOuNKirJTUmu7e5T552/AAAAdmiw+193ryV5yy7kAgAALLHWUn0qb/4LAAAwgqIKAABgBEUVAADACIN7qgAAAJJoqb4JM1UAAAAjKKoAAABGqO7FvjevN/8FAObpnDPPnkucT3/29rnEgZ06fseHa69z2K47PvT2lfrd/qz7/71deY7NVAEAAIygqAIAABhB9z8AAGBr1u7c6wyWkpkqAACAERRVAAAAIyiqAAAARrCnCgAA2Jpe2+sMlpKZKgAAgBEUVQAAACPsePlfVX1/d79wnskAAABLbM3yv2nGzFQ9fW5ZAAAArKiZM1VV9Y7NTiW5YMZ1h5McTpI640D27Tt3xwkCAAAss6HlfxckeUSST550vJK8ebOLuvtIkiNJsv+sgz0mQQAAgGU2VFS9Osl53X3dySeq6upFJAQAACyn1lJ9qplFVXc/Yca5x88/HQAAgNWipToAAMAIO26pDgAAnGa0VJ/KTBUAAMAIiioAAIARLP8DAAC2Rve/qcxUAQAAjGCmCgBYKZ/+7O17nQLA5zBTBQAAMIKZKgAAYGvW7tzrDJaSmSoAAIARFFUAAAAjWP4HAABsjZbqU5mpAgAAGEFRBQAAMIKiCgAAYITBPVVV9aVJDia5prtv3XD8kd392kUmBwAALJE1e6qmmTlTVVVPTvLKJE9Kcn1VPXbD6WcuMjEAAIBVMDRT9cQkl3T3rVV1YZKXVdWF3f38JLXZRVV1OMnhJKkzDmTfvnPnlS8AAMBSGSqqzjix5K+7b6yqh2W9sHpAZhRV3X0kyZEk2X/WwZ5PqgAAwJ7SUn2qoUYVx6rqohMfTAqsRye5Z5KHLDAvAACAlTBUVF2W5NjGA919vLsvS3LpwrICAABYETOX/3X3TTPOvWn+6QAAAEtL97+pvE8VAADACIoqAACAERRVAAAAIwy1VAcAAEiSdN+51yksJTNVAAAAIyiqAAAARrD8DwBYKV984L5zifP+T310LnHgtNJaqk9jpgoAAGAERRUAAMAIlv8BAABbs2b53zRmqgAAAEZQVAEAAIygqAIAABjBnioAAGBrtFSfykwVAADACIMzVVX10CTd3ddW1ZcneWSSd3f3axaeHQAAwJKbWVRV1dOSPCrJ/qq6MslXJrk6yRVVdXF3P2PxKQIAAEth7c69zmApDc1UfWeSi5KcneRYkvt19y1V9Zwk1ySZWlRV1eEkh5OkzjiQffvOnVvCAAAAy2RoT9Xx7r6zuz+d5H3dfUuSdPdnkmy6S627j3T3oe4+pKACAABOZUNF1R1Vdc7k/iUnDlbVgcwoqgAAAE4XQ8v/Lu3u25Ok+3P6J56Z5PKFZQUAACwfLdWnmllUnSiophy/OcnNC8kIAABghXifKgAAgBEG36cKAAAgSbJm+d80ZqoAAABGUFQBAACMYPkfAACwNbr/TWWmCgAAYAQzVQDASrnb/rvsdQoAn8NMFQAAwAhmqgAAgK3RUn0qM1UAAAAjKKoAAABGsPwPAADYGsv/pjJTBQAAMIKiCgAAYIRtF1VV9euLSAQAAGAVzdxTVVWvOvlQkq+vqvOTpLsfs6C8AACAJdN9516nsJSGGlXcL8mfJfnlJJ31oupQkucuOC8AAICVMLT871CSP0nyk0k+1d1XJ/lMd7+hu9+w2UVVdbiqjlbV0bW12+aXLQAAwJKZOVPV3WtJfraqfnvy78eGrplcdyTJkSTZf9bBnkeiAADAHtNSfaotvU9Vd9+U5HFV9a1JbllsSgAAAKtjW2/+292/n+T3F5QLAADAytlWUQUAAJzG2vK/abz5LwAAwAiKKgAAgBEUVQAAACPYUwUAAGyNlupTmakCAAAYwUwVALBSzjvj7L1OAeBzKKoAAICt0VJ9Ksv/AAAARlBUAQAAjKCoAgAAGMGeKgAAYGu0VJ/KTBUAAMAIiioAAIARLP8DAAC2Rkv1qbZVVFXV1yR5aJLru/t1i0kJAABgdcxc/ldVb91w/4lJ/nOSuyZ5WlVdseDcAAAAlt7QTNWZG+4fTvJN3f2JqvqZJG9J8qyFZQYAACwX3f+mGiqq9lXV3bM+o1Xd/Ykk6e7bqur4ZhdV1eGsF2GpMw5k375z55UvAADAUhkqqg4k+ZMklaSr6j7dfayqzpscm6q7jyQ5kiT7zzrY80oWAABg2cwsqrr7wk1OrSX5jrlnAwAAsGJ21FK9uz+d5C/mnAsAALDM7Kmaypv/AgAAjKCoAgAAGGFHy/8AAIDTUFv+N42ZKgAAgBEUVQAAACMoqgAAAEawpwoAWCl//PEb9joFOH1pqT6VmSoAAIARFFUAAAAjWP4HAABsjZbqU5mpAgAAGEFRBQAAMILlfwAAwNbo/jeVmSoAAIARFFUAAAAjzCyqquorq+puk/t3qaqnV9XvVdWzq+rA7qQIAACwvIZmqn41yacn95+f5ECSZ0+OvXCBeQEAAMum11brtkuGiqp93X18cv9Qd/9od/9xdz89yRdvdlFVHa6qo1V1dG3ttrklCwAAMA9Vdf+quqqqbqiqd1XVj0yO/3RVfbiqrpvcvmUo1lBRdX1Vff/k/tur6tDkgR6c5LObXdTdR7r7UHcf2rfv3C1+WQAAALvmeJIf7+4vS/JVSf6vqvryybmf7e6LJrfXDAUaaqn+z5I8v6p+KsnNSf5HVX0oyYcm5wAAgNPFKdRSvbs/muSjk/t/U1U3JDm4k1gzi6ru/lSSf1pVd836cr/9SW7q7o/t5MEAAACWTVVdmOTiJNck+eokP1xVlyU5mvXZrE/Oun5LLdW7+2+6++3d/ScKKgAAYBVs7PUwuR2e8jnnJXl5kh/t7luS/JckD0xyUdZnsp479DhDy/8AAABWUncfSXJks/NVdWbWC6oXd/fvTK752Ibzv5Tk1UOPo6gCAAC25hTaU1VVleRXktzQ3c/bcPy+k/1WSfIdSa4fiqWoAgAATkdfneT7kryzqq6bHPu3Sb63qi5K0kluTPKDQ4EUVQAAwGmnu/84SU05NdhC/WSKKgAAYGu69zqDpbSl7n8AAABMp6gCAAAYwfI/AABga06h7n/zZKYKAABgBEUVAADACIoqAACAEeypAgAAtsaeqqnMVAEAAIygqAIAABjB8j8AAGBr2vK/aWbOVFXVk6vq/ruVDAAAwKoZWv7375NcU1V/VFX/oqrutRtJAQAArIqhour9Se6X9eLqkiR/VlWvrarLq+qum11UVYer6mhVHV1bu22O6QIAACyXoT1V3d1rSV6X5HVVdWaSRyX53iQ/k2TqzFV3H0lyJEn2n3Ww55cuAACwZ7RUn2qoqKqNH3T3Z5O8KsmrquouC8sKAABgRQwt//vuzU5092fmnAsAAMDKmTlT1d3v2a1EAACAJdd29kzjzX8BAABGUFQBAACMMNSoAgAAYJ3uf1OZqQIAABhBUQUAADCCogoAAGAEe6oAAICtsadqKjNVAAAAIyiqAAAARrD8DwAA2Jq2/G8aM1UAAAAjKKoAAABGUFQBAACMYE8VAACwJb3We53CUppZVFXVWUm+J8lHuvsPq+rxSf5hkhuSHOnuz+5CjgAAAEtraKbqhZPPOaeqLk9yXpLfSfLwJA9Ncvli0wMAAFhuQ0XVQ7r771bV/iQfTvIF3X1nVf1GkrcvPj0AAGBprGmpPs1Qo4p9kyWAd01yTpIDk+NnJzlzs4uq6nBVHa2qo2trt80nUwAAgCU0NFP1K0neneSMJD+Z5Ler6v1JvirJf9vsou4+kuRIkuw/66DdbAAAwClrZlHV3T9bVb81uf+Rqvr1JN+Y5Je6+627kSAAALAk2vK/aQZbqnf3Rzbc/+skL1tkQgAAAKvEm/8CAACMoKgCAAAYYXD5HwAAQJJkTQ+6acxUAQAAjKCoAgAAGMHyPwAAYGvWtFSfRlEFAKyUH/uCS+cS53kfeeNc4gBY/gcAADCCogoAAGAEy/8AAICtsadqKjNVAAAAIyiqAAAARrD8DwAA2Jruvc5gKZmpAgAAGEFRBQAAMMLg8r+qemCS70hy/yTHk7w3yUu6+1MLzg0AAFgmuv9NNXOmqqqenOQXk3xekr+f5C5ZL67+R1U9bNHJAQAALLuhmaonJrmou++squcleU13P6yqXpDklUkuXniGAAAAS2wre6pOFF5nJ7lrknT3B5OcudkFVXW4qo5W1dG1tdvGZwkAALCkhmaqfjnJtVX1liSXJnl2klTVvZL81WYXdfeRJEeSZP9ZB/VdBACAU8GaX+2nmVlUdffzq+oPk3xZkud197snxz+R9SILAADgtDbY/a+735XkXbuQCwAAwMoZLKoAAACSJK2l+jTe/BcAAGAERRUAAMAIiioAAIAR7KkCAAC2Rkv1qcxUAQAAjGCmCgBYKQfa34SB5aKoAgAAtqTXtFSfxp96AAAARlBUAQAAjGD5HwAAsDW6/01lpgoAAGAERRUAAMAIiioAAIAR7KkCAAC2prVUn8ZMFQAAwAiKKgAAgBFmLv+rqgNJ/k2Sb09yr8nhjyd5ZZJndfdfb3Ld4SSHk6TOOJB9+86dU7oAAMCe0VJ9qqGZqpcm+WSSh3X3Pbr7Hkm+fnLstze7qLuPdPeh7j6koAIAAE5lQ0XVhd397O4+duJAdx/r7mcn+cLFpgYAALD8hoqqD1TVU6rqghMHquqCqvqJJB9abGoAAADLb6il+ncnuSLJG6rq3pNjH0vyqiSPW2RiAADAklnTUn2amUVVd38yyU9Mbp+jqr4/yQsXlBcAAMBKGNNS/elzywIAAGBFDbVUf8dmp5JcsMk5AADgVKSl+lRDe6ouSPKIrLdQ36iSvHkhGQEAAKyQoaLq1UnO6+7rTj5RVVcvIiEAAIBVMtSo4gkzzj1+/ukAAABLq3X/m2ZopgoAYKncba32OgWAzzGm+x8AAMBpT1EFAAAwguV/AADA1mipPpWZKgAAgBEUVQAAACNY/gcAAGxJr2mpPo2ZKgAAgBEUVQAAACMoqgAAAEawpwoAANgaLdWn2vFMVVX9wYxzh6vqaFUdXVu7bacPAQAAsPRmzlRV1VdsdirJRZtd191HkhxJkv1nHVTOAgAAp6yh5X/XJnlD1ouok50/92wAAIDlZfnfVENF1Q1JfrC733vyiar60GJSAgAAWB1De6p+esbnPGm+qQAAAKyemTNV3f2yGafvPudcAACAZdZre53BUhrzPlVPn1sWAAAAK2qo+987NjuV5IL5pwMAALBahhpVXJDkEUk+edLxSvLmhWQEAACwQoaKqlcnOa+7rzv5RFVdvYiEAACAJaWl+lRDjSqeMOPc4+efDgDAbP/yY1flV+/19XudBsD/NqZRBQDArlNQActmaPkfAABAkqQt/5vKTBUAAMAIiioAAIARFFUAAAAj2FMFAABsjT1VU5mpAgAAGEFRBQAAMILlfwAAwNasre11BkvJTBUAAMAIiioAAIARZi7/q6q7Jfk3Se6X5A+6+zc3nPuF7v4Xm1x3OMnhJKkzDmTfvnPnlzEAALA3dP+bamim6oVJKsnLk3xPVb28qs6enPuqzS7q7iPdfai7DymoAACAU9lQUfXA7r6iu1/R3Y9J8rYk/72q7rELuQEAACy9oe5/Z1fVvu5eS5LufkZV3ZTkjUnOW3h2AAAAS26oqPq9JN+Q5A9PHOjuF1XVx5L83CITAwAAlow9VVPNLKq6+ymbHH9tVT1zMSkBAACsjjEt1Z8+tywAAABW1FBL9XdsdirJBfNPBwAAWFbdlv9NM7Sn6oIkj0jyyZOOV5I3LyQjAACAFTJUVL06yXndfd3JJ6rq6kUkBAAAsEqGGlU8Yca5x88/HQCA2X7gE1ftdQoAn2NopgoAAGCdlupTjen+BwAAcNpTVAEAAIxg+R8AALA1p9Dyv6q6f5JfT3KfJGtJjnT386vq85P8VpILk9yY5Lu6++Ru6J/DTBUAAHA6Op7kx7v7y5J8VZL/q6q+PMkVSV7f3Q9K8vrJxzMpqgAAgNNOd3+0u982uf83SW5IcjDJY5O8aPJpL0ry7UOxLP8DAAC2pE+h5X8bVdWFSS5Ock2SC7r7o8l64VVV9x663kwVAABwSqqqw1V1dMPt8JTPOS/Jy5P8aHffspPHMVMFAACckrr7SJIjm52vqjOzXlC9uLt/Z3L4Y1V138ks1X2TfHzoccxUAQAAp52qqiS/kuSG7n7ehlOvSnL55P7lSV45FGvmTFVV3SfJ07LeYvCpSZ6U5B9nfRPXj5xYawgAAJwGTq09VV+d5PuSvLOqrpsc+7dJnpXkpVX1hCQfTPK4oUBDy/9+LcnvJzk3yVVJXpzkW7PeEeMXJ//+HyZrFQ8nSZ1xIPv2nTuUBwAAwK7p7j9OUpucfvh2YlX35tVmVf1pd188uf/B7v7CDeeu6+6Lhh5g/1kHT6lyFgAA5uH4HR/e7Bf6pfWpyx++Ur/bH3jR63flOR6aqdq45+rXTzp3xpxzAQAAltnaXiewnIYaVbxy0mIw3f1TJw5W1Zck+Z+LTAwAAGAVzJyp6u6nbnL8z6vq9xeTEgAAwOoY01L96XPLAgAAYEUNtVR/x2anklww/3QAAIBl1adWS/W5GWpUcUGSRyT55EnHK8mbF5IRAADAChkqql6d5Lzuvu7kE1V19SISAgAAWCVDjSqeMOPc4+efDgAAsLQs/5tqaKYKAGCpvO7uXz2XON/8yTfNJQ7AmO5/AAAApz0zVQAAwNas7XUCy8lMFQAAwAiKKgAAgBEUVQAAACPYUwUAAGxJa6k+lZkqAACAERRVAAAAI1j+BwAAbI2W6lNte6aqqu69iEQAAABW0cyZqqr6/JMPJXlrVV2cpLr7rza57nCSw0lSZxzIvn3nziNXAACApTO0/O/mJB846djBJG9L0km+eNpF3X0kyZEk2X/WQS1CAACAU9ZQUfWUJN+Y5F939zuTpKr+oru/aOGZAQAAS0VL9elm7qnq7p9J8s+SPLWqnldVd836DBUAAADZQqOK7r6pux+X5KokVyY5Z+FZAQAArIgtt1Tv7t+rqj9M8sAkqarv7+4XLiwzAABguWipPtW2Wqp392e6+/rJh09fQD4AAAArZail+js2O5XkgvmnAwAAsFqGlv9dkOQRST550vFK8uaFZAQAACyltvxvqqGi6tVJzuvu604+UVVXLyIhAACAVTKzqOruJ8w49/j5pwMAALBattz9DwBgGXzzJ9+01ykAfA5FFQAAsDX2VE21rZbqAAAAfC5FFQAAwAiW/wEAAFuipfp0ZqoAAABGUFQBAACMYPkfAACwNZb/TWWmCgAAYARFFQAAwAiKKgAAgBFmFlVV9cgN9w9U1a9U1Tuq6jer6oIZ1x2uqqNVdXRt7bZ55gsAAOyRXlut224Zmql65ob7z03y0STfluTaJC/Y7KLuPtLdh7r70L59547PEgAAYEltp/vfoe6+aHL/Z6vq8gXkAwAAsFKGiqp7V9WPJakkd6uq6u6enLMfCwAATiO7uaRulQwVRr+U5K5JzkvyoiT3TJKquk+S6xaaGQAAwAqYOVPV3U/f5PixqrpqMSkBAACsjjFL+KYWXAAAAKeTmTNVVfWOzU4l2bSlOgAAcOqxp2q6oUYVFyR5RJJPnnS8krx5IRkBAACskKGi6tVJzuvu604+UVVXLyIhAACAVTLUqOIJM849fv7pAADM9s4H/L25xHnIB94+lzhwWuna6wyWkveaAgAAGEFRBQAAMMLQnioAAIAkuv9txkwVAADACIoqAACAERRVAAAAI9hTBQAAbEmvaak+jZkqAACAERRVAAAAI1j+BwAAbImW6tNte6aqqu6xiEQAAABW0cyiqqqeVVX3nNw/VFXvT3JNVX2gqr5uxnWHq+poVR1dW7ttzikDAAAsj6GZqm/t7psn95+T5Lu7+0uSfFOS5252UXcf6e5D3X1o375z55QqAADA8hnaU3VmVe3v7uNJ7tLd1yZJd7+nqs5efHoAAMCy6NZSfZqhmaqfT/KaqvqGJK+tqv9UVZdW1dOTXLfw7AAAAJbczJmq7v65qnpnkh9K8uDJ5z84ySuS/PuFZwcAALDkBluqd/fVSa4++XhVfX+SF84/JQAAYBlpqT7dmDf/ffrcsgAAAFhRM2eqquodm51KcsH80wEAAFgtQ8v/LkjyiCSfPOl4JXnzQjICAACWUq/p/jfNUFH16iTndfd1J5+oqqsXkRAAAMAqGer+94QZ5x4//3QAAGZ7yAfevtcpAHyOMY0qAAAATnuDLdUBAACSpHuvM1hOZqoAAABGUFQBAACMYPkfAACwJVqqT2emCgAAYARFFQAAwAiKKgAAgBHsqQIAALbEnqrpzFQBAACMMLOoqqq3VdVPVdUDdyshAACAVTK0/O/uSc5PclVVHUvykiS/1d0fmXVRVR1OcjhJ6owD2bfv3DmkCgAA7KXuvc5gOQ0t//tkd/+r7v7CJD+e5EFJ3lZVV00Kp6m6+0h3H+ruQwoqAADgVLblPVXd/Ufd/S+SHEzy7CT/YGFZAQAArIih5X/vOflAd9+Z5LWTGwAAcJrQ/W+6mTNV3f09m52rqu+ffzoAAACrZUxL9afPLQsAAIAVNXP5X1W9Y7NTSS6YfzoAAACrZWhP1QVJHpHkkycdryRvXkhGAADAUuq2p2qaoaLq1UnO6+7rTj5RVVcvIiEAAIBVMrOo6u4nzDj3+PmnAwAAsFqGZqoAAJbKh//hg+YS5+Cb3zuXOHA66bW9zmA5jen+BwAAcNpTVAEAAIygqAIAABjBnioAAGBL1rRUn8pMFQAAwAiKKgAAgBEs/wMAALakLf+bykwVAADACIoqAACAESz/AwAAtqTXLP+bZuZMVVUdqqqrquo3qur+VXVlVX2qqq6tqotnXHe4qo5W1dG1tdvmnzUAAMCSGFr+9wtJ/mOS30/y5iQv6O4DSa6YnJuqu49096HuPrRv37lzSxYAAGDZDBVVZ3b3H3T3S5J0d78s63den+TzFp4dAADAkhvaU/W/quqbkxxI0lX17d39iqr6uiR3Lj49AABgWXTvdQbLaaio+udZX/63luQRSX6oqn4tyYeTPHGxqQEAACy/mcv/uvvt3f2I7n5Ud7+7u3+ku8/v7r+d5G/tUo4AAABLa0xL9acneeG8EgEAAJablurTzSyqquodm51KcsH80wEAAFgtQzNVF2R9L9UnTzpeWW+xDgAAcFobKqpeneS87r7u5BNVdfUiEgIAAFglM4uq7n7CjHOPn386AADAslpre6qmGdOoAgBg1x1883v3OgWAzzGzpToAAACzmakCAAC2pC3/m8pMFQAAwAiKKgAAgBEs/wMAALake68zWE5mqgAAAEZQVAEAAIygqAIAABjBnioAAGBL1rRUn8pMFQAAwAgzi6qqOq+q/l1VvauqPlVVn6iqt1TVPx247nBVHa2qo2trt801YQAAgGUytPzvxUl+N8kjknxXknOT/LckP1VVD+7ufzvtou4+kuRIkuw/66DGiwAAcApoy/+mGlr+d2F3/1p339Tdz0vymO5+b5LvT/KPFp8eAADAchsqqm6rqq9Jkqr6tiR/lSTdvZZEmQoAAJz2hpb//fMkv1xVD05yfZIfSJKquleSn19wbgAAAEtvZlHV3e9I8tApxz9RVX+zsKwAAICl07olTDWmpfrT55YFAADAipo5U1VV79jsVJIL5p8OAADA7qiqX03y6CQf7+6/Mzn200memOQTk0/7t939mllxhvZUXZD1duqfPPnxk7x5mzkDAAArbO3Ua6n+a0n+c5JfP+n4z3b3z2w1yFBR9eok53X3dSefqKqrt/ogAAAAy6a731hVF46NM9So4gkzzj1+7IMDAGzXX/6TL5tLnHu8+Ia5xAFOST9cVZclOZrkx7v75JV7n2NMowoAAOA00l0rdauqw1V1dMPt8Ba+zP+S5IFJLkry0STPHbpgaPkfAADASuruI0mObPOaj524X1W/lPUtUTOZqQIAAJioqvtu+PA7klw/dI2ZKgAA4LRUVS9J8rAk96yqm5I8LcnDquqiJJ3kxiQ/OBRHUQUAAGzJqdZSvbu/d8rhX9luHMv/AAAARlBUAQAAjGD5HwAAsCW91wksKTNVAAAAIyiqAAAARphZVFXVgap6VlW9u6r+cnK7YXLs/F3KEQAAYGkN7al6aZL/nuRh3X0sSarqPkkuT/LbSb5p2kVVdTjJ4SSpMw5k375z55YwAACwN061lurzMrT878LufvaJgipJuvtYdz87yRdudlF3H+nuQ919SEEFAACcyoaKqg9U1VOq6oITB6rqgqr6iSQfWmxqAAAAy29o+d93J7kiyRsmhVUn+ViSVyX5rgXnBgAALJG2/G+qmUVVd3+yql6Y5Mokb+nuW0+cq6pHJnntgvMDAABYakPd/56c5JVJfjjJ9VX12A2nn7nIxAAAAFbB0PK/Jya5pLtvraoLk7ysqi7s7ucnMfcHAACnkbW9TmBJDRVVZ5xY8tfdN1bVw7JeWD0giioAAIDB7n/HquqiEx9MCqxHJ7lnkocsMC8AAICVMFRUXZbk2MYD3X28uy9LcunCsgIAAFgRQ93/bppx7k3zTwcAYLYz7n7OXqfAae6vf/iSvU5hz7QdQFMNzVQBAAAwg6IKAABghKHufwAAAEmStd7rDJaTmSoAAIARFFUAAAAjKKoAAABGsKcKAADYkjUt1acyUwUAADCCogoAAGCEHS//q6o/6O5HzTMZAABgebXlf1PNLKqq6is2O5XkorlnAwAAsGKGZqquTfKGZGpJev5mF1XV4SSHk6TOOJB9+87daX4AAABLbaiouiHJD3b3e08+UVUf2uyi7j6S5EiS7D/roPddBgCAU8DaXiewpIYaVfz0jM950nxTAQAAWD0zi6ruflmSqqqHV9V5J53+X4tLCwAAYDXMLKqq6slJXpn1Wanrq+qxG04/c5GJAQAArIKhPVVPTHJJd99aVRcmeVlVXdjdz8/05hUAAMApSkv16YaKqjO6+9Yk6e4bq+phWS+sHhBFFQAAwGCjimNVddGJDyYF1qOT3DPJQxaYFwAAwEoYmqm6LMnxjQe6+3iSy6rqBQvLCgAAWDpaqk83s6jq7ptmnHvT/NMBAABYLUMzVQAAS+X8//wne50CK+qie3zxXOLMawwef95cwrAEhvZUAQAAMIOZKgAAYEvsqZrOTBUAAMAIiioAAIARLP8DAAC2pFN7ncJSMlMFAAAwgqIKAABgBMv/AACALVmz+m8qM1UAAAAjzCyqqupuVfUfquq/VtXjTzr3C4tNDQAAYPkNzVS9MEkleXmS76mql1fV2ZNzX7XZRVV1uKqOVtXRtbXb5pQqAADA8hnaU/XA7v7Hk/uvqKqfTPLfq+oxsy7q7iNJjiTJ/rMO9vg0AQCAvbampfpUQ0XV2VW1r7vXkqS7n1FVNyV5Y5LzFp4dAADAkhta/vd7Sb5h44HuflGSH09yx6KSAgAAWBUzi6rufkqSm6rq4VV13objr03y5EUnBwAALI9esdtuGer+96Qkr0zypCTXV9VjN5x+xiITAwAAWAVDe6oOJ7mku2+tqguTvKyqLuzu5yd2qQEAAAwVVWd0961J0t03VtXDsl5YPSCKKgAAgMFGFceq6qITH0wKrEcnuWeShywwLwAAYMmsrdhttwwVVZclObbxQHcf7+7Lkly6sKwAAABWxMzlf91904xzb5p/OgAAAKtlaE8VAADsqa+595fNJc4ff/yGucQ5na2VtgrTDC3/AwAAYAZFFQAAwAiW/wEAAFvSe53AkjJTBQAAMIKiCgAAYARFFQAAwAj2VAEAAFuyttcJLCkzVQAAACMoqgAAAEaYufyvqu6T5GlZn+l7apInJfnHSW5I8iPd/dGFZwgAACyFtdrrDJbT0EzVryX5syQfSnJVks8k+dYkf5TkFze7qKoOV9XRqjq6tnbbnFIFAABYPkNF1QXd/XPd/awk53f3s7v7g939c0kesNlF3X2kuw9196F9+86da8IAAADLZKio2nj+1086d8accwEAAFg5Qy3VX1lV53X3rd39UycOVtWXJPmfi00NAABYJmuxqWqamTNV3f3UJPerqodX1Xkbjv95kl9edHIAAADLbmZRVVVPSvLKrHf9u76qHrvh9DMXmRgAAMAqGFr+dzjJJd19a1VdmORlVXVhdz8/MfcHAACnk97rBJbUUFF1RnffmiTdfWNVPSzrhdUDoqgCAAAY7P53rKouOvHBpMB6dJJ7JnnIAvMCAABYCUMzVZclOb7xQHcfT3JZVb1gYVkBAABLZ81atalmFlXdfdOMc2+afzoAAJxKzjnz7NEx/vjjN8whE1icoeV/AAAAzKCoAgAAGGFoTxUAAECSZG2vE1hSZqoAAABGUFQBAACMYPkfAACwJb3XCSwpM1UAAAAjKKoAAABGUFQBAACMsO09VVV17+7++CKSAQAAltda7XUGy2lmUVVVn3/yoSRvraqLk1R3/9XCMgMAAFgBQzNVNyf5wEnHDiZ5W9abf3zxtIuq6nCSw0lSZxzIvn3njkwTAABgOQ0VVU9J8o1J/nV3vzNJquovuvuLZl3U3UeSHEmS/Wcd1HkRAABOAWt7ncCSmtmoort/Jsk/S/LUqnpeVd012tMDAAD8b4Pd/7r7pu5+XJKrklyZ5JyFZwUAALAiBrv/VdWXZn0f1VVJ/jDJAyfHH9ndr11segAAwLKw/G+6mTNVVfXkJK9M8qQk1yf55u6+fnL6mQvODQAAYOkNzVQ9Mckl3X1rVV2Y5GVVdWF3Pz/r7dUBAABOa0NF1RndfWuSdPeNVfWwrBdWD4iiCgAAYLBRxbGquujEB5MC69FJ7pnkIQvMCwAAWDJdq3XbLUNF1WVJjm080N3Hu/uyJJcuLCsAAIAVMXP5X3ffNOPcm+afDgAAy+CCc8+fS5yP3fbXc4kDy2ywpToAAECipfpmBt/8FwAAgM0pqgAAAEZQVAEAAIxgTxUAALAl9lRNZ6YKAABgBEUVAADACJb/AQAAW9J7ncCSMlMFAAAwwsyiqqoeueH+gar6lap6R1X9ZlVdsPj0AAAAltvQTNUzN9x/bpKPJvm2JNcmecGikgIAAJbPWq3WbbdsZ0/Voe6+aHL/Z6vq8s0+saoOJzmcJHXGgezbd+7OMwQAAFhiQ0XVvavqx5JUkrtVVXX3if1pm85ydfeRJEeSZP9ZB+1nAwAATllDy/9+Kcldk5yX5EVJ7pkkVXWfJNctNDMAAIAVMHOmqrufXlVfmuRgkmu6+9bJ8WNV9Zu7kSAAALAc1vY6gSU11P3vSUlemeRJSa6vqsduOP3M6VcBAACcPob2VB1Ockl331pVFyZ5WVVd2N3Pz/o+KwAAgNPaUFF1xoYlfzdW1cOyXlg9IIoqAAA4rVj+N91Qo4pjVXXRiQ8mBdajs96w4iELzAsAAGAlDBVVlyU5tvFAdx/v7suSXLqwrAAAAFbEUPe/m2ace9P80wEAAFgtQ3uqAACWyt/83r+ZS5y7ftt/mEucZeP5YZF6rxNYUkPL/wAAAJhBUQUAADCC5X8AAMCWrHlTpanMVAEAAIygqAIAABjB8j8AAGBL1vY6gSVlpgoAAGAERRUAAMAI2y6qquoei0gEAABgFc0sqqrqWVV1z8n9Q1X1/iTXVNUHqurrdiVDAABgKfSK3XbL0EzVt3b3zZP7z0ny3d39JUm+KclzN7uoqg5X1dGqOrq2dtucUgUAAJifqvrVqvp4VV2/4djnV9WVVfXeyb93H4ozVFSdWVUnOgTepbuvTZLufk+Ssze7qLuPdPeh7j60b9+5W/hyAAAAdt2vJXnkSceuSPL67n5QktdPPp5pqKX6zyd5TVU9K8lrq+o/JfmdJA9Pct328gUAAFbZ2q4uqlu87n5jVV140uHHJnnY5P6Lklyd5CdmxZlZVHX3z1XVO5P8UJIHTz7/wUlekeT/3mbOAAAAy+6C7v5oknT3R6vq3kMXbOXNf48lOZLkmu6+9cTBqnpkktfuNFMAAIBFqqrDSQ5vOHSku4/M+3GGuv89OckrkzwpyfVV9dgNp58572QAAADmZWOvh8ltKwXVx6rqvkky+ffjQxcMzVQ9Mckl3X3rZK3hy6rqwu5+fpLaQkIAAMApYm2vE9gdr0pyeZJnTf595dAFQ0XVGSeW/HX3jVX1sKwXVg+IogoAAFhhVfWSrDeluGdV3ZTkaVkvpl5aVU9I8sEkjxuKM1RUHauqi7r7uiSZzFg9OsmvJnnIztMHAADYW939vZucevh24gwVVZclOX7SAx9PcllVvWA7DwQAAKy2U6uh+vwMtVS/aca5N80/HQAAgNWylZbqAABL467f9h/2OoWF+OsfvmQucU7V5weWmaIKAADYktOk+9+2zXyfKgAAAGZTVAEAAIygqAIAABjBnioAAGBL1mqvM1hOZqoAAABGUFQBAACMYPkfAACwJWvpvU5hKZmpAgAAGGFmUVVVb6uqn6qqB+5WQgAAAKtkaPnf3ZOcn+SqqjqW5CVJfqu7PzLroqo6nORwktQZB7Jv37lzSBUAANhLFv9NN7T875Pd/a+6+wuT/HiSByV5W1VdNSmcpuruI919qLsPKagAAIBT2Zb3VHX3H3X3v0hyMMmzk/yDhWUFAACwIoaW/73n5APdfWeS105uAAAAp7WZM1Xd/T1V9aVV9fCqOm/juap65GJTAwAAlsnait12y1D3vycleWWSJyW5vqoeu+H0MxeZGAAAwCoYWv53OMkl3X1rVV2Y5GVVdWF3Pz9JLTw7AACAJTdUVJ3R3bcmSXffWFUPy3ph9YAoqgAA4LSypqn6VEPd/45V1UUnPpgUWI9Ocs8kD1lgXgAAACthqKi6LMmxjQe6+3h3X5bk0oVlBQAAsCJmLv/r7ptmnHvT/NMBADg9nf+f/2SvUwB2aGhPFQAAQJLYUbWJoeV/AAAAzKCoAgAAGMHyPwAAYEvW9jqBJWWmCgAAYARFFQAAwAiW/wEAAFuypv/fVGaqAAAARlBUAQAAjKCoAgAAGGFmUVVVh6rqqqr6jaq6f1VdWVWfqqprq+ri3UoSAADYe71it90yNFP1C0n+Y5LfT/LmJC/o7gNJrpicm6qqDlfV0ao6urZ229ySBQAAWDZDRdWZ3f0H3f2SJN3dL8v6ndcn+bzNLuruI919qLsP7dt37hzTBQAAWC5DLdX/V1V9c5IDSbqqvr27X1FVX5fkzsWnBwAALIu1vU5gSQ0VVf8868v/1pI8IskPVdWvJflwkicuNjUAAIDlN3P5X3e/PcmPJvmZJDd194909/nd/beT3G0X8gMAAFhqQ93/npzkd5M8Kcn1VfXYDaefucjEAAAAVsHQ8r8nJjnU3bdW1YVJXlZVF3b385PUwrMDAACWRu9qo/LVMVRUndHdtyZJd99YVQ/LemH1gCiqAAAABluqH6uqi058MCmwHp3knkkessC8AAAAVsLQTNVlSY5vPNDdx5NcVlUvWFhWAADA0tFSfbqZRVV33zTj3Jvmnw4AAMBqGVr+BwAAwAxDy/8AAACSJGu6/01lpgoAAGAERRUAAMAIiioAAIAR7KkCAAC2xI6q6cxUAQAAjKCoAgAAGMHyPwAAYEu0VJ9u5kxVVZ1XVf+uqt5VVZ+qqk9U1Vuq6p/uUn4AAABLbWj534uTvD/JI5I8Pcn/k+T7knx9VT1zs4uq6nBVHa2qo2trt80tWQAAgGUzVFRd2N2/1t03dffzkjymu9+b5PuT/KPNLuruI919qLsP7dt37jzzBQAAWCpDe6puq6qv6e4/rqpvS/JXSdLda1VVi08PAABYFmt7ncCSGiqqfijJL1XVg5Ncn+QJSVJV90ry8wvODQAAYOnNLKq6++1VdXmSg0ne0t23To5/oqresxsJAgAALLOh7n9PTvK7SX44yfVV9dgNpzdtVAEAAJx6esX+2y1Dy/+emORQd99aVRcmeVlVXdjdz09iTxUAAHDaGyqqztiw5O/GqnpY1gurB0RRBQAAMNhS/VhVXXTig0mB9egk90zykAXmBQAALJm1FbvtlqGi6rIkxzYe6O7j3X1ZkksXlhUAAMCKGOr+d9OMc2+afzoAAACrZWhPFQAAM3zmI380lzh3+YKvnUuceTlVv655mNdzw6lDUQUAAGzJbrYpXyVDe6oAAACYQVEFAAAwguV/AADAluxmm/JVYqYKAABgBEUVAADACIoqAACAEeypAgAAtmSttVSfxkwVAADACDOLqqo6UFXPqqp3V9VfTm43TI6dv0s5AgAALK2hmaqXJvlkkod19z26+x5Jvn5y7Lc3u6iqDlfV0ao6urZ22/yyBQAA9kyv2G23DBVVF3b3s7v72IkD3X2su5+d5As3u6i7j3T3oe4+tG/fufPKFQAAYOkMFVUfqKqnVNUFJw5U1QVV9RNJPrTY1AAAAJbfUPe/705yRZI3TAqrTvKxJK9K8l0Lzg0AAFgia7u6qG51zCyquvuTVfXyJC/r7mur6m8neWSSG7r7r3YlQwAAgCU2s6iqqqcleVSS/VV1ZZKHJnlDkiuq6uLufsYu5AgAALC0hpb/fWeSi5KcneRYkvt19y1V9Zwk1yRRVAEAAKe1oaLqeHffmeTTVfW+7r4lSbr7M1W1tvj0AACAZdH2VE011P3vjqo6Z3L/khMHq+pAEkUVAABw2huaqbq0u29Pku7eWESdmeTyhWUFAACwIoa6/92+yfGbk9y8kIwAAIClZKnadEMzVQAAzHCXL/javU5hIU7Vr2se5vXcHL/jw3OJw94b2lMFAADADIoqAACAESz/AwAAtmRNS/WpzFQBAACMoKgCAAAYwfI/AABgS9ryv6nMVAEAAIygqAIAABjB8j8AAGBL1vY6gSW145mqqvqDeSYCAACwimbOVFXVV2x2KslFM647nORwktQZB7Jv37k7zQ8AAGCpDS3/uzbJG7JeRJ3s/M0u6u4jSY4kyf6zDmoRAgAAnLKGiqobkvxgd7/35BNV9aHFpAQAACyjbvMl0wztqfrpGZ/zpPmmAgAAsHpmFlXd/bIkB6rq7ydJVX15Vf1YVX1Ld79iNxIEAABYZkONKp6W5FFJ9lfVlUm+MsnVSa6oqou7+xmLTxEAAFgGa7H8b5qhPVXfmfUuf2cnOZbkft19S1U9J8k1SRRVAADAaW1oT9Xx7r6zuz+d5H3dfUuSdPdn4r2/AAAABouqO6rqnMn9S04crKoDUVQBAAAMLv+7tLtvT5Lu3lhEnZnk8oVlBQAALB2zKtPNLKpOFFRTjt+c5OaFZAQAALBChpb/AQAAMMPQ8j8AAIAkSWupPpWZKgAAgBEUVQAAACNY/gcAAGzJmuV/U5mpAgAAGEFRBQAAMIKiCgAAYAR7qgAAgC3ptqdqGjNVAAAAI8wsqqrqblX1H6rqv1bV40869wuLTQ0AAGD5Dc1UvTBJJXl5ku+pqpdX1dmTc1+12UVVdbiqjlbV0bW12+aUKgAAsJfWVuy2W4aKqgd29xXd/YrufkyStyX571V1j1kXdfeR7j7U3Yf27Tt3bskCAAAsm6FGFWdX1b7uXkuS7n5GVd2U5I1Jzlt4dgAAAEtuaKbq95J8w8YD3f2iJD+e5I5FJQUAALAqZhZV3f2UJLdU1d9Pkqr68qr6sST7uvtBu5EgAACwHHrF/tstM5f/VdXTkjwqyf6qujLJVya5OskVVXVxdz9j8SkCAAAsr6E9Vd+Z5KIkZyc5luR+3X1LVT0nyTVJFFUAAMBpbaioOt7ddyb5dFW9r7tvSZLu/kxV7WaXQgAAYI+t7eKSulUy1Kjijqo6Z3L/khMHq+pAdrf1OwAAwFIamqm6tLtvT5ITbdUnzkxy+cKyAgAAWBEzi6oTBdWU4zcnuXkhGQEAAEup2/K/aYaW/wEAADCDogoAAGAERRUAAMAIQ40qAAAAkpx6LdWr6sYkf5Pkzqy/ndShncRRVAEAAKezr5804tsxy/8AAABGMFMFAABsSZ9iy/+SdJLXVVUneUF3H9lJEEUVAABwSqqqw0kObzh05KTC6au7+yNVde8kV1bVu7v7jdt9HEUVAABwSpoUUJvOPnX3Ryb/fryqfjfJQ5Nsu6iauaeqqu5TVf+lqn6+qu5RVT9dVe+sqpdW1X23+2AAAADLoKrOraq7nrif5JuTXL+TWEMzVb+W5PeTnJvkqiQvTvKtSR6b5Bcn/05L8H9Ps9UZB7Jv37k7yQ0AAFgia31K7am6IMnvVlWyXhf9Zne/dieBqmc8MVX1p9198eT+B7v7Czecu667Lxp6gP1nHTylnnkAAJiH43d8uPY6h+269ODDV+p3+zd++PW78hwPtVTfeP7Xt3ktAADAKW9o+d8rq+q87r61u3/qxMGq+pIk71lsagAAwDJZqWmqXTSzqOrup1bVQ6uqu/vaqvryJI9M8u7u/s7dSREAAGB5zSyqquppSR6VZH9VXZnkK5NcneSKqrq4u5+x+BQBAACW19Dyv+9MclGSs5McS3K/7r6lqp6T5JokiioAADhNrFkAONVQs4nj3X1nd386yfu6+5Yk6e7PJFlbeHYAAABLbqiouqOqzpncv+TEwao6EEUVAADA4PK/S7v79iTp7o1F1JlJLl9YVgAAACtiqPvf7ZscvznJzQvJCAAAWEr2VE3nDXwBAABGUFQBAACMMLSnCgAAIEnSbfnfNGaqAAAARlBUAQAAjKCoAgAAGMGeKgAAYEu0VJ/OTBUAAMAIiioAAIARtr38r6ru3d0fX0QyAADA8mrL/6aaWVRV1eeffCjJW6vq4iTV3X+1sMwAAABWwNBM1c1JPnDSsYNJ3pakk3zxtIuq6nCSw0lSZxzIvn3njkwTAABgOQ0VVU9J8o1J/nV3vzNJquovuvuLZl3U3UeSHEmS/WcdNEcIAACngG6/2k8zs1FFd/9Mkn+W5KlV9byqumtiISUAAMAJg93/uvum7n5ckquSXJnknIVnBQAAsCIGu/9V1UOTdHf/XlXdmOSxVfUt3f2ahWcHAACw5Ia6/z0tyaOS7K+qK5M8NMkbklxRVRd39zN2IUcAAGAJrNkJNNXQTNV3JrkoydlJjiW5X3ffUlXPSXJNEkUVAABwWhvaU3W8u+/s7k8neV9335Ik3f2ZJGsLzw4AAGDJDc1U3VFV50yKqktOHKyqA1FUAQDAaUVL9emGiqpLu/v2JOnujUXUmUkuX1hWAAAAK2JmUXWioJpy/OYkNy8kIwAAgBUy+D5VAAAAbG7wfaoAAAASLdU3Y6YKAABgBEUVAADACJb/AQAAW9KW/01lpgoAAGAERRUAAMAIlv8BAABbstaW/01jpgoAAGAERRUAAMAIM4uqqnrkhvsHqupXquodVfWbVXXB4tMDAABYbkMzVc/ccP+5ST6a5NuSXJvkBZtdVFWHq+poVR1dW7ttfJYAAMCe6xX7b7dsp1HFoe6+aHL/Z6vq8s0+sbuPJDmSJPvPOmg3GwAAcMoaKqruXVU/lqSS3K2qqvt/t/ywHwsAADjtDRVVv5TkrpP7L0pyzySfqKr7JLlugXkBAABLRkv16WYWVd399Kp66Prdvraqvryqvi/Ju7v7st1JEQAAYHnNLKqq6mlJHpVkf1VdmeQrk1yd5Iqquri7n7H4FAEAAJbX0PK/70xyUZKzkxxLcr/uvqWqnpPkmiSKKgAA4LQ2VFQd7+47k3y6qt7X3bckSXd/pqrWFp8eAACwLHazTfkqGergd0dVnTO5f8mJg1V1IImiCgAAOO0NzVRd2t23J0l3byyizkyy6ftUAQAAnC6Guv/dvsnxm5PcvJCMAACApaSl+nTewBcAAGAERRUAAMAIQ3uqAAAAkuj+txkzVQAAACMoqgAAAEZQVAEAAIxgTxUAALAlWqpPZ6YKAABgBEUVAADACNte/ldV9+juv1xEMgAAwPLSUn26mTNVVfWsqrrn5P6hqnp/kmuq6gNV9XW7kiEAAMASG1r+963dffPk/nOSfHd3f0mSb0ry3M0uqqrDVXW0qo6urd02p1QBAACWz1BRdWZVnVgieJfuvjZJuvs9Sc7e7KLuPtLdh7r70L59584pVQAAgOUztKfq55O8pqqeleS1VfWfkvxOkocnuW6xqQEAAMuke22vU1hKM4uq7v65qnpnkh9K8uDJ5z84ySuS/N8Lzw4AAGDJbaX736eT/Ex3X1tVfzvJI5Pc1N2fXWxqAAAAy29mUVVVT0vyqCT7q+rKJA9N8oYkV1TVxd39jF3IEQAAWAJrWqpPNTRT9Z1JLsp6U4pjSe7X3bdU1XOSXJNEUQUAAJzWhrr/He/uO7v700ne1923JEl3fyaJXWoAAMBpb2im6o6qOmdSVF1y4mBVHYiiCgAATivdlv9NM1RUXdrdtydJf27/xDOTXL6wrAAAAFbEUEv12zc5fnOSmxeSEQAAwAoZ2lMFAADADFt5nyoAAAAt1TdhpgoAAGAERRUAAMAIlv8BAABboqX6dGaqAAAARlBUAQAAjKCoAgAAGMGeKgAAYEvW7KmaauZMVVW9rap+qqoeuFsJAQAArJKh5X93T3J+kquq6q1V9S+r6guGglbV4ao6WlVH19Zum0eeAAAAS6lmtUWsqrd191dM7n9tku9N8o+S3JDkJd19ZOgB9p910BwhAACc5PgdH669zmG77nP+l63U7/bH/vqGXXmOt9yoorv/qLv/RZKDSZ6d5B8sLCsAAIAVMdSo4j0nH+juO5O8dnIDAAA4rc0sqrr7e6rqoet3+9qq+vIkj0zy7u5+za5kCAAALIVZW4dOZzOLqqp6WpJHJdlfVVcm+cokVye5oqou7u5nLD5FAACA5TW0/O87k1yU5Owkx5Lcr7tvqarnJLkmiaIKAAA4rQ01qjje3Xd296eTvK+7b0mS7v5MkrWFZwcAALDkhmaq7qiqcyZF1SUnDlbVgSiqAADgtLIWe6qmGSqqLu3u25OkuzcWUWcmuXxhWQEAAKyIoe5/t29y/OYkNy8kIwAAgBUyNFMFAACQREv1zQw1qgAAAGAGRRUAAMAIiioAAIAR7KkCAAC2ZM2eqqnMVAEAAIygqAIAABjB8j8AAGBLtFSfzkwVAADACIoqAACAEWYWVVV1qKquqqrfqKr7V9WVVfWpqrq2qi7erSQBAIC9t5ZeqdtuGZqp+oUk/zHJ7yd5c5IXdPeBJFdMzk1VVYer6mhVHV1bu21uyQIAACybmrXZrKr+tLsvntz/YHd/4bRzs+w/66DdbAAAcJLjd3y49jqH7Tpw3gNX6nf7T936vl15jodmqv5XVX1zVT0uSVfVtydJVX1dkjsXnRwAAMCyG2qp/s+zvvxvLckjkvxQVb0wyUeSHF5wbgAAwBLRUn26mUVVd7+9qp6aZK27311VR5J8MMkN3f2mXckQAABgic0sqqrqaUkelWR/VV2Z5KFJ3pDkiqq6uLufsQs5AgAALK2hRhXvTHJRkrOTHEtyv+6+parukuSa7v67Qw+gUQUAAPyfVrFRxXnnfNFK/W5/66f/YikaVRzv7ju7+9NJ3tfdtyRJd38m6/usAAAATmtDRdUdVXXO5P4lJw5W1YEoqgAAAAa7/13a3bcnSXdvLKLOTHL5wrICAABYEUPd/27f5PjNSW5eSEYAAMBS6qzUlqpdM7T8DwAAgBkUVQAAACMM7akCAABIkqzNeDum05mZKgAAgBEUVQAAACNY/gcAAGxJW/43lZkqAACAERRVAAAAIyiqAAAARrCnCgAA2JKOPVXTzJypqqrzqurfVdW7qupTVfWJqnpLVf3TXcoPAABgqQ0t/3txkvcneUSSpyf5f5J8X5Kvr6pnbnZRVR2uqqNVdXRt7ba5JQsAALBsalZbxKp6e3f/vQ0fX9vdf7+q9iX5s+7+0qEH2H/WQXOEAABwkuN3fLj2OoftOuvs+63U7/Z33H7TrjzHQzNVt1XV1yRJVX1bkr9Kku5eS7JygwAAAGDehhpV/FCSX6qqBye5PskPJElV3SvJzy84NwAAgKU3c/lfklTVVyZZ6+5rq+rLkzwyybu7+zVbeQDL/wAA4P9k+d/i7dbyv5kzVVX1tCSPSrK/qq5M8pVJrk5yRVVd3N3PWHyKAADAMhiakDldDTWqeGeSi5KcneRYkvt19y1VdZck13T33x16ADNVAADwf1rFmaozV+x3+8/u0nM81KjieHff2d2fTvK+7r4lSbr7M0nWFp4dAADAglTVI6vqf1bVn1fVFTuNM9So4o6qOmdSVF2y4cEPRFEFAACnlZWaphpQVWdkvfneNyW5Kcm1VfWq7v6z7cYamqm6dFJQnWijfsKZSS7f7oMBAAAsiYcm+fPufn9335HkvyV57E4CzSyquvv2TY7f3N3v3MkDAgAALIGDST604eObJse2r7v3/JbksDiLjbNMuYjjey6O77k4vufirH4u4uxeHLdx34MkRzfcDm8497gkv7zh4+9L8nM7eZyh5X+75bA4C4+zTLmIsztxlikXcXYnzjLlIs7uxFmmXMTZnTjLlIs4uxeHHeruI919aMPtyIbTNyW5/4aP75fkIzt5nGUpqgAAAHbTtUkeVFVfVFVnJfmeJK/aSaCh7n8AAACnnO4+XlU/nOT/TXJGkl/t7nftJNayFFVHhj9FnCWIIc5qxVmmXMTZnTjLlIs4uxNnmXIRZ3fiLFMu4uxeHBaku1+T5DVj49RkUxYAAAA7YE8VAADACHteVFXVI6vqf1bVn1fVFTuM8atV9fGqun5EHvevqquq6oaqeldV/cgO43xeVb21qt4+ifP0neY0iXdGVf1pVb16RIwbq+qdVXVdVR0dEef8qnpZVb178jz9gx3E+FuTPE7cbqmqH91BnH85eX6vr6qXVNXnbTfGJM6PTGK8azt5TBtzVfX5VXVlVb138u/ddxjncZN81qrq0Ih8njP5Xr2jqn63qs7fYZx/P4lxXVW9rqq+YCdxNpz7V1XVVXXPHebz01X14Q1j6Ft2mk9VPWny+vOuqvqPO8jltzbkcWNVXbfDr+miqnrLif9Hq+qhO4zz96rqf0z+f/+9qrrbFuJMfe3bznieEWNbY3lGnG2N5RlxtjWWN4uz4fyWxvKMfLY1lmfls82xvFk+Wx7PM2JsayzPiLOtsVyb/OzdzjgeiLPdsbxZnO2O5c3ibHcsz/zdZCtjeUYu2x3Hm+ayzXG8WT7bel2eEWe7Y3mzONt+XWZF7XHf+DOSvC/JFyc5K8nbk3z5DuJcmuQrklw/Ipf7JvmKyf27JnnPDnOpJOdN7p+Z5JokXzUirx9L8ptJXj0ixo1J7jmH79eLkvyzyf2zkpw/h+//sSQP2OZ1B5P8RZK7TD5+aZJ/uoPH/ztJrk9yTtb3F/5hkgftdMwl+Y9JrpjcvyLJs3cY58uS/K0kVyc5NCKfb06yf3L/2SPyuduG+09O8os7iTM5fv+sbwb9wFbG5Cb5/HSSf7XN7/W0OF8/+Z6fPfn43jv5mjacf26Sp+4wl9cledTk/rckuXqHca5N8nWT+z+Q5N9vIc7U177tjOcZMbY1lmfE2dZYnhFnW2N5szjbHcsz8tnWWJ4RZ7tjefDn3dB4npHLtsbyjDjbGsvZ5GfvdsbxQJztjuXN4mx3LG8WZ7tjedPfTbY6lmfkst1xvFmc7Y7jwd+3hsbxQD7bHcubxdn267Lbat72eqbqoUn+vLvf3913JPlvSR673SDd/cYkfzUmke7+aHe/bXL/b5LckB28o3Kvu3Xy4ZmT2442rlXV/ZJ8a5Jf3sn18zT5y8qlSX4lSbr7ju7+65FhH57kfd39gR1cuz/JXapqf9aLop28p8CXJXlLd3+6u48neUOS79jKhZuMucdmvfDM5N9v30mc7r6hu//nVvIYiPO6ydeVJG/J+nsv7CTOLRs+PDdbGM8z/p/82SRP2UqMgTjbskmcH0ryrO6+ffI5H99pLlVVSb4ryUt2mEsnOfHXywPZwnjeJM7fSvLGyf0rk/zjLcTZ7LVvy+N5sxjbHcsz4mxrLM+Is62xPPBzYctjeY4/XzaLs92xPDOfrYznGTG2NZZnxNnWWJ7xs3dbr8ubxdnBWN4sznbH8mZxtjuWZ/1usqWxPK/fb2bE2e44npnPVl+XZ8TZ7ljeLM62X5dZTXtdVB1M8qENH9+UHfygmbequjDJxVn/K8NOrj9jMt388SRXdveO4iT5T1l/oVvb4fUndJLXVdWfVNVO34Tui5N8IskLa3054i9X1bkj8/qebOGX0JN194eT/EySDyb5aJJPdffrdvD41ye5tKruUVXnZP0vUfcfuGaWC7r7o5McP5rk3iNizdsPJPmDnV5cVc+oqg8l+SdJnrrDGI9J8uHufvtO89jghydLX351aDnPDA9O8rVVdU1VvaGq/v6IfL42yce6+707vP5Hkzxn8hz/TJJ/s8M41yd5zOT+47LN8XzSa9+OxvPY188txNnWWD45zk7H8sY4Y8bylK9rR2P5pDg7HsubPM/bGs8nxfjR7HAsnxRn22N5k5+92x7H8/oZvoU4WxrLm8XZ7lieFme7Y3nG17StcbxJnG2P44HneMvjeJM4P5ptjuVN4ox6XWZ17HVRVVOO7WhWZ16q6rwkL0/yoyf9JWjLuvvO7r4o63+BemhV/Z0d5PHoJB/v7j/ZSQ4n+eru/ookj0ryf1XVpTuIsT/rS43+S3dfnOS2rC+l2JFaf4O1xyT57R1ce/es//Xxi5J8QZJzq+r/t9043X1D1pdfXJnktVlffnp85kUrqKp+Mutf14t3GqO7f7K77z+J8cM7yOGcJD+ZHRZkJ/kvSR6Y5KKsF9XP3WGc/UnunvXlGf86yUsnf9ncie/NDv5AsMEPJfmXk+f4X2YyI7wDP5D1/8f/JOtLqe7Y6oXzeO2bR4xZcbY7lqfF2clY3hhn8vg7GstT8tnRWJ4SZ0djecb3a8vjeUqMHY3lKXG2PZbn8bN3t+JsZyxvFme7Y3lKnL+bbY7lTXLZ9jjeJM62x/HA92rL43iTONsey5vE2fHrMqtlr4uqm/K5Ffv9srNlXHNRVWdm/UX9xd39O2Pj9fryuKuTPHIHl391ksdU1Y1ZXxb5DVX1GzvM4yOTfz+e5Hezvuxyu25KctOGvwK9LOtF1k49KsnbuvtjO7j2G5P8RXd/ors/m+R3kvzDnSTR3b/S3V/R3ZdmfSnVTmcakuRjVXXfJJn8O3Ppwm6oqsuTPDrJP+nuefzB4jezs6ULD8x6Efz2yZi+X5K3VdV9thuouz82+cG1luSXsrPxnKyP6d+ZLNl4a9ZnhAebZ5ys1peg/qMkv7XDPJLk8qyP42T9Dw07+pq6+93d/c3dfUnWf5l431au2+S1b1vjeV6vn5vF2e5Y3kI+WxrLU+LsaCxPy2cnY3mTr2vbY3nG87zl8bxJjG2P5U2emx2N5cm1f53//8/eHb8uj/wZvmmcnb4uz8hnW6/LG+Kc+OPktl+XN+Yy5jX5pK9px6/JU57jHb0unxRnx6/LJz0/Ox7LrJa9LqquTfKgqvqiyczF9yR51V4kMvlryK8kuaG7nzcizr1q0s2nqu6S9QLg3duN093/prvv190XZv15+e/dve3ZmKo6t6rueuJ+1jfJbrtLYncfS/Khqvpbk0MPT/Jn242zwZi/7H8wyVdV1TmT79vDs74Of9uq6t6Tf78w6y/AY2YbXpX1F+FM/n3liFijVdUjk/xEksd096dHxHnQhg8fk52N53d29727+8LJmL4p65vTj+0gn/tu+PA7soPxPPGKJN8wifngrDdfuXkHcb4xybu7+6Yd5pGs/zHp6yb3vyE7LO43jOd9SX4qyS9u4ZrNXvu2PJ7n+Po5Nc52x/KMONsay9Pi7GQsz8hnW2N5xvP8imxjLA98v7Y0nmfE2NZYnvHcbGssz/jZu63X5Xn9DN8szg7G8mZxtjuWp8X50+2M5Rm5bHccb/YcvyLbG8ezvldbfl2eEWe7Y3mz52fbr8usqN7jThlZ38fynqxX7j+5wxgvyfqU82ez/qLwhB3E+JqsLz18R5LrJrdv2UGcv5vkTydxrs8WuoFtIebDssPuf1nfC/X2ye1dO32OJ7EuSnJ08rW9IsnddxjnnCR/meTAiFyenvUXveuT/NdMugXtIM4fZb04fHuSh48Zc0nukeT1WX/hfX2Sz99hnO+Y3L89yceS/L87jPPnWd+zeGI8b6Vr37Q4L588z+9I8ntZ3/C/7Tgnnb8xW+v+Ny2f/5rknZN8XpXkvjuMc1aS35h8bW9L8g07+ZqS/FqSfz5y7HxNkj+ZjMNrklyywzg/kvXX0/ckeVay/gbvA3GmvvZtZzzPiLGtsTwjzrbG8ow42xrLm8XZ7liekc+2xvKMONsdy5t+XdnieJ6Ry7bG8ow42xrL2eRnb7b5ujwjznbH8mZxtjuWN4uz3bE8+LtJBsbyjFy2O443i7Pdcbzp17TVcTyQz3bH8mZxtv267Laat5p8wwEAANiBvV7+BwAAsNIUVQAAACMoqgAAAEZQVAEAAIygqAIAABhBUQUAADCCogoAAGAERRUAAMAI/x/pZMwlcR6YmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,16))\n",
    "np.savetxt(\"f1_matrix.csv\", result_matrix[:,:,0], delimiter=\",\")\n",
    "sns.heatmap(result_matrix[:,:,0])\n",
    "plt.savefig(\"f1_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "cf635336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "np.savetxt(\"f2_matrix.csv\", result_matrix[:,:,1], delimiter=\",\")\n",
    "sns.heatmap(result_matrix[:,:,1])\n",
    "plt.savefig(\"f2_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6d065505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "np.savetxt(\"fCombone_matrix.csv\", result_matrix[:,:,2], delimiter=\",\")\n",
    "sns.heatmap(result_matrix[:,:,2])\n",
    "plt.savefig(\"fCombone_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dae19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fequence():\n",
    "    sampling_rate = 30\n",
    "    y_true = np.argmax( y, axis=2 )\n",
    "    y_true = np.unique(y_true, axis=0)\n",
    "    print(y_true.shape)\n",
    "    for f1, f2 in y_true:\n",
    "        #print(f1, f2)\n",
    "        s = np_generate_signal([f1,f2],sampling_rate)\n",
    "        X_test = X_test.reshape([1,best_timesteps,180//best_timesteps])\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        #y_pred = np.array([y_pred_1, y_pred_2]).sort()\n",
    "        y_pred = np.argmax(y_pred, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9485d98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.46279785e-07, 6.98145494e-14, 2.33478883e-12, 7.59068622e-20,\n",
       "         4.10294501e-16, 1.62270072e-10, 4.82517455e-12, 5.21158897e-12,\n",
       "         4.19165657e-12, 1.39542418e-16, 6.73716725e-14, 3.08990538e-14,\n",
       "         9.99931812e-01, 1.05143193e-10, 4.34227784e-12, 6.71630212e-15,\n",
       "         9.00853725e-10, 1.10208283e-13, 1.01224469e-13, 1.18029162e-13,\n",
       "         5.83057803e-21, 5.27000998e-10, 1.95810868e-10, 5.36742387e-11,\n",
       "         9.63500113e-11, 9.59014552e-13, 1.57186902e-11, 3.35900300e-14,\n",
       "         6.60254300e-05, 1.60698555e-11, 1.64591756e-06, 3.50081563e-13,\n",
       "         3.38775342e-20, 1.28500082e-08, 6.53171137e-12, 1.05062436e-13,\n",
       "         7.94309063e-11, 8.48779380e-10, 1.57507714e-15, 1.51009478e-12]],\n",
       "       dtype=float32),\n",
       " array([[5.0993550e-12, 2.4339555e-10, 1.2016673e-12, 1.5750065e-09,\n",
       "         3.4357023e-10, 1.2233755e-09, 1.1173384e-10, 3.4300292e-08,\n",
       "         3.9659378e-09, 2.3780229e-13, 1.6062122e-12, 4.0381773e-09,\n",
       "         1.6145525e-07, 8.4467748e-09, 3.2886788e-10, 1.1462050e-10,\n",
       "         3.2233450e-12, 5.7831045e-07, 6.6844359e-07, 4.1444126e-11,\n",
       "         1.3673105e-11, 5.6972547e-12, 6.5844364e-15, 1.9603458e-11,\n",
       "         4.0008143e-11, 4.3556470e-13, 1.4618734e-08, 6.2730123e-18,\n",
       "         2.4656849e-08, 1.0190937e-11, 3.7220556e-11, 5.4967125e-10,\n",
       "         3.9374939e-08, 9.9965703e-01, 2.1870251e-10, 1.9457753e-09,\n",
       "         2.5159452e-04, 1.2373350e-05, 1.5853542e-08, 7.7504956e-05]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]=34\n",
    "a = np.sort(a, axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b82182ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12],\n",
       "       [33]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.argmax(y_pred, axis = 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6eb752b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-8dacb2701557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbest_timesteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_pred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#ans[i, :] = [a1,a2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \"\"\"\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3981\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3982\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3983\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3212\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3213\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mpermutation\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;31m# than reusing the same range Tensor. (presumably because of buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       \u001b[0;31m# forwarding.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m       \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_range\u001b[0;34m(start, limit, delta, name)\u001b[0m\n\u001b[1;32m   7122\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7123\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 7124\u001b[0;31m         \"Range\", start=start, limit=limit, delta=delta, name=name)\n\u001b[0m\u001b[1;32m   7125\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7126\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1817\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-ra/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   op_desc = pywrap_tf_session.TF_NewOperation(graph._c_graph,\n\u001b[1;32m   1628\u001b[0m                                               \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                                               compat.as_str(node_def.name))\n\u001b[0m\u001b[1;32m   1630\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m     \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nX= X.numpy()\n",
    "result_matrix = np.zeros((40,40))\n",
    "ans = np.zeros([y.shape[0], 2])\n",
    "pred = np.zeros([y.shape[0], 2])\n",
    "for i in np.arange(y.shape[0]):\n",
    "    #a1, a2 = np.argmax(y[i][0]), np.argmax(y[i][1])\n",
    "    X_test = nX[ 180*i:180*(i+1) ].copy()\n",
    "    X_test = X_test.reshape([1,best_timesteps,180//best_timesteps])\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_1, y_pred_2 = y_pred[0], y_pred[1]\n",
    "    #ans[i, :] = [a1,a2]\n",
    "    #pred[i, :] = [y_pred_1,y_pred_2]\n",
    "    print(y.shape[0]-i, end=\"\\r\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5239af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5ebc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "42bffe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((3,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "192a479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:] = [1,2]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57e56835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36690a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc0154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733cf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a3111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4bdb43af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_fequence2(test_y):\n",
    "    #test_y = [5,45]\n",
    "    _test_X = np_generate_signal(test_y,30)\n",
    "    test_X = tf.reshape(_test_X, [1,3,60])\n",
    "    test_X = tf.convert_to_tensor(test_X)\n",
    "    y_pred = best_model.predict(test_X)\n",
    "    y_pred_1, y_pred_2 = np.argmax(y_pred[0]), np.argmax(y_pred[1])\n",
    "    #print(y_pred_1, y_pred_2)\n",
    "    return y_pred_1, y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ad81679",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-53dab83e919d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-53dab83e919d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [ for f1,f2 in zip(np.arange(0, 40, 5),np.arange(0, 40, 5))]\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[ for f1,f2 in zip(np.arange(0, 40, 5),np.arange(0, 40, 5))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "478f6d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (5, 5), (10, 10), (15, 15), (20, 20), (25, 25), (30, 30), (35, 35)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(np.arange(0, 40, 5),np.arange(0, 40, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c0d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "y_pred_1, y_pred_2 = test_fequence([0,0])\n",
    "print(y_pred_1, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65fb5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame([], columns=[[\"y1\", \"y2\", \"y_pred_1\", \"y_pred_2\"]])\n",
    "for y1 in np.arange(5, 40, 5):\n",
    "    for y2 in np.arange(40, 0, -5):\n",
    "        if (y2<y1):\n",
    "            continue\n",
    "        y_pred_1, y_pred_2 = test_fequence([y1,y2])\n",
    "        df = pd.DataFrame([[y1/2, y2/2, y_pred_1/2, y_pred_2/2]], columns=[[\"y1\", \"y2\", \"y_pred_1\", \"y_pred_2\"]])    \n",
    "        df_all = df_all.append(df)\n",
    "df_all.to_csv(\"save/testing-freq-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194c2256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y_pred_1</th>\n",
       "      <th>y_pred_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1    y2 y_pred_1 y_pred_2\n",
       "0   2.5  20.0      2.5     15.0\n",
       "0   2.5  17.5      2.5     17.5\n",
       "0   2.5  15.0      0.0      2.5\n",
       "0   2.5  12.5      2.5     12.5\n",
       "0   2.5  10.0      2.5     10.0\n",
       "0   2.5   7.5      2.5      7.5\n",
       "0   2.5   5.0      2.5      5.0\n",
       "0   2.5   2.5      2.5      2.5\n",
       "0   5.0  20.0     14.5     18.0\n",
       "0   5.0  17.5      5.0     17.5\n",
       "0   5.0  15.0      5.0      5.0\n",
       "0   5.0  12.5      5.0     12.5\n",
       "0   5.0  10.0      5.0     10.0\n",
       "0   5.0   7.5      5.0      7.5\n",
       "0   5.0   5.0      5.0      5.0\n",
       "0   7.5  20.0      7.5     15.0\n",
       "0   7.5  17.5      7.5     17.5\n",
       "0   7.5  15.0      0.0      7.5\n",
       "0   7.5  12.5      7.5     12.5\n",
       "0   7.5  10.0      7.5     10.0\n",
       "0   7.5   7.5      7.5      7.5\n",
       "0  10.0  20.0     10.5     18.5\n",
       "0  10.0  17.5     10.0     17.5\n",
       "0  10.0  15.0     10.0     15.0\n",
       "0  10.0  12.5     10.0     12.5\n",
       "0  10.0  10.0     10.0     10.0\n",
       "0  12.5  20.0     11.5     15.0\n",
       "0  12.5  17.5     14.0     18.0\n",
       "0  12.5  15.0      0.0     12.5\n",
       "0  12.5  12.5     12.5     12.5\n",
       "0  15.0  20.0     11.5     15.0\n",
       "0  15.0  17.5      0.0     17.5\n",
       "0  15.0  15.0     15.0     15.0\n",
       "0  17.5  20.0     11.5     17.5\n",
       "0  17.5  17.5     17.5     17.5\n",
       "0  20.0  20.0     14.5     18.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a26748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67301093",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d7efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "timely-charge",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
